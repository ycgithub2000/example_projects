{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DQN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"FwbpYJbM5jTd","colab_type":"code","colab":{}},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5X8mT3GH5jbE","colab_type":"code","colab":{}},"source":["# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k9pkegwy5jRT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwLkCC0G_5n1","colab_type":"code","outputId":"c5f69551-2480-4ec9-bdbf-ed26d6142d4d","executionInfo":{"status":"ok","timestamp":1573613756963,"user_tz":-480,"elapsed":26485,"user":{"displayName":"Yuyuan Cui","photoUrl":"","userId":"09671263114648218673"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G6Tfa95WDZz8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vSRe8b4OoPzt","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import datetime as dt\n","import timeit\n","import os.path\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U7PF-pfjLk6Z","colab_type":"code","colab":{}},"source":["IH_input_dir = '/content/drive/My Drive/DL_Project/input_df_cross_assets_v2/'\n","front_month_map = {1: '1802', 2: '1803', 3: '1804', 4: '1805', 5: '1806', 6: '1807', \n","           7: '1808', 8: '1809', 9: '1810', 10: '1811', 11: '1812', 12: '1901'}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LEmjF_hkLk2D","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZZ58KYLLkuB","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vcrw9-WCGAY-","colab_type":"code","colab":{}},"source":["class Input_Sampler:\n","  def __init__(self, x_col_names=['mid_lag_01s', 'mid_lag_05s'], \n","         ref_col_names=['mid', 'bid1', 'ask1'], \n","         sample_start_str='20180101',\n","         sample_end_str='20181031'):\n","    self.x_col_names = x_col_names  # actual predictive features (x)\n","    self.ref_col_names = ref_col_names # reference data\n","    self.x_col_len = len(self.x_col_names)\n","    self.state_len = self.x_col_len + 1 # x features, pos holding (actual state for model)\n","    # x features, pos holding, ref data, \n","    # initial time entering position, cash\n","    # input to NN (only the first self.state_len elements actually used in NN fitting)\n","    self.input_len = self.state_len + len(self.ref_col_names) + 2 \n","    self.sample_start_str = sample_start_str\n","    self.sample_end_str = sample_end_str\n","\n","    self.morning_start = dt.timedelta(hours=9, minutes=30)\n","    self.morning_end = dt.timedelta(hours=11, minutes=30)\n","    self.afternoon_start = dt.timedelta(hours=13)\n","    self.afternoon_end = dt.timedelta(hours=15)\n","\n","    self.sample_morning_start = dt.timedelta(hours=9, minutes=30)\n","    self.sample_morning_end = dt.timedelta(hours=11, minutes=15)\n","    self.sample_afternoon_start = dt.timedelta(hours=13)\n","    self.sample_afternoon_end = dt.timedelta(hours=14, minutes=45)\n","  \n","  def get_input_shape(self):\n","    return self.input_len\n","\n","  def get_state_shape(self):\n","    return self.state_len\n","  \n","  # return a (randomly sampled new) single state - numpy array (self.state_len, )\n","  def sample_state(self):\n","    file_name = 'NaN'\n","    while(not os.path.exists(IH_input_dir + file_name)):\n","      trade_date = pd.to_datetime(np.random.choice(\n","          pd.date_range(self.sample_start_str, self.sample_end_str)))\n","      file_name = 'input_' + trade_date.strftime('%Y%m%d') + '.csv.gz' \n","\n","    df = pd.read_csv(IH_input_dir + file_name)\n","\n","    # use AM is 0, otherwise use PM\n","    if np.random.randint(0, 2) == 0: # random from {0, 1}\n","      df = df[(df['datetime']>trade_date+self.sample_morning_start) &\n","           (df['datetime']<trade_date+self.sample_morning_end)]\n","    else:\n","      df = df[(df['datetime']>trade_date+self.sample_afternoon_start) &\n","           (df['datetime']<trade_date+self.sample_afternoon_end)]\n","    \n","    sample_slice = df.sample(n=1)\n","    # timestamp_item = pd.to_datetime(sample_slice['datetime'])\n","\n","    return np.array(list(sample_slice[self.x_col_names]) + # actual features\n","            [0] +  # position holding\n","            list(sample_slice[self.ref_col_names]) + # reference data\n","            [pd.NaT, 0.0]) # reference data: time entered pos, cash\n","\n","    #return np.random.normal(0, 1, self.state_len)\n","  \n","  # return next_state, immediate return, done or not, info dict\n","  def get_feedback(self, s, a):\n","    return s_, r, done\n","    return s_, r, done, {}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JgShwomXGApQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ESs642LoPxL","colab_type":"code","colab":{}},"source":["# Hyper Parameters\n","BATCH_SIZE = 32\n","LR = 0.01 # learning rate\n","EPSILON = 0.9  # greedy policy\n","GAMMA = 0.9 # reward discount\n","TARGET_REPLACE_ITER = 100   # target update frequency\n","MEMORY_CAPACITY = 2000\n","NUM_EPOCHS = 400\n","N_ACTIONS = 3 # buy/hold/sell (number of actions to choose from)\n","\n","env = Input_Sampler()\n","# (state + ref data)'s dimension:\n","# (x features, position held, ref data, time entered, cash)\n","N_STATES_REF = env.get_input_shape()\n","\n","N_STATES = env.get_state_shape()  # x features + pos held"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z3_NyzMwoPui","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vi4XjuBsoPrb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MXZqHcfYoPpB","colab_type":"code","colab":{}},"source":["# Estimates Q(s, a): input state, output Q(s, a) for each a in action space\n","class Net(nn.Module):\n","  def __init__(self, input_features_dimension=N_STATES, \n","         num_actions=N_ACTIONS, hidden_size=10):\n","    super(Net, self).__init__()\n","    self.input_features_dimension = input_features_dimension\n","    self.num_actions = num_actions\n","    self.hidden_size = hidden_size\n","\n","    self.fc1 = nn.Linear(self.input_features_dimension, self.hidden_size)\n","    self.fc1.weight.data.normal_(0, 0.1)   # initialization\n","    self.out = nn.Linear(self.hidden_size, self.num_actions)\n","    self.out.weight.data.normal_(0, 0.1)   # initialization\n","\n","  def forward(self, x):\n","    x = self.fc1(x)\n","    x = F.relu(x)\n","    actions_value = self.out(x)\n","    return actions_value"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ClY_C3T4oPmh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TO7snh4_oPii","colab_type":"code","colab":{}},"source":["class DQN(object):\n","  def __init__(self, input_features_dimension=N_STATES,\n","         input_dimension=N_STATES_REF, num_actions=N_ACTIONS, \n","         memory_size=MEMORY_CAPACITY, target_update_period=TARGET_REPLACE_ITER, \n","         batch_size=BATCH_SIZE, discount_gamma=GAMMA, hidden_size=10):\n","\n","    self.eval_net = Net(input_features_dimension, num_actions, hidden_size)\n","    self.target_net = Net(input_features_dimension, num_actions, hidden_size)\n","\n","    self.input_features_dimension = input_features_dimension\n","    self.input_dimension = input_dimension\n","    self.num_actions = num_actions\n","    self.memory_size = memory_size\n","    self.target_update_period = target_update_period\n","    self.batch_size = batch_size\n","    self.discount_gamma = discount_gamma\n","    \n","    self.learn_step_counter = 0  # for target updating\n","    self.memory_counter = 0    # for storing memory\n","    self.memory = np.zeros((self.memory_size, self.input_features_dimension * 2 + 2)) # (2000, len([s, a, r, s_next]))\n","    self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr=LR)\n","    self.loss_func = nn.MSELoss()\n","\n","  def choose_action(self, x):\n","    # unsqueeze(): Returns a new tensor with a dimension of size one inserted at the specified position\n","    # x size: (input_dimension, ) (1d)\n","    # torch.unsqueeze(torch.FloatTensor(x), 0) size: torch.Size([1, input_dimension]) (2d)\n","    # tensor([[x_1, x_2, ..., x_input_dimension]])\n","    x = Variable(torch.unsqueeze(torch.FloatTensor(x), 0)) # only one sample\n","    # input only one sample\n","    if np.random.uniform() < EPSILON:   # greedy\n","      # actions_value is: tensor([[x_1, x_2, x_3, ..., x_input_dimension]], grad_fn=<AddmmBackward>)\n","      actions_value = self.eval_net.forward(x)\n","      # torch.max(actions_value, 1) returns a 2D structure (max taken across axis=1)\n","      # 1st is array of max values (each element is max value across column for a row)\n","      # 2nd is array of indices of max value (column index of the max col value for a row)\n","      # torch.max(actions_value, 1)[1] extracts the max indices\n","      # torch.max(actions_value, 1)[1].data.numpy() transforms it into numpy array\n","      action = torch.max(actions_value, 1)[1].data.numpy()[0, 0]\n","      # action = torch.max(actions_value, 1)[1].data.numpy()\n","      # action = action[0] if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)  # return the argmax index\n","    else:   # random\n","      action = np.random.randint(0, self.num_actions)\n","    return action\n","\n","  def store_transition(self, s, a, r, s_):\n","    transition = np.hstack((s, [a, r], s_))\n","    index = self.memory_counter % self.memory_size\n","    self.memory[index, :] = transition\n","    self.memory_counter += 1\n","\n","  def learn(self):\n","    # target parameter update\n","    if self.learn_step_counter % self.target_update_period == 0:\n","        self.target_net.load_state_dict(self.eval_net.state_dict())\n","    self.learn_step_counter += 1\n","\n","    # sample batch transitions\n","    # extract data from memory\n","    # (32,) vector, choose 32 (==BATCH_SIZE) random indicies in memory\n","    # the random sample is generated from np.arange(self.memory_size)\n","    sample_index = np.random.choice(self.memory_size, self.batch_size)\n","    b_memory = self.memory[sample_index, :] # (32, self.input_features_dimension *2 +2)\n","    # torch.Size([32, self.input_features_dimension]):\n","    b_s = Variable(torch.FloatTensor(b_memory[:, :self.input_features_dimension]))\n","    # torch.Size([32, 1]):\n","    b_a = Variable(torch.LongTensor(b_memory[:, self.input_features_dimension:self.input_features_dimension+1].astype(int)))\n","    b_r = Variable(torch.FloatTensor(b_memory[:, self.input_features_dimension+1:self.input_features_dimension+2]))\n","    b_s_ = Variable(torch.FloatTensor(b_memory[:, -self.input_features_dimension:]))\n","\n","    # q_eval w.r.t the action in experience\n","    # according to action taken b_a, choose q_eval (q_eval has value for all actions)\n","    q_eval = self.eval_net(b_s).gather(1, b_a)  # shape (batch, 1)\n","    # self.eval_net(b_s) shape: torch.Size([32, self.num_actions]) (2D, one row for each batch item)\n","    # self.eval_net(b_s).gather(1, b_a)  shape: torch.Size([32, 1]) (2D, one row for each batch, 1 column in total,\n","    #    choose the value for row i as the b_a[i]-th column value of eval_net(b_s)'s ith row)\n","    #    selects the index of b_s's axis=1 based on value of b_a\n","    q_next = self.target_net(b_s_).detach()     # q_next does not pass error in opposite direction\n","    # detach from graph, don't backpropagate\n","    q_target = b_r + self.discount_gamma * q_next.max(1)[0]   # shape (batch, 1)\n","    loss = self.loss_func(q_eval, q_target)\n","\n","    # calculate, and update evel_net\n","    self.optimizer.zero_grad()\n","    loss.backward()\n","    self.optimizer.step()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ib-e22HZoPfj","colab_type":"code","colab":{}},"source":["dqn = DQN(input_features_dimension=N_STATES,\n","      input_dimension=N_STATES_REF, num_actions=N_ACTIONS, \n","      memory_size=MEMORY_CAPACITY, target_update_period=TARGET_REPLACE_ITER, \n","      batch_size=BATCH_SIZE, discount_gamma=GAMMA, hidden_size=10)\n","\n","print('\\nCollecting experience...')\n","for i_episode in range(NUM_EPOCHS):\n","  s = env.sample_state()  # single observation, e.g. array([-0.01674417,  0.03288027,  0.00696402, -0.01111758])\n","  x_input = s[:dqn.input_features_dimension]\n","  while True:\n","    a = dqn.choose_action(x_input)  # 0 ,or 1, or 2\n","    # take action\n","    # s_: next state; r: immediate reward\n","    # done: if terminal state\n","    # info {}\n","    s_, r, done, info = env.get_feedback(s, a)\n","    x_input_next = s_[:dqn.input_features_dimension]\n","\n","    dqn.store_transition(x_input, a, r, x_input_next)\n","\n","    if dqn.memory_counter > dqn.memory_size:\n","      dqn.learn()\n","\n","    if done:\n","      break\n","    s = s_"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HcoOBkZGoPbS","colab_type":"code","outputId":"8ce79538-ec59-4c82-8ec4-2a10b485dbdd","executionInfo":{"status":"ok","timestamp":1573329349414,"user_tz":-480,"elapsed":459,"user":{"displayName":"Yuyuan Cui","photoUrl":"","userId":"09671263114648218673"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["s"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.01674417,  0.03288027,  0.00696402, -0.01111758])"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"6szdvf-yoPYN","colab_type":"code","colab":{}},"source":["s = env.reset()\n","ep_r = 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5GfAlOP6oPUI","colab_type":"code","outputId":"b7627471-061f-4aaf-df9e-5f138f3019a8","executionInfo":{"status":"ok","timestamp":1573332327964,"user_tz":-480,"elapsed":450,"user":{"displayName":"Yuyuan Cui","photoUrl":"","userId":"09671263114648218673"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["env.x_threshold"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2.4"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"NNxZUGCCvR2K","colab_type":"code","outputId":"86e90cb5-aba1-43dc-8089-12d9b84ff750","executionInfo":{"status":"ok","timestamp":1573329499222,"user_tz":-480,"elapsed":454,"user":{"displayName":"Yuyuan Cui","photoUrl":"","userId":"09671263114648218673"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["x = s\n","x = torch.unsqueeze(torch.FloatTensor(x), 0)\n","x"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.0167,  0.0329,  0.0070, -0.0111]])"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"gW57nrq7vRzJ","colab_type":"code","outputId":"d45250cc-b8cc-40c4-ae6f-6629dbb43d21","executionInfo":{"status":"ok","timestamp":1573329811895,"user_tz":-480,"elapsed":339,"user":{"displayName":"Yuyuan Cui","photoUrl":"","userId":"09671263114648218673"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["action = np.random.randint(0, N_ACTIONS)\n","action = action \n","action"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"VvgwqBwSvRvr","colab_type":"code","colab":{}},"source":["s_, r, done, info = env.step(action)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YeAKX-YEvRsk","colab_type":"code","outputId":"2884d2e0-df4f-454d-b715-9fca5cef787f","executionInfo":{"status":"ok","timestamp":1573332292872,"user_tz":-480,"elapsed":669,"user":{"displayName":"Yuyuan Cui","photoUrl":"","userId":"09671263114648218673"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["info"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{}"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"R4cDW2wAvRo_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SiGc6Mf5vRf4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hhagfQr5DZwx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KEuuffy_3AMr","colab_type":"code","colab":{}},"source":["IH_dir = '/content/drive/My Drive/DL_Project/IH/'\n","IF_dir = '/content/drive/My Drive/DL_Project/IF/'\n","IC_dir = '/content/drive/My Drive/DL_Project/IC/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ULoHAzx4lTU","colab_type":"code","colab":{}},"source":["front_month_map = {1: '1802', 2: '1803', 3: '1804', 4: '1805', 5: '1806', 6: '1807', \n","           7: '1808', 8: '1809', 9: '1810', 10: '1811', 11: '1812', 12: '1901'}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ftM8_yLo3AXz","colab_type":"code","colab":{}},"source":["Morning_Start = dt.timedelta(hours=9, minutes=30)\n","Morning_End = dt.timedelta(hours=11, minutes=30)\n","Afternoon_Start = dt.timedelta(hours=13)\n","Afternoon_End = dt.timedelta(hours=15)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bab9IfNmD_KR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q_GpLJegD_Hn","colab_type":"code","colab":{}},"source":["def regularize(df, fill_last, fill_zero, reg_col = 'datetime', reg_str='0.5S'):\n","  df = df.set_index(reg_col)\n","  df = df.resample(reg_str).last()\n","  # ffill: propagate last valid observation forward to next valid\n","  df[fill_last] = df[fill_last].fillna(method='ffill')\n","  df[fill_zero] = df[fill_zero].fillna(0)\n","  return df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7SGsCMVKD_Et","colab_type":"code","colab":{}},"source":["def add_features(df):\n","  \n","  # helper start:\n","  df['mid'] = 0.5*(df['bid1'] + df['ask1'])\n","  df['wmid'] = (df['bid1']*df['askv1'] + df['ask1']*df['bidv1']) / (df['askv1'] + df['bidv1'])\n","  \n","  df['trade_dir'] = 0 # approximation\n","  df.loc[((df['mid'] > df['mid'].shift(1)) | \n","      (df['last'] >= df['ask1'].shift(1)) ) & (df['volume'] > 0), 'trade_dir'] = 1\n","  df.loc[((df['mid'] < df['mid'].shift(1)) | \n","      (df['last'] <= df['bid1'].shift(1)) ) & (df['volume'] > 0), 'trade_dir'] = -1\n","  df['signed_volume'] = df['trade_dir'] * df['volume']\n","  # df['price_volume'] = df['volume'] * df['last']\n","  # df['price_volume'] = df['price_volume'].replace(to_replace=0, method='ffill')\n","  \n","  df['bid_bsize'] = df['bid1'] * df['bidv1']\n","  df['ask_asize'] = df['ask1'] * df['askv1']\n","  \n","  df['tick_up'] = 0\n","  df.loc[df['mid'] > df['mid'].shift(1), 'tick_up'] = 1\n","  \n","  df['tick_down'] = 0\n","  df.loc[df['mid'] < df['mid'].shift(1), 'tick_down'] = 1\n","  \n","  # helper end ---------------------------------------------------------------\n","  \n","  df['wmid_mid'] = df['wmid'] - df['mid']\n","  df['wmid_last'] = df['wmid'] - df['last']\n","  \n","  df['mid_lag_1tick'] = df['mid'] - df['mid'].shift(1)\n","  df['mid_lag_01s'] = df['mid'] - df['mid'].shift(1*2)\n","  df['mid_lag_05s'] = df['mid'] - df['mid'].shift(5*2)\n","  df['mid_lag_10s'] = df['mid'] - df['mid'].shift(10*2)\n","  df['mid_lag_30s'] = df['mid'] - df['mid'].shift(30*2)\n","  df['mid_lag_01m'] = df['mid'] - df['mid'].shift(1*60*2)\n","  df['mid_lag_05m'] = df['mid'] - df['mid'].shift(5*60*2)\n","  df['mid_lag_10m'] = df['mid'] - df['mid'].shift(10*60*2)\n","  # df['mid_lag_01s_lag1'] = df['mid'].shift(1*2) - df['mid'].shift(2*1*2)\n","  \n","  df['wmid_ma_05m'] = df['wmid'] - df['wmid'].rolling(5*60*2).mean()\n","  df['wmid_max_05m'] = df['wmid'] - df['wmid'].rolling(5*60*2).max()\n","  df['wmid_min_05m'] = df['wmid'] - df['wmid'].rolling(5*60*2).min()\n","  df['wmid_ma_10m'] = df['wmid'] - df['wmid'].rolling(10*60*2).mean()\n","  df['wmid_max_10m'] = df['wmid'] - df['wmid'].rolling(10*60*2).max()\n","  df['wmid_min_10m'] = df['wmid'] - df['wmid'].rolling(10*60*2).min()\n","  \n","  df['wmid_bidask_10m'] = df['wmid'] - ((df['bid_bsize'].rolling(10*60*2).mean() * df['askv1'].rolling(10*60*2).mean() + \n","                                           df['ask_asize'].rolling(10*60*2).mean() * df['bidv1'].rolling(10*60*2).mean()) /\n","                                          (df['askv1'].rolling(10*60*2).mean() + df['bidv1'].rolling(10*60*2).mean()))\n","  df['wmid_bidask_01m'] = df['wmid'] - ((df['bid_bsize'].rolling(1*60*2).mean() * df['askv1'].rolling(1*60*2).mean() + \n","                                           df['ask_asize'].rolling(1*60*2).mean() * df['bidv1'].rolling(1*60*2).mean()) /\n","                                          (df['askv1'].rolling(1*60*2).mean() + df['bidv1'].rolling(1*60*2).mean())) \n","  \n","  df['total_volume_10s'] = df['volume'].rolling(10*2).sum()\n","  df['signed_volume_10s'] = df['signed_volume'].rolling(10*2).sum()\n","  df['signed_tick_10s'] = df['tick_up'].rolling(10*2).sum() - df['tick_down'].rolling(10*2).sum()\n","\n","  df['total_volume_01m'] = df['volume'].rolling(60*2).sum()\n","  df['signed_volume_01m'] = df['signed_volume'].rolling(60*2).sum()\n","  df['signed_tick_01m'] = df['tick_up'].rolling(60*2).sum() - df['tick_down'].rolling(60*2).sum()\n","  \n","  df['total_volume_10m'] = df['volume'].rolling(10*60*2).sum()\n","  df['signed_volume_10m'] = df['signed_volume'].rolling(10*60*2).sum()\n","  df['signed_tick_10m'] = df['tick_up'].rolling(10*60*2).sum() - df['tick_down'].rolling(10*60*2).sum()\n","  \n","  \n","  # clean up helper columns:\n","  del df['bid_bsize']\n","  del df['ask_asize']\n","  del df['signed_volume']\n","  del df['tick_up']\n","  del df['tick_down']\n","\n","  return df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZXfzqUewh9N9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rM9zQXLUh9Vz","colab_type":"code","colab":{}},"source":["def add_features_other_assets(df, ticker):\n","  \n","  # helper start:\n","  df['mid'] = 0.5*(df['bid1'] + df['ask1'])\n","  # helper end ---------------------------------------------------------------\n","  \n","  df['mid_lag_01s'] = df['mid'] - df['mid'].shift(1*2) \n","  df['mid_lag_05s'] = df['mid'] - df['mid'].shift(5*2)  \n","  df['mid_lag_30s'] = df['mid'] - df['mid'].shift(30*2)  \n","  df['mid_lag_01m'] = df['mid'] - df['mid'].shift(1*60*2)\n","  df['mid_lag_05m'] = df['mid'] - df['mid'].shift(5*60*2)\n","  df['mid_lag_10m'] = df['mid'] - df['mid'].shift(10*60*2)\n","\n","  df['total_volume_10s'] = df['volume'].rolling(10*2).sum()\n","  df['total_volume_01m'] = df['volume'].rolling(60*2).sum()\n","  df['total_volume_10m'] = df['volume'].rolling(10*60*2).sum()\n","  \n","  return df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G6YtI9LjD_B6","colab_type":"code","colab":{}},"source":["def add_y(df):\n","  df['mid_1tick'] = df['mid'].shift(-1) - df['mid']  # future - current\n","  df['mid_01s'] = df['mid'].shift(-1*2) - df['mid']\n","  df['mid_05s'] = df['mid'].shift(-5*2) - df['mid']\n","  df['mid_10s'] = df['mid'].shift(-10*2) - df['mid']\n","  df['mid_30s'] = df['mid'].shift(-30*2) - df['mid']\n","  df['mid_01m'] = df['mid'].shift(-1*60*2) - df['mid']\n","  df['mid_05m'] = df['mid'].shift(-5*60*2) - df['mid']\n","  df['mid_10m'] = df['mid'].shift(-10*60*2) - df['mid']\n","  df['mid_15m'] = df['mid'].shift(-15*60*2) - df['mid']\n","  \n","  df['wmid_1tick'] = df['wmid'].shift(-1) - df['wmid']\n","  df['wmid_01s'] = df['wmid'].shift(-1*2) - df['wmid']\n","  df['wmid_05s'] = df['wmid'].shift(-5*2) - df['wmid']\n","  df['wmid_10s'] = df['wmid'].shift(-10*2) - df['wmid']\n","  df['wmid_30s'] = df['wmid'].shift(-30*2) - df['wmid']\n","  df['wmid_01m'] = df['wmid'].shift(-1*60*2) - df['wmid']\n","  df['wmid_05m'] = df['wmid'].shift(-5*60*2) - df['wmid']\n","  df['wmid_10m'] = df['wmid'].shift(-10*60*2) - df['wmid']\n","  df['wmid_15m'] = df['wmid'].shift(-15*60*2) - df['wmid']\n","  \n","  return df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cx7oKusLEE9P","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rjx47vYSEFDH","colab_type":"code","colab":{}},"source":["def build_one_day_IH(df, other_assets, morning_session_start, morning_session_end,\n","                     afternoon_session_start, afternoon_session_end):\n","  df.rename(columns = {' instrument': 'instrument',\n","                     ' datetime': 'datetime',\n","                     ' last': 'last',\n","                     ' opi': 'opi',\n","                     ' turnover': 'turnover',\n","                     ' volume': 'volume',\n","                     ' bid1': 'bid1',\n","                     ' ask1': 'ask1',\n","                     ' bidv1': 'bidv1',\n","                     ' askv1': 'askv1'}, inplace = True)\n","  \n","  df = df[['datetime', 'last', 'opi', 'turnover', 'volume', 'bid1', 'ask1', 'bidv1', 'askv1']]\n","  fill_last_cols = ['last', 'opi', 'bid1', 'ask1', 'bidv1', 'askv1']\n","  fill_zero_cols = ['turnover', 'volume']\n","\n","  df['datetime'] = pd.to_datetime(df['datetime'])\n","\n","  df_am = df[(df['datetime'] >= morning_session_start) & \n","             (df['datetime'] <= morning_session_end)]\n","  df_pm = df[(df['datetime'] >= afternoon_session_start) & \n","             (df['datetime'] <= afternoon_session_end)]\n","  \n","  df_am = regularize(df_am, fill_last_cols, fill_zero_cols)\n","  df_pm = regularize(df_pm, fill_last_cols, fill_zero_cols)\n","  \n","  df_am = add_features(df_am)\n","  df_pm = add_features(df_pm)\n","  df_am = add_y(df_am)\n","  df_pm = add_y(df_pm)\n","  \n","  # expand columns\n","  for other_asset in other_assets:\n","    df_am = pd.merge(df_am, other_asset['am'], how='left', left_index=True, right_index=True)\n","    df_pm = pd.merge(df_pm, other_asset['pm'], how='left', left_index=True, right_index=True)\n","  \n","  # merge rows\n","  df = pd.concat([df_am, df_pm])\n","  return df\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"83nlBWkhkopj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dcS2nqpktlxD","colab_type":"code","colab":{}},"source":["def build_one_day_other_asset(df, ticker, morning_session_start, morning_session_end,\n","                                  afternoon_session_start, afternoon_session_end):\n","  df.rename(columns = {' instrument': 'instrument',\n","                     ' datetime': 'datetime',\n","                     ' last': 'last',\n","                     ' opi': 'opi',\n","                     ' turnover': 'turnover',\n","                     ' volume': 'volume',\n","                     ' bid1': 'bid1',\n","                     ' ask1': 'ask1',\n","                     ' bidv1': 'bidv1',\n","                     ' askv1': 'askv1'}, inplace = True)\n","  \n","  df = df[['datetime', 'last', 'opi', 'turnover', 'volume', 'bid1', 'ask1', 'bidv1', 'askv1']]\n","  fill_last_cols = ['last', 'opi', 'bid1', 'ask1', 'bidv1', 'askv1']\n","  fill_zero_cols = ['turnover', 'volume']\n","\n","  df['datetime'] = pd.to_datetime(df['datetime'])\n","\n","  df_am = df[(df['datetime'] >= morning_session_start) & \n","             (df['datetime'] <= morning_session_end)]\n","  df_pm = df[(df['datetime'] >= afternoon_session_start) & \n","             (df['datetime'] <= afternoon_session_end)]\n","  \n","  df_am = regularize(df_am, fill_last_cols, fill_zero_cols)\n","  df_pm = regularize(df_pm, fill_last_cols, fill_zero_cols)\n","  \n","  df_am = add_features_other_assets(df_am, ticker)\n","  df_pm = add_features_other_assets(df_pm, ticker)\n","  \n","  df_am.columns = [ticker + '_' + c for c in df_am.columns]\n","  df_pm.columns = [ticker + '_' + c for c in df_pm.columns]\n","  \n","  return {'am': df_am, 'pm': df_pm}  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OJMQW_STrK1p","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yThkLd3AAU_C","colab_type":"code","outputId":"3f81b24b-d7da-4209-9b17-81fa9e9c5549","executionInfo":{"status":"ok","timestamp":1573012180557,"user_tz":-480,"elapsed":2187594,"user":{"displayName":"Yuyuan Cui","photoUrl":"","userId":"09671263114648218673"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["start_time = timeit.default_timer()\n","\n","for trade_date in pd.date_range('20180101', '20181231'):\n","  contract = 'IH' + front_month_map[trade_date.month] + '_' + trade_date.strftime('%Y%m%d')\n","  contract_if = 'IF' + front_month_map[trade_date.month] + '_' + trade_date.strftime('%Y%m%d')\n","  contract_ic = 'IC' + front_month_map[trade_date.month] + '_' + trade_date.strftime('%Y%m%d')\n","  \n","  if not os.path.exists(IH_dir + contract + '.csv'):\n","    # print(IH_dir + contract + '.csv', ' not found')\n","    continue\n","  \n","  print('Processing', trade_date.date(), ' Contract:', contract)\n","  \n","  IH = pd.read_csv(IH_dir + contract + '.csv')\n","  IF = pd.read_csv(IF_dir + contract_if + '.csv')\n","  IC = pd.read_csv(IC_dir + contract_ic + '.csv')\n","  \n","  morning_start = trade_date + Morning_Start\n","  morning_end = trade_date + Morning_End\n","  afternoon_start = trade_date + Afternoon_Start\n","  afternoon_end = trade_date + Afternoon_End\n","  \n","   \n","  IF = build_one_day_other_asset(IF, 'IF', morning_start, morning_end,\n","                  afternoon_start, afternoon_end)\n","  IC = build_one_day_other_asset(IC, 'IC', morning_start, morning_end,\n","                   afternoon_start, afternoon_end)\n","  \n","  \n","  IH = build_one_day_IH(IH, [IF, IC], morning_start, morning_end,\n","              afternoon_start, afternoon_end)\n","  \n","  IH_dropna = IH.dropna()\n","  \n","  # IH.to_csv('/content/drive/My Drive/DL_Project/input_df_cross_assets_v2/raw_input_' + \n","  #           trade_date.strftime('%Y%m%d') + '.csv.gz', compression='gzip')\n","  IH_dropna.to_csv('/content/drive/My Drive/DL_Project/input_df_cross_assets_v2/input_' + \n","           trade_date.strftime('%Y%m%d') + '.csv.gz', compression='gzip')\n","\n","print('Time took: ', timeit.default_timer() - start_time)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Processing 2018-01-02  Contract: IH1802_20180102\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"},{"output_type":"stream","text":["Processing 2018-01-03  Contract: IH1802_20180103\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"},{"output_type":"stream","text":["Processing 2018-01-04  Contract: IH1802_20180104\n","Processing 2018-01-05  Contract: IH1802_20180105\n","Processing 2018-01-08  Contract: IH1802_20180108\n","Processing 2018-01-09  Contract: IH1802_20180109\n","Processing 2018-01-10  Contract: IH1802_20180110\n","Processing 2018-01-11  Contract: IH1802_20180111\n","Processing 2018-01-12  Contract: IH1802_20180112\n","Processing 2018-01-15  Contract: IH1802_20180115\n","Processing 2018-01-16  Contract: IH1802_20180116\n","Processing 2018-01-17  Contract: IH1802_20180117\n","Processing 2018-01-18  Contract: IH1802_20180118\n","Processing 2018-01-19  Contract: IH1802_20180119\n","Processing 2018-01-22  Contract: IH1802_20180122\n","Processing 2018-01-23  Contract: IH1802_20180123\n","Processing 2018-01-24  Contract: IH1802_20180124\n","Processing 2018-01-25  Contract: IH1802_20180125\n","Processing 2018-01-26  Contract: IH1802_20180126\n","Processing 2018-01-29  Contract: IH1802_20180129\n","Processing 2018-01-30  Contract: IH1802_20180130\n","Processing 2018-01-31  Contract: IH1802_20180131\n","Processing 2018-02-01  Contract: IH1803_20180201\n","Processing 2018-02-02  Contract: IH1803_20180202\n","Processing 2018-02-05  Contract: IH1803_20180205\n","Processing 2018-02-06  Contract: IH1803_20180206\n","Processing 2018-02-07  Contract: IH1803_20180207\n","Processing 2018-02-08  Contract: IH1803_20180208\n","Processing 2018-02-09  Contract: IH1803_20180209\n","Processing 2018-02-12  Contract: IH1803_20180212\n","Processing 2018-02-13  Contract: IH1803_20180213\n","Processing 2018-02-14  Contract: IH1803_20180214\n","Processing 2018-02-22  Contract: IH1803_20180222\n","Processing 2018-02-23  Contract: IH1803_20180223\n","Processing 2018-02-26  Contract: IH1803_20180226\n","Processing 2018-02-27  Contract: IH1803_20180227\n","Processing 2018-02-28  Contract: IH1803_20180228\n","Processing 2018-03-01  Contract: IH1804_20180301\n","Processing 2018-03-02  Contract: IH1804_20180302\n","Processing 2018-03-05  Contract: IH1804_20180305\n","Processing 2018-03-06  Contract: IH1804_20180306\n","Processing 2018-03-07  Contract: IH1804_20180307\n","Processing 2018-03-08  Contract: IH1804_20180308\n","Processing 2018-03-09  Contract: IH1804_20180309\n","Processing 2018-03-12  Contract: IH1804_20180312\n","Processing 2018-03-13  Contract: IH1804_20180313\n","Processing 2018-03-14  Contract: IH1804_20180314\n","Processing 2018-03-15  Contract: IH1804_20180315\n","Processing 2018-03-16  Contract: IH1804_20180316\n","Processing 2018-03-19  Contract: IH1804_20180319\n","Processing 2018-03-20  Contract: IH1804_20180320\n","Processing 2018-03-21  Contract: IH1804_20180321\n","Processing 2018-03-22  Contract: IH1804_20180322\n","Processing 2018-03-23  Contract: IH1804_20180323\n","Processing 2018-03-26  Contract: IH1804_20180326\n","Processing 2018-03-27  Contract: IH1804_20180327\n","Processing 2018-03-28  Contract: IH1804_20180328\n","Processing 2018-03-29  Contract: IH1804_20180329\n","Processing 2018-03-30  Contract: IH1804_20180330\n","Processing 2018-04-02  Contract: IH1805_20180402\n","Processing 2018-04-03  Contract: IH1805_20180403\n","Processing 2018-04-04  Contract: IH1805_20180404\n","Processing 2018-04-09  Contract: IH1805_20180409\n","Processing 2018-04-10  Contract: IH1805_20180410\n","Processing 2018-04-11  Contract: IH1805_20180411\n","Processing 2018-04-12  Contract: IH1805_20180412\n","Processing 2018-04-13  Contract: IH1805_20180413\n","Processing 2018-04-16  Contract: IH1805_20180416\n","Processing 2018-04-17  Contract: IH1805_20180417\n","Processing 2018-04-18  Contract: IH1805_20180418\n","Processing 2018-04-19  Contract: IH1805_20180419\n","Processing 2018-04-20  Contract: IH1805_20180420\n","Processing 2018-04-23  Contract: IH1805_20180423\n","Processing 2018-04-24  Contract: IH1805_20180424\n","Processing 2018-04-25  Contract: IH1805_20180425\n","Processing 2018-04-26  Contract: IH1805_20180426\n","Processing 2018-04-27  Contract: IH1805_20180427\n","Processing 2018-05-02  Contract: IH1806_20180502\n","Processing 2018-05-03  Contract: IH1806_20180503\n","Processing 2018-05-04  Contract: IH1806_20180504\n","Processing 2018-05-07  Contract: IH1806_20180507\n","Processing 2018-05-08  Contract: IH1806_20180508\n","Processing 2018-05-09  Contract: IH1806_20180509\n","Processing 2018-05-10  Contract: IH1806_20180510\n","Processing 2018-05-11  Contract: IH1806_20180511\n","Processing 2018-05-14  Contract: IH1806_20180514\n","Processing 2018-05-15  Contract: IH1806_20180515\n","Processing 2018-05-16  Contract: IH1806_20180516\n","Processing 2018-05-17  Contract: IH1806_20180517\n","Processing 2018-05-18  Contract: IH1806_20180518\n","Processing 2018-05-21  Contract: IH1806_20180521\n","Processing 2018-05-22  Contract: IH1806_20180522\n","Processing 2018-05-23  Contract: IH1806_20180523\n","Processing 2018-05-24  Contract: IH1806_20180524\n","Processing 2018-05-25  Contract: IH1806_20180525\n","Processing 2018-05-28  Contract: IH1806_20180528\n","Processing 2018-05-29  Contract: IH1806_20180529\n","Processing 2018-05-30  Contract: IH1806_20180530\n","Processing 2018-05-31  Contract: IH1806_20180531\n","Processing 2018-06-01  Contract: IH1807_20180601\n","Processing 2018-06-04  Contract: IH1807_20180604\n","Processing 2018-06-05  Contract: IH1807_20180605\n","Processing 2018-06-06  Contract: IH1807_20180606\n","Processing 2018-06-07  Contract: IH1807_20180607\n","Processing 2018-06-08  Contract: IH1807_20180608\n","Processing 2018-06-11  Contract: IH1807_20180611\n","Processing 2018-06-12  Contract: IH1807_20180612\n","Processing 2018-06-13  Contract: IH1807_20180613\n","Processing 2018-06-14  Contract: IH1807_20180614\n","Processing 2018-06-15  Contract: IH1807_20180615\n","Processing 2018-06-19  Contract: IH1807_20180619\n","Processing 2018-06-20  Contract: IH1807_20180620\n","Processing 2018-06-21  Contract: IH1807_20180621\n","Processing 2018-06-22  Contract: IH1807_20180622\n","Processing 2018-06-25  Contract: IH1807_20180625\n","Processing 2018-06-26  Contract: IH1807_20180626\n","Processing 2018-06-27  Contract: IH1807_20180627\n","Processing 2018-06-28  Contract: IH1807_20180628\n","Processing 2018-06-29  Contract: IH1807_20180629\n","Processing 2018-07-02  Contract: IH1808_20180702\n","Processing 2018-07-03  Contract: IH1808_20180703\n","Processing 2018-07-04  Contract: IH1808_20180704\n","Processing 2018-07-05  Contract: IH1808_20180705\n","Processing 2018-07-06  Contract: IH1808_20180706\n","Processing 2018-07-09  Contract: IH1808_20180709\n","Processing 2018-07-10  Contract: IH1808_20180710\n","Processing 2018-07-11  Contract: IH1808_20180711\n","Processing 2018-07-12  Contract: IH1808_20180712\n","Processing 2018-07-13  Contract: IH1808_20180713\n","Processing 2018-07-16  Contract: IH1808_20180716\n","Processing 2018-07-17  Contract: IH1808_20180717\n","Processing 2018-07-18  Contract: IH1808_20180718\n","Processing 2018-07-19  Contract: IH1808_20180719\n","Processing 2018-07-20  Contract: IH1808_20180720\n","Processing 2018-07-23  Contract: IH1808_20180723\n","Processing 2018-07-24  Contract: IH1808_20180724\n","Processing 2018-07-25  Contract: IH1808_20180725\n","Processing 2018-07-26  Contract: IH1808_20180726\n","Processing 2018-07-27  Contract: IH1808_20180727\n","Processing 2018-07-30  Contract: IH1808_20180730\n","Processing 2018-07-31  Contract: IH1808_20180731\n","Processing 2018-08-01  Contract: IH1809_20180801\n","Processing 2018-08-02  Contract: IH1809_20180802\n","Processing 2018-08-03  Contract: IH1809_20180803\n","Processing 2018-08-06  Contract: IH1809_20180806\n","Processing 2018-08-07  Contract: IH1809_20180807\n","Processing 2018-08-08  Contract: IH1809_20180808\n","Processing 2018-08-09  Contract: IH1809_20180809\n","Processing 2018-08-10  Contract: IH1809_20180810\n","Processing 2018-08-13  Contract: IH1809_20180813\n","Processing 2018-08-14  Contract: IH1809_20180814\n","Processing 2018-08-15  Contract: IH1809_20180815\n","Processing 2018-08-16  Contract: IH1809_20180816\n","Processing 2018-08-17  Contract: IH1809_20180817\n","Processing 2018-08-20  Contract: IH1809_20180820\n","Processing 2018-08-21  Contract: IH1809_20180821\n","Processing 2018-08-22  Contract: IH1809_20180822\n","Processing 2018-08-23  Contract: IH1809_20180823\n","Processing 2018-08-24  Contract: IH1809_20180824\n","Processing 2018-08-27  Contract: IH1809_20180827\n","Processing 2018-08-28  Contract: IH1809_20180828\n","Processing 2018-08-29  Contract: IH1809_20180829\n","Processing 2018-08-30  Contract: IH1809_20180830\n","Processing 2018-08-31  Contract: IH1809_20180831\n","Processing 2018-09-03  Contract: IH1810_20180903\n","Processing 2018-09-04  Contract: IH1810_20180904\n","Processing 2018-09-05  Contract: IH1810_20180905\n","Processing 2018-09-06  Contract: IH1810_20180906\n","Processing 2018-09-07  Contract: IH1810_20180907\n","Processing 2018-09-10  Contract: IH1810_20180910\n","Processing 2018-09-11  Contract: IH1810_20180911\n","Processing 2018-09-12  Contract: IH1810_20180912\n","Processing 2018-09-13  Contract: IH1810_20180913\n","Processing 2018-09-14  Contract: IH1810_20180914\n","Processing 2018-09-17  Contract: IH1810_20180917\n","Processing 2018-09-18  Contract: IH1810_20180918\n","Processing 2018-09-19  Contract: IH1810_20180919\n","Processing 2018-09-20  Contract: IH1810_20180920\n","Processing 2018-09-21  Contract: IH1810_20180921\n","Processing 2018-09-25  Contract: IH1810_20180925\n","Processing 2018-09-26  Contract: IH1810_20180926\n","Processing 2018-09-27  Contract: IH1810_20180927\n","Processing 2018-09-28  Contract: IH1810_20180928\n","Processing 2018-10-08  Contract: IH1811_20181008\n","Processing 2018-10-09  Contract: IH1811_20181009\n","Processing 2018-10-10  Contract: IH1811_20181010\n","Processing 2018-10-11  Contract: IH1811_20181011\n","Processing 2018-10-12  Contract: IH1811_20181012\n","Processing 2018-10-15  Contract: IH1811_20181015\n","Processing 2018-10-16  Contract: IH1811_20181016\n","Processing 2018-10-17  Contract: IH1811_20181017\n","Processing 2018-10-18  Contract: IH1811_20181018\n","Processing 2018-10-19  Contract: IH1811_20181019\n","Processing 2018-10-22  Contract: IH1811_20181022\n","Processing 2018-10-23  Contract: IH1811_20181023\n","Processing 2018-10-24  Contract: IH1811_20181024\n","Processing 2018-10-25  Contract: IH1811_20181025\n","Processing 2018-10-26  Contract: IH1811_20181026\n","Processing 2018-10-29  Contract: IH1811_20181029\n","Processing 2018-10-30  Contract: IH1811_20181030\n","Processing 2018-10-31  Contract: IH1811_20181031\n","Processing 2018-11-01  Contract: IH1812_20181101\n","Processing 2018-11-02  Contract: IH1812_20181102\n","Processing 2018-11-05  Contract: IH1812_20181105\n","Processing 2018-11-06  Contract: IH1812_20181106\n","Processing 2018-11-07  Contract: IH1812_20181107\n","Processing 2018-11-08  Contract: IH1812_20181108\n","Processing 2018-11-09  Contract: IH1812_20181109\n","Processing 2018-11-12  Contract: IH1812_20181112\n","Processing 2018-11-13  Contract: IH1812_20181113\n","Processing 2018-11-14  Contract: IH1812_20181114\n","Processing 2018-11-15  Contract: IH1812_20181115\n","Processing 2018-11-16  Contract: IH1812_20181116\n","Processing 2018-11-19  Contract: IH1812_20181119\n","Processing 2018-11-20  Contract: IH1812_20181120\n","Processing 2018-11-21  Contract: IH1812_20181121\n","Processing 2018-11-22  Contract: IH1812_20181122\n","Processing 2018-11-23  Contract: IH1812_20181123\n","Processing 2018-11-26  Contract: IH1812_20181126\n","Processing 2018-11-27  Contract: IH1812_20181127\n","Processing 2018-11-28  Contract: IH1812_20181128\n","Processing 2018-11-29  Contract: IH1812_20181129\n","Processing 2018-11-30  Contract: IH1812_20181130\n","Processing 2018-12-03  Contract: IH1901_20181203\n","Processing 2018-12-04  Contract: IH1901_20181204\n","Processing 2018-12-05  Contract: IH1901_20181205\n","Processing 2018-12-06  Contract: IH1901_20181206\n","Processing 2018-12-07  Contract: IH1901_20181207\n","Processing 2018-12-10  Contract: IH1901_20181210\n","Processing 2018-12-11  Contract: IH1901_20181211\n","Processing 2018-12-12  Contract: IH1901_20181212\n","Processing 2018-12-13  Contract: IH1901_20181213\n","Processing 2018-12-14  Contract: IH1901_20181214\n","Processing 2018-12-17  Contract: IH1901_20181217\n","Processing 2018-12-18  Contract: IH1901_20181218\n","Processing 2018-12-19  Contract: IH1901_20181219\n","Processing 2018-12-20  Contract: IH1901_20181220\n","Processing 2018-12-21  Contract: IH1901_20181221\n","Processing 2018-12-24  Contract: IH1901_20181224\n","Processing 2018-12-25  Contract: IH1901_20181225\n","Processing 2018-12-26  Contract: IH1901_20181226\n","Processing 2018-12-27  Contract: IH1901_20181227\n","Processing 2018-12-28  Contract: IH1901_20181228\n","Time took:  2187.2369514679995\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qydc2Jk7JuQg","colab_type":"code","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tudSEGexJuM0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cJ4nF-obDZoP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}