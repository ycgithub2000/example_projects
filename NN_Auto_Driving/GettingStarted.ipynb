{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22230,
     "status": "ok",
     "timestamp": 1569876981037,
     "user": {
      "displayName": "Xiren Zhou",
      "photoUrl": "",
      "userId": "01353105023980702896"
     },
     "user_tz": 240
    },
    "id": "u7pAF10oO3ef",
    "outputId": "089b989c-4588-489d-bcc1-2f422cef85da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0unEf_juA6p"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.chdir(\"drive/My Drive/Learning-to-Drive_Competition/starter_kit/\")\n",
    "os.chdir(\"/home/ziyan/Desktop/Competition/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 102216,
     "status": "ok",
     "timestamp": 1569877089762,
     "user": {
      "displayName": "Xiren Zhou",
      "photoUrl": "",
      "userId": "01353105023980702896"
     },
     "user_tz": 240
    },
    "id": "k6lhbnWuc6I1",
    "outputId": "d2f66b95-7978-4a46-976d-8d13ebcee972"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: attrs==19.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (19.1.0)\n",
      "Requirement already satisfied: backcall==0.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.1.0)\n",
      "Requirement already satisfied: bleach==3.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (3.1.0)\n",
      "Collecting certifi==2019.6.16 (from -r requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/1b/b853c7a9d4f6a6d00749e94eb6f3a041e342a885b87340b79c1ef73e3a78/certifi-2019.6.16-py2.py3-none-any.whl (157kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 6.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: decorator==4.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (4.4.0)\n",
      "Requirement already satisfied: defusedxml==0.6.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.6.0)\n",
      "Requirement already satisfied: entrypoints==0.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (0.3)\n",
      "Collecting ipykernel==5.1.1 (from -r requirements.txt (line 8))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/35/dd97fbb48d4e6b5ae97307497e31e46691adc2feedb6279d29fc1c8ad9c1/ipykernel-5.1.1-py3-none-any.whl (114kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 45.3MB/s \n",
      "\u001b[?25hCollecting ipython==7.6.1 (from -r requirements.txt (line 9))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/2c/c7d44277b599df35af734d8f4142d501192fdb7aef5d04daf882d7eccfbc/ipython-7.6.1-py3-none-any.whl (774kB)\n",
      "\u001b[K     |████████████████████████████████| 778kB 21.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.2.0)\n",
      "Collecting ipywidgets==7.5.0 (from -r requirements.txt (line 11))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/c2/20a3514f87fc063b4853673966e85c091843de659374d6e1dd046319815a/ipywidgets-7.5.0-py2.py3-none-any.whl (121kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 51.0MB/s \n",
      "\u001b[?25hCollecting jedi==0.14.1 (from -r requirements.txt (line 12))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/06/e906725a5b3ad7996bbdbfe9958aab75db64ef84bbaabefe47574de58865/jedi-0.14.1-py2.py3-none-any.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 19.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: Jinja2==2.10.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 13)) (2.10.1)\n",
      "Collecting jsonschema==3.0.1 (from -r requirements.txt (line 14))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/69/df679dfbdd051568b53c38ec8152a3ab6bc533434fc7ed11ab034bf5e82f/jsonschema-3.0.1-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 25.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 15)) (1.0.0)\n",
      "Collecting jupyter-client==5.3.1 (from -r requirements.txt (line 16))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/4c/bf613864ae0644e2ac7d4a40bd209c40c8c71e3dc88d5f1d0aa92a68e716/jupyter_client-5.3.1-py2.py3-none-any.whl (91kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 27.0MB/s \n",
      "\u001b[?25hCollecting jupyter-console==6.0.0 (from -r requirements.txt (line 17))\n",
      "  Downloading https://files.pythonhosted.org/packages/cb/ee/6374ae8c21b7d0847f9c3722dcdfac986b8e54fa9ad9ea66e1eb6320d2b8/jupyter_console-6.0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: jupyter-core==4.5.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 18)) (4.5.0)\n",
      "Requirement already satisfied: MarkupSafe==1.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 19)) (1.1.1)\n",
      "Requirement already satisfied: mistune==0.8.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 20)) (0.8.4)\n",
      "Collecting nbconvert==5.5.0 (from -r requirements.txt (line 21))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/e7/f46c9d65f149271e47fca6ab084ef5c6e4cb1870f4c5cce6690feac55231/nbconvert-5.5.0-py2.py3-none-any.whl (447kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 49.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: nbformat==4.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 22)) (4.4.0)\n",
      "Collecting notebook==6.0.0 (from -r requirements.txt (line 23))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/b6/a6189ca7146482d93c912dbe6c65db0f264c1c88f707feea3683caa6c1f8/notebook-6.0.0-py3-none-any.whl (9.0MB)\n",
      "\u001b[K     |████████████████████████████████| 9.0MB 38.3MB/s \n",
      "\u001b[?25hCollecting numpy==1.16.4 (from -r requirements.txt (line 24))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3MB 28.9MB/s \n",
      "\u001b[?25hCollecting pandas==0.25.0 (from -r requirements.txt (line 25))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/9a/7eb9952f4b4d73fbd75ad1d5d6112f407e695957444cb695cbb3cdab918a/pandas-0.25.0-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)\n",
      "\u001b[K     |████████████████████████████████| 10.5MB 42.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandocfilters==1.4.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 26)) (1.4.2)\n",
      "Requirement already satisfied: parso==0.5.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 27)) (0.5.1)\n",
      "Requirement already satisfied: pexpect==4.7.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 28)) (4.7.0)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 29)) (0.7.5)\n",
      "Collecting Pillow==6.1.0 (from -r requirements.txt (line 30))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/41/db6dec65ddbc176a59b89485e8cc136a433ed9c6397b6bfe2cd38412051e/Pillow-6.1.0-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 35.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: prometheus-client==0.7.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 31)) (0.7.1)\n",
      "Collecting prompt-toolkit==2.0.9 (from -r requirements.txt (line 32))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a7/9b1dd14ef45345f186ef69d175bdd2491c40ab1dfa4b2b3e4352df719ed7/prompt_toolkit-2.0.9-py3-none-any.whl (337kB)\n",
      "\u001b[K     |████████████████████████████████| 337kB 45.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: ptyprocess==0.6.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 33)) (0.6.0)\n",
      "Collecting Pygments==2.4.2 (from -r requirements.txt (line 34))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/73/1dfa428150e3ccb0fa3e68db406e5be48698f2a979ccbcec795f28f44048/Pygments-2.4.2-py2.py3-none-any.whl (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 47.3MB/s \n",
      "\u001b[?25hCollecting pyrsistent==0.15.3 (from -r requirements.txt (line 35))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/ef/7781092174a42d0b57fb02a2eb23f78ebc8e588c9bd7455e1d1c7b1ea516/pyrsistent-0.15.3.tar.gz (106kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 45.4MB/s \n",
      "\u001b[?25hCollecting python-dateutil==2.8.0 (from -r requirements.txt (line 36))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 38.7MB/s \n",
      "\u001b[?25hCollecting pytz==2019.1 (from -r requirements.txt (line 37))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 48.3MB/s \n",
      "\u001b[?25hCollecting pyzmq==18.0.2 (from -r requirements.txt (line 38))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/92/ea8f20560d5f1d0c6eb3c7c67ca72abfb97307f4e6494fc05cc7c37904cf/pyzmq-18.0.2-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 42.0MB/s \n",
      "\u001b[?25hCollecting qtconsole==4.5.2 (from -r requirements.txt (line 39))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/42/2999d79d012923a5b1503b981c55cb2a0105e25c8b86d23c1d2d1ba6310c/qtconsole-4.5.2-py2.py3-none-any.whl (119kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 44.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: Send2Trash==1.5.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 40)) (1.5.0)\n",
      "Requirement already satisfied: six==1.12.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 41)) (1.12.0)\n",
      "Requirement already satisfied: terminado==0.8.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 42)) (0.8.2)\n",
      "Requirement already satisfied: testpath==0.4.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 43)) (0.4.2)\n",
      "Collecting torch==1.1.0 (from -r requirements.txt (line 44))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/60/f685fb2cfb3088736bafbc9bdbb455327bdc8906b606da9c9a81bae1c81e/torch-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (676.9MB)\n",
      "\u001b[K     |████████████████████████████████| 676.9MB 38kB/s \n",
      "\u001b[?25hCollecting torchvision==0.3.0 (from -r requirements.txt (line 45))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/45/0f2f3062c92d9cf1d5d7eabd3cae88cea9affbd2b17fb1c043627838cb0a/torchvision-0.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.6MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6MB 30.8MB/s \n",
      "\u001b[?25hCollecting tornado==6.0.3 (from -r requirements.txt (line 46))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/78/2d2823598496127b21423baffaa186b668f73cd91887fcef78b6eade136b/tornado-6.0.3.tar.gz (482kB)\n",
      "\u001b[K     |████████████████████████████████| 491kB 49.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: traitlets==4.3.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 47)) (4.3.2)\n",
      "Requirement already satisfied: wcwidth==0.1.7 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 48)) (0.1.7)\n",
      "Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 49)) (0.5.1)\n",
      "Collecting widgetsnbextension==3.5.0 (from -r requirements.txt (line 50))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/2b/32408aa2aaf5230450903b148dae888734add9e2fc190a817811546d2f93/widgetsnbextension-3.5.0-py2.py3-none-any.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2MB 39.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->-r requirements.txt (line 9)) (41.2.0)\n",
      "Building wheels for collected packages: pyrsistent, tornado\n",
      "  Building wheel for pyrsistent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyrsistent: filename=pyrsistent-0.15.3-cp36-cp36m-linux_x86_64.whl size=97521 sha256=d60de80eea0b7737de7c0405fc794e675cf21a0a64c92f5bf1ac4c1e4e816372\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/ec/e2/3b9045d997adb0376026267ebbb641bed0f9126eb2bc615330\n",
      "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for tornado: filename=tornado-6.0.3-cp36-cp36m-linux_x86_64.whl size=423199 sha256=6d57aaec4f1ba77677497850b5882b45adddff57802bb2ead6c67a9483be6aba\n",
      "  Stored in directory: /root/.cache/pip/wheels/84/bf/40/2f6ef700f48401ca40e5e3dd7d0e3c0a90e064897b7fe5fc08\n",
      "Successfully built pyrsistent tornado\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.6.0, but you'll have ipykernel 5.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.6.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement notebook~=5.2.0, but you'll have notebook 6.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=0.24.0, but you'll have pandas 0.25.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=4.5.0, but you'll have tornado 6.0.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: certifi, tornado, pyzmq, python-dateutil, jupyter-client, jedi, prompt-toolkit, Pygments, ipython, ipykernel, nbconvert, notebook, widgetsnbextension, ipywidgets, pyrsistent, jsonschema, jupyter-console, numpy, pytz, pandas, Pillow, qtconsole, torch, torchvision\n",
      "  Found existing installation: certifi 2019.9.11\n",
      "    Uninstalling certifi-2019.9.11:\n",
      "      Successfully uninstalled certifi-2019.9.11\n",
      "  Found existing installation: tornado 4.5.3\n",
      "    Uninstalling tornado-4.5.3:\n",
      "      Successfully uninstalled tornado-4.5.3\n",
      "  Found existing installation: pyzmq 17.0.0\n",
      "    Uninstalling pyzmq-17.0.0:\n",
      "      Successfully uninstalled pyzmq-17.0.0\n",
      "  Found existing installation: python-dateutil 2.5.3\n",
      "    Uninstalling python-dateutil-2.5.3:\n",
      "      Successfully uninstalled python-dateutil-2.5.3\n",
      "  Found existing installation: jupyter-client 5.3.3\n",
      "    Uninstalling jupyter-client-5.3.3:\n",
      "      Successfully uninstalled jupyter-client-5.3.3\n",
      "  Found existing installation: jedi 0.15.1\n",
      "    Uninstalling jedi-0.15.1:\n",
      "      Successfully uninstalled jedi-0.15.1\n",
      "  Found existing installation: prompt-toolkit 1.0.16\n",
      "    Uninstalling prompt-toolkit-1.0.16:\n",
      "      Successfully uninstalled prompt-toolkit-1.0.16\n",
      "  Found existing installation: Pygments 2.1.3\n",
      "    Uninstalling Pygments-2.1.3:\n",
      "      Successfully uninstalled Pygments-2.1.3\n",
      "  Found existing installation: ipython 5.5.0\n",
      "    Uninstalling ipython-5.5.0:\n",
      "      Successfully uninstalled ipython-5.5.0\n",
      "  Found existing installation: ipykernel 4.6.1\n",
      "    Uninstalling ipykernel-4.6.1:\n",
      "      Successfully uninstalled ipykernel-4.6.1\n",
      "  Found existing installation: nbconvert 5.6.0\n",
      "    Uninstalling nbconvert-5.6.0:\n",
      "      Successfully uninstalled nbconvert-5.6.0\n",
      "  Found existing installation: notebook 5.2.2\n",
      "    Uninstalling notebook-5.2.2:\n",
      "      Successfully uninstalled notebook-5.2.2\n",
      "  Found existing installation: widgetsnbextension 3.5.1\n",
      "    Uninstalling widgetsnbextension-3.5.1:\n",
      "      Successfully uninstalled widgetsnbextension-3.5.1\n",
      "  Found existing installation: ipywidgets 7.5.1\n",
      "    Uninstalling ipywidgets-7.5.1:\n",
      "      Successfully uninstalled ipywidgets-7.5.1\n",
      "  Found existing installation: pyrsistent 0.15.4\n",
      "    Uninstalling pyrsistent-0.15.4:\n",
      "      Successfully uninstalled pyrsistent-0.15.4\n",
      "  Found existing installation: jsonschema 2.6.0\n",
      "    Uninstalling jsonschema-2.6.0:\n",
      "      Successfully uninstalled jsonschema-2.6.0\n",
      "  Found existing installation: jupyter-console 5.2.0\n",
      "    Uninstalling jupyter-console-5.2.0:\n",
      "      Successfully uninstalled jupyter-console-5.2.0\n",
      "  Found existing installation: numpy 1.16.5\n",
      "    Uninstalling numpy-1.16.5:\n",
      "      Successfully uninstalled numpy-1.16.5\n",
      "  Found existing installation: pytz 2018.9\n",
      "    Uninstalling pytz-2018.9:\n",
      "      Successfully uninstalled pytz-2018.9\n",
      "  Found existing installation: pandas 0.24.2\n",
      "    Uninstalling pandas-0.24.2:\n",
      "      Successfully uninstalled pandas-0.24.2\n",
      "  Found existing installation: Pillow 4.3.0\n",
      "    Uninstalling Pillow-4.3.0:\n",
      "      Successfully uninstalled Pillow-4.3.0\n",
      "  Found existing installation: qtconsole 4.5.5\n",
      "    Uninstalling qtconsole-4.5.5:\n",
      "      Successfully uninstalled qtconsole-4.5.5\n",
      "  Found existing installation: torch 1.2.0\n",
      "    Uninstalling torch-1.2.0:\n",
      "      Successfully uninstalled torch-1.2.0\n",
      "  Found existing installation: torchvision 0.4.0\n",
      "    Uninstalling torchvision-0.4.0:\n",
      "      Successfully uninstalled torchvision-0.4.0\n",
      "Successfully installed Pillow-6.1.0 Pygments-2.4.2 certifi-2019.6.16 ipykernel-5.1.1 ipython-7.6.1 ipywidgets-7.5.0 jedi-0.14.1 jsonschema-3.0.1 jupyter-client-5.3.1 jupyter-console-6.0.0 nbconvert-5.5.0 notebook-6.0.0 numpy-1.16.4 pandas-0.25.0 prompt-toolkit-2.0.9 pyrsistent-0.15.3 python-dateutil-2.8.0 pytz-2019.1 pyzmq-18.0.2 qtconsole-4.5.2 torch-1.1.0 torchvision-0.3.0 tornado-6.0.3 widgetsnbextension-3.5.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "IPython",
         "PIL",
         "certifi",
         "dateutil",
         "ipykernel",
         "ipywidgets",
         "jupyter_client",
         "numpy",
         "pandas",
         "prompt_toolkit",
         "pygments",
         "pytz",
         "tornado",
         "zmq"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GIlRGmzt-Ibg"
   },
   "outputs": [],
   "source": [
    "# !unzip ../Sample2.zip >../log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFP91yyychql"
   },
   "source": [
    "# Getting Started:\n",
    "## A simple driving model training and evaluation pipeline using the Drive360 dataset and PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eeTTXKFEchqm"
   },
   "source": [
    "## Loading data from Drive360 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9dUjc8BHchqn"
   },
   "source": [
    "The **dataset.py** file contains the 3 classes necessary for creating a Drive360Loader. Using the **config.json** file to specify the location of the csv and data directory, we can generate phase (train, validation, test) specific data loaders that can output samples from each set. Adjust the **dataset.py** to your preferred training framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2877,
     "status": "ok",
     "timestamp": 1569877387576,
     "user": {
      "displayName": "Xiren Zhou",
      "photoUrl": "",
      "userId": "01353105023980702896"
     },
     "user_tz": 240
    },
    "id": "FMS1e2vVchqo",
    "outputId": "b5598824-6f71-4863-fe18-0048da742521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: train # of data: 38328\n",
      "Phase: validation # of data: 2522\n",
      "Phase: test # of data: 0\n",
      "Loaded train loader with the following data available as a dict.\n",
      "Index(['cameraRight', 'cameraFront', 'cameraRear', 'cameraLeft', 'canSteering',\n",
      "       'canSpeed', 'chapter'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "# sys.path.append(\"drive/My Drive/Learning-to-Drive_Competition/starter_kit\")\n",
    "from dataset import Drive360Loader\n",
    "\n",
    "# load the config.json file that specifies data \n",
    "# location parameters and other hyperparameters \n",
    "# required.\n",
    "config = json.load(open('./config.json'))\n",
    "\n",
    "# create a train, validation and test data loader\n",
    "train_loader = Drive360Loader(config, 'train')\n",
    "validation_loader = Drive360Loader(config, 'validation')\n",
    "test_loader = Drive360Loader(config, 'test')\n",
    "\n",
    "# print the data (keys) available for use. See full \n",
    "# description of each data type in the documents.\n",
    "print('Loaded train loader with the following data available as a dict.')\n",
    "print(train_loader.drive360.dataframe.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KMV2svdJchqt"
   },
   "source": [
    "## Training a basic driving model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bvQMkdW0chqu"
   },
   "source": [
    "Create your driving model. This is specific to your learning framework. \n",
    "\n",
    "Below we give a very basic dummy model that uses the front facing camera and a resnet34 + LSTM architecture to predict canSteering and canSpeed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQNxTxMOchqv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /home/ziyan/.cache/torch/checkpoints/resnet34-333f7ec4.pth\n",
      "28.1%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "65.8%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class SomeDrivingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SomeDrivingModel, self).__init__()\n",
    "        final_concat_size = 0\n",
    "        \n",
    "        # Main CNN\n",
    "        cnn = models.resnet34(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(cnn.children())[:-1])\n",
    "        self.intermediate = nn.Sequential(nn.Linear(\n",
    "                          cnn.fc.in_features, 128),\n",
    "                          nn.ReLU())\n",
    "        final_concat_size += 128\n",
    "\n",
    "        # Main LSTM\n",
    "        self.lstm = nn.LSTM(input_size=128,\n",
    "                            hidden_size=64,\n",
    "                            num_layers=3,\n",
    "                            batch_first=False)\n",
    "        final_concat_size += 64\n",
    "        \n",
    "        # Angle Regressor\n",
    "        self.control_angle = nn.Sequential(\n",
    "            nn.Linear(final_concat_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        # Speed Regressor\n",
    "        self.control_speed = nn.Sequential(\n",
    "            nn.Linear(final_concat_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        module_outputs = []\n",
    "        lstm_i = []\n",
    "        # Loop through temporal sequence of\n",
    "        # front facing camera images and pass \n",
    "        # through the cnn.\n",
    "        for k, v in data['cameraFront'].items():\n",
    "            x = self.features(v)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.intermediate(x)\n",
    "            lstm_i.append(x)\n",
    "            # feed the current front facing camera\n",
    "            # output directly into the \n",
    "            # regression networks.\n",
    "            if k == 0:\n",
    "                module_outputs.append(x)\n",
    "\n",
    "        # Feed temporal outputs of CNN into LSTM\n",
    "        i_lstm, _ = self.lstm(torch.stack(lstm_i))\n",
    "        module_outputs.append(i_lstm[-1])\n",
    "        \n",
    "        # Concatenate current image CNN output \n",
    "        # and LSTM output.\n",
    "        x_cat = torch.cat(module_outputs, dim=-1)\n",
    "        \n",
    "        # Feed concatenated outputs into the \n",
    "        # regession networks.\n",
    "        prediction = {'canSteering': torch.squeeze(self.control_angle(x_cat)),\n",
    "                      'canSpeed': torch.squeeze(self.control_speed(x_cat))}\n",
    "        return prediction\n",
    "\n",
    "# Create your own driving model, this is\n",
    "#  a very basic one. \n",
    "model = SomeDrivingModel()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5EEBPLHnchqy"
   },
   "source": [
    "A basic training procedure that iterates over the train_loader and feeds each sample into our dummy model, subsequently calculates loss. We kill after 20 batches just"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "3WvoNo2Ychqz",
    "outputId": "6dc1e34d-9ec1-4575-fa1c-c9e6cd448b70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch:      2] loss: 0.35498\n",
      "[epoch: 1, batch:      4] loss: 0.36764\n",
      "[epoch: 1, batch:      6] loss: 0.73646\n",
      "[epoch: 1, batch:      8] loss: 0.69931\n",
      "[epoch: 1, batch:     10] loss: 0.38580\n",
      "[epoch: 1, batch:     12] loss: 0.10882\n",
      "[epoch: 1, batch:     14] loss: 0.17673\n",
      "[epoch: 1, batch:     16] loss: 0.51130\n",
      "[epoch: 1, batch:     18] loss: 0.45939\n",
      "[epoch: 1, batch:     20] loss: 0.75628\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "model.train()\n",
    "for epoch in range(1):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(data)\n",
    "        # Ony optimizing for canSpeed at the moment\n",
    "        # add canSteering to optimize simulatenously.\n",
    "        loss = criterion(prediction['canSpeed'], target['canSpeed'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % 2 == 1:  \n",
    "            print('[epoch: %d, batch:  %5d] loss: %.5f' %\n",
    "                  (epoch + 1, batch_idx + 1, running_loss / 2.0))\n",
    "            running_loss = 0.0\n",
    "        # Remove this when actually training. \n",
    "        # Used to terminate early. \n",
    "        if batch_idx >= 20: \n",
    "            break\n",
    "            \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IpyL6o7gchq2"
   },
   "source": [
    "## Local evaluation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "GVYUbR4qchq3",
    "outputId": "5178c2e4-3f14-4daf-82b2-e625d9139607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0119)\n",
      "tensor(1.0615)\n",
      "tensor(0.7933)\n",
      "tensor(1.5232)\n",
      "tensor(0.1701)\n",
      "tensor(0.3057)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(validation_loader):\n",
    "        prediction = model(data)\n",
    "        # Again only evaluating the canSpeed \n",
    "        # predictions, add canSteering when \n",
    "        # jointly training.\n",
    "        mse = (np.square(prediction['canSpeed'] - \n",
    "                    target['canSpeed'])).mean()\n",
    "        print(mse)\n",
    "        # Used to terminate early, remove.\n",
    "        if batch_idx >= 5: \n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wmytfALkchq6"
   },
   "source": [
    "## Creating a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uL0kP0lYchq7"
   },
   "outputs": [],
   "source": [
    "normalize_targets = config['target']['normalize']\n",
    "target_mean = config['target']['mean']\n",
    "target_std = config['target']['std']\n",
    "\n",
    "def add_results(results, output):\n",
    "    steering = np.squeeze(output['canSteering'].cpu().data.numpy())\n",
    "    speed = np.squeeze(output['canSpeed'].cpu().data.numpy())\n",
    "    if normalize_targets:\n",
    "        steering = (steering*target_std['canSteering'])+target_mean['canSteering']\n",
    "        speed = (speed*target_std['canSpeed'])+target_mean['canSpeed']\n",
    "    if np.isscalar(steering):\n",
    "        steering = [steering]\n",
    "    if np.isscalar(speed):\n",
    "        speed = [speed]\n",
    "    results['canSteering'].extend(steering)\n",
    "    results['canSpeed'].extend(speed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sf28f1B6chq-"
   },
   "source": [
    "We use pandas to create a submission file which is simply a 2-column csv with a canSteering and canSpeed prediction for each row in the **drive360_test.csv** a total of 305437 rows/predictions not including the header. See the **sample_submission.csv** file as an example.\n",
    "\n",
    "IMPORTANT: for the test phase indices will start 10s (100 samples) into each chapter this is to allow challenge participants to experiment with different temporal settings of data input. If challenge participants have a greater temporal length than 10s for each training sample, then they must write a custom function here. Please check out the **dataset.py** file for additional explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ogBR8mhFchq_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = './submission.csv'\n",
    "results = {'canSteering': [],\n",
    "           'canSpeed': []}\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        prediction = model(data)\n",
    "        add_results(results, prediction)\n",
    "\n",
    "        # Used to terminate early, remove.\n",
    "        if batch_idx >= 5: \n",
    "            break\n",
    "        \n",
    "df = pd.DataFrame.from_dict(results)\n",
    "df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-E9gwbQCchrF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I6MTILhOchrI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "GettingStarted.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
