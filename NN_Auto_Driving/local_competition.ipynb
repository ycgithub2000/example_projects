{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/ziyan/Desktop/Competition/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: train # of data: 38328\n",
      "Phase: validation # of data: 2522\n",
      "Phase: test # of data: 6859\n",
      "Loaded train loader with the following data available as a dict.\n",
      "Index(['cameraRight', 'cameraFront', 'cameraRear', 'cameraLeft', 'canSteering',\n",
      "       'canSpeed', 'chapter'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "# sys.path.append(\"drive/My Drive/Learning-to-Drive_Competition/starter_kit\")\n",
    "from dataset import Drive360Loader\n",
    "\n",
    "# load the config.json file that specifies data \n",
    "# location parameters and other hyperparameters \n",
    "# required.\n",
    "config = json.load(open('./config.json'))\n",
    "\n",
    "# create a train, validation and test data loader\n",
    "train_loader = Drive360Loader(config, 'train')\n",
    "validation_loader = Drive360Loader(config, 'validation')\n",
    "test_loader = Drive360Loader(config, 'test')\n",
    "\n",
    "# print the data (keys) available for use. See full \n",
    "# description of each data type in the documents.\n",
    "print('Loaded train loader with the following data available as a dict.')\n",
    "print(train_loader.drive360.dataframe.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Egg/go_pro_1/image/6/img00040.jpg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader.drive360.dataframe['cameraRight'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(models.resnet34(pretrained=True).children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 6. resnet18 + front + rear lstm \"\"\"\n",
    "\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class SomeDrivingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SomeDrivingModel, self).__init__()\n",
    "        final_concat_size = 0\n",
    "        \n",
    "        # Main CNN\n",
    "        cnn = models.resnet18(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(cnn.children())[:-1])\n",
    "        self.intermediate = nn.Sequential(nn.Linear(\n",
    "                          cnn.fc.in_features, 128),\n",
    "                          nn.ReLU())\n",
    "        final_concat_size += 128\n",
    "\n",
    "        # Main LSTM\n",
    "        self.lstm = nn.LSTM(input_size=128,\n",
    "                            hidden_size=64,\n",
    "                            num_layers=3,\n",
    "                            batch_first=False)\n",
    "        final_concat_size += 64\n",
    "        \n",
    "#         # Right CNN\n",
    "#         cnn_right = models.resnet18(pretrained=True)\n",
    "#         self.features_right = nn.Sequential(*list(cnn_right.children())[:-1])\n",
    "#         self.intermediate_right = nn.Sequential(nn.Linear(\n",
    "#                           cnn_right.fc.in_features, 128),\n",
    "#                           nn.ReLU())\n",
    "#         final_concat_size += 128\n",
    "        \n",
    "#         # Right LSTM\n",
    "#         self.lstm_right = nn.LSTM(input_size=128,\n",
    "#                             hidden_size=64,\n",
    "#                             num_layers=3,\n",
    "#                             batch_first=False)\n",
    "#         final_concat_size += 64\n",
    "        \n",
    "#         # Left CNN\n",
    "#         cnn_left = models.resnet18(pretrained=True)\n",
    "#         self.features_left = nn.Sequential(*list(cnn_left.children())[:-1])\n",
    "#         self.intermediate_left = nn.Sequential(nn.Linear(\n",
    "#                           cnn_left.fc.in_features, 128),\n",
    "#                           nn.ReLU())\n",
    "#         final_concat_size += 128\n",
    "        \n",
    "#         # Left LSTM\n",
    "#         self.lstm_left = nn.LSTM(input_size=128,\n",
    "#                             hidden_size=64,\n",
    "#                             num_layers=3,\n",
    "#                             batch_first=False)\n",
    "#         final_concat_size += 64\n",
    "        \n",
    "#         # Rear CNN\n",
    "#         cnn_rear = models.resnet18(pretrained=True)\n",
    "#         self.features_rear = nn.Sequential(*list(cnn_rear.children())[:-1])\n",
    "#         self.intermediate_rear = nn.Sequential(nn.Linear(\n",
    "#                           cnn_rear.fc.in_features, 128),\n",
    "#                           nn.ReLU())\n",
    "#         final_concat_size += 128\n",
    "        \n",
    "        # rear LSTM\n",
    "        self.lstm_rear = nn.LSTM(input_size=128,\n",
    "                            hidden_size=64,\n",
    "                            num_layers=3,\n",
    "                            batch_first=False)\n",
    "        final_concat_size += 64\n",
    "        \n",
    "        # Angle Regressor\n",
    "        self.control_angle = nn.Sequential(\n",
    "            nn.Linear(final_concat_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        # Speed Regressor\n",
    "        self.control_speed = nn.Sequential(\n",
    "            nn.Linear(final_concat_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        module_outputs = []\n",
    "        lstm_i = []  # cameraFront\n",
    "        lstm_r = []  # cameraRight\n",
    "        lstm_l = []  # cameraLeft\n",
    "        lstm_rear = []  # cameraRear\n",
    "        \n",
    "        # Loop through temporal sequence of\n",
    "        # front facing camera images and pass \n",
    "        # through the cnn.\n",
    "        for k, v in data['cameraFront'].items():\n",
    "            v = v.cuda()\n",
    "            x = self.features(v)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.intermediate(x)\n",
    "            lstm_i.append(x)\n",
    "            # feed the current front facing camera\n",
    "            # output directly into the \n",
    "            # regression networks.\n",
    "            if k == 0:\n",
    "                module_outputs.append(x)\n",
    "        \n",
    "#         for k, v in data['cameraRight'].items():\n",
    "#             v = v.cuda()\n",
    "#             x = self.features_right(v)\n",
    "#             x = x.view(x.size(0), -1)\n",
    "#             x = self.intermediate_right(x)\n",
    "#             lstm_r.append(x)\n",
    "#             if k == 0:\n",
    "#                 module_outputs.append(x)\n",
    "        \n",
    "#         for k, v in data['cameraLeft'].items():\n",
    "#             v = v.cuda()\n",
    "#             x = self.features_left(v)\n",
    "#             x = x.view(x.size(0), -1)\n",
    "#             x = self.intermediate_left(x)\n",
    "#             lstm_l.append(x)\n",
    "#             if k == 0:\n",
    "#                 module_outputs.append(x)\n",
    "        \n",
    "        for k, v in data['cameraRear'].items():\n",
    "            v = v.cuda()\n",
    "#             x = self.features_rear(v)\n",
    "#             x = x.view(x.size(0), -1)\n",
    "#             x = self.intermediate_rear(x)\n",
    "            x = self.features(v)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.intermediate(x)\n",
    "            lstm_rear.append(x)\n",
    "#             if k == 0:\n",
    "#                 module_outputs.append(x)\n",
    "\n",
    "        # Feed temporal outputs of CNN into LSTM\n",
    "        i_lstm, _ = self.lstm(torch.stack(lstm_i))\n",
    "        module_outputs.append(i_lstm[-1])\n",
    "        \n",
    "#         r_lstm, _ = self.lstm_right(torch.stack(lstm_r))\n",
    "#         module_outputs.append(r_lstm[-1])\n",
    "        \n",
    "#         l_lstm, _ = self.lstm_left(torch.stack(lstm_l))\n",
    "#         module_outputs.append(l_lstm[-1])\n",
    "        \n",
    "        rear_lstm, _ = self.lstm_rear(torch.stack(lstm_rear))\n",
    "        module_outputs.append(rear_lstm[-1])\n",
    "        \n",
    "        # Concatenate current image CNN output\n",
    "        # and LSTM output.\n",
    "        x_cat = torch.cat(module_outputs, dim=-1)\n",
    "        \n",
    "        # Feed concatenated outputs into the \n",
    "        # regession networks.\n",
    "        prediction = {'canSteering': torch.squeeze(self.control_angle(x_cat)),\n",
    "                      'canSpeed': torch.squeeze(self.control_speed(x_cat))}\n",
    "        return prediction\n",
    "\n",
    "# Create your own driving model, this is\n",
    "#  a very basic one. \n",
    "model = SomeDrivingModel().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch:      2] loss: 0.53716  | 1.42\n",
      "[epoch: 1, batch:      4] loss: 0.32949  | 0.19\n",
      "[epoch: 1, batch:      6] loss: 0.54619  | 0.18\n",
      "[epoch: 1, batch:      8] loss: 0.60564  | 0.17\n",
      "[epoch: 1, batch:     10] loss: 0.38309  | 0.17\n",
      "[epoch: 1, batch:     12] loss: 0.53608  | 0.19\n",
      "[epoch: 1, batch:     14] loss: 0.40215  | 0.17\n",
      "[epoch: 1, batch:     16] loss: 1.54246  | 0.17\n",
      "[epoch: 1, batch:     18] loss: 1.08935  | 0.18\n",
      "[epoch: 1, batch:     20] loss: 0.43924  | 0.18\n",
      "[epoch: 1, batch:     22] loss: 1.12192  | 0.18\n",
      "[epoch: 1, batch:     24] loss: 1.58606  | 0.18\n",
      "[epoch: 1, batch:     26] loss: 0.19112  | 0.18\n",
      "[epoch: 1, batch:     28] loss: 0.69837  | 0.18\n",
      "[epoch: 1, batch:     30] loss: 0.73107  | 0.18\n",
      "[epoch: 1, batch:     32] loss: 0.59604  | 0.18\n",
      "[epoch: 1, batch:     34] loss: 0.28533  | 0.18\n",
      "[epoch: 1, batch:     36] loss: 2.11958  | 0.18\n",
      "[epoch: 1, batch:     38] loss: 0.10758  | 0.18\n",
      "[epoch: 1, batch:     40] loss: 0.85731  | 0.18\n",
      "[epoch: 1, batch:     42] loss: 1.03294  | 0.18\n",
      "[epoch: 1, batch:     44] loss: 0.66223  | 0.18\n",
      "[epoch: 1, batch:     46] loss: 0.24023  | 0.18\n",
      "[epoch: 1, batch:     48] loss: 0.46469  | 0.18\n",
      "[epoch: 1, batch:     50] loss: 0.04233  | 0.18\n",
      "[epoch: 1, batch:     52] loss: 0.60476  | 0.18\n",
      "[epoch: 1, batch:     54] loss: 0.45232  | 0.18\n",
      "[epoch: 1, batch:     56] loss: 0.22909  | 0.18\n",
      "[epoch: 1, batch:     58] loss: 1.36869  | 0.18\n",
      "[epoch: 1, batch:     60] loss: 0.19663  | 0.18\n",
      "[epoch: 1, batch:     62] loss: 0.12496  | 0.18\n",
      "[epoch: 1, batch:     64] loss: 0.46741  | 0.18\n",
      "[epoch: 1, batch:     66] loss: 0.39099  | 0.18\n",
      "[epoch: 1, batch:     68] loss: 0.13914  | 0.18\n",
      "[epoch: 1, batch:     70] loss: 0.19980  | 0.18\n",
      "[epoch: 1, batch:     72] loss: 0.64313  | 0.18\n",
      "[epoch: 1, batch:     74] loss: 0.13544  | 0.18\n",
      "[epoch: 1, batch:     76] loss: 0.98423  | 0.18\n",
      "[epoch: 1, batch:     78] loss: 0.73921  | 0.18\n",
      "[epoch: 1, batch:     80] loss: 0.47812  | 0.18\n",
      "[epoch: 1, batch:     82] loss: 0.02270  | 0.18\n",
      "[epoch: 1, batch:     84] loss: 0.34661  | 0.18\n",
      "[epoch: 1, batch:     86] loss: 1.64724  | 0.18\n",
      "[epoch: 1, batch:     88] loss: 1.03292  | 0.18\n",
      "[epoch: 1, batch:     90] loss: 0.47901  | 0.18\n",
      "[epoch: 1, batch:     92] loss: 0.68607  | 0.18\n",
      "[epoch: 1, batch:     94] loss: 0.97577  | 0.18\n",
      "[epoch: 1, batch:     96] loss: 0.24540  | 0.18\n",
      "[epoch: 1, batch:     98] loss: 0.09923  | 0.18\n",
      "[epoch: 1, batch:    100] loss: 1.17408  | 0.18\n",
      "[epoch: 1, batch:    102] loss: 0.14009  | 0.18\n",
      "[epoch: 1, batch:    104] loss: 0.63051  | 0.18\n",
      "[epoch: 1, batch:    106] loss: 0.54452  | 0.18\n",
      "[epoch: 1, batch:    108] loss: 0.83141  | 0.18\n",
      "[epoch: 1, batch:    110] loss: 0.32381  | 0.18\n",
      "[epoch: 1, batch:    112] loss: 0.74994  | 0.18\n",
      "[epoch: 1, batch:    114] loss: 0.92277  | 0.18\n",
      "[epoch: 1, batch:    116] loss: 0.32860  | 0.18\n",
      "[epoch: 1, batch:    118] loss: 0.91405  | 0.18\n",
      "[epoch: 1, batch:    120] loss: 0.27154  | 0.18\n",
      "[epoch: 1, batch:    122] loss: 0.01262  | 0.18\n",
      "[epoch: 1, batch:    124] loss: 0.71187  | 0.18\n",
      "[epoch: 1, batch:    126] loss: 0.35396  | 0.18\n",
      "[epoch: 1, batch:    128] loss: 0.29800  | 0.18\n",
      "[epoch: 1, batch:    130] loss: 0.22862  | 0.18\n",
      "[epoch: 1, batch:    132] loss: 0.39731  | 0.18\n",
      "[epoch: 1, batch:    134] loss: 0.41590  | 0.18\n",
      "[epoch: 1, batch:    136] loss: 0.15645  | 0.18\n",
      "[epoch: 1, batch:    138] loss: 0.99715  | 0.18\n",
      "[epoch: 1, batch:    140] loss: 0.53142  | 0.18\n",
      "[epoch: 1, batch:    142] loss: 1.08087  | 0.18\n",
      "[epoch: 1, batch:    144] loss: 0.51610  | 0.18\n",
      "[epoch: 1, batch:    146] loss: 0.67043  | 0.18\n",
      "[epoch: 1, batch:    148] loss: 0.37201  | 0.18\n",
      "[epoch: 1, batch:    150] loss: 0.79809  | 0.18\n",
      "[epoch: 1, batch:    152] loss: 0.71593  | 0.18\n",
      "[epoch: 1, batch:    154] loss: 0.37691  | 0.18\n",
      "[epoch: 1, batch:    156] loss: 0.59091  | 0.18\n",
      "[epoch: 1, batch:    158] loss: 0.55576  | 0.18\n",
      "[epoch: 1, batch:    160] loss: 0.67929  | 0.18\n",
      "[epoch: 1, batch:    162] loss: 0.26677  | 0.18\n",
      "[epoch: 1, batch:    164] loss: 0.72998  | 0.18\n",
      "[epoch: 1, batch:    166] loss: 0.74652  | 0.18\n",
      "[epoch: 1, batch:    168] loss: 0.28241  | 0.18\n",
      "[epoch: 1, batch:    170] loss: 0.14366  | 0.18\n",
      "[epoch: 1, batch:    172] loss: 0.13753  | 0.18\n",
      "[epoch: 1, batch:    174] loss: 0.68170  | 0.18\n",
      "[epoch: 1, batch:    176] loss: 0.78529  | 0.18\n",
      "[epoch: 1, batch:    178] loss: 0.50499  | 0.18\n",
      "[epoch: 1, batch:    180] loss: 0.40036  | 0.18\n",
      "[epoch: 1, batch:    182] loss: 0.21903  | 0.18\n",
      "[epoch: 1, batch:    184] loss: 0.66638  | 0.17\n",
      "[epoch: 1, batch:    186] loss: 0.47712  | 0.19\n",
      "[epoch: 1, batch:    188] loss: 0.69616  | 0.17\n",
      "[epoch: 1, batch:    190] loss: 0.32505  | 0.18\n",
      "[epoch: 1, batch:    192] loss: 0.56509  | 0.18\n",
      "[epoch: 1, batch:    194] loss: 0.59939  | 0.18\n",
      "[epoch: 1, batch:    196] loss: 0.21505  | 0.18\n",
      "[epoch: 1, batch:    198] loss: 0.63533  | 0.18\n",
      "[epoch: 1, batch:    200] loss: 0.67091  | 0.18\n",
      "[epoch: 1, batch:    202] loss: 0.59142  | 0.18\n",
      "[epoch: 1, batch:    204] loss: 0.09105  | 0.18\n",
      "[epoch: 1, batch:    206] loss: 0.41788  | 0.18\n",
      "[epoch: 1, batch:    208] loss: 0.12458  | 0.18\n",
      "[epoch: 1, batch:    210] loss: 0.16541  | 0.18\n",
      "[epoch: 1, batch:    212] loss: 0.23559  | 0.18\n",
      "[epoch: 1, batch:    214] loss: 0.56509  | 0.18\n",
      "[epoch: 1, batch:    216] loss: 0.87561  | 0.18\n",
      "[epoch: 1, batch:    218] loss: 0.21114  | 0.18\n",
      "[epoch: 1, batch:    220] loss: 0.23150  | 0.18\n",
      "[epoch: 1, batch:    222] loss: 0.71157  | 0.18\n",
      "[epoch: 1, batch:    224] loss: 0.31151  | 0.18\n",
      "[epoch: 1, batch:    226] loss: 0.63417  | 0.18\n",
      "[epoch: 1, batch:    228] loss: 0.25802  | 0.18\n",
      "[epoch: 1, batch:    230] loss: 0.23272  | 0.18\n",
      "[epoch: 1, batch:    232] loss: 0.05054  | 0.18\n",
      "[epoch: 1, batch:    234] loss: 0.23229  | 0.18\n",
      "[epoch: 1, batch:    236] loss: 0.24565  | 0.18\n",
      "[epoch: 1, batch:    238] loss: 0.26201  | 0.18\n",
      "[epoch: 1, batch:    240] loss: 0.38845  | 0.18\n",
      "[epoch: 1, batch:    242] loss: 0.43736  | 0.18\n",
      "[epoch: 1, batch:    244] loss: 0.13425  | 0.18\n",
      "[epoch: 1, batch:    246] loss: 0.40364  | 0.18\n",
      "[epoch: 1, batch:    248] loss: 0.36687  | 0.18\n",
      "[epoch: 1, batch:    250] loss: 0.50180  | 0.18\n",
      "[epoch: 1, batch:    252] loss: 1.47466  | 0.18\n",
      "[epoch: 1, batch:    254] loss: 0.60414  | 0.18\n",
      "[epoch: 1, batch:    256] loss: 0.33657  | 0.18\n",
      "[epoch: 1, batch:    258] loss: 0.18098  | 0.18\n",
      "[epoch: 1, batch:    260] loss: 0.42399  | 0.18\n",
      "[epoch: 1, batch:    262] loss: 0.34640  | 0.18\n",
      "[epoch: 1, batch:    264] loss: 0.09096  | 0.18\n",
      "[epoch: 1, batch:    266] loss: 0.09498  | 0.18\n",
      "[epoch: 1, batch:    268] loss: 0.33436  | 0.18\n",
      "[epoch: 1, batch:    270] loss: 0.36113  | 0.18\n",
      "[epoch: 1, batch:    272] loss: 0.33710  | 0.18\n",
      "[epoch: 1, batch:    274] loss: 0.64029  | 0.18\n",
      "[epoch: 1, batch:    276] loss: 0.30180  | 0.18\n",
      "[epoch: 1, batch:    278] loss: 0.69467  | 0.18\n",
      "[epoch: 1, batch:    280] loss: 0.34023  | 0.18\n",
      "[epoch: 1, batch:    282] loss: 0.80931  | 0.18\n",
      "[epoch: 1, batch:    284] loss: 0.71767  | 0.18\n",
      "[epoch: 1, batch:    286] loss: 0.50466  | 0.18\n",
      "[epoch: 1, batch:    288] loss: 0.59495  | 0.18\n",
      "[epoch: 1, batch:    290] loss: 0.20965  | 0.18\n",
      "[epoch: 1, batch:    292] loss: 0.05342  | 0.18\n",
      "[epoch: 1, batch:    294] loss: 1.42696  | 0.18\n",
      "[epoch: 1, batch:    296] loss: 0.21725  | 0.18\n",
      "[epoch: 1, batch:    298] loss: 0.56643  | 0.18\n",
      "[epoch: 1, batch:    300] loss: 0.56824  | 0.18\n",
      "[epoch: 1, batch:    302] loss: 0.50751  | 0.18\n",
      "[epoch: 1, batch:    304] loss: 1.08208  | 0.18\n",
      "[epoch: 1, batch:    306] loss: 0.27883  | 0.18\n",
      "[epoch: 1, batch:    308] loss: 0.62621  | 0.18\n",
      "[epoch: 1, batch:    310] loss: 0.39438  | 0.18\n",
      "[epoch: 1, batch:    312] loss: 0.51972  | 0.18\n",
      "[epoch: 1, batch:    314] loss: 0.73639  | 0.18\n",
      "[epoch: 1, batch:    316] loss: 0.15652  | 0.18\n",
      "[epoch: 1, batch:    318] loss: 0.93316  | 0.18\n",
      "[epoch: 1, batch:    320] loss: 0.51535  | 0.18\n",
      "[epoch: 1, batch:    322] loss: 0.31773  | 0.18\n",
      "[epoch: 1, batch:    324] loss: 0.34534  | 0.18\n",
      "[epoch: 1, batch:    326] loss: 0.41082  | 0.18\n",
      "[epoch: 1, batch:    328] loss: 0.43004  | 0.18\n",
      "[epoch: 1, batch:    330] loss: 0.40666  | 0.18\n",
      "[epoch: 1, batch:    332] loss: 0.41177  | 0.18\n",
      "[epoch: 1, batch:    334] loss: 0.35855  | 0.18\n",
      "[epoch: 1, batch:    336] loss: 0.46017  | 0.18\n",
      "[epoch: 1, batch:    338] loss: 0.24092  | 0.18\n",
      "[epoch: 1, batch:    340] loss: 0.04577  | 0.18\n",
      "[epoch: 1, batch:    342] loss: 0.68459  | 0.18\n",
      "[epoch: 1, batch:    344] loss: 0.54592  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch:    346] loss: 0.33977  | 0.18\n",
      "[epoch: 1, batch:    348] loss: 1.13683  | 0.18\n",
      "[epoch: 1, batch:    350] loss: 0.35701  | 0.18\n",
      "[epoch: 1, batch:    352] loss: 0.65229  | 0.18\n",
      "[epoch: 1, batch:    354] loss: 0.80642  | 0.18\n",
      "[epoch: 1, batch:    356] loss: 0.38529  | 0.18\n",
      "[epoch: 1, batch:    358] loss: 0.60205  | 0.18\n",
      "[epoch: 1, batch:    360] loss: 0.61455  | 0.18\n",
      "[epoch: 1, batch:    362] loss: 0.29691  | 0.18\n",
      "[epoch: 1, batch:    364] loss: 0.10586  | 0.18\n",
      "[epoch: 1, batch:    366] loss: 0.44022  | 0.18\n",
      "[epoch: 1, batch:    368] loss: 0.23240  | 0.18\n",
      "[epoch: 1, batch:    370] loss: 0.27119  | 0.18\n",
      "[epoch: 1, batch:    372] loss: 0.58770  | 0.18\n",
      "[epoch: 1, batch:    374] loss: 0.12137  | 0.18\n",
      "[epoch: 1, batch:    376] loss: 0.26348  | 0.18\n",
      "[epoch: 1, batch:    378] loss: 0.40861  | 0.18\n",
      "[epoch: 1, batch:    380] loss: 1.09203  | 0.18\n",
      "[epoch: 1, batch:    382] loss: 0.39924  | 0.18\n",
      "[epoch: 1, batch:    384] loss: 0.07209  | 0.18\n",
      "[epoch: 1, batch:    386] loss: 0.38561  | 0.18\n",
      "[epoch: 1, batch:    388] loss: 0.45701  | 0.18\n",
      "[epoch: 1, batch:    390] loss: 0.39007  | 0.18\n",
      "[epoch: 1, batch:    392] loss: 0.16935  | 0.18\n",
      "[epoch: 1, batch:    394] loss: 0.71578  | 0.18\n",
      "[epoch: 1, batch:    396] loss: 0.35670  | 0.18\n",
      "[epoch: 1, batch:    398] loss: 0.37842  | 0.18\n",
      "[epoch: 1, batch:    400] loss: 0.23837  | 0.18\n",
      "[epoch: 1, batch:    402] loss: 0.43766  | 0.18\n",
      "[epoch: 1, batch:    404] loss: 0.40465  | 0.18\n",
      "[epoch: 1, batch:    406] loss: 0.68981  | 0.18\n",
      "[epoch: 1, batch:    408] loss: 0.51987  | 0.18\n",
      "[epoch: 1, batch:    410] loss: 0.32574  | 0.18\n",
      "[epoch: 1, batch:    412] loss: 0.18463  | 0.18\n",
      "[epoch: 1, batch:    414] loss: 0.57494  | 0.18\n",
      "[epoch: 1, batch:    416] loss: 0.55505  | 0.18\n",
      "[epoch: 1, batch:    418] loss: 0.34901  | 0.18\n",
      "[epoch: 1, batch:    420] loss: 0.59211  | 0.18\n",
      "[epoch: 1, batch:    422] loss: 0.84530  | 0.18\n",
      "[epoch: 1, batch:    424] loss: 0.67136  | 0.18\n",
      "[epoch: 1, batch:    426] loss: 0.68420  | 0.18\n",
      "[epoch: 1, batch:    428] loss: 0.66376  | 0.18\n",
      "[epoch: 1, batch:    430] loss: 0.75919  | 0.18\n",
      "[epoch: 1, batch:    432] loss: 0.14659  | 0.18\n",
      "[epoch: 1, batch:    434] loss: 0.16512  | 0.18\n",
      "[epoch: 1, batch:    436] loss: 0.53717  | 0.18\n",
      "[epoch: 1, batch:    438] loss: 0.12739  | 0.18\n",
      "[epoch: 1, batch:    440] loss: 0.79965  | 0.18\n",
      "[epoch: 1, batch:    442] loss: 0.22575  | 0.18\n",
      "[epoch: 1, batch:    444] loss: 0.29823  | 0.18\n",
      "[epoch: 1, batch:    446] loss: 1.11655  | 0.18\n",
      "[epoch: 1, batch:    448] loss: 0.42744  | 0.18\n",
      "[epoch: 1, batch:    450] loss: 0.56632  | 0.18\n",
      "[epoch: 1, batch:    452] loss: 0.72393  | 0.18\n",
      "[epoch: 1, batch:    454] loss: 0.02321  | 0.18\n",
      "[epoch: 1, batch:    456] loss: 0.34922  | 0.18\n",
      "[epoch: 1, batch:    458] loss: 0.22241  | 0.18\n",
      "[epoch: 1, batch:    460] loss: 0.62822  | 0.18\n",
      "[epoch: 1, batch:    462] loss: 0.30789  | 0.18\n",
      "[epoch: 1, batch:    464] loss: 0.44821  | 0.18\n",
      "[epoch: 1, batch:    466] loss: 0.34649  | 0.18\n",
      "[epoch: 1, batch:    468] loss: 0.52391  | 0.18\n",
      "[epoch: 1, batch:    470] loss: 0.76274  | 0.18\n",
      "[epoch: 1, batch:    472] loss: 0.46031  | 0.18\n",
      "[epoch: 1, batch:    474] loss: 0.18265  | 0.18\n",
      "[epoch: 1, batch:    476] loss: 0.20730  | 0.18\n",
      "[epoch: 1, batch:    478] loss: 0.15925  | 0.18\n",
      "[epoch: 1, batch:    480] loss: 0.36491  | 0.18\n",
      "[epoch: 1, batch:    482] loss: 1.61912  | 0.18\n",
      "[epoch: 1, batch:    484] loss: 0.13209  | 0.18\n",
      "[epoch: 1, batch:    486] loss: 1.71044  | 0.18\n",
      "[epoch: 1, batch:    488] loss: 0.28344  | 0.18\n",
      "[epoch: 1, batch:    490] loss: 0.48202  | 0.18\n",
      "[epoch: 1, batch:    492] loss: 1.17137  | 0.18\n",
      "[epoch: 1, batch:    494] loss: 0.35792  | 0.18\n",
      "[epoch: 1, batch:    496] loss: 0.30902  | 0.18\n",
      "[epoch: 1, batch:    498] loss: 0.44391  | 0.18\n",
      "[epoch: 1, batch:    500] loss: 1.40674  | 0.18\n",
      "[epoch: 1, batch:    502] loss: 0.18185  | 0.18\n",
      "[epoch: 1, batch:    504] loss: 0.53413  | 0.18\n",
      "[epoch: 1, batch:    506] loss: 0.89051  | 0.18\n",
      "[epoch: 1, batch:    508] loss: 0.37862  | 0.18\n",
      "[epoch: 1, batch:    510] loss: 1.37997  | 0.18\n",
      "[epoch: 1, batch:    512] loss: 0.27158  | 0.18\n",
      "[epoch: 1, batch:    514] loss: 0.61221  | 0.18\n",
      "[epoch: 1, batch:    516] loss: 0.16853  | 0.18\n",
      "[epoch: 1, batch:    518] loss: 0.50807  | 0.18\n",
      "[epoch: 1, batch:    520] loss: 0.59850  | 0.18\n",
      "[epoch: 1, batch:    522] loss: 0.27886  | 0.18\n",
      "[epoch: 1, batch:    524] loss: 0.31870  | 0.18\n",
      "[epoch: 1, batch:    526] loss: 0.53985  | 0.18\n",
      "[epoch: 1, batch:    528] loss: 0.49555  | 0.18\n",
      "[epoch: 1, batch:    530] loss: 0.08029  | 0.18\n",
      "[epoch: 1, batch:    532] loss: 0.65061  | 0.18\n",
      "[epoch: 1, batch:    534] loss: 0.66600  | 0.18\n",
      "[epoch: 1, batch:    536] loss: 0.60063  | 0.18\n",
      "[epoch: 1, batch:    538] loss: 0.36070  | 0.18\n",
      "[epoch: 1, batch:    540] loss: 0.26036  | 0.18\n",
      "[epoch: 1, batch:    542] loss: 0.33725  | 0.18\n",
      "[epoch: 1, batch:    544] loss: 0.18687  | 0.18\n",
      "[epoch: 1, batch:    546] loss: 0.60404  | 0.18\n",
      "[epoch: 1, batch:    548] loss: 0.38304  | 0.18\n",
      "[epoch: 1, batch:    550] loss: 0.37572  | 0.18\n",
      "[epoch: 1, batch:    552] loss: 0.25621  | 0.18\n",
      "[epoch: 1, batch:    554] loss: 0.11795  | 0.18\n",
      "[epoch: 1, batch:    556] loss: 0.90810  | 0.18\n",
      "[epoch: 1, batch:    558] loss: 0.07792  | 0.18\n",
      "[epoch: 1, batch:    560] loss: 0.13815  | 0.18\n",
      "[epoch: 1, batch:    562] loss: 0.42501  | 0.18\n",
      "[epoch: 1, batch:    564] loss: 0.81254  | 0.18\n",
      "[epoch: 1, batch:    566] loss: 0.69176  | 0.18\n",
      "[epoch: 1, batch:    568] loss: 0.20966  | 0.18\n",
      "[epoch: 1, batch:    570] loss: 0.37941  | 0.18\n",
      "[epoch: 1, batch:    572] loss: 0.31650  | 0.18\n",
      "[epoch: 1, batch:    574] loss: 1.01987  | 0.18\n",
      "[epoch: 1, batch:    576] loss: 0.54162  | 0.18\n",
      "[epoch: 1, batch:    578] loss: 0.94813  | 0.18\n",
      "[epoch: 1, batch:    580] loss: 0.12549  | 0.18\n",
      "[epoch: 1, batch:    582] loss: 1.13720  | 0.18\n",
      "[epoch: 1, batch:    584] loss: 0.13519  | 0.18\n",
      "[epoch: 1, batch:    586] loss: 0.66212  | 0.18\n",
      "[epoch: 1, batch:    588] loss: 0.31146  | 0.18\n",
      "[epoch: 1, batch:    590] loss: 0.55714  | 0.18\n",
      "[epoch: 1, batch:    592] loss: 0.20886  | 0.18\n",
      "[epoch: 1, batch:    594] loss: 0.25806  | 0.18\n",
      "[epoch: 1, batch:    596] loss: 0.45601  | 0.18\n",
      "[epoch: 1, batch:    598] loss: 0.54103  | 0.18\n",
      "[epoch: 1, batch:    600] loss: 0.79926  | 0.18\n",
      "[epoch: 1, batch:    602] loss: 0.80643  | 0.18\n",
      "[epoch: 1, batch:    604] loss: 0.79508  | 0.18\n",
      "[epoch: 1, batch:    606] loss: 0.69685  | 0.18\n",
      "[epoch: 1, batch:    608] loss: 0.17876  | 0.18\n",
      "[epoch: 1, batch:    610] loss: 1.67892  | 0.18\n",
      "[epoch: 1, batch:    612] loss: 0.55556  | 0.18\n",
      "[epoch: 1, batch:    614] loss: 0.55353  | 0.18\n",
      "[epoch: 1, batch:    616] loss: 0.35800  | 0.18\n",
      "[epoch: 1, batch:    618] loss: 0.25668  | 0.20\n",
      "[epoch: 1, batch:    620] loss: 0.65675  | 0.18\n",
      "[epoch: 1, batch:    622] loss: 0.49364  | 0.19\n",
      "[epoch: 1, batch:    624] loss: 0.45851  | 0.20\n",
      "[epoch: 1, batch:    626] loss: 0.33657  | 0.18\n",
      "[epoch: 1, batch:    628] loss: 0.15535  | 0.18\n",
      "[epoch: 1, batch:    630] loss: 0.13151  | 0.18\n",
      "[epoch: 1, batch:    632] loss: 0.34430  | 0.18\n",
      "[epoch: 1, batch:    634] loss: 0.48232  | 0.19\n",
      "[epoch: 1, batch:    636] loss: 0.39163  | 0.20\n",
      "[epoch: 1, batch:    638] loss: 0.50506  | 0.19\n",
      "[epoch: 1, batch:    640] loss: 0.35646  | 0.18\n",
      "[epoch: 1, batch:    642] loss: 0.12824  | 0.18\n",
      "[epoch: 1, batch:    644] loss: 0.59796  | 0.18\n",
      "[epoch: 1, batch:    646] loss: 0.47637  | 0.18\n",
      "[epoch: 1, batch:    648] loss: 0.38584  | 0.18\n",
      "[epoch: 1, batch:    650] loss: 0.44794  | 0.18\n",
      "[epoch: 1, batch:    652] loss: 0.32597  | 0.18\n",
      "[epoch: 1, batch:    654] loss: 0.63693  | 0.18\n",
      "[epoch: 1, batch:    656] loss: 0.42939  | 0.18\n",
      "[epoch: 1, batch:    658] loss: 1.28298  | 0.18\n",
      "[epoch: 1, batch:    660] loss: 0.28155  | 0.18\n",
      "[epoch: 1, batch:    662] loss: 0.04540  | 0.18\n",
      "[epoch: 1, batch:    664] loss: 0.45403  | 0.18\n",
      "[epoch: 1, batch:    666] loss: 1.00117  | 0.18\n",
      "[epoch: 1, batch:    668] loss: 0.27271  | 0.18\n",
      "[epoch: 1, batch:    670] loss: 1.04785  | 0.19\n",
      "[epoch: 1, batch:    672] loss: 0.06442  | 0.18\n",
      "[epoch: 1, batch:    674] loss: 0.17185  | 0.18\n",
      "[epoch: 1, batch:    676] loss: 0.66088  | 0.18\n",
      "[epoch: 1, batch:    678] loss: 1.46070  | 0.18\n",
      "[epoch: 1, batch:    680] loss: 0.87888  | 0.18\n",
      "[epoch: 1, batch:    682] loss: 1.03641  | 0.18\n",
      "[epoch: 1, batch:    684] loss: 0.22443  | 0.18\n",
      "[epoch: 1, batch:    686] loss: 0.34765  | 0.18\n",
      "[epoch: 1, batch:    688] loss: 0.33721  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch:    690] loss: 0.30213  | 0.18\n",
      "[epoch: 1, batch:    692] loss: 0.37185  | 0.18\n",
      "[epoch: 1, batch:    694] loss: 1.33979  | 0.18\n",
      "[epoch: 1, batch:    696] loss: 0.53798  | 0.18\n",
      "[epoch: 1, batch:    698] loss: 0.35957  | 0.18\n",
      "[epoch: 1, batch:    700] loss: 0.43300  | 0.18\n",
      "[epoch: 1, batch:    702] loss: 0.14358  | 0.18\n",
      "[epoch: 1, batch:    704] loss: 0.28917  | 0.18\n",
      "[epoch: 1, batch:    706] loss: 0.22156  | 0.18\n",
      "[epoch: 1, batch:    708] loss: 0.79058  | 0.18\n",
      "[epoch: 1, batch:    710] loss: 0.78743  | 0.18\n",
      "[epoch: 1, batch:    712] loss: 0.50154  | 0.18\n",
      "[epoch: 1, batch:    714] loss: 1.68402  | 0.18\n",
      "[epoch: 1, batch:    716] loss: 0.49971  | 0.18\n",
      "[epoch: 1, batch:    718] loss: 0.58964  | 0.18\n",
      "[epoch: 1, batch:    720] loss: 0.55928  | 0.18\n",
      "[epoch: 1, batch:    722] loss: 0.39582  | 0.18\n",
      "[epoch: 1, batch:    724] loss: 0.12901  | 0.18\n",
      "[epoch: 1, batch:    726] loss: 0.54810  | 0.18\n",
      "[epoch: 1, batch:    728] loss: 1.27495  | 0.18\n",
      "[epoch: 1, batch:    730] loss: 1.42656  | 0.18\n",
      "[epoch: 1, batch:    732] loss: 0.61624  | 0.18\n",
      "[epoch: 1, batch:    734] loss: 0.60635  | 0.18\n",
      "[epoch: 1, batch:    736] loss: 0.85911  | 0.18\n",
      "[epoch: 1, batch:    738] loss: 0.82808  | 0.18\n",
      "[epoch: 1, batch:    740] loss: 0.21123  | 0.18\n",
      "[epoch: 1, batch:    742] loss: 0.35998  | 0.18\n",
      "[epoch: 1, batch:    744] loss: 0.44882  | 0.18\n",
      "[epoch: 1, batch:    746] loss: 0.16394  | 0.18\n",
      "[epoch: 1, batch:    748] loss: 1.96549  | 0.18\n",
      "[epoch: 1, batch:    750] loss: 0.22974  | 0.18\n",
      "[epoch: 1, batch:    752] loss: 0.74657  | 0.18\n",
      "[epoch: 1, batch:    754] loss: 0.28496  | 0.18\n",
      "[epoch: 1, batch:    756] loss: 0.80964  | 0.18\n",
      "[epoch: 1, batch:    758] loss: 0.18592  | 0.18\n",
      "[epoch: 1, batch:    760] loss: 0.25145  | 0.18\n",
      "[epoch: 1, batch:    762] loss: 0.30771  | 0.18\n",
      "[epoch: 1, batch:    764] loss: 0.30922  | 0.18\n",
      "[epoch: 1, batch:    766] loss: 0.95748  | 0.18\n",
      "[epoch: 1, batch:    768] loss: 0.58608  | 0.18\n",
      "[epoch: 1, batch:    770] loss: 0.48550  | 0.18\n",
      "[epoch: 1, batch:    772] loss: 0.36690  | 0.18\n",
      "[epoch: 1, batch:    774] loss: 0.04942  | 0.18\n",
      "[epoch: 1, batch:    776] loss: 0.81515  | 0.18\n",
      "[epoch: 1, batch:    778] loss: 0.78209  | 0.18\n",
      "[epoch: 1, batch:    780] loss: 0.36676  | 0.18\n",
      "[epoch: 1, batch:    782] loss: 0.98265  | 0.18\n",
      "[epoch: 1, batch:    784] loss: 0.96638  | 0.18\n",
      "[epoch: 1, batch:    786] loss: 0.75434  | 0.18\n",
      "[epoch: 1, batch:    788] loss: 0.78756  | 0.18\n",
      "[epoch: 1, batch:    790] loss: 0.32231  | 0.18\n",
      "[epoch: 1, batch:    792] loss: 0.82002  | 0.18\n",
      "[epoch: 1, batch:    794] loss: 0.23803  | 0.18\n",
      "[epoch: 1, batch:    796] loss: 0.29097  | 0.18\n",
      "[epoch: 1, batch:    798] loss: 0.48643  | 0.18\n",
      "[epoch: 1, batch:    800] loss: 0.73177  | 0.18\n",
      "[epoch: 1, batch:    802] loss: 0.86538  | 0.18\n",
      "[epoch: 1, batch:    804] loss: 0.21437  | 0.18\n",
      "[epoch: 1, batch:    806] loss: 0.57905  | 0.18\n",
      "[epoch: 1, batch:    808] loss: 0.09720  | 0.18\n",
      "[epoch: 1, batch:    810] loss: 0.60225  | 0.18\n",
      "[epoch: 1, batch:    812] loss: 0.15834  | 0.18\n",
      "[epoch: 1, batch:    814] loss: 0.75458  | 0.18\n",
      "[epoch: 1, batch:    816] loss: 0.28319  | 0.18\n",
      "[epoch: 1, batch:    818] loss: 0.13575  | 0.18\n",
      "[epoch: 1, batch:    820] loss: 0.64571  | 0.18\n",
      "[epoch: 1, batch:    822] loss: 0.42297  | 0.18\n",
      "[epoch: 1, batch:    824] loss: 0.18052  | 0.18\n",
      "[epoch: 1, batch:    826] loss: 0.80989  | 0.19\n",
      "[epoch: 1, batch:    828] loss: 0.24848  | 0.18\n",
      "[epoch: 1, batch:    830] loss: 0.87011  | 0.18\n",
      "[epoch: 1, batch:    832] loss: 0.38094  | 0.18\n",
      "[epoch: 1, batch:    834] loss: 0.32156  | 0.18\n",
      "[epoch: 1, batch:    836] loss: 0.29489  | 0.18\n",
      "[epoch: 1, batch:    838] loss: 0.20979  | 0.18\n",
      "[epoch: 1, batch:    840] loss: 0.96757  | 0.18\n",
      "[epoch: 1, batch:    842] loss: 0.62240  | 0.18\n",
      "[epoch: 1, batch:    844] loss: 0.22342  | 0.18\n",
      "[epoch: 1, batch:    846] loss: 0.23482  | 0.18\n",
      "[epoch: 1, batch:    848] loss: 0.41518  | 0.18\n",
      "[epoch: 1, batch:    850] loss: 0.24574  | 0.18\n",
      "[epoch: 1, batch:    852] loss: 0.22230  | 0.18\n",
      "[epoch: 1, batch:    854] loss: 0.31415  | 0.18\n",
      "[epoch: 1, batch:    856] loss: 0.72650  | 0.18\n",
      "[epoch: 1, batch:    858] loss: 1.03080  | 0.18\n",
      "[epoch: 1, batch:    860] loss: 0.45781  | 0.18\n",
      "[epoch: 1, batch:    862] loss: 0.35270  | 0.18\n",
      "[epoch: 1, batch:    864] loss: 0.55742  | 0.18\n",
      "[epoch: 1, batch:    866] loss: 0.38808  | 0.18\n",
      "[epoch: 1, batch:    868] loss: 1.38740  | 0.18\n",
      "[epoch: 1, batch:    870] loss: 0.03496  | 0.18\n",
      "[epoch: 1, batch:    872] loss: 0.41581  | 0.18\n",
      "[epoch: 1, batch:    874] loss: 0.24090  | 0.18\n",
      "[epoch: 1, batch:    876] loss: 0.48053  | 0.18\n",
      "[epoch: 1, batch:    878] loss: 1.38972  | 0.18\n",
      "[epoch: 1, batch:    880] loss: 0.21763  | 0.18\n",
      "[epoch: 1, batch:    882] loss: 0.36339  | 0.18\n",
      "[epoch: 1, batch:    884] loss: 0.58019  | 0.18\n",
      "[epoch: 1, batch:    886] loss: 0.05867  | 0.18\n",
      "[epoch: 1, batch:    888] loss: 0.29790  | 0.18\n",
      "[epoch: 1, batch:    890] loss: 0.56397  | 0.18\n",
      "[epoch: 1, batch:    892] loss: 0.43471  | 0.18\n",
      "[epoch: 1, batch:    894] loss: 0.51938  | 0.18\n",
      "[epoch: 1, batch:    896] loss: 0.42577  | 0.18\n",
      "[epoch: 1, batch:    898] loss: 0.13034  | 0.18\n",
      "[epoch: 1, batch:    900] loss: 0.28467  | 0.18\n",
      "[epoch: 1, batch:    902] loss: 0.15526  | 0.18\n",
      "[epoch: 1, batch:    904] loss: 0.03210  | 0.18\n",
      "[epoch: 1, batch:    906] loss: 0.46517  | 0.18\n",
      "[epoch: 1, batch:    908] loss: 0.58503  | 0.18\n",
      "[epoch: 1, batch:    910] loss: 0.56795  | 0.18\n",
      "[epoch: 1, batch:    912] loss: 0.96283  | 0.18\n",
      "[epoch: 1, batch:    914] loss: 0.60110  | 0.18\n",
      "[epoch: 1, batch:    916] loss: 0.69825  | 0.18\n",
      "[epoch: 1, batch:    918] loss: 0.44329  | 0.18\n",
      "[epoch: 1, batch:    920] loss: 0.65407  | 0.18\n",
      "[epoch: 1, batch:    922] loss: 0.33094  | 0.18\n",
      "[epoch: 1, batch:    924] loss: 0.42591  | 0.18\n",
      "[epoch: 1, batch:    926] loss: 0.35779  | 0.18\n",
      "[epoch: 1, batch:    928] loss: 1.00947  | 0.18\n",
      "[epoch: 1, batch:    930] loss: 0.34268  | 0.18\n",
      "[epoch: 1, batch:    932] loss: 0.49709  | 0.18\n",
      "[epoch: 1, batch:    934] loss: 0.11720  | 0.18\n",
      "[epoch: 1, batch:    936] loss: 0.49805  | 0.18\n",
      "[epoch: 1, batch:    938] loss: 0.48276  | 0.18\n",
      "[epoch: 1, batch:    940] loss: 1.25927  | 0.18\n",
      "[epoch: 1, batch:    942] loss: 0.26745  | 0.18\n",
      "[epoch: 1, batch:    944] loss: 0.44066  | 0.18\n",
      "[epoch: 1, batch:    946] loss: 0.41676  | 0.18\n",
      "[epoch: 1, batch:    948] loss: 0.81799  | 0.18\n",
      "[epoch: 1, batch:    950] loss: 0.83930  | 0.18\n",
      "[epoch: 1, batch:    952] loss: 0.69868  | 0.18\n",
      "[epoch: 1, batch:    954] loss: 0.01264  | 0.18\n",
      "[epoch: 1, batch:    956] loss: 0.55418  | 0.18\n",
      "[epoch: 1, batch:    958] loss: 0.96912  | 0.18\n",
      "[epoch: 1, batch:    960] loss: 0.31017  | 0.18\n",
      "[epoch: 1, batch:    962] loss: 0.27787  | 0.18\n",
      "[epoch: 1, batch:    964] loss: 0.75302  | 0.18\n",
      "[epoch: 1, batch:    966] loss: 0.91679  | 0.18\n",
      "[epoch: 1, batch:    968] loss: 0.51406  | 0.18\n",
      "[epoch: 1, batch:    970] loss: 0.24241  | 0.18\n",
      "[epoch: 1, batch:    972] loss: 0.21943  | 0.18\n",
      "[epoch: 1, batch:    974] loss: 0.83933  | 0.18\n",
      "[epoch: 1, batch:    976] loss: 0.12644  | 0.18\n",
      "[epoch: 1, batch:    978] loss: 0.24586  | 0.18\n",
      "[epoch: 1, batch:    980] loss: 0.47651  | 0.18\n",
      "[epoch: 1, batch:    982] loss: 0.12381  | 0.18\n",
      "[epoch: 1, batch:    984] loss: 0.33281  | 0.18\n",
      "[epoch: 1, batch:    986] loss: 0.42505  | 0.18\n",
      "[epoch: 1, batch:    988] loss: 0.07332  | 0.18\n",
      "[epoch: 1, batch:    990] loss: 0.21873  | 0.18\n",
      "[epoch: 1, batch:    992] loss: 0.47718  | 0.18\n",
      "[epoch: 1, batch:    994] loss: 1.41207  | 0.18\n",
      "[epoch: 1, batch:    996] loss: 0.32601  | 0.18\n",
      "[epoch: 1, batch:    998] loss: 0.69337  | 0.18\n",
      "[epoch: 1, batch:   1000] loss: 0.31151  | 0.18\n",
      "[epoch: 1, batch:   1002] loss: 0.43363  | 0.18\n",
      "[epoch: 1, batch:   1004] loss: 0.32112  | 0.18\n",
      "[epoch: 1, batch:   1006] loss: 0.24247  | 0.18\n",
      "[epoch: 1, batch:   1008] loss: 0.80727  | 0.18\n",
      "[epoch: 1, batch:   1010] loss: 0.19370  | 0.18\n",
      "[epoch: 1, batch:   1012] loss: 0.39081  | 0.18\n",
      "[epoch: 1, batch:   1014] loss: 0.17309  | 0.18\n",
      "[epoch: 1, batch:   1016] loss: 0.51729  | 0.18\n",
      "[epoch: 1, batch:   1018] loss: 0.27334  | 0.18\n",
      "[epoch: 1, batch:   1020] loss: 0.14052  | 0.18\n",
      "[epoch: 1, batch:   1022] loss: 0.06529  | 0.18\n",
      "[epoch: 1, batch:   1024] loss: 0.33871  | 0.18\n",
      "[epoch: 1, batch:   1026] loss: 0.23767  | 0.18\n",
      "[epoch: 1, batch:   1028] loss: 1.01820  | 0.18\n",
      "[epoch: 1, batch:   1030] loss: 0.25608  | 0.18\n",
      "[epoch: 1, batch:   1032] loss: 0.54311  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch:   1034] loss: 0.67917  | 0.18\n",
      "[epoch: 1, batch:   1036] loss: 0.46703  | 0.18\n",
      "[epoch: 1, batch:   1038] loss: 0.08175  | 0.18\n",
      "[epoch: 1, batch:   1040] loss: 0.62861  | 0.18\n",
      "[epoch: 1, batch:   1042] loss: 0.47409  | 0.18\n",
      "[epoch: 1, batch:   1044] loss: 0.56097  | 0.18\n",
      "[epoch: 1, batch:   1046] loss: 0.59330  | 0.18\n",
      "[epoch: 1, batch:   1048] loss: 1.00939  | 0.18\n",
      "[epoch: 1, batch:   1050] loss: 0.68412  | 0.18\n",
      "[epoch: 1, batch:   1052] loss: 0.72326  | 0.18\n",
      "[epoch: 1, batch:   1054] loss: 0.17802  | 0.18\n",
      "[epoch: 1, batch:   1056] loss: 0.15778  | 0.18\n",
      "[epoch: 1, batch:   1058] loss: 0.32794  | 0.18\n",
      "[epoch: 1, batch:   1060] loss: 0.94226  | 0.18\n",
      "[epoch: 1, batch:   1062] loss: 0.74382  | 0.18\n",
      "[epoch: 1, batch:   1064] loss: 0.59798  | 0.18\n",
      "[epoch: 1, batch:   1066] loss: 0.26675  | 0.18\n",
      "[epoch: 1, batch:   1068] loss: 0.48951  | 0.18\n",
      "[epoch: 1, batch:   1070] loss: 0.25198  | 0.18\n",
      "[epoch: 1, batch:   1072] loss: 1.38223  | 0.18\n",
      "[epoch: 1, batch:   1074] loss: 0.62126  | 0.18\n",
      "[epoch: 1, batch:   1076] loss: 0.14238  | 0.18\n",
      "[epoch: 1, batch:   1078] loss: 0.33005  | 0.18\n",
      "[epoch: 1, batch:   1080] loss: 0.46241  | 0.18\n",
      "[epoch: 1, batch:   1082] loss: 0.87184  | 0.18\n",
      "[epoch: 1, batch:   1084] loss: 0.37736  | 0.18\n",
      "[epoch: 1, batch:   1086] loss: 0.05058  | 0.18\n",
      "[epoch: 1, batch:   1088] loss: 0.90158  | 0.18\n",
      "[epoch: 1, batch:   1090] loss: 0.64914  | 0.18\n",
      "[epoch: 1, batch:   1092] loss: 0.24728  | 0.18\n",
      "[epoch: 1, batch:   1094] loss: 0.47555  | 0.18\n",
      "[epoch: 1, batch:   1096] loss: 0.21141  | 0.18\n",
      "[epoch: 1, batch:   1098] loss: 1.00384  | 0.18\n",
      "[epoch: 1, batch:   1100] loss: 0.68450  | 0.18\n",
      "[epoch: 1, batch:   1102] loss: 0.27636  | 0.18\n",
      "[epoch: 1, batch:   1104] loss: 1.36156  | 0.18\n",
      "[epoch: 1, batch:   1106] loss: 0.32757  | 0.18\n",
      "[epoch: 1, batch:   1108] loss: 0.62049  | 0.18\n",
      "[epoch: 1, batch:   1110] loss: 0.90676  | 0.18\n",
      "[epoch: 1, batch:   1112] loss: 0.73534  | 0.18\n",
      "[epoch: 1, batch:   1114] loss: 1.07449  | 0.18\n",
      "[epoch: 1, batch:   1116] loss: 0.37170  | 0.18\n",
      "[epoch: 1, batch:   1118] loss: 0.80750  | 0.18\n",
      "[epoch: 1, batch:   1120] loss: 0.36232  | 0.18\n",
      "[epoch: 1, batch:   1122] loss: 0.32072  | 0.18\n",
      "[epoch: 1, batch:   1124] loss: 0.37776  | 0.18\n",
      "[epoch: 1, batch:   1126] loss: 0.28986  | 0.18\n",
      "[epoch: 1, batch:   1128] loss: 0.18341  | 0.18\n",
      "[epoch: 1, batch:   1130] loss: 0.76682  | 0.18\n",
      "[epoch: 1, batch:   1132] loss: 0.43706  | 0.18\n",
      "[epoch: 1, batch:   1134] loss: 0.72333  | 0.18\n",
      "[epoch: 1, batch:   1136] loss: 1.35069  | 0.18\n",
      "[epoch: 1, batch:   1138] loss: 0.49042  | 0.18\n",
      "[epoch: 1, batch:   1140] loss: 1.26883  | 0.18\n",
      "[epoch: 1, batch:   1142] loss: 0.70031  | 0.18\n",
      "[epoch: 1, batch:   1144] loss: 1.23969  | 0.18\n",
      "[epoch: 1, batch:   1146] loss: 0.62595  | 0.18\n",
      "[epoch: 1, batch:   1148] loss: 0.23717  | 0.18\n",
      "[epoch: 1, batch:   1150] loss: 0.18181  | 0.18\n",
      "[epoch: 1, batch:   1152] loss: 0.58297  | 0.18\n",
      "[epoch: 1, batch:   1154] loss: 0.65073  | 0.18\n",
      "[epoch: 1, batch:   1156] loss: 0.16942  | 0.18\n",
      "[epoch: 1, batch:   1158] loss: 0.54143  | 0.18\n",
      "[epoch: 1, batch:   1160] loss: 0.10558  | 0.18\n",
      "[epoch: 1, batch:   1162] loss: 0.21853  | 0.18\n",
      "[epoch: 1, batch:   1164] loss: 0.50319  | 0.18\n",
      "[epoch: 1, batch:   1166] loss: 0.10024  | 0.18\n",
      "[epoch: 1, batch:   1168] loss: 0.14437  | 0.18\n",
      "[epoch: 1, batch:   1170] loss: 0.47630  | 0.18\n",
      "[epoch: 1, batch:   1172] loss: 0.29570  | 0.18\n",
      "[epoch: 1, batch:   1174] loss: 0.27657  | 0.18\n",
      "[epoch: 1, batch:   1176] loss: 0.36264  | 0.18\n",
      "[epoch: 1, batch:   1178] loss: 1.46364  | 0.18\n",
      "[epoch: 1, batch:   1180] loss: 0.06792  | 0.18\n",
      "[epoch: 1, batch:   1182] loss: 0.47457  | 0.18\n",
      "[epoch: 1, batch:   1184] loss: 0.09263  | 0.18\n",
      "[epoch: 1, batch:   1186] loss: 1.25352  | 0.18\n",
      "[epoch: 1, batch:   1188] loss: 0.44034  | 0.18\n",
      "[epoch: 1, batch:   1190] loss: 0.93370  | 0.18\n",
      "[epoch: 1, batch:   1192] loss: 0.86249  | 0.18\n",
      "[epoch: 1, batch:   1194] loss: 0.10028  | 0.18\n",
      "[epoch: 1, batch:   1196] loss: 0.33624  | 0.18\n",
      "[epoch: 1, batch:   1198] loss: 0.22619  | 0.18\n",
      "[epoch: 1, batch:   1200] loss: 0.25769  | 0.18\n",
      "[epoch: 1, batch:   1202] loss: 0.63407  | 0.18\n",
      "[epoch: 1, batch:   1204] loss: 0.37568  | 0.18\n",
      "[epoch: 1, batch:   1206] loss: 0.15315  | 0.18\n",
      "[epoch: 1, batch:   1208] loss: 0.44355  | 0.18\n",
      "[epoch: 1, batch:   1210] loss: 0.07483  | 0.18\n",
      "[epoch: 1, batch:   1212] loss: 0.62495  | 0.18\n",
      "[epoch: 1, batch:   1214] loss: 0.47827  | 0.18\n",
      "[epoch: 1, batch:   1216] loss: 0.37664  | 0.18\n",
      "[epoch: 1, batch:   1218] loss: 0.20682  | 0.18\n",
      "[epoch: 1, batch:   1220] loss: 1.04665  | 0.18\n",
      "[epoch: 1, batch:   1222] loss: 0.15381  | 0.18\n",
      "[epoch: 1, batch:   1224] loss: 0.38553  | 0.18\n",
      "[epoch: 1, batch:   1226] loss: 0.65952  | 0.18\n",
      "[epoch: 1, batch:   1228] loss: 0.14124  | 0.18\n",
      "[epoch: 1, batch:   1230] loss: 0.21466  | 0.18\n",
      "[epoch: 1, batch:   1232] loss: 0.35042  | 0.18\n",
      "[epoch: 1, batch:   1234] loss: 0.19843  | 0.18\n",
      "[epoch: 1, batch:   1236] loss: 0.67152  | 0.18\n",
      "[epoch: 1, batch:   1238] loss: 0.86296  | 0.18\n",
      "[epoch: 1, batch:   1240] loss: 0.05542  | 0.18\n",
      "[epoch: 1, batch:   1242] loss: 0.06030  | 0.18\n",
      "[epoch: 1, batch:   1244] loss: 1.05491  | 0.18\n",
      "[epoch: 1, batch:   1246] loss: 1.19283  | 0.18\n",
      "[epoch: 1, batch:   1248] loss: 0.54143  | 0.18\n",
      "[epoch: 1, batch:   1250] loss: 0.08246  | 0.18\n",
      "[epoch: 1, batch:   1252] loss: 0.31718  | 0.18\n",
      "[epoch: 1, batch:   1254] loss: 0.84367  | 0.18\n",
      "[epoch: 1, batch:   1256] loss: 0.24292  | 0.18\n",
      "[epoch: 1, batch:   1258] loss: 0.35598  | 0.18\n",
      "[epoch: 1, batch:   1260] loss: 0.26602  | 0.18\n",
      "[epoch: 1, batch:   1262] loss: 0.66973  | 0.18\n",
      "[epoch: 1, batch:   1264] loss: 0.12934  | 0.18\n",
      "[epoch: 1, batch:   1266] loss: 0.16949  | 0.18\n",
      "[epoch: 1, batch:   1268] loss: 0.39389  | 0.18\n",
      "[epoch: 1, batch:   1270] loss: 0.81559  | 0.18\n",
      "[epoch: 1, batch:   1272] loss: 0.29387  | 0.18\n",
      "[epoch: 1, batch:   1274] loss: 0.78131  | 0.18\n",
      "[epoch: 1, batch:   1276] loss: 0.40935  | 0.18\n",
      "[epoch: 1, batch:   1278] loss: 0.62091  | 0.18\n",
      "[epoch: 1, batch:   1280] loss: 0.35185  | 0.18\n",
      "[epoch: 1, batch:   1282] loss: 0.24682  | 0.18\n",
      "[epoch: 1, batch:   1284] loss: 0.40328  | 0.18\n",
      "[epoch: 1, batch:   1286] loss: 0.71977  | 0.18\n",
      "[epoch: 1, batch:   1288] loss: 0.55374  | 0.18\n",
      "[epoch: 1, batch:   1290] loss: 0.35190  | 0.18\n",
      "[epoch: 1, batch:   1292] loss: 0.13687  | 0.18\n",
      "[epoch: 1, batch:   1294] loss: 0.27343  | 0.18\n",
      "[epoch: 1, batch:   1296] loss: 0.38897  | 0.18\n",
      "[epoch: 1, batch:   1298] loss: 0.19899  | 0.18\n",
      "[epoch: 1, batch:   1300] loss: 0.29829  | 0.18\n",
      "[epoch: 1, batch:   1302] loss: 0.30940  | 0.18\n",
      "[epoch: 1, batch:   1304] loss: 0.41943  | 0.18\n",
      "[epoch: 1, batch:   1306] loss: 0.44745  | 0.18\n",
      "[epoch: 1, batch:   1308] loss: 0.40911  | 0.18\n",
      "[epoch: 1, batch:   1310] loss: 0.54597  | 0.18\n",
      "[epoch: 1, batch:   1312] loss: 0.08511  | 0.18\n",
      "[epoch: 1, batch:   1314] loss: 1.16722  | 0.18\n",
      "[epoch: 1, batch:   1316] loss: 0.55873  | 0.18\n",
      "[epoch: 1, batch:   1318] loss: 0.57202  | 0.18\n",
      "[epoch: 1, batch:   1320] loss: 0.20343  | 0.18\n",
      "[epoch: 1, batch:   1322] loss: 0.33347  | 0.18\n",
      "[epoch: 1, batch:   1324] loss: 0.20361  | 0.18\n",
      "[epoch: 1, batch:   1326] loss: 0.64790  | 0.18\n",
      "[epoch: 1, batch:   1328] loss: 0.83864  | 0.18\n",
      "[epoch: 1, batch:   1330] loss: 0.49597  | 0.18\n",
      "[epoch: 1, batch:   1332] loss: 0.47738  | 0.18\n",
      "[epoch: 1, batch:   1334] loss: 0.90230  | 0.18\n",
      "[epoch: 1, batch:   1336] loss: 0.19657  | 0.18\n",
      "[epoch: 1, batch:   1338] loss: 0.88575  | 0.18\n",
      "[epoch: 1, batch:   1340] loss: 0.81811  | 0.18\n",
      "[epoch: 1, batch:   1342] loss: 0.33637  | 0.18\n",
      "[epoch: 1, batch:   1344] loss: 0.55320  | 0.18\n",
      "[epoch: 1, batch:   1346] loss: 0.51484  | 0.18\n",
      "[epoch: 1, batch:   1348] loss: 0.45569  | 0.18\n",
      "[epoch: 1, batch:   1350] loss: 0.63065  | 0.18\n",
      "[epoch: 1, batch:   1352] loss: 0.30605  | 0.18\n",
      "[epoch: 1, batch:   1354] loss: 0.11762  | 0.18\n",
      "[epoch: 1, batch:   1356] loss: 0.66514  | 0.18\n",
      "[epoch: 1, batch:   1358] loss: 0.39003  | 0.18\n",
      "[epoch: 1, batch:   1360] loss: 0.64679  | 0.18\n",
      "[epoch: 1, batch:   1362] loss: 0.34201  | 0.18\n",
      "[epoch: 1, batch:   1364] loss: 0.62639  | 0.18\n",
      "[epoch: 1, batch:   1366] loss: 0.27509  | 0.18\n",
      "[epoch: 1, batch:   1368] loss: 0.36091  | 0.18\n",
      "[epoch: 1, batch:   1370] loss: 0.42153  | 0.18\n",
      "[epoch: 1, batch:   1372] loss: 0.27411  | 0.18\n",
      "[epoch: 1, batch:   1374] loss: 0.40905  | 0.18\n",
      "[epoch: 1, batch:   1376] loss: 0.61444  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch:   1378] loss: 0.92520  | 0.18\n",
      "[epoch: 1, batch:   1380] loss: 0.36455  | 0.18\n",
      "[epoch: 1, batch:   1382] loss: 0.18323  | 0.18\n",
      "[epoch: 1, batch:   1384] loss: 0.24614  | 0.18\n",
      "[epoch: 1, batch:   1386] loss: 0.28829  | 0.18\n",
      "[epoch: 1, batch:   1388] loss: 0.66898  | 0.18\n",
      "[epoch: 1, batch:   1390] loss: 0.47189  | 0.18\n",
      "[epoch: 1, batch:   1392] loss: 0.34402  | 0.18\n",
      "[epoch: 1, batch:   1394] loss: 0.16135  | 0.18\n",
      "[epoch: 1, batch:   1396] loss: 0.56814  | 0.18\n",
      "[epoch: 1, batch:   1398] loss: 0.04072  | 0.18\n",
      "[epoch: 1, batch:   1400] loss: 0.61122  | 0.18\n",
      "[epoch: 1, batch:   1402] loss: 0.40381  | 0.18\n",
      "[epoch: 1, batch:   1404] loss: 0.38727  | 0.18\n",
      "[epoch: 1, batch:   1406] loss: 0.69135  | 0.18\n",
      "[epoch: 1, batch:   1408] loss: 0.90668  | 0.18\n",
      "[epoch: 1, batch:   1410] loss: 0.85228  | 0.18\n",
      "[epoch: 1, batch:   1412] loss: 0.60331  | 0.18\n",
      "[epoch: 1, batch:   1414] loss: 0.47959  | 0.18\n",
      "[epoch: 1, batch:   1416] loss: 0.35140  | 0.18\n",
      "[epoch: 1, batch:   1418] loss: 0.30645  | 0.18\n",
      "[epoch: 1, batch:   1420] loss: 0.53407  | 0.18\n",
      "[epoch: 1, batch:   1422] loss: 0.80978  | 0.18\n",
      "[epoch: 1, batch:   1424] loss: 0.73427  | 0.18\n",
      "[epoch: 1, batch:   1426] loss: 0.54587  | 0.18\n",
      "[epoch: 1, batch:   1428] loss: 0.18779  | 0.18\n",
      "[epoch: 1, batch:   1430] loss: 0.88168  | 0.18\n",
      "[epoch: 1, batch:   1432] loss: 0.44129  | 0.18\n",
      "[epoch: 1, batch:   1434] loss: 0.16858  | 0.18\n",
      "[epoch: 1, batch:   1436] loss: 0.34177  | 0.18\n",
      "[epoch: 1, batch:   1438] loss: 0.20301  | 0.18\n",
      "[epoch: 1, batch:   1440] loss: 0.21632  | 0.18\n",
      "[epoch: 1, batch:   1442] loss: 0.98994  | 0.18\n",
      "[epoch: 1, batch:   1444] loss: 0.32370  | 0.18\n",
      "[epoch: 1, batch:   1446] loss: 0.07904  | 0.18\n",
      "[epoch: 1, batch:   1448] loss: 0.75280  | 0.18\n",
      "[epoch: 1, batch:   1450] loss: 0.66773  | 0.18\n",
      "[epoch: 1, batch:   1452] loss: 0.10910  | 0.18\n",
      "[epoch: 1, batch:   1454] loss: 0.31187  | 0.18\n",
      "[epoch: 1, batch:   1456] loss: 0.52924  | 0.18\n",
      "[epoch: 1, batch:   1458] loss: 1.77655  | 0.18\n",
      "[epoch: 1, batch:   1460] loss: 0.69476  | 0.18\n",
      "[epoch: 1, batch:   1462] loss: 0.15471  | 0.18\n",
      "[epoch: 1, batch:   1464] loss: 0.08119  | 0.18\n",
      "[epoch: 1, batch:   1466] loss: 0.39161  | 0.18\n",
      "[epoch: 1, batch:   1468] loss: 0.75029  | 0.18\n",
      "[epoch: 1, batch:   1470] loss: 0.19905  | 0.18\n",
      "[epoch: 1, batch:   1472] loss: 0.48276  | 0.18\n",
      "[epoch: 1, batch:   1474] loss: 0.82421  | 0.18\n",
      "[epoch: 1, batch:   1476] loss: 0.47993  | 0.18\n",
      "[epoch: 1, batch:   1478] loss: 0.50151  | 0.18\n",
      "[epoch: 1, batch:   1480] loss: 0.62804  | 0.18\n",
      "[epoch: 1, batch:   1482] loss: 0.11374  | 0.18\n",
      "[epoch: 1, batch:   1484] loss: 0.18572  | 0.18\n",
      "[epoch: 1, batch:   1486] loss: 0.44800  | 0.18\n",
      "[epoch: 1, batch:   1488] loss: 0.75969  | 0.18\n",
      "[epoch: 1, batch:   1490] loss: 0.16427  | 0.18\n",
      "[epoch: 1, batch:   1492] loss: 0.15934  | 0.18\n",
      "[epoch: 1, batch:   1494] loss: 0.73611  | 0.18\n",
      "[epoch: 1, batch:   1496] loss: 1.16970  | 0.18\n",
      "[epoch: 1, batch:   1498] loss: 0.95596  | 0.18\n",
      "[epoch: 1, batch:   1500] loss: 0.41681  | 0.18\n",
      "[epoch: 1, batch:   1502] loss: 0.74249  | 0.18\n",
      "[epoch: 1, batch:   1504] loss: 0.03702  | 0.18\n",
      "[epoch: 1, batch:   1506] loss: 0.11801  | 0.18\n",
      "[epoch: 1, batch:   1508] loss: 0.23570  | 0.18\n",
      "[epoch: 1, batch:   1510] loss: 0.37912  | 0.18\n",
      "[epoch: 1, batch:   1512] loss: 0.24798  | 0.18\n",
      "[epoch: 1, batch:   1514] loss: 0.21058  | 0.18\n",
      "[epoch: 1, batch:   1516] loss: 0.85166  | 0.18\n",
      "[epoch: 1, batch:   1518] loss: 0.85130  | 0.18\n",
      "[epoch: 1, batch:   1520] loss: 0.36051  | 0.18\n",
      "[epoch: 1, batch:   1522] loss: 0.29683  | 0.18\n",
      "[epoch: 1, batch:   1524] loss: 0.26411  | 0.18\n",
      "[epoch: 1, batch:   1526] loss: 2.12728  | 0.18\n",
      "[epoch: 1, batch:   1528] loss: 0.27249  | 0.18\n",
      "[epoch: 1, batch:   1530] loss: 0.29299  | 0.18\n",
      "[epoch: 1, batch:   1532] loss: 0.98198  | 0.18\n",
      "[epoch: 1, batch:   1534] loss: 0.05279  | 0.18\n",
      "[epoch: 1, batch:   1536] loss: 0.55435  | 0.18\n",
      "[epoch: 1, batch:   1538] loss: 0.32993  | 0.18\n",
      "[epoch: 1, batch:   1540] loss: 0.18551  | 0.18\n",
      "[epoch: 1, batch:   1542] loss: 0.87693  | 0.18\n",
      "[epoch: 1, batch:   1544] loss: 0.36040  | 0.18\n",
      "[epoch: 1, batch:   1546] loss: 0.48070  | 0.18\n",
      "[epoch: 1, batch:   1548] loss: 0.12242  | 0.18\n",
      "[epoch: 1, batch:   1550] loss: 0.22725  | 0.18\n",
      "[epoch: 1, batch:   1552] loss: 0.11415  | 0.18\n",
      "[epoch: 1, batch:   1554] loss: 0.98054  | 0.18\n",
      "[epoch: 1, batch:   1556] loss: 0.41498  | 0.18\n",
      "[epoch: 1, batch:   1558] loss: 0.04652  | 0.18\n",
      "[epoch: 1, batch:   1560] loss: 0.85170  | 0.18\n",
      "[epoch: 1, batch:   1562] loss: 0.31200  | 0.18\n",
      "[epoch: 1, batch:   1564] loss: 0.56088  | 0.18\n",
      "[epoch: 1, batch:   1566] loss: 0.27611  | 0.18\n",
      "[epoch: 1, batch:   1568] loss: 0.99642  | 0.18\n",
      "[epoch: 1, batch:   1570] loss: 0.39305  | 0.18\n",
      "[epoch: 1, batch:   1572] loss: 0.47338  | 0.18\n",
      "[epoch: 1, batch:   1574] loss: 0.64869  | 0.18\n",
      "[epoch: 1, batch:   1576] loss: 0.52363  | 0.18\n",
      "[epoch: 1, batch:   1578] loss: 0.23335  | 0.18\n",
      "[epoch: 1, batch:   1580] loss: 0.98992  | 0.18\n",
      "[epoch: 1, batch:   1582] loss: 0.41416  | 0.18\n",
      "[epoch: 1, batch:   1584] loss: 0.30659  | 0.18\n",
      "[epoch: 1, batch:   1586] loss: 0.34725  | 0.18\n",
      "[epoch: 1, batch:   1588] loss: 1.13891  | 0.18\n",
      "[epoch: 1, batch:   1590] loss: 0.59343  | 0.18\n",
      "[epoch: 1, batch:   1592] loss: 0.54010  | 0.18\n",
      "[epoch: 1, batch:   1594] loss: 0.40222  | 0.18\n",
      "[epoch: 1, batch:   1596] loss: 0.04671  | 0.18\n",
      "[epoch: 1, batch:   1598] loss: 0.95871  | 0.18\n",
      "[epoch: 1, batch:   1600] loss: 0.35804  | 0.18\n",
      "[epoch: 1, batch:   1602] loss: 0.27112  | 0.18\n",
      "[epoch: 1, batch:   1604] loss: 0.42058  | 0.18\n",
      "[epoch: 1, batch:   1606] loss: 0.37014  | 0.18\n",
      "[epoch: 1, batch:   1608] loss: 0.12977  | 0.18\n",
      "[epoch: 1, batch:   1610] loss: 0.40431  | 0.18\n",
      "[epoch: 1, batch:   1612] loss: 0.10958  | 0.18\n",
      "[epoch: 1, batch:   1614] loss: 0.45656  | 0.18\n",
      "[epoch: 1, batch:   1616] loss: 0.33960  | 0.18\n",
      "[epoch: 1, batch:   1618] loss: 0.83792  | 0.18\n",
      "[epoch: 1, batch:   1620] loss: 0.63625  | 0.18\n",
      "[epoch: 1, batch:   1622] loss: 2.05352  | 0.18\n",
      "[epoch: 1, batch:   1624] loss: 0.09796  | 0.18\n",
      "[epoch: 1, batch:   1626] loss: 0.22541  | 0.18\n",
      "[epoch: 1, batch:   1628] loss: 0.51651  | 0.18\n",
      "[epoch: 1, batch:   1630] loss: 0.93895  | 0.18\n",
      "[epoch: 1, batch:   1632] loss: 0.27176  | 0.18\n",
      "[epoch: 1, batch:   1634] loss: 0.03057  | 0.18\n",
      "[epoch: 1, batch:   1636] loss: 0.27536  | 0.18\n",
      "[epoch: 1, batch:   1638] loss: 0.37593  | 0.18\n",
      "[epoch: 1, batch:   1640] loss: 0.14682  | 0.18\n",
      "[epoch: 1, batch:   1642] loss: 0.33476  | 0.18\n",
      "[epoch: 1, batch:   1644] loss: 1.84949  | 0.18\n",
      "[epoch: 1, batch:   1646] loss: 0.62199  | 0.18\n",
      "[epoch: 1, batch:   1648] loss: 0.40943  | 0.18\n",
      "[epoch: 1, batch:   1650] loss: 0.38683  | 0.18\n",
      "[epoch: 1, batch:   1652] loss: 0.15587  | 0.18\n",
      "[epoch: 1, batch:   1654] loss: 0.18872  | 0.18\n",
      "[epoch: 1, batch:   1656] loss: 0.63046  | 0.18\n",
      "[epoch: 1, batch:   1658] loss: 1.92530  | 0.18\n",
      "[epoch: 1, batch:   1660] loss: 0.58788  | 0.18\n",
      "[epoch: 1, batch:   1662] loss: 0.68315  | 0.18\n",
      "[epoch: 1, batch:   1664] loss: 0.64371  | 0.18\n",
      "[epoch: 1, batch:   1666] loss: 0.31377  | 0.18\n",
      "[epoch: 1, batch:   1668] loss: 0.26179  | 0.18\n",
      "[epoch: 1, batch:   1670] loss: 0.13375  | 0.18\n",
      "[epoch: 1, batch:   1672] loss: 0.40891  | 0.18\n",
      "[epoch: 1, batch:   1674] loss: 0.12449  | 0.18\n",
      "[epoch: 1, batch:   1676] loss: 0.35811  | 0.18\n",
      "[epoch: 1, batch:   1678] loss: 0.55569  | 0.18\n",
      "[epoch: 1, batch:   1680] loss: 0.31098  | 0.18\n",
      "[epoch: 1, batch:   1682] loss: 0.16309  | 0.18\n",
      "[epoch: 1, batch:   1684] loss: 0.40868  | 0.18\n",
      "[epoch: 1, batch:   1686] loss: 0.17277  | 0.18\n",
      "[epoch: 1, batch:   1688] loss: 0.04206  | 0.18\n",
      "[epoch: 1, batch:   1690] loss: 0.48019  | 0.18\n",
      "[epoch: 1, batch:   1692] loss: 0.19650  | 0.18\n",
      "[epoch: 1, batch:   1694] loss: 0.55958  | 0.18\n",
      "[epoch: 1, batch:   1696] loss: 0.33088  | 0.18\n",
      "[epoch: 1, batch:   1698] loss: 0.92494  | 0.18\n",
      "[epoch: 1, batch:   1700] loss: 0.40336  | 0.18\n",
      "[epoch: 1, batch:   1702] loss: 0.50129  | 0.18\n",
      "[epoch: 1, batch:   1704] loss: 0.18002  | 0.18\n",
      "[epoch: 1, batch:   1706] loss: 1.02217  | 0.18\n",
      "[epoch: 1, batch:   1708] loss: 0.50257  | 0.18\n",
      "[epoch: 1, batch:   1710] loss: 1.04487  | 0.18\n",
      "[epoch: 1, batch:   1712] loss: 0.05938  | 0.18\n",
      "[epoch: 1, batch:   1714] loss: 0.94923  | 0.18\n",
      "[epoch: 1, batch:   1716] loss: 0.38180  | 0.18\n",
      "[epoch: 1, batch:   1718] loss: 0.67697  | 0.18\n",
      "[epoch: 1, batch:   1720] loss: 0.43239  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch:   1722] loss: 1.84868  | 0.18\n",
      "[epoch: 1, batch:   1724] loss: 0.75443  | 0.18\n",
      "[epoch: 1, batch:   1726] loss: 0.25667  | 0.18\n",
      "[epoch: 1, batch:   1728] loss: 0.50326  | 0.18\n",
      "[epoch: 1, batch:   1730] loss: 0.38420  | 0.18\n",
      "[epoch: 1, batch:   1732] loss: 0.80491  | 0.18\n",
      "[epoch: 1, batch:   1734] loss: 0.46960  | 0.18\n",
      "[epoch: 1, batch:   1736] loss: 0.17730  | 0.18\n",
      "[epoch: 1, batch:   1738] loss: 0.80299  | 0.18\n",
      "[epoch: 1, batch:   1740] loss: 0.72112  | 0.18\n",
      "[epoch: 1, batch:   1742] loss: 0.40192  | 0.18\n",
      "[epoch: 1, batch:   1744] loss: 1.28641  | 0.18\n",
      "[epoch: 1, batch:   1746] loss: 0.42760  | 0.18\n",
      "[epoch: 1, batch:   1748] loss: 0.23525  | 0.18\n",
      "[epoch: 1, batch:   1750] loss: 0.26891  | 0.18\n",
      "[epoch: 1, batch:   1752] loss: 0.32569  | 0.18\n",
      "[epoch: 1, batch:   1754] loss: 0.10604  | 0.18\n",
      "[epoch: 1, batch:   1756] loss: 0.37827  | 0.18\n",
      "[epoch: 1, batch:   1758] loss: 0.21992  | 0.18\n",
      "[epoch: 1, batch:   1760] loss: 0.74746  | 0.18\n",
      "[epoch: 1, batch:   1762] loss: 0.00823  | 0.18\n",
      "[epoch: 1, batch:   1764] loss: 0.29774  | 0.18\n",
      "[epoch: 1, batch:   1766] loss: 0.55878  | 0.18\n",
      "[epoch: 1, batch:   1768] loss: 0.25917  | 0.18\n",
      "[epoch: 1, batch:   1770] loss: 0.49602  | 0.18\n",
      "[epoch: 1, batch:   1772] loss: 0.32646  | 0.18\n",
      "[epoch: 1, batch:   1774] loss: 0.60727  | 0.18\n",
      "[epoch: 1, batch:   1776] loss: 0.55167  | 0.18\n",
      "[epoch: 1, batch:   1778] loss: 0.27695  | 0.18\n",
      "[epoch: 1, batch:   1780] loss: 0.14962  | 0.18\n",
      "[epoch: 1, batch:   1782] loss: 0.12730  | 0.18\n",
      "[epoch: 1, batch:   1784] loss: 0.19958  | 0.18\n",
      "[epoch: 1, batch:   1786] loss: 0.44878  | 0.18\n",
      "[epoch: 1, batch:   1788] loss: 0.35934  | 0.18\n",
      "[epoch: 1, batch:   1790] loss: 0.18245  | 0.18\n",
      "[epoch: 1, batch:   1792] loss: 1.19081  | 0.18\n",
      "[epoch: 1, batch:   1794] loss: 0.32626  | 0.18\n",
      "[epoch: 1, batch:   1796] loss: 0.09752  | 0.18\n",
      "[epoch: 1, batch:   1798] loss: 1.14537  | 0.18\n",
      "[epoch: 1, batch:   1800] loss: 0.15860  | 0.18\n",
      "[epoch: 1, batch:   1802] loss: 0.17169  | 0.18\n",
      "[epoch: 1, batch:   1804] loss: 0.41149  | 0.18\n",
      "[epoch: 1, batch:   1806] loss: 0.50964  | 0.18\n",
      "[epoch: 1, batch:   1808] loss: 0.18354  | 0.18\n",
      "[epoch: 1, batch:   1810] loss: 0.88160  | 0.18\n",
      "[epoch: 1, batch:   1812] loss: 0.11333  | 0.18\n",
      "[epoch: 1, batch:   1814] loss: 0.27405  | 0.18\n",
      "[epoch: 1, batch:   1816] loss: 0.29979  | 0.18\n",
      "[epoch: 1, batch:   1818] loss: 0.89599  | 0.18\n",
      "[epoch: 1, batch:   1820] loss: 0.74062  | 0.18\n",
      "[epoch: 1, batch:   1822] loss: 0.92368  | 0.18\n",
      "[epoch: 1, batch:   1824] loss: 0.38938  | 0.18\n",
      "[epoch: 1, batch:   1826] loss: 0.21415  | 0.18\n",
      "[epoch: 1, batch:   1828] loss: 0.11223  | 0.18\n",
      "[epoch: 1, batch:   1830] loss: 0.75189  | 0.18\n",
      "[epoch: 1, batch:   1832] loss: 0.10434  | 0.18\n",
      "[epoch: 1, batch:   1834] loss: 0.54747  | 0.18\n",
      "[epoch: 1, batch:   1836] loss: 0.87041  | 0.18\n",
      "[epoch: 1, batch:   1838] loss: 0.15137  | 0.18\n",
      "[epoch: 1, batch:   1840] loss: 0.36916  | 0.18\n",
      "[epoch: 1, batch:   1842] loss: 0.48603  | 0.18\n",
      "[epoch: 1, batch:   1844] loss: 0.33316  | 0.18\n",
      "[epoch: 1, batch:   1846] loss: 0.57839  | 0.18\n",
      "[epoch: 1, batch:   1848] loss: 0.33967  | 0.18\n",
      "[epoch: 1, batch:   1850] loss: 1.54005  | 0.18\n",
      "[epoch: 1, batch:   1852] loss: 0.25571  | 0.18\n",
      "[epoch: 1, batch:   1854] loss: 0.03326  | 0.18\n",
      "[epoch: 1, batch:   1856] loss: 0.33453  | 0.18\n",
      "[epoch: 1, batch:   1858] loss: 0.69305  | 0.18\n",
      "[epoch: 1, batch:   1860] loss: 0.50267  | 0.18\n",
      "[epoch: 1, batch:   1862] loss: 0.72723  | 0.18\n",
      "[epoch: 1, batch:   1864] loss: 0.68762  | 0.18\n",
      "[epoch: 1, batch:   1866] loss: 0.66949  | 0.18\n",
      "[epoch: 1, batch:   1868] loss: 0.24898  | 0.18\n",
      "[epoch: 1, batch:   1870] loss: 0.20694  | 0.18\n",
      "[epoch: 1, batch:   1872] loss: 0.65395  | 0.18\n",
      "[epoch: 1, batch:   1874] loss: 0.85279  | 0.18\n",
      "[epoch: 1, batch:   1876] loss: 0.31881  | 0.18\n",
      "[epoch: 1, batch:   1878] loss: 0.15328  | 0.18\n",
      "[epoch: 1, batch:   1880] loss: 0.24788  | 0.18\n",
      "[epoch: 1, batch:   1882] loss: 0.44501  | 0.18\n",
      "[epoch: 1, batch:   1884] loss: 0.22777  | 0.18\n",
      "[epoch: 1, batch:   1886] loss: 0.94337  | 0.18\n",
      "[epoch: 1, batch:   1888] loss: 0.36518  | 0.18\n",
      "[epoch: 1, batch:   1890] loss: 0.26480  | 0.18\n",
      "[epoch: 1, batch:   1892] loss: 0.10417  | 0.18\n",
      "[epoch: 1, batch:   1894] loss: 1.10520  | 0.18\n",
      "[epoch: 1, batch:   1896] loss: 0.64715  | 0.18\n",
      "[epoch: 1, batch:   1898] loss: 0.97625  | 0.18\n",
      "[epoch: 1, batch:   1900] loss: 0.65641  | 0.18\n",
      "[epoch: 1, batch:   1902] loss: 0.50420  | 0.18\n",
      "[epoch: 1, batch:   1904] loss: 0.32762  | 0.18\n",
      "[epoch: 1, batch:   1906] loss: 0.40128  | 0.18\n",
      "[epoch: 1, batch:   1908] loss: 0.32290  | 0.18\n",
      "[epoch: 1, batch:   1910] loss: 0.45876  | 0.18\n",
      "[epoch: 1, batch:   1912] loss: 0.39097  | 0.18\n",
      "[epoch: 1, batch:   1914] loss: 0.25781  | 0.18\n",
      "[epoch: 1, batch:   1916] loss: 0.45428  | 0.18\n",
      "[epoch: 1, batch:   1918] loss: 0.35674  | 0.18\n",
      "[epoch: 1, batch:   1920] loss: 0.42705  | 0.18\n",
      "[epoch: 1, batch:   1922] loss: 0.48069  | 0.18\n",
      "[epoch: 1, batch:   1924] loss: 0.91731  | 0.18\n",
      "[epoch: 1, batch:   1926] loss: 0.44584  | 0.18\n",
      "[epoch: 1, batch:   1928] loss: 0.78416  | 0.18\n",
      "[epoch: 1, batch:   1930] loss: 0.36183  | 0.18\n",
      "[epoch: 1, batch:   1932] loss: 0.58504  | 0.18\n",
      "[epoch: 1, batch:   1934] loss: 0.10344  | 0.18\n",
      "[epoch: 1, batch:   1936] loss: 0.06444  | 0.18\n",
      "[epoch: 1, batch:   1938] loss: 0.68370  | 0.18\n",
      "[epoch: 1, batch:   1940] loss: 0.45655  | 0.18\n",
      "[epoch: 1, batch:   1942] loss: 1.19787  | 0.18\n",
      "[epoch: 1, batch:   1944] loss: 0.78953  | 0.18\n",
      "[epoch: 1, batch:   1946] loss: 0.42393  | 0.18\n",
      "[epoch: 1, batch:   1948] loss: 0.62420  | 0.18\n",
      "[epoch: 1, batch:   1950] loss: 0.62248  | 0.18\n",
      "[epoch: 1, batch:   1952] loss: 0.31760  | 0.18\n",
      "[epoch: 1, batch:   1954] loss: 0.30132  | 0.18\n",
      "[epoch: 1, batch:   1956] loss: 0.70778  | 0.18\n",
      "[epoch: 1, batch:   1958] loss: 0.66439  | 0.18\n",
      "[epoch: 1, batch:   1960] loss: 0.50597  | 0.18\n",
      "[epoch: 1, batch:   1962] loss: 0.45749  | 0.18\n",
      "[epoch: 1, batch:   1964] loss: 0.51628  | 0.18\n",
      "[epoch: 1, batch:   1966] loss: 0.45158  | 0.18\n",
      "[epoch: 1, batch:   1968] loss: 0.40415  | 0.18\n",
      "[epoch: 1, batch:   1970] loss: 1.13836  | 0.18\n",
      "[epoch: 1, batch:   1972] loss: 1.34552  | 0.18\n",
      "[epoch: 1, batch:   1974] loss: 0.58198  | 0.18\n",
      "[epoch: 1, batch:   1976] loss: 0.46051  | 0.18\n",
      "[epoch: 1, batch:   1978] loss: 0.07329  | 0.18\n",
      "[epoch: 1, batch:   1980] loss: 0.14910  | 0.18\n",
      "[epoch: 1, batch:   1982] loss: 0.32006  | 0.18\n",
      "[epoch: 1, batch:   1984] loss: 0.70012  | 0.18\n",
      "[epoch: 1, batch:   1986] loss: 0.21546  | 0.18\n",
      "[epoch: 1, batch:   1988] loss: 0.41448  | 0.18\n",
      "[epoch: 1, batch:   1990] loss: 0.12584  | 0.18\n",
      "[epoch: 1, batch:   1992] loss: 0.71199  | 0.18\n",
      "[epoch: 1, batch:   1994] loss: 0.56831  | 0.18\n",
      "[epoch: 1, batch:   1996] loss: 0.45160  | 0.18\n",
      "[epoch: 1, batch:   1998] loss: 0.14020  | 0.18\n",
      "[epoch: 1, batch:   2000] loss: 0.36285  | 0.18\n",
      "[epoch: 1, batch:   2002] loss: 0.79205  | 0.18\n",
      "[epoch: 1, batch:   2004] loss: 0.40024  | 0.18\n",
      "[epoch: 1, batch:   2006] loss: 1.67613  | 0.18\n",
      "[epoch: 1, batch:   2008] loss: 0.31156  | 0.18\n",
      "[epoch: 1, batch:   2010] loss: 0.56715  | 0.18\n",
      "[epoch: 1, batch:   2012] loss: 0.67319  | 0.18\n",
      "[epoch: 1, batch:   2014] loss: 0.52563  | 0.18\n",
      "[epoch: 1, batch:   2016] loss: 0.18183  | 0.18\n",
      "[epoch: 1, batch:   2018] loss: 0.41714  | 0.18\n",
      "[epoch: 1, batch:   2020] loss: 0.40769  | 0.18\n",
      "[epoch: 1, batch:   2022] loss: 0.14093  | 0.18\n",
      "[epoch: 1, batch:   2024] loss: 0.69544  | 0.18\n",
      "[epoch: 1, batch:   2026] loss: 0.32886  | 0.18\n",
      "[epoch: 1, batch:   2028] loss: 0.51401  | 0.18\n",
      "[epoch: 1, batch:   2030] loss: 0.70154  | 0.18\n",
      "[epoch: 1, batch:   2032] loss: 0.10707  | 0.18\n",
      "[epoch: 1, batch:   2034] loss: 0.64397  | 0.18\n",
      "[epoch: 1, batch:   2036] loss: 0.36815  | 0.18\n",
      "[epoch: 1, batch:   2038] loss: 0.84606  | 0.18\n",
      "[epoch: 1, batch:   2040] loss: 0.93448  | 0.18\n",
      "[epoch: 1, batch:   2042] loss: 1.06386  | 0.18\n",
      "[epoch: 1, batch:   2044] loss: 0.59867  | 0.18\n",
      "[epoch: 1, batch:   2046] loss: 0.43451  | 0.18\n",
      "[epoch: 1, batch:   2048] loss: 0.38822  | 0.18\n",
      "[epoch: 1, batch:   2050] loss: 0.16517  | 0.18\n",
      "[epoch: 1, batch:   2052] loss: 0.28841  | 0.18\n",
      "[epoch: 1, batch:   2054] loss: 0.04645  | 0.18\n",
      "[epoch: 1, batch:   2056] loss: 0.38432  | 0.18\n",
      "[epoch: 1, batch:   2058] loss: 0.18820  | 0.18\n",
      "[epoch: 1, batch:   2060] loss: 0.16537  | 0.18\n",
      "[epoch: 1, batch:   2062] loss: 0.33781  | 0.18\n",
      "[epoch: 1, batch:   2064] loss: 0.37175  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch:   2066] loss: 0.11701  | 0.18\n",
      "[epoch: 1, batch:   2068] loss: 0.59350  | 0.18\n",
      "[epoch: 1, batch:   2070] loss: 1.31149  | 0.18\n",
      "[epoch: 1, batch:   2072] loss: 0.36213  | 0.18\n",
      "[epoch: 1, batch:   2074] loss: 0.50664  | 0.18\n",
      "[epoch: 1, batch:   2076] loss: 0.44641  | 0.18\n",
      "[epoch: 1, batch:   2078] loss: 0.81781  | 0.18\n",
      "[epoch: 1, batch:   2080] loss: 0.67832  | 0.18\n",
      "[epoch: 1, batch:   2082] loss: 0.45060  | 0.18\n",
      "[epoch: 1, batch:   2084] loss: 0.42739  | 0.18\n",
      "[epoch: 1, batch:   2086] loss: 0.76070  | 0.18\n",
      "[epoch: 1, batch:   2088] loss: 0.30769  | 0.18\n",
      "[epoch: 1, batch:   2090] loss: 0.02937  | 0.18\n",
      "[epoch: 1, batch:   2092] loss: 0.39289  | 0.18\n",
      "[epoch: 1, batch:   2094] loss: 0.34909  | 0.18\n",
      "[epoch: 1, batch:   2096] loss: 0.19144  | 0.18\n",
      "[epoch: 1, batch:   2098] loss: 0.22837  | 0.18\n",
      "[epoch: 1, batch:   2100] loss: 0.31926  | 0.18\n",
      "[epoch: 1, batch:   2102] loss: 0.63583  | 0.18\n",
      "[epoch: 1, batch:   2104] loss: 0.24241  | 0.18\n",
      "[epoch: 1, batch:   2106] loss: 0.15515  | 0.18\n",
      "[epoch: 1, batch:   2108] loss: 0.34741  | 0.18\n",
      "[epoch: 1, batch:   2110] loss: 0.45660  | 0.18\n",
      "[epoch: 1, batch:   2112] loss: 0.45755  | 0.18\n",
      "[epoch: 1, batch:   2114] loss: 0.37111  | 0.18\n",
      "[epoch: 1, batch:   2116] loss: 0.39859  | 0.18\n",
      "[epoch: 1, batch:   2118] loss: 0.55411  | 0.18\n",
      "[epoch: 1, batch:   2120] loss: 0.38134  | 0.18\n",
      "[epoch: 1, batch:   2122] loss: 0.35904  | 0.18\n",
      "[epoch: 1, batch:   2124] loss: 0.45280  | 0.18\n",
      "[epoch: 1, batch:   2126] loss: 0.24096  | 0.18\n",
      "[epoch: 1, batch:   2128] loss: 0.50116  | 0.18\n",
      "[epoch: 1, batch:   2130] loss: 0.27537  | 0.18\n",
      "[epoch: 1, batch:   2132] loss: 0.37789  | 0.18\n",
      "[epoch: 1, batch:   2134] loss: 0.50589  | 0.18\n",
      "[epoch: 1, batch:   2136] loss: 0.41355  | 0.18\n",
      "[epoch: 1, batch:   2138] loss: 0.57723  | 0.18\n",
      "[epoch: 1, batch:   2140] loss: 0.55292  | 0.18\n",
      "[epoch: 1, batch:   2142] loss: 0.06582  | 0.18\n",
      "[epoch: 1, batch:   2144] loss: 0.61472  | 0.18\n",
      "[epoch: 1, batch:   2146] loss: 0.26679  | 0.18\n",
      "[epoch: 1, batch:   2148] loss: 0.19950  | 0.18\n",
      "[epoch: 1, batch:   2150] loss: 0.77516  | 0.18\n",
      "[epoch: 1, batch:   2152] loss: 0.58872  | 0.19\n",
      "[epoch: 1, batch:   2154] loss: 0.81229  | 0.18\n",
      "[epoch: 1, batch:   2156] loss: 0.32844  | 0.18\n",
      "[epoch: 1, batch:   2158] loss: 1.66051  | 0.18\n",
      "[epoch: 1, batch:   2160] loss: 1.15503  | 0.18\n",
      "[epoch: 1, batch:   2162] loss: 0.90390  | 0.18\n",
      "[epoch: 1, batch:   2164] loss: 0.57828  | 0.18\n",
      "[epoch: 1, batch:   2166] loss: 0.22500  | 0.18\n",
      "[epoch: 1, batch:   2168] loss: 0.33619  | 0.18\n",
      "[epoch: 1, batch:   2170] loss: 0.13723  | 0.18\n",
      "[epoch: 1, batch:   2172] loss: 0.43103  | 0.18\n",
      "[epoch: 1, batch:   2174] loss: 0.21043  | 0.19\n",
      "[epoch: 1, batch:   2176] loss: 0.65628  | 0.18\n",
      "[epoch: 1, batch:   2178] loss: 0.31415  | 0.18\n",
      "[epoch: 1, batch:   2180] loss: 0.40814  | 0.18\n",
      "[epoch: 1, batch:   2182] loss: 0.36305  | 0.18\n",
      "[epoch: 1, batch:   2184] loss: 0.63520  | 0.18\n",
      "[epoch: 1, batch:   2186] loss: 0.38482  | 0.18\n",
      "[epoch: 1, batch:   2188] loss: 0.29627  | 0.18\n",
      "[epoch: 1, batch:   2190] loss: 0.38108  | 0.18\n",
      "[epoch: 1, batch:   2192] loss: 0.42513  | 0.18\n",
      "[epoch: 1, batch:   2194] loss: 0.42961  | 0.18\n",
      "[epoch: 1, batch:   2196] loss: 0.93055  | 0.18\n",
      "[epoch: 1, batch:   2198] loss: 0.62378  | 0.18\n",
      "[epoch: 1, batch:   2200] loss: 0.17432  | 0.18\n",
      "[epoch: 1, batch:   2202] loss: 0.62719  | 0.18\n",
      "[epoch: 1, batch:   2204] loss: 0.56827  | 0.18\n",
      "[epoch: 1, batch:   2206] loss: 0.49484  | 0.18\n",
      "[epoch: 1, batch:   2208] loss: 0.08172  | 0.18\n",
      "[epoch: 1, batch:   2210] loss: 0.12449  | 0.18\n",
      "[epoch: 1, batch:   2212] loss: 0.27544  | 0.18\n",
      "[epoch: 1, batch:   2214] loss: 0.73920  | 0.18\n",
      "[epoch: 1, batch:   2216] loss: 0.20322  | 0.18\n",
      "[epoch: 1, batch:   2218] loss: 0.27627  | 0.18\n",
      "[epoch: 1, batch:   2220] loss: 0.04032  | 0.18\n",
      "[epoch: 1, batch:   2222] loss: 0.30714  | 0.18\n",
      "[epoch: 1, batch:   2224] loss: 0.86710  | 0.18\n",
      "[epoch: 1, batch:   2226] loss: 0.10932  | 0.18\n",
      "[epoch: 1, batch:   2228] loss: 0.49377  | 0.18\n",
      "[epoch: 1, batch:   2230] loss: 0.27398  | 0.18\n",
      "[epoch: 1, batch:   2232] loss: 0.59415  | 0.18\n",
      "[epoch: 1, batch:   2234] loss: 0.69332  | 0.18\n",
      "[epoch: 1, batch:   2236] loss: 0.06624  | 0.18\n",
      "[epoch: 1, batch:   2238] loss: 0.90538  | 0.18\n",
      "[epoch: 1, batch:   2240] loss: 1.25267  | 0.18\n",
      "[epoch: 1, batch:   2242] loss: 0.47015  | 0.18\n",
      "[epoch: 1, batch:   2244] loss: 0.67406  | 0.18\n",
      "[epoch: 1, batch:   2246] loss: 0.30053  | 0.18\n",
      "[epoch: 1, batch:   2248] loss: 0.53543  | 0.18\n",
      "[epoch: 1, batch:   2250] loss: 0.33754  | 0.18\n",
      "[epoch: 1, batch:   2252] loss: 0.76603  | 0.18\n",
      "[epoch: 1, batch:   2254] loss: 0.97091  | 0.18\n",
      "[epoch: 1, batch:   2256] loss: 0.53163  | 0.18\n",
      "[epoch: 1, batch:   2258] loss: 0.42269  | 0.18\n",
      "[epoch: 1, batch:   2260] loss: 1.00299  | 0.18\n",
      "[epoch: 1, batch:   2262] loss: 0.48332  | 0.18\n",
      "[epoch: 1, batch:   2264] loss: 0.58455  | 0.18\n",
      "[epoch: 1, batch:   2266] loss: 0.06788  | 0.18\n",
      "[epoch: 1, batch:   2268] loss: 0.64379  | 0.18\n",
      "[epoch: 1, batch:   2270] loss: 0.44092  | 0.18\n",
      "[epoch: 1, batch:   2272] loss: 0.65528  | 0.18\n",
      "[epoch: 1, batch:   2274] loss: 0.18090  | 0.18\n",
      "[epoch: 1, batch:   2276] loss: 0.47645  | 0.18\n",
      "[epoch: 1, batch:   2278] loss: 0.79413  | 0.18\n",
      "[epoch: 1, batch:   2280] loss: 0.56613  | 0.18\n",
      "[epoch: 1, batch:   2282] loss: 0.47734  | 0.18\n",
      "[epoch: 1, batch:   2284] loss: 0.73388  | 0.18\n",
      "[epoch: 1, batch:   2286] loss: 0.05783  | 0.18\n",
      "[epoch: 1, batch:   2288] loss: 0.23378  | 0.18\n",
      "[epoch: 1, batch:   2290] loss: 0.45831  | 0.18\n",
      "[epoch: 1, batch:   2292] loss: 1.03425  | 0.18\n",
      "[epoch: 1, batch:   2294] loss: 0.24669  | 0.18\n",
      "[epoch: 1, batch:   2296] loss: 0.28653  | 0.18\n",
      "[epoch: 1, batch:   2298] loss: 0.89044  | 0.18\n",
      "[epoch: 1, batch:   2300] loss: 0.46281  | 0.18\n",
      "[epoch: 1, batch:   2302] loss: 0.65854  | 0.18\n",
      "[epoch: 1, batch:   2304] loss: 0.15791  | 0.18\n",
      "[epoch: 1, batch:   2306] loss: 0.05940  | 0.18\n",
      "[epoch: 1, batch:   2308] loss: 0.63070  | 0.18\n",
      "[epoch: 1, batch:   2310] loss: 0.63803  | 0.18\n",
      "[epoch: 1, batch:   2312] loss: 0.37204  | 0.18\n",
      "[epoch: 1, batch:   2314] loss: 0.82232  | 0.18\n",
      "[epoch: 1, batch:   2316] loss: 0.89633  | 0.18\n",
      "[epoch: 1, batch:   2318] loss: 0.33188  | 0.18\n",
      "[epoch: 1, batch:   2320] loss: 0.58300  | 0.18\n",
      "[epoch: 1, batch:   2322] loss: 1.13396  | 0.18\n",
      "[epoch: 1, batch:   2324] loss: 0.55958  | 0.18\n",
      "[epoch: 1, batch:   2326] loss: 0.32971  | 0.18\n",
      "[epoch: 1, batch:   2328] loss: 0.91372  | 0.18\n",
      "[epoch: 1, batch:   2330] loss: 0.23546  | 0.19\n",
      "[epoch: 1, batch:   2332] loss: 0.18507  | 0.18\n",
      "[epoch: 1, batch:   2334] loss: 0.16540  | 0.18\n",
      "[epoch: 1, batch:   2336] loss: 0.25872  | 0.18\n",
      "[epoch: 1, batch:   2338] loss: 0.43125  | 0.18\n",
      "[epoch: 1, batch:   2340] loss: 1.34355  | 0.18\n",
      "[epoch: 1, batch:   2342] loss: 0.84989  | 0.18\n",
      "[epoch: 1, batch:   2344] loss: 0.24870  | 0.18\n",
      "[epoch: 1, batch:   2346] loss: 0.49437  | 0.18\n",
      "[epoch: 1, batch:   2348] loss: 0.19916  | 0.18\n",
      "[epoch: 1, batch:   2350] loss: 0.42434  | 0.18\n",
      "[epoch: 1, batch:   2352] loss: 1.22892  | 0.18\n",
      "[epoch: 1, batch:   2354] loss: 0.07425  | 0.18\n",
      "[epoch: 1, batch:   2356] loss: 0.33406  | 0.18\n",
      "[epoch: 1, batch:   2358] loss: 0.03985  | 0.18\n",
      "[epoch: 1, batch:   2360] loss: 0.58018  | 0.18\n",
      "[epoch: 1, batch:   2362] loss: 0.46324  | 0.18\n",
      "[epoch: 1, batch:   2364] loss: 0.68970  | 0.18\n",
      "[epoch: 1, batch:   2366] loss: 0.82203  | 0.18\n",
      "[epoch: 1, batch:   2368] loss: 0.28144  | 0.18\n",
      "[epoch: 1, batch:   2370] loss: 0.62765  | 0.18\n",
      "[epoch: 1, batch:   2372] loss: 0.58960  | 0.18\n",
      "[epoch: 1, batch:   2374] loss: 0.31248  | 0.18\n",
      "[epoch: 1, batch:   2376] loss: 0.01324  | 0.18\n",
      "[epoch: 1, batch:   2378] loss: 0.38881  | 0.18\n",
      "[epoch: 1, batch:   2380] loss: 0.32202  | 0.18\n",
      "[epoch: 1, batch:   2382] loss: 0.41663  | 0.18\n",
      "[epoch: 1, batch:   2384] loss: 0.13937  | 0.18\n",
      "[epoch: 1, batch:   2386] loss: 0.01344  | 0.19\n",
      "[epoch: 1, batch:   2388] loss: 0.53913  | 0.18\n",
      "[epoch: 1, batch:   2390] loss: 0.11274  | 0.18\n",
      "[epoch: 1, batch:   2392] loss: 0.07449  | 0.18\n",
      "[epoch: 1, batch:   2394] loss: 0.10617  | 0.18\n",
      "[epoch: 1, batch:   2396] loss: 0.75258  | 0.18\n",
      "[epoch: 1, batch:   2398] loss: 0.22524  | 0.18\n",
      "[epoch: 1, batch:   2400] loss: 0.62410  | 0.18\n",
      "[epoch: 1, batch:   2402] loss: 0.22309  | 0.18\n",
      "[epoch: 1, batch:   2404] loss: 0.70756  | 0.18\n",
      "[epoch: 1, batch:   2406] loss: 0.34101  | 0.18\n",
      "[epoch: 1, batch:   2408] loss: 0.18967  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch:   2410] loss: 0.14619  | 0.18\n",
      "[epoch: 1, batch:   2412] loss: 0.38102  | 0.18\n",
      "[epoch: 1, batch:   2414] loss: 0.36069  | 0.18\n",
      "[epoch: 1, batch:   2416] loss: 0.17332  | 0.18\n",
      "[epoch: 1, batch:   2418] loss: 0.18719  | 0.18\n",
      "[epoch: 1, batch:   2420] loss: 0.17833  | 0.18\n",
      "[epoch: 1, batch:   2422] loss: 0.65355  | 0.18\n",
      "[epoch: 1, batch:   2424] loss: 0.41555  | 0.18\n",
      "[epoch: 1, batch:   2426] loss: 0.12165  | 0.18\n",
      "[epoch: 1, batch:   2428] loss: 0.64732  | 0.18\n",
      "[epoch: 1, batch:   2430] loss: 0.65116  | 0.18\n",
      "[epoch: 1, batch:   2432] loss: 0.68059  | 0.18\n",
      "[epoch: 1, batch:   2434] loss: 0.15258  | 0.18\n",
      "[epoch: 1, batch:   2436] loss: 0.40214  | 0.18\n",
      "[epoch: 1, batch:   2438] loss: 0.04439  | 0.18\n",
      "[epoch: 1, batch:   2440] loss: 0.48688  | 0.18\n",
      "[epoch: 1, batch:   2442] loss: 0.58917  | 0.18\n",
      "[epoch: 1, batch:   2444] loss: 0.35610  | 0.18\n",
      "[epoch: 1, batch:   2446] loss: 0.75956  | 0.18\n",
      "[epoch: 1, batch:   2448] loss: 0.34132  | 0.18\n",
      "[epoch: 1, batch:   2450] loss: 0.37826  | 0.18\n",
      "[epoch: 1, batch:   2452] loss: 0.54020  | 0.18\n",
      "[epoch: 1, batch:   2454] loss: 0.74500  | 0.18\n",
      "[epoch: 1, batch:   2456] loss: 0.91048  | 0.18\n",
      "[epoch: 1, batch:   2458] loss: 0.31326  | 0.18\n",
      "[epoch: 1, batch:   2460] loss: 0.37406  | 0.18\n",
      "[epoch: 1, batch:   2462] loss: 0.15774  | 0.18\n",
      "[epoch: 1, batch:   2464] loss: 0.19534  | 0.18\n",
      "[epoch: 1, batch:   2466] loss: 0.34251  | 0.18\n",
      "[epoch: 1, batch:   2468] loss: 0.38464  | 0.18\n",
      "[epoch: 1, batch:   2470] loss: 0.35317  | 0.18\n",
      "[epoch: 1, batch:   2472] loss: 0.03690  | 0.18\n",
      "[epoch: 1, batch:   2474] loss: 0.35042  | 0.18\n",
      "[epoch: 1, batch:   2476] loss: 0.53747  | 0.18\n",
      "[epoch: 1, batch:   2478] loss: 1.61260  | 0.18\n",
      "[epoch: 1, batch:   2480] loss: 0.39209  | 0.18\n",
      "[epoch: 1, batch:   2482] loss: 0.60415  | 0.18\n",
      "[epoch: 1, batch:   2484] loss: 0.24067  | 0.18\n",
      "[epoch: 1, batch:   2486] loss: 0.59331  | 0.18\n",
      "[epoch: 1, batch:   2488] loss: 0.84496  | 0.18\n",
      "[epoch: 1, batch:   2490] loss: 0.21536  | 0.18\n",
      "[epoch: 1, batch:   2492] loss: 0.46913  | 0.18\n",
      "[epoch: 1, batch:   2494] loss: 0.39238  | 0.18\n",
      "[epoch: 1, batch:   2496] loss: 0.02916  | 0.18\n",
      "[epoch: 1, batch:   2498] loss: 0.21218  | 0.18\n",
      "[epoch: 1, batch:   2500] loss: 0.62908  | 0.18\n",
      "[epoch: 1, batch:   2502] loss: 0.90001  | 0.18\n",
      "[epoch: 1, batch:   2504] loss: 0.90808  | 0.18\n",
      "[epoch: 1, batch:   2506] loss: 0.41997  | 0.18\n",
      "[epoch: 1, batch:   2508] loss: 0.15770  | 0.18\n",
      "[epoch: 1, batch:   2510] loss: 0.46312  | 0.18\n",
      "[epoch: 1, batch:   2512] loss: 0.83293  | 0.18\n",
      "[epoch: 1, batch:   2514] loss: 0.06126  | 0.18\n",
      "[epoch: 1, batch:   2516] loss: 0.41525  | 0.18\n",
      "[epoch: 1, batch:   2518] loss: 0.42251  | 0.18\n",
      "[epoch: 1, batch:   2520] loss: 0.49974  | 0.18\n",
      "[epoch: 1, batch:   2522] loss: 0.60989  | 0.18\n",
      "[epoch: 1, batch:   2524] loss: 0.56393  | 0.18\n",
      "[epoch: 1, batch:   2526] loss: 0.89109  | 0.18\n",
      "[epoch: 1, batch:   2528] loss: 0.62385  | 0.18\n",
      "[epoch: 1, batch:   2530] loss: 0.50575  | 0.18\n",
      "[epoch: 1, batch:   2532] loss: 1.67068  | 0.18\n",
      "[epoch: 1, batch:   2534] loss: 0.26913  | 0.18\n",
      "[epoch: 1, batch:   2536] loss: 0.52674  | 0.18\n",
      "[epoch: 1, batch:   2538] loss: 0.02901  | 0.18\n",
      "[epoch: 1, batch:   2540] loss: 0.20851  | 0.18\n",
      "[epoch: 1, batch:   2542] loss: 0.01987  | 0.18\n",
      "[epoch: 1, batch:   2544] loss: 0.52963  | 0.18\n",
      "[epoch: 1, batch:   2546] loss: 0.31066  | 0.18\n",
      "[epoch: 1, batch:   2548] loss: 0.34912  | 0.18\n",
      "[epoch: 1, batch:   2550] loss: 0.63973  | 0.18\n",
      "[epoch: 1, batch:   2552] loss: 1.11869  | 0.18\n",
      "[epoch: 1, batch:   2554] loss: 0.44087  | 0.18\n",
      "[epoch: 1, batch:   2556] loss: 1.33305  | 0.18\n",
      "[epoch: 1, batch:   2558] loss: 0.34045  | 0.19\n",
      "[epoch: 1, batch:   2560] loss: 0.02192  | 0.18\n",
      "[epoch: 1, batch:   2562] loss: 0.17419  | 0.19\n",
      "[epoch: 1, batch:   2564] loss: 0.25648  | 0.18\n",
      "[epoch: 1, batch:   2566] loss: 0.39578  | 0.18\n",
      "[epoch: 1, batch:   2568] loss: 0.68096  | 0.18\n",
      "[epoch: 1, batch:   2570] loss: 0.78515  | 0.18\n",
      "[epoch: 1, batch:   2572] loss: 0.08791  | 0.18\n",
      "[epoch: 1, batch:   2574] loss: 0.05736  | 0.20\n",
      "[epoch: 1, batch:   2576] loss: 0.61020  | 0.20\n",
      "[epoch: 1, batch:   2578] loss: 0.20426  | 0.20\n",
      "[epoch: 1, batch:   2580] loss: 0.23782  | 0.20\n",
      "[epoch: 1, batch:   2582] loss: 0.85204  | 0.20\n",
      "[epoch: 1, batch:   2584] loss: 0.81310  | 0.18\n",
      "[epoch: 1, batch:   2586] loss: 1.09252  | 0.18\n",
      "[epoch: 1, batch:   2588] loss: 0.45550  | 0.18\n",
      "[epoch: 1, batch:   2590] loss: 0.59753  | 0.19\n",
      "[epoch: 1, batch:   2592] loss: 0.87652  | 0.18\n",
      "[epoch: 1, batch:   2594] loss: 0.65717  | 0.18\n",
      "[epoch: 1, batch:   2596] loss: 0.39385  | 0.18\n",
      "[epoch: 1, batch:   2598] loss: 0.24355  | 0.18\n",
      "[epoch: 1, batch:   2600] loss: 0.15676  | 0.18\n",
      "[epoch: 1, batch:   2602] loss: 0.33851  | 0.18\n",
      "[epoch: 1, batch:   2604] loss: 0.92606  | 0.18\n",
      "[epoch: 1, batch:   2606] loss: 0.52559  | 0.18\n",
      "[epoch: 1, batch:   2608] loss: 0.31943  | 0.19\n",
      "[epoch: 1, batch:   2610] loss: 0.53379  | 0.18\n",
      "[epoch: 1, batch:   2612] loss: 0.50628  | 0.18\n",
      "[epoch: 1, batch:   2614] loss: 0.10350  | 0.18\n",
      "[epoch: 1, batch:   2616] loss: 0.54480  | 0.18\n",
      "[epoch: 1, batch:   2618] loss: 0.31364  | 0.18\n",
      "[epoch: 1, batch:   2620] loss: 0.09965  | 0.18\n",
      "[epoch: 1, batch:   2622] loss: 0.27382  | 0.18\n",
      "[epoch: 1, batch:   2624] loss: 0.72282  | 0.18\n",
      "[epoch: 1, batch:   2626] loss: 0.43569  | 0.18\n",
      "[epoch: 1, batch:   2628] loss: 0.34172  | 0.18\n",
      "[epoch: 1, batch:   2630] loss: 0.75593  | 0.18\n",
      "[epoch: 1, batch:   2632] loss: 0.41553  | 0.18\n",
      "[epoch: 1, batch:   2634] loss: 0.45150  | 0.18\n",
      "[epoch: 1, batch:   2636] loss: 0.41164  | 0.18\n",
      "[epoch: 1, batch:   2638] loss: 0.14264  | 0.18\n",
      "[epoch: 1, batch:   2640] loss: 0.33841  | 0.18\n",
      "[epoch: 1, batch:   2642] loss: 0.42438  | 0.18\n",
      "[epoch: 1, batch:   2644] loss: 1.69245  | 0.18\n",
      "[epoch: 1, batch:   2646] loss: 0.82750  | 0.18\n",
      "[epoch: 1, batch:   2648] loss: 0.47424  | 0.18\n",
      "[epoch: 1, batch:   2650] loss: 0.37997  | 0.18\n",
      "[epoch: 1, batch:   2652] loss: 0.72712  | 0.18\n",
      "[epoch: 1, batch:   2654] loss: 0.39331  | 0.18\n",
      "[epoch: 1, batch:   2656] loss: 0.03643  | 0.18\n",
      "[epoch: 1, batch:   2658] loss: 0.52032  | 0.18\n",
      "[epoch: 1, batch:   2660] loss: 0.79455  | 0.18\n",
      "[epoch: 1, batch:   2662] loss: 1.02095  | 0.18\n",
      "[epoch: 1, batch:   2664] loss: 0.72164  | 0.18\n",
      "[epoch: 1, batch:   2666] loss: 0.53886  | 0.18\n",
      "[epoch: 1, batch:   2668] loss: 0.32521  | 0.18\n",
      "[epoch: 1, batch:   2670] loss: 0.31177  | 0.18\n",
      "[epoch: 1, batch:   2672] loss: 0.08657  | 0.18\n",
      "[epoch: 1, batch:   2674] loss: 0.15756  | 0.18\n",
      "[epoch: 1, batch:   2676] loss: 1.27553  | 0.18\n",
      "[epoch: 1, batch:   2678] loss: 0.39072  | 0.18\n",
      "[epoch: 1, batch:   2680] loss: 0.10206  | 0.18\n",
      "[epoch: 1, batch:   2682] loss: 0.49954  | 0.18\n",
      "[epoch: 1, batch:   2684] loss: 0.41114  | 0.18\n",
      "[epoch: 1, batch:   2686] loss: 1.01494  | 0.18\n",
      "[epoch: 1, batch:   2688] loss: 0.14319  | 0.18\n",
      "[epoch: 1, batch:   2690] loss: 0.26839  | 0.18\n",
      "[epoch: 1, batch:   2692] loss: 0.59909  | 0.18\n",
      "[epoch: 1, batch:   2694] loss: 0.23036  | 0.18\n",
      "[epoch: 1, batch:   2696] loss: 0.63338  | 0.18\n",
      "[epoch: 1, batch:   2698] loss: 0.74943  | 0.18\n",
      "[epoch: 1, batch:   2700] loss: 0.32503  | 0.18\n",
      "[epoch: 1, batch:   2702] loss: 0.30801  | 0.18\n",
      "[epoch: 1, batch:   2704] loss: 1.40146  | 0.18\n",
      "[epoch: 1, batch:   2706] loss: 0.14554  | 0.18\n",
      "[epoch: 1, batch:   2708] loss: 0.85967  | 0.18\n",
      "[epoch: 1, batch:   2710] loss: 0.40112  | 0.18\n",
      "[epoch: 1, batch:   2712] loss: 0.44565  | 0.18\n",
      "[epoch: 1, batch:   2714] loss: 0.11280  | 0.18\n",
      "[epoch: 1, batch:   2716] loss: 0.78557  | 0.18\n",
      "[epoch: 1, batch:   2718] loss: 0.28830  | 0.18\n",
      "[epoch: 1, batch:   2720] loss: 0.83533  | 0.18\n",
      "[epoch: 1, batch:   2722] loss: 1.08697  | 0.18\n",
      "[epoch: 1, batch:   2724] loss: 0.24643  | 0.18\n",
      "[epoch: 1, batch:   2726] loss: 0.29997  | 0.18\n",
      "[epoch: 1, batch:   2728] loss: 0.45449  | 0.18\n",
      "[epoch: 1, batch:   2730] loss: 0.64333  | 0.18\n",
      "[epoch: 1, batch:   2732] loss: 0.48709  | 0.18\n",
      "[epoch: 1, batch:   2734] loss: 0.55044  | 0.18\n",
      "[epoch: 1, batch:   2736] loss: 0.26793  | 0.18\n",
      "[epoch: 1, batch:   2738] loss: 1.09613  | 0.18\n",
      "[epoch: 1, batch:   2740] loss: 0.87661  | 0.18\n",
      "[epoch: 1, batch:   2742] loss: 0.20012  | 0.18\n",
      "[epoch: 1, batch:   2744] loss: 0.92616  | 0.18\n",
      "[epoch: 1, batch:   2746] loss: 0.10341  | 0.18\n",
      "[epoch: 1, batch:   2748] loss: 0.47576  | 0.18\n",
      "[epoch: 1, batch:   2750] loss: 0.29241  | 0.18\n",
      "[epoch: 1, batch:   2752] loss: 0.30785  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch:   2754] loss: 0.35847  | 0.18\n",
      "[epoch: 1, batch:   2756] loss: 0.74347  | 0.18\n",
      "[epoch: 1, batch:   2758] loss: 0.79009  | 0.18\n",
      "[epoch: 1, batch:   2760] loss: 0.14673  | 0.18\n",
      "[epoch: 1, batch:   2762] loss: 1.19090  | 0.18\n",
      "[epoch: 1, batch:   2764] loss: 0.68187  | 0.18\n",
      "[epoch: 1, batch:   2766] loss: 0.31516  | 0.18\n",
      "[epoch: 1, batch:   2768] loss: 0.08502  | 0.18\n",
      "[epoch: 1, batch:   2770] loss: 0.66699  | 0.18\n",
      "[epoch: 1, batch:   2772] loss: 0.01372  | 0.18\n",
      "[epoch: 1, batch:   2774] loss: 0.40301  | 0.18\n",
      "[epoch: 1, batch:   2776] loss: 0.36425  | 0.18\n",
      "[epoch: 1, batch:   2778] loss: 0.42700  | 0.18\n",
      "[epoch: 1, batch:   2780] loss: 0.39406  | 0.18\n",
      "[epoch: 1, batch:   2782] loss: 0.19957  | 0.18\n",
      "[epoch: 1, batch:   2784] loss: 1.29578  | 0.18\n",
      "[epoch: 1, batch:   2786] loss: 0.34148  | 0.18\n",
      "[epoch: 1, batch:   2788] loss: 0.09558  | 0.18\n",
      "[epoch: 1, batch:   2790] loss: 0.19184  | 0.18\n",
      "[epoch: 1, batch:   2792] loss: 0.54499  | 0.18\n",
      "[epoch: 1, batch:   2794] loss: 0.77807  | 0.18\n",
      "[epoch: 1, batch:   2796] loss: 0.21226  | 0.18\n",
      "[epoch: 1, batch:   2798] loss: 0.42013  | 0.18\n",
      "[epoch: 1, batch:   2800] loss: 0.44752  | 0.18\n",
      "[epoch: 1, batch:   2802] loss: 0.63357  | 0.18\n",
      "[epoch: 1, batch:   2804] loss: 1.20779  | 0.18\n",
      "[epoch: 1, batch:   2806] loss: 0.72963  | 0.18\n",
      "[epoch: 1, batch:   2808] loss: 0.48975  | 0.18\n",
      "[epoch: 1, batch:   2810] loss: 0.58129  | 0.18\n",
      "[epoch: 1, batch:   2812] loss: 0.54258  | 0.18\n",
      "[epoch: 1, batch:   2814] loss: 0.31537  | 0.18\n",
      "[epoch: 1, batch:   2816] loss: 0.06432  | 0.18\n",
      "[epoch: 1, batch:   2818] loss: 0.13033  | 0.18\n",
      "[epoch: 1, batch:   2820] loss: 0.88246  | 0.18\n",
      "[epoch: 1, batch:   2822] loss: 0.58716  | 0.18\n",
      "[epoch: 1, batch:   2824] loss: 0.75013  | 0.18\n",
      "[epoch: 1, batch:   2826] loss: 0.53125  | 0.18\n",
      "[epoch: 1, batch:   2828] loss: 0.16518  | 0.18\n",
      "[epoch: 1, batch:   2830] loss: 0.40041  | 0.18\n",
      "[epoch: 1, batch:   2832] loss: 0.41799  | 0.18\n",
      "[epoch: 1, batch:   2834] loss: 0.62326  | 0.18\n",
      "[epoch: 1, batch:   2836] loss: 0.06656  | 0.18\n",
      "[epoch: 1, batch:   2838] loss: 0.32645  | 0.18\n",
      "[epoch: 1, batch:   2840] loss: 0.21580  | 0.18\n",
      "[epoch: 1, batch:   2842] loss: 0.40216  | 0.18\n",
      "[epoch: 1, batch:   2844] loss: 0.46279  | 0.18\n",
      "[epoch: 1, batch:   2846] loss: 0.15145  | 0.18\n",
      "[epoch: 1, batch:   2848] loss: 0.35376  | 0.18\n",
      "[epoch: 1, batch:   2850] loss: 0.60636  | 0.18\n",
      "[epoch: 1, batch:   2852] loss: 0.46194  | 0.18\n",
      "[epoch: 1, batch:   2854] loss: 0.34032  | 0.18\n",
      "[epoch: 1, batch:   2856] loss: 0.82566  | 0.18\n",
      "[epoch: 1, batch:   2858] loss: 0.40219  | 0.18\n",
      "[epoch: 1, batch:   2860] loss: 0.20359  | 0.18\n",
      "[epoch: 1, batch:   2862] loss: 0.67915  | 0.18\n",
      "[epoch: 1, batch:   2864] loss: 0.20486  | 0.18\n",
      "[epoch: 1, batch:   2866] loss: 0.14478  | 0.19\n",
      "[epoch: 1, batch:   2868] loss: 0.62910  | 0.18\n",
      "[epoch: 1, batch:   2870] loss: 0.47635  | 0.18\n",
      "[epoch: 1, batch:   2872] loss: 0.03335  | 0.18\n",
      "[epoch: 1, batch:   2874] loss: 0.32260  | 0.18\n",
      "[epoch: 1, batch:   2876] loss: 0.65832  | 0.18\n",
      "[epoch: 1, batch:   2878] loss: 0.14333  | 0.18\n",
      "[epoch: 1, batch:   2880] loss: 0.11491  | 0.18\n",
      "[epoch: 1, batch:   2882] loss: 0.54857  | 0.18\n",
      "[epoch: 1, batch:   2884] loss: 0.08149  | 0.18\n",
      "[epoch: 1, batch:   2886] loss: 0.33121  | 0.18\n",
      "[epoch: 1, batch:   2888] loss: 1.22556  | 0.18\n",
      "[epoch: 1, batch:   2890] loss: 0.95889  | 0.18\n",
      "[epoch: 1, batch:   2892] loss: 0.28750  | 0.18\n",
      "[epoch: 1, batch:   2894] loss: 0.36197  | 0.18\n",
      "[epoch: 1, batch:   2896] loss: 0.14539  | 0.18\n",
      "[epoch: 1, batch:   2898] loss: 0.49590  | 0.18\n",
      "[epoch: 1, batch:   2900] loss: 0.10644  | 0.18\n",
      "[epoch: 1, batch:   2902] loss: 0.19179  | 0.18\n",
      "[epoch: 1, batch:   2904] loss: 0.76008  | 0.18\n",
      "[epoch: 1, batch:   2906] loss: 0.79028  | 0.18\n",
      "[epoch: 1, batch:   2908] loss: 0.07018  | 0.18\n",
      "[epoch: 1, batch:   2910] loss: 0.48912  | 0.18\n",
      "[epoch: 1, batch:   2912] loss: 0.33185  | 0.18\n",
      "[epoch: 1, batch:   2914] loss: 0.17588  | 0.18\n",
      "[epoch: 1, batch:   2916] loss: 0.29532  | 0.18\n",
      "[epoch: 1, batch:   2918] loss: 0.63235  | 0.18\n",
      "[epoch: 1, batch:   2920] loss: 0.37098  | 0.18\n",
      "[epoch: 1, batch:   2922] loss: 0.53162  | 0.18\n",
      "[epoch: 1, batch:   2924] loss: 0.29250  | 0.18\n",
      "[epoch: 1, batch:   2926] loss: 0.28974  | 0.18\n",
      "[epoch: 1, batch:   2928] loss: 0.59642  | 0.18\n",
      "[epoch: 1, batch:   2930] loss: 0.50028  | 0.18\n",
      "[epoch: 1, batch:   2932] loss: 1.38203  | 0.18\n",
      "[epoch: 1, batch:   2934] loss: 0.10974  | 0.18\n",
      "[epoch: 1, batch:   2936] loss: 0.48553  | 0.18\n",
      "[epoch: 1, batch:   2938] loss: 0.10505  | 0.18\n",
      "[epoch: 1, batch:   2940] loss: 0.36815  | 0.18\n",
      "[epoch: 1, batch:   2942] loss: 0.29739  | 0.18\n",
      "[epoch: 1, batch:   2944] loss: 0.45562  | 0.18\n",
      "[epoch: 1, batch:   2946] loss: 0.30137  | 0.18\n",
      "[epoch: 1, batch:   2948] loss: 0.47303  | 0.18\n",
      "[epoch: 1, batch:   2950] loss: 0.06075  | 0.18\n",
      "[epoch: 1, batch:   2952] loss: 0.57053  | 0.18\n",
      "[epoch: 1, batch:   2954] loss: 0.56583  | 0.18\n",
      "[epoch: 1, batch:   2956] loss: 1.03455  | 0.18\n",
      "[epoch: 1, batch:   2958] loss: 0.22926  | 0.18\n",
      "[epoch: 1, batch:   2960] loss: 1.47720  | 0.18\n",
      "[epoch: 1, batch:   2962] loss: 0.01833  | 0.18\n",
      "[epoch: 1, batch:   2964] loss: 0.27585  | 0.18\n",
      "[epoch: 1, batch:   2966] loss: 0.62439  | 0.18\n",
      "[epoch: 1, batch:   2968] loss: 0.26279  | 0.18\n",
      "[epoch: 1, batch:   2970] loss: 0.76352  | 0.18\n",
      "[epoch: 1, batch:   2972] loss: 0.54038  | 0.18\n",
      "[epoch: 1, batch:   2974] loss: 0.48478  | 0.18\n",
      "[epoch: 1, batch:   2976] loss: 0.46053  | 0.18\n",
      "[epoch: 1, batch:   2978] loss: 0.91892  | 0.18\n",
      "[epoch: 1, batch:   2980] loss: 0.47408  | 0.18\n",
      "[epoch: 1, batch:   2982] loss: 0.61622  | 0.18\n",
      "[epoch: 1, batch:   2984] loss: 0.54621  | 0.18\n",
      "[epoch: 1, batch:   2986] loss: 1.66166  | 0.18\n",
      "[epoch: 1, batch:   2988] loss: 0.68995  | 0.18\n",
      "[epoch: 1, batch:   2990] loss: 0.52733  | 0.18\n",
      "[epoch: 1, batch:   2992] loss: 0.42923  | 0.18\n",
      "[epoch: 1, batch:   2994] loss: 0.29261  | 0.18\n",
      "[epoch: 1, batch:   2996] loss: 0.48450  | 0.18\n",
      "[epoch: 1, batch:   2998] loss: 0.53604  | 0.18\n",
      "[epoch: 1, batch:   3000] loss: 0.13691  | 0.18\n",
      "[epoch: 1, batch:   3002] loss: 0.16734  | 0.18\n",
      "[epoch: 1, batch:   3004] loss: 0.43123  | 0.18\n",
      "[epoch: 1, batch:   3006] loss: 0.14578  | 0.18\n",
      "[epoch: 1, batch:   3008] loss: 0.15120  | 0.18\n",
      "[epoch: 1, batch:   3010] loss: 0.36506  | 0.18\n",
      "[epoch: 1, batch:   3012] loss: 0.08841  | 0.18\n",
      "[epoch: 1, batch:   3014] loss: 0.47297  | 0.18\n",
      "[epoch: 1, batch:   3016] loss: 0.20003  | 0.18\n",
      "[epoch: 1, batch:   3018] loss: 0.86418  | 0.18\n",
      "[epoch: 1, batch:   3020] loss: 0.18150  | 0.18\n",
      "[epoch: 1, batch:   3022] loss: 0.07434  | 0.18\n",
      "[epoch: 1, batch:   3024] loss: 0.57232  | 0.18\n",
      "[epoch: 1, batch:   3026] loss: 0.85282  | 0.18\n",
      "[epoch: 1, batch:   3028] loss: 1.43185  | 0.18\n",
      "[epoch: 1, batch:   3030] loss: 0.41143  | 0.18\n",
      "[epoch: 1, batch:   3032] loss: 0.76116  | 0.18\n",
      "[epoch: 1, batch:   3034] loss: 0.11813  | 0.18\n",
      "[epoch: 1, batch:   3036] loss: 0.22105  | 0.18\n",
      "[epoch: 1, batch:   3038] loss: 0.35638  | 0.18\n",
      "[epoch: 1, batch:   3040] loss: 0.18766  | 0.18\n",
      "[epoch: 1, batch:   3042] loss: 0.38441  | 0.18\n",
      "[epoch: 1, batch:   3044] loss: 0.41109  | 0.18\n",
      "[epoch: 1, batch:   3046] loss: 1.04382  | 0.18\n",
      "[epoch: 1, batch:   3048] loss: 0.92964  | 0.18\n",
      "[epoch: 1, batch:   3050] loss: 0.73778  | 0.18\n",
      "[epoch: 1, batch:   3052] loss: 0.14069  | 0.18\n",
      "[epoch: 1, batch:   3054] loss: 1.36910  | 0.18\n",
      "[epoch: 1, batch:   3056] loss: 0.02687  | 0.18\n",
      "[epoch: 1, batch:   3058] loss: 0.75398  | 0.18\n",
      "[epoch: 1, batch:   3060] loss: 0.53330  | 0.18\n",
      "[epoch: 1, batch:   3062] loss: 0.11420  | 0.18\n",
      "[epoch: 1, batch:   3064] loss: 0.26776  | 0.18\n",
      "[epoch: 1, batch:   3066] loss: 0.06234  | 0.18\n",
      "[epoch: 1, batch:   3068] loss: 0.25500  | 0.18\n",
      "[epoch: 1, batch:   3070] loss: 0.75320  | 0.18\n",
      "[epoch: 1, batch:   3072] loss: 0.34929  | 0.18\n",
      "[epoch: 1, batch:   3074] loss: 0.34320  | 0.18\n",
      "[epoch: 1, batch:   3076] loss: 0.21696  | 0.18\n",
      "[epoch: 1, batch:   3078] loss: 0.32272  | 0.18\n",
      "[epoch: 1, batch:   3080] loss: 0.22923  | 0.18\n",
      "[epoch: 1, batch:   3082] loss: 0.38883  | 0.18\n",
      "[epoch: 1, batch:   3084] loss: 0.38305  | 0.18\n",
      "[epoch: 1, batch:   3086] loss: 0.36038  | 0.18\n",
      "[epoch: 1, batch:   3088] loss: 0.34604  | 0.18\n",
      "[epoch: 1, batch:   3090] loss: 0.28810  | 0.18\n",
      "[epoch: 1, batch:   3092] loss: 0.10796  | 0.18\n",
      "[epoch: 1, batch:   3094] loss: 0.27070  | 0.18\n",
      "[epoch: 1, batch:   3096] loss: 0.38113  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch:   3098] loss: 0.24478  | 0.18\n",
      "[epoch: 1, batch:   3100] loss: 0.74885  | 0.18\n",
      "[epoch: 1, batch:   3102] loss: 0.12351  | 0.18\n",
      "[epoch: 1, batch:   3104] loss: 0.21745  | 0.18\n",
      "[epoch: 1, batch:   3106] loss: 0.46515  | 0.18\n",
      "[epoch: 1, batch:   3108] loss: 0.32839  | 0.18\n",
      "[epoch: 1, batch:   3110] loss: 1.80525  | 0.18\n",
      "[epoch: 1, batch:   3112] loss: 0.29332  | 0.18\n",
      "[epoch: 1, batch:   3114] loss: 0.89330  | 0.18\n",
      "[epoch: 1, batch:   3116] loss: 0.67026  | 0.18\n",
      "[epoch: 1, batch:   3118] loss: 0.22137  | 0.18\n",
      "[epoch: 1, batch:   3120] loss: 0.20878  | 0.18\n",
      "[epoch: 1, batch:   3122] loss: 0.60609  | 0.18\n",
      "[epoch: 1, batch:   3124] loss: 0.40970  | 0.18\n",
      "[epoch: 1, batch:   3126] loss: 0.26183  | 0.18\n",
      "[epoch: 1, batch:   3128] loss: 0.10411  | 0.18\n",
      "[epoch: 1, batch:   3130] loss: 0.25581  | 0.18\n",
      "[epoch: 1, batch:   3132] loss: 1.19061  | 0.18\n",
      "[epoch: 1, batch:   3134] loss: 0.78023  | 0.18\n",
      "[epoch: 1, batch:   3136] loss: 0.17101  | 0.18\n",
      "[epoch: 1, batch:   3138] loss: 1.12733  | 0.18\n",
      "[epoch: 1, batch:   3140] loss: 0.33544  | 0.18\n",
      "[epoch: 1, batch:   3142] loss: 0.09395  | 0.18\n",
      "[epoch: 1, batch:   3144] loss: 0.27135  | 0.18\n",
      "[epoch: 1, batch:   3146] loss: 0.56566  | 0.18\n",
      "[epoch: 1, batch:   3148] loss: 0.37568  | 0.18\n",
      "[epoch: 1, batch:   3150] loss: 0.38234  | 0.18\n",
      "[epoch: 1, batch:   3152] loss: 1.38503  | 0.18\n",
      "[epoch: 1, batch:   3154] loss: 0.11717  | 0.18\n",
      "[epoch: 1, batch:   3156] loss: 0.93658  | 0.18\n",
      "[epoch: 1, batch:   3158] loss: 0.32957  | 0.18\n",
      "[epoch: 1, batch:   3160] loss: 0.37450  | 0.18\n",
      "[epoch: 1, batch:   3162] loss: 0.31850  | 0.18\n",
      "[epoch: 1, batch:   3164] loss: 0.70573  | 0.18\n",
      "[epoch: 1, batch:   3166] loss: 1.35566  | 0.18\n",
      "[epoch: 1, batch:   3168] loss: 0.19438  | 0.18\n",
      "[epoch: 1, batch:   3170] loss: 0.36030  | 0.18\n",
      "[epoch: 1, batch:   3172] loss: 0.12030  | 0.18\n",
      "[epoch: 1, batch:   3174] loss: 0.04246  | 0.18\n",
      "[epoch: 1, batch:   3176] loss: 0.48310  | 0.18\n",
      "[epoch: 1, batch:   3178] loss: 0.06175  | 0.18\n",
      "[epoch: 1, batch:   3180] loss: 0.36149  | 0.18\n",
      "[epoch: 1, batch:   3182] loss: 0.60780  | 0.18\n",
      "[epoch: 1, batch:   3184] loss: 0.48705  | 0.18\n",
      "[epoch: 1, batch:   3186] loss: 0.25727  | 0.18\n",
      "[epoch: 1, batch:   3188] loss: 0.53429  | 0.18\n",
      "[epoch: 1, batch:   3190] loss: 0.23413  | 0.18\n",
      "[epoch: 1, batch:   3192] loss: 2.12723  | 0.18\n",
      "[epoch: 1, batch:   3194] loss: 0.49169  | 0.18\n",
      "[epoch: 1, batch:   3196] loss: 0.10597  | 0.18\n",
      "[epoch: 1, batch:   3198] loss: 0.09135  | 0.18\n",
      "[epoch: 1, batch:   3200] loss: 0.85594  | 0.18\n",
      "[epoch: 1, batch:   3202] loss: 0.45647  | 0.18\n",
      "[epoch: 1, batch:   3204] loss: 0.77086  | 0.18\n",
      "[epoch: 1, batch:   3206] loss: 0.68181  | 0.18\n",
      "[epoch: 1, batch:   3208] loss: 0.02694  | 0.18\n",
      "[epoch: 1, batch:   3210] loss: 0.45978  | 0.18\n",
      "[epoch: 1, batch:   3212] loss: 0.52253  | 0.18\n",
      "[epoch: 1, batch:   3214] loss: 0.36977  | 0.18\n",
      "[epoch: 1, batch:   3216] loss: 0.63463  | 0.18\n",
      "[epoch: 1, batch:   3218] loss: 0.01926  | 0.18\n",
      "[epoch: 1, batch:   3220] loss: 0.04214  | 0.18\n",
      "[epoch: 1, batch:   3222] loss: 0.40769  | 0.18\n",
      "[epoch: 1, batch:   3224] loss: 0.63983  | 0.18\n",
      "[epoch: 1, batch:   3226] loss: 0.31730  | 0.18\n",
      "[epoch: 1, batch:   3228] loss: 0.52299  | 0.18\n",
      "[epoch: 1, batch:   3230] loss: 0.30903  | 0.18\n",
      "[epoch: 1, batch:   3232] loss: 0.27027  | 0.18\n",
      "[epoch: 1, batch:   3234] loss: 0.40092  | 0.18\n",
      "[epoch: 1, batch:   3236] loss: 0.71846  | 0.18\n",
      "[epoch: 1, batch:   3238] loss: 0.50274  | 0.18\n",
      "[epoch: 1, batch:   3240] loss: 0.02252  | 0.18\n",
      "[epoch: 1, batch:   3242] loss: 0.81485  | 0.18\n",
      "[epoch: 1, batch:   3244] loss: 0.44246  | 0.18\n",
      "[epoch: 1, batch:   3246] loss: 0.33622  | 0.18\n",
      "[epoch: 1, batch:   3248] loss: 0.09475  | 0.18\n",
      "[epoch: 1, batch:   3250] loss: 0.47776  | 0.18\n",
      "[epoch: 1, batch:   3252] loss: 0.06173  | 0.18\n",
      "[epoch: 1, batch:   3254] loss: 1.51327  | 0.18\n",
      "[epoch: 1, batch:   3256] loss: 0.45405  | 0.18\n",
      "[epoch: 1, batch:   3258] loss: 0.32376  | 0.18\n",
      "[epoch: 1, batch:   3260] loss: 0.28760  | 0.18\n",
      "[epoch: 1, batch:   3262] loss: 0.28396  | 0.18\n",
      "[epoch: 1, batch:   3264] loss: 0.18147  | 0.18\n",
      "[epoch: 1, batch:   3266] loss: 0.39541  | 0.18\n",
      "[epoch: 1, batch:   3268] loss: 0.78254  | 0.18\n",
      "[epoch: 1, batch:   3270] loss: 0.44274  | 0.18\n",
      "[epoch: 1, batch:   3272] loss: 0.27507  | 0.18\n",
      "[epoch: 1, batch:   3274] loss: 0.09462  | 0.18\n",
      "[epoch: 1, batch:   3276] loss: 0.25593  | 0.18\n",
      "[epoch: 1, batch:   3278] loss: 0.29506  | 0.18\n",
      "[epoch: 1, batch:   3280] loss: 0.28789  | 0.18\n",
      "[epoch: 1, batch:   3282] loss: 0.14971  | 0.18\n",
      "[epoch: 1, batch:   3284] loss: 0.64637  | 0.18\n",
      "[epoch: 1, batch:   3286] loss: 0.01088  | 0.18\n",
      "[epoch: 1, batch:   3288] loss: 0.66750  | 0.18\n",
      "[epoch: 1, batch:   3290] loss: 1.04088  | 0.18\n",
      "[epoch: 1, batch:   3292] loss: 0.37440  | 0.18\n",
      "[epoch: 1, batch:   3294] loss: 0.09166  | 0.18\n",
      "[epoch: 1, batch:   3296] loss: 0.79864  | 0.18\n",
      "[epoch: 1, batch:   3298] loss: 0.74684  | 0.18\n",
      "[epoch: 1, batch:   3300] loss: 0.41649  | 0.18\n",
      "[epoch: 1, batch:   3302] loss: 0.12212  | 0.18\n",
      "[epoch: 1, batch:   3304] loss: 0.11293  | 0.18\n",
      "[epoch: 1, batch:   3306] loss: 0.21733  | 0.18\n",
      "[epoch: 1, batch:   3308] loss: 0.22647  | 0.18\n",
      "[epoch: 1, batch:   3310] loss: 0.37976  | 0.18\n",
      "[epoch: 1, batch:   3312] loss: 0.65021  | 0.18\n",
      "[epoch: 1, batch:   3314] loss: 0.36597  | 0.18\n",
      "[epoch: 1, batch:   3316] loss: 0.22949  | 0.18\n",
      "[epoch: 1, batch:   3318] loss: 0.47170  | 0.18\n",
      "[epoch: 1, batch:   3320] loss: 0.79208  | 0.18\n",
      "[epoch: 1, batch:   3322] loss: 0.15353  | 0.18\n",
      "[epoch: 1, batch:   3324] loss: 1.15812  | 0.18\n",
      "[epoch: 1, batch:   3326] loss: 0.22085  | 0.18\n",
      "[epoch: 1, batch:   3328] loss: 0.41912  | 0.18\n",
      "[epoch: 1, batch:   3330] loss: 0.60887  | 0.18\n",
      "[epoch: 1, batch:   3332] loss: 0.32565  | 0.18\n",
      "[epoch: 1, batch:   3334] loss: 0.71688  | 0.18\n",
      "[epoch: 1, batch:   3336] loss: 0.39780  | 0.18\n",
      "[epoch: 1, batch:   3338] loss: 0.54683  | 0.18\n",
      "[epoch: 1, batch:   3340] loss: 0.55247  | 0.18\n",
      "[epoch: 1, batch:   3342] loss: 0.24153  | 0.18\n",
      "[epoch: 1, batch:   3344] loss: 0.41470  | 0.18\n",
      "[epoch: 1, batch:   3346] loss: 0.17368  | 0.18\n",
      "[epoch: 1, batch:   3348] loss: 0.56795  | 0.18\n",
      "[epoch: 1, batch:   3350] loss: 0.28146  | 0.18\n",
      "[epoch: 1, batch:   3352] loss: 0.26751  | 0.18\n",
      "[epoch: 1, batch:   3354] loss: 0.65091  | 0.18\n",
      "[epoch: 1, batch:   3356] loss: 0.46422  | 0.18\n",
      "[epoch: 1, batch:   3358] loss: 0.37598  | 0.18\n",
      "[epoch: 1, batch:   3360] loss: 0.73917  | 0.18\n",
      "[epoch: 1, batch:   3362] loss: 0.27761  | 0.18\n",
      "[epoch: 1, batch:   3364] loss: 0.99280  | 0.18\n",
      "[epoch: 1, batch:   3366] loss: 0.21768  | 0.18\n",
      "[epoch: 1, batch:   3368] loss: 0.39906  | 0.18\n",
      "[epoch: 1, batch:   3370] loss: 0.59334  | 0.18\n",
      "[epoch: 1, batch:   3372] loss: 0.62317  | 0.18\n",
      "[epoch: 1, batch:   3374] loss: 0.09667  | 0.18\n",
      "[epoch: 1, batch:   3376] loss: 0.30011  | 0.18\n",
      "[epoch: 1, batch:   3378] loss: 0.35576  | 0.18\n",
      "[epoch: 1, batch:   3380] loss: 0.46691  | 0.18\n",
      "[epoch: 1, batch:   3382] loss: 0.20727  | 0.18\n",
      "[epoch: 1, batch:   3384] loss: 0.35410  | 0.18\n",
      "[epoch: 1, batch:   3386] loss: 0.61605  | 0.18\n",
      "[epoch: 1, batch:   3388] loss: 0.65340  | 0.18\n",
      "[epoch: 1, batch:   3390] loss: 0.41676  | 0.18\n",
      "[epoch: 1, batch:   3392] loss: 0.26477  | 0.18\n",
      "[epoch: 1, batch:   3394] loss: 0.43078  | 0.18\n",
      "[epoch: 1, batch:   3396] loss: 0.75082  | 0.18\n",
      "[epoch: 1, batch:   3398] loss: 0.29801  | 0.18\n",
      "[epoch: 1, batch:   3400] loss: 0.15357  | 0.18\n",
      "[epoch: 1, batch:   3402] loss: 0.22499  | 0.18\n",
      "[epoch: 1, batch:   3404] loss: 0.69172  | 0.18\n",
      "[epoch: 1, batch:   3406] loss: 0.87569  | 0.18\n",
      "[epoch: 1, batch:   3408] loss: 0.22594  | 0.18\n",
      "[epoch: 1, batch:   3410] loss: 0.50309  | 0.18\n",
      "[epoch: 1, batch:   3412] loss: 0.40725  | 0.18\n",
      "[epoch: 1, batch:   3414] loss: 0.56808  | 0.18\n",
      "[epoch: 1, batch:   3416] loss: 0.14064  | 0.18\n",
      "[epoch: 1, batch:   3418] loss: 0.93431  | 0.18\n",
      "[epoch: 1, batch:   3420] loss: 0.80526  | 0.18\n",
      "[epoch: 1, batch:   3422] loss: 0.12621  | 0.18\n",
      "[epoch: 1, batch:   3424] loss: 0.79394  | 0.18\n",
      "[epoch: 1, batch:   3426] loss: 0.38588  | 0.18\n",
      "[epoch: 1, batch:   3428] loss: 0.45793  | 0.18\n",
      "[epoch: 1, batch:   3430] loss: 0.37235  | 0.18\n",
      "[epoch: 1, batch:   3432] loss: 0.33939  | 0.18\n",
      "[epoch: 1, batch:   3434] loss: 0.04304  | 0.18\n",
      "[epoch: 1, batch:   3436] loss: 0.26567  | 0.18\n",
      "[epoch: 1, batch:   3438] loss: 0.54997  | 0.18\n",
      "[epoch: 1, batch:   3440] loss: 0.34508  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch:   3442] loss: 0.20945  | 0.18\n",
      "[epoch: 1, batch:   3444] loss: 0.30805  | 0.18\n",
      "[epoch: 1, batch:   3446] loss: 0.29246  | 0.18\n",
      "[epoch: 1, batch:   3448] loss: 0.58950  | 0.18\n",
      "[epoch: 1, batch:   3450] loss: 0.80010  | 0.18\n",
      "[epoch: 1, batch:   3452] loss: 0.13559  | 0.18\n",
      "[epoch: 1, batch:   3454] loss: 0.21945  | 0.18\n",
      "[epoch: 1, batch:   3456] loss: 0.79156  | 0.18\n",
      "[epoch: 1, batch:   3458] loss: 0.47158  | 0.18\n",
      "[epoch: 1, batch:   3460] loss: 0.44603  | 0.18\n",
      "[epoch: 1, batch:   3462] loss: 0.25876  | 0.18\n",
      "[epoch: 1, batch:   3464] loss: 0.01361  | 0.18\n",
      "[epoch: 1, batch:   3466] loss: 0.69629  | 0.18\n",
      "[epoch: 1, batch:   3468] loss: 0.67974  | 0.18\n",
      "[epoch: 1, batch:   3470] loss: 0.45346  | 0.19\n",
      "[epoch: 1, batch:   3472] loss: 0.46703  | 0.18\n",
      "[epoch: 1, batch:   3474] loss: 0.57512  | 0.19\n",
      "[epoch: 1, batch:   3476] loss: 0.49053  | 0.18\n",
      "[epoch: 1, batch:   3478] loss: 0.46130  | 0.18\n",
      "[epoch: 1, batch:   3480] loss: 0.25535  | 0.18\n",
      "[epoch: 1, batch:   3482] loss: 0.94315  | 0.18\n",
      "[epoch: 1, batch:   3484] loss: 0.52387  | 0.18\n",
      "[epoch: 1, batch:   3486] loss: 0.48064  | 0.18\n",
      "[epoch: 1, batch:   3488] loss: 0.04761  | 0.18\n",
      "[epoch: 1, batch:   3490] loss: 0.61211  | 0.18\n",
      "[epoch: 1, batch:   3492] loss: 0.75751  | 0.18\n",
      "[epoch: 1, batch:   3494] loss: 0.64801  | 0.18\n",
      "[epoch: 1, batch:   3496] loss: 1.62722  | 0.19\n",
      "[epoch: 1, batch:   3498] loss: 0.29874  | 0.18\n",
      "[epoch: 1, batch:   3500] loss: 1.31332  | 0.18\n",
      "[epoch: 1, batch:   3502] loss: 0.06206  | 0.18\n",
      "[epoch: 1, batch:   3504] loss: 0.13941  | 0.18\n",
      "[epoch: 1, batch:   3506] loss: 0.52240  | 0.18\n",
      "[epoch: 1, batch:   3508] loss: 0.61761  | 0.18\n",
      "[epoch: 1, batch:   3510] loss: 0.41277  | 0.18\n",
      "[epoch: 1, batch:   3512] loss: 0.32319  | 0.18\n",
      "[epoch: 1, batch:   3514] loss: 0.42600  | 0.18\n",
      "[epoch: 1, batch:   3516] loss: 0.33137  | 0.18\n",
      "[epoch: 1, batch:   3518] loss: 0.25449  | 0.18\n",
      "[epoch: 1, batch:   3520] loss: 0.02528  | 0.18\n",
      "[epoch: 1, batch:   3522] loss: 0.30004  | 0.18\n",
      "[epoch: 1, batch:   3524] loss: 0.41747  | 0.18\n",
      "[epoch: 1, batch:   3526] loss: 0.22939  | 0.18\n",
      "[epoch: 1, batch:   3528] loss: 0.01864  | 0.18\n",
      "[epoch: 1, batch:   3530] loss: 0.35867  | 0.18\n",
      "[epoch: 1, batch:   3532] loss: 0.89371  | 0.18\n",
      "[epoch: 1, batch:   3534] loss: 0.45617  | 0.18\n",
      "[epoch: 1, batch:   3536] loss: 0.30923  | 0.18\n",
      "[epoch: 1, batch:   3538] loss: 0.25038  | 0.18\n",
      "[epoch: 1, batch:   3540] loss: 0.22562  | 0.18\n",
      "[epoch: 1, batch:   3542] loss: 0.90514  | 0.18\n",
      "[epoch: 1, batch:   3544] loss: 0.41249  | 0.18\n",
      "[epoch: 1, batch:   3546] loss: 0.40771  | 0.18\n",
      "[epoch: 1, batch:   3548] loss: 0.65869  | 0.18\n",
      "[epoch: 1, batch:   3550] loss: 0.39444  | 0.18\n",
      "[epoch: 1, batch:   3552] loss: 0.39711  | 0.18\n",
      "[epoch: 1, batch:   3554] loss: 0.45812  | 0.18\n",
      "[epoch: 1, batch:   3556] loss: 0.48617  | 0.18\n",
      "[epoch: 1, batch:   3558] loss: 1.30483  | 0.18\n",
      "[epoch: 1, batch:   3560] loss: 0.68878  | 0.18\n",
      "[epoch: 1, batch:   3562] loss: 0.29720  | 0.18\n",
      "[epoch: 1, batch:   3564] loss: 0.58187  | 0.18\n",
      "[epoch: 1, batch:   3566] loss: 0.63773  | 0.18\n",
      "[epoch: 1, batch:   3568] loss: 0.13093  | 0.18\n",
      "[epoch: 1, batch:   3570] loss: 0.52595  | 0.18\n",
      "[epoch: 1, batch:   3572] loss: 0.93205  | 0.18\n",
      "[epoch: 1, batch:   3574] loss: 0.03956  | 0.18\n",
      "[epoch: 1, batch:   3576] loss: 0.35441  | 0.18\n",
      "[epoch: 1, batch:   3578] loss: 0.67692  | 0.18\n",
      "[epoch: 1, batch:   3580] loss: 0.49087  | 0.18\n",
      "[epoch: 1, batch:   3582] loss: 1.01635  | 0.18\n",
      "[epoch: 1, batch:   3584] loss: 0.71011  | 0.18\n",
      "[epoch: 1, batch:   3586] loss: 0.99562  | 0.18\n",
      "[epoch: 1, batch:   3588] loss: 0.77478  | 0.18\n",
      "[epoch: 1, batch:   3590] loss: 0.32244  | 0.18\n",
      "[epoch: 1, batch:   3592] loss: 0.57871  | 0.18\n",
      "[epoch: 1, batch:   3594] loss: 0.55735  | 0.18\n",
      "[epoch: 1, batch:   3596] loss: 0.73608  | 0.18\n",
      "[epoch: 1, batch:   3598] loss: 0.84167  | 0.18\n",
      "[epoch: 1, batch:   3600] loss: 0.62447  | 0.18\n",
      "[epoch: 1, batch:   3602] loss: 1.11665  | 0.18\n",
      "[epoch: 1, batch:   3604] loss: 0.03306  | 0.18\n",
      "[epoch: 1, batch:   3606] loss: 0.13665  | 0.18\n",
      "[epoch: 1, batch:   3608] loss: 0.07294  | 0.18\n",
      "[epoch: 1, batch:   3610] loss: 0.42102  | 0.18\n",
      "[epoch: 1, batch:   3612] loss: 0.13767  | 0.18\n",
      "[epoch: 1, batch:   3614] loss: 0.43943  | 0.18\n",
      "[epoch: 1, batch:   3616] loss: 0.36062  | 0.18\n",
      "[epoch: 1, batch:   3618] loss: 0.45525  | 0.18\n",
      "[epoch: 1, batch:   3620] loss: 0.61272  | 0.18\n",
      "[epoch: 1, batch:   3622] loss: 1.93536  | 0.18\n",
      "[epoch: 1, batch:   3624] loss: 0.45091  | 0.18\n",
      "[epoch: 1, batch:   3626] loss: 0.38294  | 0.18\n",
      "[epoch: 1, batch:   3628] loss: 0.54693  | 0.18\n",
      "[epoch: 1, batch:   3630] loss: 0.35102  | 0.18\n",
      "[epoch: 1, batch:   3632] loss: 0.12951  | 0.18\n",
      "[epoch: 1, batch:   3634] loss: 0.43983  | 0.18\n",
      "[epoch: 1, batch:   3636] loss: 0.15091  | 0.18\n",
      "[epoch: 1, batch:   3638] loss: 0.87279  | 0.18\n",
      "[epoch: 1, batch:   3640] loss: 0.40428  | 0.18\n",
      "[epoch: 1, batch:   3642] loss: 0.77694  | 0.18\n",
      "[epoch: 1, batch:   3644] loss: 0.10738  | 0.18\n",
      "[epoch: 1, batch:   3646] loss: 0.25073  | 0.18\n",
      "[epoch: 1, batch:   3648] loss: 0.48139  | 0.18\n",
      "[epoch: 1, batch:   3650] loss: 0.12908  | 0.18\n",
      "[epoch: 1, batch:   3652] loss: 0.25468  | 0.18\n",
      "[epoch: 1, batch:   3654] loss: 0.77045  | 0.18\n",
      "[epoch: 1, batch:   3656] loss: 0.67615  | 0.18\n",
      "[epoch: 1, batch:   3658] loss: 0.07540  | 0.18\n",
      "[epoch: 1, batch:   3660] loss: 0.52888  | 0.18\n",
      "[epoch: 1, batch:   3662] loss: 1.05028  | 0.18\n",
      "[epoch: 1, batch:   3664] loss: 0.19310  | 0.18\n",
      "[epoch: 1, batch:   3666] loss: 0.49565  | 0.18\n",
      "[epoch: 1, batch:   3668] loss: 0.07376  | 0.18\n",
      "[epoch: 1, batch:   3670] loss: 0.46982  | 0.18\n",
      "[epoch: 1, batch:   3672] loss: 0.63011  | 0.18\n",
      "[epoch: 1, batch:   3674] loss: 0.14749  | 0.18\n",
      "[epoch: 1, batch:   3676] loss: 0.10500  | 0.18\n",
      "[epoch: 1, batch:   3678] loss: 0.18751  | 0.18\n",
      "[epoch: 1, batch:   3680] loss: 0.61472  | 0.18\n",
      "[epoch: 1, batch:   3682] loss: 0.39973  | 0.18\n",
      "[epoch: 1, batch:   3684] loss: 0.40827  | 0.18\n",
      "[epoch: 1, batch:   3686] loss: 0.91446  | 0.18\n",
      "[epoch: 1, batch:   3688] loss: 0.24195  | 0.18\n",
      "[epoch: 1, batch:   3690] loss: 0.15677  | 0.18\n",
      "[epoch: 1, batch:   3692] loss: 0.48099  | 0.18\n",
      "[epoch: 1, batch:   3694] loss: 0.49663  | 0.18\n",
      "[epoch: 1, batch:   3696] loss: 0.15340  | 0.18\n",
      "[epoch: 1, batch:   3698] loss: 0.76249  | 0.18\n",
      "[epoch: 1, batch:   3700] loss: 0.32671  | 0.18\n",
      "[epoch: 1, batch:   3702] loss: 0.68418  | 0.18\n",
      "[epoch: 1, batch:   3704] loss: 0.15443  | 0.18\n",
      "[epoch: 1, batch:   3706] loss: 0.13106  | 0.18\n",
      "[epoch: 1, batch:   3708] loss: 0.48577  | 0.18\n",
      "[epoch: 1, batch:   3710] loss: 0.13481  | 0.18\n",
      "[epoch: 1, batch:   3712] loss: 0.29236  | 0.18\n",
      "[epoch: 1, batch:   3714] loss: 0.41704  | 0.18\n",
      "[epoch: 1, batch:   3716] loss: 0.47232  | 0.18\n",
      "[epoch: 1, batch:   3718] loss: 0.40921  | 0.18\n",
      "[epoch: 1, batch:   3720] loss: 0.89164  | 0.18\n",
      "[epoch: 1, batch:   3722] loss: 0.36472  | 0.18\n",
      "[epoch: 1, batch:   3724] loss: 0.26406  | 0.18\n",
      "[epoch: 1, batch:   3726] loss: 0.31004  | 0.18\n",
      "[epoch: 1, batch:   3728] loss: 0.14896  | 0.18\n",
      "[epoch: 1, batch:   3730] loss: 0.40707  | 0.18\n",
      "[epoch: 1, batch:   3732] loss: 0.72595  | 0.18\n",
      "[epoch: 1, batch:   3734] loss: 0.10125  | 0.18\n",
      "[epoch: 1, batch:   3736] loss: 0.14471  | 0.18\n",
      "[epoch: 1, batch:   3738] loss: 0.54813  | 0.18\n",
      "[epoch: 1, batch:   3740] loss: 0.19461  | 0.18\n",
      "[epoch: 1, batch:   3742] loss: 0.24525  | 0.18\n",
      "[epoch: 1, batch:   3744] loss: 0.12173  | 0.18\n",
      "[epoch: 1, batch:   3746] loss: 0.25756  | 0.18\n",
      "[epoch: 1, batch:   3748] loss: 0.22361  | 0.18\n",
      "[epoch: 1, batch:   3750] loss: 0.22555  | 0.18\n",
      "[epoch: 1, batch:   3752] loss: 0.52851  | 0.18\n",
      "[epoch: 1, batch:   3754] loss: 0.08450  | 0.18\n",
      "[epoch: 1, batch:   3756] loss: 0.41402  | 0.18\n",
      "[epoch: 1, batch:   3758] loss: 1.43080  | 0.18\n",
      "[epoch: 1, batch:   3760] loss: 0.31100  | 0.18\n",
      "[epoch: 1, batch:   3762] loss: 0.20364  | 0.18\n",
      "[epoch: 1, batch:   3764] loss: 0.55543  | 0.18\n",
      "[epoch: 1, batch:   3766] loss: 0.52624  | 0.18\n",
      "[epoch: 1, batch:   3768] loss: 0.61324  | 0.18\n",
      "[epoch: 1, batch:   3770] loss: 0.75585  | 0.18\n",
      "[epoch: 1, batch:   3772] loss: 0.36897  | 0.18\n",
      "[epoch: 1, batch:   3774] loss: 0.20969  | 0.18\n",
      "[epoch: 1, batch:   3776] loss: 0.10876  | 0.18\n",
      "[epoch: 1, batch:   3778] loss: 0.08815  | 0.18\n",
      "[epoch: 1, batch:   3780] loss: 0.43378  | 0.18\n",
      "[epoch: 1, batch:   3782] loss: 0.07057  | 0.18\n",
      "[epoch: 1, batch:   3784] loss: 1.07146  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch:   3786] loss: 0.22608  | 0.18\n",
      "[epoch: 1, batch:   3788] loss: 0.38499  | 0.18\n",
      "[epoch: 1, batch:   3790] loss: 0.12992  | 0.18\n",
      "[epoch: 1, batch:   3792] loss: 0.64485  | 0.18\n",
      "[epoch: 1, batch:   3794] loss: 0.12875  | 0.18\n",
      "[epoch: 1, batch:   3796] loss: 0.05673  | 0.18\n",
      "[epoch: 1, batch:   3798] loss: 0.32236  | 0.18\n",
      "[epoch: 1, batch:   3800] loss: 0.28765  | 0.18\n",
      "[epoch: 1, batch:   3802] loss: 0.22683  | 0.18\n",
      "[epoch: 1, batch:   3804] loss: 0.11233  | 0.18\n",
      "[epoch: 1, batch:   3806] loss: 0.74635  | 0.18\n",
      "[epoch: 1, batch:   3808] loss: 0.26790  | 0.18\n",
      "[epoch: 1, batch:   3810] loss: 0.34805  | 0.18\n",
      "[epoch: 1, batch:   3812] loss: 0.01806  | 0.18\n",
      "[epoch: 1, batch:   3814] loss: 0.06086  | 0.18\n",
      "[epoch: 1, batch:   3816] loss: 0.30792  | 0.18\n",
      "[epoch: 1, batch:   3818] loss: 0.39142  | 0.18\n",
      "[epoch: 1, batch:   3820] loss: 0.24288  | 0.18\n",
      "[epoch: 1, batch:   3822] loss: 0.46831  | 0.18\n",
      "[epoch: 1, batch:   3824] loss: 0.63608  | 0.18\n",
      "[epoch: 1, batch:   3826] loss: 0.77925  | 0.18\n",
      "[epoch: 1, batch:   3828] loss: 1.15357  | 0.18\n",
      "[epoch: 1, batch:   3830] loss: 0.50979  | 0.18\n",
      "[epoch: 1, batch:   3832] loss: 0.10700  | 0.18\n",
      "[epoch: 1, batch:   3834] loss: 0.21870  | 0.18\n",
      "[epoch: 1, batch:   3836] loss: 0.38682  | 0.18\n",
      "[epoch: 1, batch:   3838] loss: 0.12981  | 0.18\n",
      "[epoch: 1, batch:   3840] loss: 0.09407  | 0.18\n",
      "[epoch: 1, batch:   3842] loss: 0.07525  | 0.18\n",
      "[epoch: 1, batch:   3844] loss: 0.19668  | 0.18\n",
      "[epoch: 1, batch:   3846] loss: 0.26954  | 0.18\n",
      "[epoch: 1, batch:   3848] loss: 0.64684  | 0.18\n",
      "[epoch: 1, batch:   3850] loss: 0.49807  | 0.18\n",
      "[epoch: 1, batch:   3852] loss: 0.10920  | 0.18\n",
      "[epoch: 1, batch:   3854] loss: 0.19598  | 0.18\n",
      "[epoch: 1, batch:   3856] loss: 0.50600  | 0.18\n",
      "[epoch: 1, batch:   3858] loss: 0.39918  | 0.18\n",
      "[epoch: 1, batch:   3860] loss: 0.56425  | 0.18\n",
      "[epoch: 1, batch:   3862] loss: 0.69304  | 0.18\n",
      "[epoch: 1, batch:   3864] loss: 0.26994  | 0.18\n",
      "[epoch: 1, batch:   3866] loss: 0.88775  | 0.18\n",
      "[epoch: 1, batch:   3868] loss: 0.49423  | 0.18\n",
      "[epoch: 1, batch:   3870] loss: 0.60634  | 0.18\n",
      "[epoch: 1, batch:   3872] loss: 0.28141  | 0.18\n",
      "[epoch: 1, batch:   3874] loss: 1.07937  | 0.18\n",
      "[epoch: 1, batch:   3876] loss: 0.30739  | 0.18\n",
      "[epoch: 1, batch:   3878] loss: 0.21848  | 0.18\n",
      "[epoch: 1, batch:   3880] loss: 0.13017  | 0.18\n",
      "[epoch: 1, batch:   3882] loss: 0.35119  | 0.18\n",
      "[epoch: 1, batch:   3884] loss: 0.25406  | 0.18\n",
      "[epoch: 1, batch:   3886] loss: 0.12075  | 0.18\n",
      "[epoch: 1, batch:   3888] loss: 1.66639  | 0.18\n",
      "[epoch: 1, batch:   3890] loss: 0.77773  | 0.18\n",
      "[epoch: 1, batch:   3892] loss: 0.12830  | 0.18\n",
      "[epoch: 1, batch:   3894] loss: 0.23423  | 0.18\n",
      "[epoch: 1, batch:   3896] loss: 0.47152  | 0.18\n",
      "[epoch: 1, batch:   3898] loss: 0.51789  | 0.18\n",
      "[epoch: 1, batch:   3900] loss: 0.38794  | 0.18\n",
      "[epoch: 1, batch:   3902] loss: 0.39619  | 0.18\n",
      "[epoch: 1, batch:   3904] loss: 0.31401  | 0.18\n",
      "[epoch: 1, batch:   3906] loss: 0.04023  | 0.18\n",
      "[epoch: 1, batch:   3908] loss: 1.20870  | 0.18\n",
      "[epoch: 1, batch:   3910] loss: 0.43415  | 0.18\n",
      "[epoch: 1, batch:   3912] loss: 0.24981  | 0.18\n",
      "[epoch: 1, batch:   3914] loss: 0.13807  | 0.18\n",
      "[epoch: 1, batch:   3916] loss: 0.44190  | 0.18\n",
      "[epoch: 1, batch:   3918] loss: 0.31712  | 0.18\n",
      "[epoch: 1, batch:   3920] loss: 0.17911  | 0.18\n",
      "[epoch: 1, batch:   3922] loss: 0.77264  | 0.18\n",
      "[epoch: 1, batch:   3924] loss: 1.38367  | 0.18\n",
      "[epoch: 1, batch:   3926] loss: 0.47432  | 0.18\n",
      "[epoch: 1, batch:   3928] loss: 0.52305  | 0.18\n",
      "[epoch: 1, batch:   3930] loss: 0.81912  | 0.18\n",
      "[epoch: 1, batch:   3932] loss: 0.12889  | 0.18\n",
      "[epoch: 1, batch:   3934] loss: 0.71795  | 0.18\n",
      "[epoch: 1, batch:   3936] loss: 0.37012  | 0.18\n",
      "[epoch: 1, batch:   3938] loss: 0.56739  | 0.18\n",
      "[epoch: 1, batch:   3940] loss: 0.49056  | 0.18\n",
      "[epoch: 1, batch:   3942] loss: 0.25208  | 0.18\n",
      "[epoch: 1, batch:   3944] loss: 0.37341  | 0.18\n",
      "[epoch: 1, batch:   3946] loss: 0.24480  | 0.18\n",
      "[epoch: 1, batch:   3948] loss: 0.44828  | 0.18\n",
      "[epoch: 1, batch:   3950] loss: 0.16351  | 0.18\n",
      "[epoch: 1, batch:   3952] loss: 0.12791  | 0.18\n",
      "[epoch: 1, batch:   3954] loss: 0.09603  | 0.18\n",
      "[epoch: 1, batch:   3956] loss: 0.34344  | 0.18\n",
      "[epoch: 1, batch:   3958] loss: 0.49949  | 0.18\n",
      "[epoch: 1, batch:   3960] loss: 0.68575  | 0.18\n",
      "[epoch: 1, batch:   3962] loss: 0.48740  | 0.18\n",
      "[epoch: 1, batch:   3964] loss: 0.18610  | 0.18\n",
      "[epoch: 1, batch:   3966] loss: 0.30829  | 0.18\n",
      "[epoch: 1, batch:   3968] loss: 0.07333  | 0.18\n",
      "[epoch: 1, batch:   3970] loss: 0.52915  | 0.18\n",
      "[epoch: 1, batch:   3972] loss: 0.78606  | 0.18\n",
      "[epoch: 1, batch:   3974] loss: 0.30361  | 0.18\n",
      "[epoch: 1, batch:   3976] loss: 0.70951  | 0.18\n",
      "[epoch: 1, batch:   3978] loss: 0.47854  | 0.18\n",
      "[epoch: 1, batch:   3980] loss: 0.56197  | 0.18\n",
      "[epoch: 1, batch:   3982] loss: 0.08839  | 0.18\n",
      "[epoch: 1, batch:   3984] loss: 0.34946  | 0.18\n",
      "[epoch: 1, batch:   3986] loss: 0.12328  | 0.18\n",
      "[epoch: 1, batch:   3988] loss: 0.38335  | 0.18\n",
      "[epoch: 1, batch:   3990] loss: 1.44097  | 0.18\n",
      "[epoch: 1, batch:   3992] loss: 0.70017  | 0.18\n",
      "[epoch: 1, batch:   3994] loss: 0.22926  | 0.18\n",
      "[epoch: 1, batch:   3996] loss: 0.03914  | 0.18\n",
      "[epoch: 1, batch:   3998] loss: 1.26859  | 0.18\n",
      "[epoch: 1, batch:   4000] loss: 0.55528  | 0.18\n",
      "[epoch: 1, batch:   4002] loss: 0.16425  | 0.18\n",
      "[epoch: 1, batch:   4004] loss: 0.44482  | 0.18\n",
      "[epoch: 1, batch:   4006] loss: 0.22242  | 0.18\n",
      "[epoch: 1, batch:   4008] loss: 0.50335  | 0.18\n",
      "[epoch: 1, batch:   4010] loss: 0.12927  | 0.18\n",
      "[epoch: 1, batch:   4012] loss: 0.45883  | 0.18\n",
      "[epoch: 1, batch:   4014] loss: 0.91662  | 0.18\n",
      "[epoch: 1, batch:   4016] loss: 0.35429  | 0.18\n",
      "[epoch: 1, batch:   4018] loss: 0.68972  | 0.18\n",
      "[epoch: 1, batch:   4020] loss: 0.09331  | 0.18\n",
      "[epoch: 1, batch:   4022] loss: 0.15662  | 0.18\n",
      "[epoch: 1, batch:   4024] loss: 0.33876  | 0.18\n",
      "[epoch: 1, batch:   4026] loss: 0.77517  | 0.18\n",
      "[epoch: 1, batch:   4028] loss: 0.30354  | 0.18\n",
      "[epoch: 1, batch:   4030] loss: 0.14272  | 0.18\n",
      "[epoch: 1, batch:   4032] loss: 0.23730  | 0.18\n",
      "[epoch: 1, batch:   4034] loss: 0.61982  | 0.18\n",
      "[epoch: 1, batch:   4036] loss: 0.63939  | 0.18\n",
      "[epoch: 1, batch:   4038] loss: 0.50069  | 0.18\n",
      "[epoch: 1, batch:   4040] loss: 0.59606  | 0.18\n",
      "[epoch: 1, batch:   4042] loss: 0.29717  | 0.18\n",
      "[epoch: 1, batch:   4044] loss: 0.80509  | 0.18\n",
      "[epoch: 1, batch:   4046] loss: 1.98052  | 0.18\n",
      "[epoch: 1, batch:   4048] loss: 1.49794  | 0.18\n",
      "[epoch: 1, batch:   4050] loss: 0.34313  | 0.18\n",
      "[epoch: 1, batch:   4052] loss: 0.36089  | 0.18\n",
      "[epoch: 1, batch:   4054] loss: 0.35201  | 0.18\n",
      "[epoch: 1, batch:   4056] loss: 0.32532  | 0.18\n",
      "[epoch: 1, batch:   4058] loss: 1.26374  | 0.18\n",
      "[epoch: 1, batch:   4060] loss: 0.09960  | 0.18\n",
      "[epoch: 1, batch:   4062] loss: 0.01188  | 0.18\n",
      "[epoch: 1, batch:   4064] loss: 0.39198  | 0.18\n",
      "[epoch: 1, batch:   4066] loss: 0.24046  | 0.18\n",
      "[epoch: 1, batch:   4068] loss: 0.41400  | 0.18\n",
      "[epoch: 1, batch:   4070] loss: 0.34428  | 0.18\n",
      "[epoch: 1, batch:   4072] loss: 0.57174  | 0.18\n",
      "[epoch: 1, batch:   4074] loss: 0.32968  | 0.18\n",
      "[epoch: 1, batch:   4076] loss: 0.62351  | 0.18\n",
      "[epoch: 1, batch:   4078] loss: 0.11626  | 0.18\n",
      "[epoch: 1, batch:   4080] loss: 0.45104  | 0.18\n",
      "[epoch: 1, batch:   4082] loss: 0.25377  | 0.18\n",
      "[epoch: 1, batch:   4084] loss: 1.35799  | 0.18\n",
      "[epoch: 1, batch:   4086] loss: 0.14347  | 0.18\n",
      "[epoch: 1, batch:   4088] loss: 0.01877  | 0.18\n",
      "[epoch: 1, batch:   4090] loss: 0.10794  | 0.18\n",
      "[epoch: 1, batch:   4092] loss: 0.08873  | 0.18\n",
      "[epoch: 1, batch:   4094] loss: 0.59398  | 0.18\n",
      "[epoch: 1, batch:   4096] loss: 0.25076  | 0.18\n",
      "[epoch: 1, batch:   4098] loss: 0.36184  | 0.18\n",
      "[epoch: 1, batch:   4100] loss: 0.24270  | 0.18\n",
      "[epoch: 1, batch:   4102] loss: 0.11247  | 0.18\n",
      "[epoch: 1, batch:   4104] loss: 0.45017  | 0.18\n",
      "[epoch: 1, batch:   4106] loss: 0.55289  | 0.18\n",
      "[epoch: 1, batch:   4108] loss: 0.06566  | 0.18\n",
      "[epoch: 1, batch:   4110] loss: 0.54521  | 0.18\n",
      "[epoch: 1, batch:   4112] loss: 0.80909  | 0.18\n",
      "[epoch: 1, batch:   4114] loss: 0.29546  | 0.18\n",
      "[epoch: 1, batch:   4116] loss: 0.15738  | 0.18\n",
      "[epoch: 1, batch:   4118] loss: 0.98884  | 0.18\n",
      "[epoch: 1, batch:   4120] loss: 1.93919  | 0.18\n",
      "[epoch: 1, batch:   4122] loss: 0.90512  | 0.18\n",
      "[epoch: 1, batch:   4124] loss: 0.55332  | 0.18\n",
      "[epoch: 1, batch:   4126] loss: 0.31254  | 0.18\n",
      "[epoch: 1, batch:   4128] loss: 0.26771  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch:   4130] loss: 0.17902  | 0.18\n",
      "[epoch: 1, batch:   4132] loss: 0.52948  | 0.18\n",
      "[epoch: 1, batch:   4134] loss: 0.03382  | 0.18\n",
      "[epoch: 1, batch:   4136] loss: 0.24786  | 0.18\n",
      "[epoch: 1, batch:   4138] loss: 0.10228  | 0.18\n",
      "[epoch: 1, batch:   4140] loss: 0.54674  | 0.18\n",
      "[epoch: 1, batch:   4142] loss: 0.66357  | 0.18\n",
      "[epoch: 1, batch:   4144] loss: 0.14295  | 0.18\n",
      "[epoch: 1, batch:   4146] loss: 0.95952  | 0.18\n",
      "[epoch: 1, batch:   4148] loss: 0.13592  | 0.18\n",
      "[epoch: 1, batch:   4150] loss: 0.63698  | 0.18\n",
      "[epoch: 1, batch:   4152] loss: 0.30658  | 0.18\n",
      "[epoch: 1, batch:   4154] loss: 0.53469  | 0.18\n",
      "[epoch: 1, batch:   4156] loss: 0.15672  | 0.18\n",
      "[epoch: 1, batch:   4158] loss: 0.76472  | 0.18\n",
      "[epoch: 1, batch:   4160] loss: 0.60730  | 0.18\n",
      "[epoch: 1, batch:   4162] loss: 0.07963  | 0.18\n",
      "[epoch: 1, batch:   4164] loss: 0.31034  | 0.18\n",
      "[epoch: 1, batch:   4166] loss: 0.09957  | 0.18\n",
      "[epoch: 1, batch:   4168] loss: 0.09705  | 0.18\n",
      "[epoch: 1, batch:   4170] loss: 0.73045  | 0.18\n",
      "[epoch: 1, batch:   4172] loss: 0.26437  | 0.18\n",
      "[epoch: 1, batch:   4174] loss: 0.60200  | 0.18\n",
      "[epoch: 1, batch:   4176] loss: 0.40094  | 0.18\n",
      "[epoch: 1, batch:   4178] loss: 0.24579  | 0.18\n",
      "[epoch: 1, batch:   4180] loss: 0.70350  | 0.18\n",
      "[epoch: 1, batch:   4182] loss: 0.45800  | 0.18\n",
      "[epoch: 1, batch:   4184] loss: 0.16722  | 0.18\n",
      "[epoch: 1, batch:   4186] loss: 0.10701  | 0.18\n",
      "[epoch: 1, batch:   4188] loss: 0.78919  | 0.18\n",
      "[epoch: 1, batch:   4190] loss: 0.83786  | 0.18\n",
      "[epoch: 1, batch:   4192] loss: 0.28184  | 0.18\n",
      "[epoch: 1, batch:   4194] loss: 0.17549  | 0.19\n",
      "[epoch: 1, batch:   4196] loss: 0.04550  | 0.20\n",
      "[epoch: 1, batch:   4198] loss: 0.64776  | 0.19\n",
      "[epoch: 1, batch:   4200] loss: 0.71781  | 0.19\n",
      "[epoch: 1, batch:   4202] loss: 0.56170  | 0.19\n",
      "[epoch: 1, batch:   4204] loss: 0.96915  | 0.19\n",
      "[epoch: 1, batch:   4206] loss: 0.12670  | 0.19\n",
      "[epoch: 1, batch:   4208] loss: 0.74110  | 0.21\n",
      "[epoch: 1, batch:   4210] loss: 0.26867  | 0.19\n",
      "[epoch: 1, batch:   4212] loss: 1.59368  | 0.18\n",
      "[epoch: 1, batch:   4214] loss: 0.23431  | 0.18\n",
      "[epoch: 1, batch:   4216] loss: 0.42673  | 0.18\n",
      "[epoch: 1, batch:   4218] loss: 0.74145  | 0.18\n",
      "[epoch: 1, batch:   4220] loss: 0.81842  | 0.18\n",
      "[epoch: 1, batch:   4222] loss: 0.13310  | 0.19\n",
      "[epoch: 1, batch:   4224] loss: 0.06469  | 0.19\n",
      "[epoch: 1, batch:   4226] loss: 0.12077  | 0.18\n",
      "[epoch: 1, batch:   4228] loss: 0.05910  | 0.18\n",
      "[epoch: 1, batch:   4230] loss: 0.23489  | 0.18\n",
      "[epoch: 1, batch:   4232] loss: 0.15785  | 0.18\n",
      "[epoch: 1, batch:   4234] loss: 0.22408  | 0.18\n",
      "[epoch: 1, batch:   4236] loss: 0.19227  | 0.20\n",
      "[epoch: 1, batch:   4238] loss: 0.09463  | 0.19\n",
      "[epoch: 1, batch:   4240] loss: 0.10903  | 0.19\n",
      "[epoch: 1, batch:   4242] loss: 0.64397  | 0.19\n",
      "[epoch: 1, batch:   4244] loss: 0.64285  | 0.20\n",
      "[epoch: 1, batch:   4246] loss: 0.97001  | 0.20\n",
      "[epoch: 1, batch:   4248] loss: 0.74616  | 0.19\n",
      "[epoch: 1, batch:   4250] loss: 0.40489  | 0.19\n",
      "[epoch: 1, batch:   4252] loss: 0.54403  | 0.19\n",
      "[epoch: 1, batch:   4254] loss: 0.30659  | 0.19\n",
      "[epoch: 1, batch:   4256] loss: 0.35117  | 0.19\n",
      "[epoch: 1, batch:   4258] loss: 0.43719  | 0.19\n",
      "[epoch: 1, batch:   4260] loss: 0.46468  | 0.19\n",
      "[epoch: 1, batch:   4262] loss: 0.10117  | 0.19\n",
      "[epoch: 1, batch:   4264] loss: 0.63568  | 0.19\n",
      "[epoch: 1, batch:   4266] loss: 0.26197  | 0.18\n",
      "[epoch: 1, batch:   4268] loss: 0.42769  | 0.19\n",
      "[epoch: 1, batch:   4270] loss: 0.06092  | 0.19\n",
      "[epoch: 1, batch:   4272] loss: 0.43000  | 0.19\n",
      "[epoch: 1, batch:   4274] loss: 0.11963  | 0.19\n",
      "[epoch: 1, batch:   4276] loss: 0.01571  | 0.19\n",
      "[epoch: 1, batch:   4278] loss: 0.33671  | 0.19\n",
      "[epoch: 1, batch:   4280] loss: 0.10907  | 0.19\n",
      "[epoch: 1, batch:   4282] loss: 0.19711  | 0.18\n",
      "[epoch: 1, batch:   4284] loss: 0.69844  | 0.19\n",
      "[epoch: 1, batch:   4286] loss: 0.54253  | 0.19\n",
      "[epoch: 1, batch:   4288] loss: 0.36112  | 0.19\n",
      "[epoch: 1, batch:   4290] loss: 0.25504  | 0.19\n",
      "[epoch: 1, batch:   4292] loss: 0.17604  | 0.20\n",
      "[epoch: 1, batch:   4294] loss: 0.27232  | 0.20\n",
      "[epoch: 1, batch:   4296] loss: 0.49112  | 0.19\n",
      "[epoch: 1, batch:   4298] loss: 0.73801  | 0.19\n",
      "[epoch: 1, batch:   4300] loss: 0.01036  | 0.19\n",
      "[epoch: 1, batch:   4302] loss: 0.06804  | 0.18\n",
      "[epoch: 1, batch:   4304] loss: 0.17920  | 0.19\n",
      "[epoch: 1, batch:   4306] loss: 0.48295  | 0.19\n",
      "[epoch: 1, batch:   4308] loss: 0.57032  | 0.18\n",
      "[epoch: 1, batch:   4310] loss: 0.55683  | 0.19\n",
      "[epoch: 1, batch:   4312] loss: 0.29939  | 0.19\n",
      "[epoch: 1, batch:   4314] loss: 0.29119  | 0.19\n",
      "[epoch: 1, batch:   4316] loss: 0.33268  | 0.19\n",
      "[epoch: 1, batch:   4318] loss: 0.74365  | 0.19\n",
      "[epoch: 1, batch:   4320] loss: 0.07304  | 0.19\n",
      "[epoch: 1, batch:   4322] loss: 1.30059  | 0.20\n",
      "[epoch: 1, batch:   4324] loss: 0.49541  | 0.20\n",
      "[epoch: 1, batch:   4326] loss: 0.84564  | 0.20\n",
      "[epoch: 1, batch:   4328] loss: 0.22818  | 0.19\n",
      "[epoch: 1, batch:   4330] loss: 0.60604  | 0.20\n",
      "[epoch: 1, batch:   4332] loss: 0.03832  | 0.19\n",
      "[epoch: 1, batch:   4334] loss: 0.21239  | 0.18\n",
      "[epoch: 1, batch:   4336] loss: 0.43635  | 0.18\n",
      "[epoch: 1, batch:   4338] loss: 0.05499  | 0.19\n",
      "[epoch: 1, batch:   4340] loss: 0.35350  | 0.19\n",
      "[epoch: 1, batch:   4342] loss: 0.71683  | 0.19\n",
      "[epoch: 1, batch:   4344] loss: 0.06773  | 0.20\n",
      "[epoch: 1, batch:   4346] loss: 1.17520  | 0.20\n",
      "[epoch: 1, batch:   4348] loss: 0.35005  | 0.20\n",
      "[epoch: 1, batch:   4350] loss: 0.47517  | 0.19\n",
      "[epoch: 1, batch:   4352] loss: 0.33738  | 0.20\n",
      "[epoch: 1, batch:   4354] loss: 0.12266  | 0.20\n",
      "[epoch: 1, batch:   4356] loss: 1.20557  | 0.20\n",
      "[epoch: 1, batch:   4358] loss: 0.61288  | 0.20\n",
      "[epoch: 1, batch:   4360] loss: 0.83227  | 0.19\n",
      "[epoch: 1, batch:   4362] loss: 0.95899  | 0.20\n",
      "[epoch: 1, batch:   4364] loss: 1.46790  | 0.19\n",
      "[epoch: 1, batch:   4366] loss: 0.54048  | 0.19\n",
      "[epoch: 1, batch:   4368] loss: 0.16941  | 0.19\n",
      "[epoch: 1, batch:   4370] loss: 0.06979  | 0.19\n",
      "[epoch: 1, batch:   4372] loss: 0.19072  | 0.19\n",
      "[epoch: 1, batch:   4374] loss: 0.21312  | 0.20\n",
      "[epoch: 1, batch:   4376] loss: 0.22986  | 0.18\n",
      "[epoch: 1, batch:   4378] loss: 0.33643  | 0.19\n",
      "[epoch: 1, batch:   4380] loss: 0.33616  | 0.21\n",
      "[epoch: 1, batch:   4382] loss: 0.11293  | 0.18\n",
      "[epoch: 1, batch:   4384] loss: 0.22907  | 0.18\n",
      "[epoch: 1, batch:   4386] loss: 0.76343  | 0.18\n",
      "[epoch: 1, batch:   4388] loss: 0.13206  | 0.18\n",
      "[epoch: 1, batch:   4390] loss: 0.98298  | 0.18\n",
      "[epoch: 1, batch:   4392] loss: 0.45884  | 0.19\n",
      "[epoch: 1, batch:   4394] loss: 0.22858  | 0.19\n",
      "[epoch: 1, batch:   4396] loss: 0.47995  | 0.17\n",
      "[epoch: 1, batch:   4398] loss: 0.52942  | 0.18\n",
      "[epoch: 1, batch:   4400] loss: 0.32780  | 0.18\n",
      "[epoch: 1, batch:   4402] loss: 0.66407  | 0.18\n",
      "[epoch: 1, batch:   4404] loss: 0.29071  | 0.19\n",
      "[epoch: 1, batch:   4406] loss: 0.77386  | 0.18\n",
      "[epoch: 1, batch:   4408] loss: 0.10511  | 0.19\n",
      "[epoch: 1, batch:   4410] loss: 0.30881  | 0.19\n",
      "[epoch: 1, batch:   4412] loss: 0.22166  | 0.18\n",
      "[epoch: 1, batch:   4414] loss: 0.30161  | 0.19\n",
      "[epoch: 1, batch:   4416] loss: 0.02226  | 0.19\n",
      "[epoch: 1, batch:   4418] loss: 0.36683  | 0.20\n",
      "[epoch: 1, batch:   4420] loss: 0.35760  | 0.19\n",
      "[epoch: 1, batch:   4422] loss: 0.21758  | 0.20\n",
      "[epoch: 1, batch:   4424] loss: 0.20858  | 0.20\n",
      "[epoch: 1, batch:   4426] loss: 0.61562  | 0.20\n",
      "[epoch: 1, batch:   4428] loss: 0.38272  | 0.18\n",
      "[epoch: 1, batch:   4430] loss: 0.47456  | 0.18\n",
      "[epoch: 1, batch:   4432] loss: 0.41984  | 0.18\n",
      "[epoch: 1, batch:   4434] loss: 0.68524  | 0.18\n",
      "[epoch: 1, batch:   4436] loss: 0.46672  | 0.18\n",
      "[epoch: 1, batch:   4438] loss: 0.64901  | 0.18\n",
      "[epoch: 1, batch:   4440] loss: 0.22511  | 0.18\n",
      "[epoch: 1, batch:   4442] loss: 0.36696  | 0.18\n",
      "[epoch: 1, batch:   4444] loss: 0.20165  | 0.18\n",
      "[epoch: 1, batch:   4446] loss: 0.53430  | 0.18\n",
      "[epoch: 1, batch:   4448] loss: 0.34508  | 0.18\n",
      "[epoch: 1, batch:   4450] loss: 0.02361  | 0.18\n",
      "[epoch: 1, batch:   4452] loss: 0.54766  | 0.18\n",
      "[epoch: 1, batch:   4454] loss: 0.47376  | 0.19\n",
      "[epoch: 1, batch:   4456] loss: 0.03836  | 0.18\n",
      "[epoch: 1, batch:   4458] loss: 0.07600  | 0.18\n",
      "[epoch: 1, batch:   4460] loss: 0.79043  | 0.18\n",
      "[epoch: 1, batch:   4462] loss: 0.20623  | 0.18\n",
      "[epoch: 1, batch:   4464] loss: 0.55450  | 0.18\n",
      "[epoch: 1, batch:   4466] loss: 0.22720  | 0.19\n",
      "[epoch: 1, batch:   4468] loss: 0.23960  | 0.19\n",
      "[epoch: 1, batch:   4470] loss: 0.43953  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch:   4472] loss: 0.11544  | 0.18\n",
      "[epoch: 1, batch:   4474] loss: 0.24625  | 0.18\n",
      "[epoch: 1, batch:   4476] loss: 0.11328  | 0.19\n",
      "[epoch: 1, batch:   4478] loss: 0.35775  | 0.19\n",
      "[epoch: 1, batch:   4480] loss: 0.21404  | 0.19\n",
      "[epoch: 1, batch:   4482] loss: 0.69898  | 0.18\n",
      "[epoch: 1, batch:   4484] loss: 0.34127  | 0.18\n",
      "[epoch: 1, batch:   4486] loss: 0.02979  | 0.18\n",
      "[epoch: 1, batch:   4488] loss: 0.36718  | 0.19\n",
      "[epoch: 1, batch:   4490] loss: 0.80471  | 0.19\n",
      "[epoch: 1, batch:   4492] loss: 0.26996  | 0.19\n",
      "[epoch: 1, batch:   4494] loss: 0.20427  | 0.18\n",
      "[epoch: 1, batch:   4496] loss: 0.53228  | 0.19\n",
      "[epoch: 1, batch:   4498] loss: 0.16244  | 0.20\n",
      "[epoch: 1, batch:   4500] loss: 0.18089  | 0.19\n",
      "[epoch: 1, batch:   4502] loss: 0.14726  | 0.19\n",
      "[epoch: 1, batch:   4504] loss: 0.59230  | 0.20\n",
      "[epoch: 1, batch:   4506] loss: 0.44813  | 0.18\n",
      "[epoch: 1, batch:   4508] loss: 0.25975  | 0.18\n",
      "[epoch: 1, batch:   4510] loss: 0.51355  | 0.19\n",
      "[epoch: 1, batch:   4512] loss: 0.20053  | 0.18\n",
      "[epoch: 1, batch:   4514] loss: 0.11362  | 0.19\n",
      "[epoch: 1, batch:   4516] loss: 0.71449  | 0.20\n",
      "[epoch: 1, batch:   4518] loss: 0.43960  | 0.19\n",
      "[epoch: 1, batch:   4520] loss: 0.38223  | 0.18\n",
      "[epoch: 1, batch:   4522] loss: 0.42562  | 0.18\n",
      "[epoch: 1, batch:   4524] loss: 0.47488  | 0.18\n",
      "[epoch: 1, batch:   4526] loss: 0.28978  | 0.18\n",
      "[epoch: 1, batch:   4528] loss: 0.36950  | 0.18\n",
      "[epoch: 1, batch:   4530] loss: 0.36360  | 0.18\n",
      "[epoch: 1, batch:   4532] loss: 0.24208  | 0.18\n",
      "[epoch: 1, batch:   4534] loss: 0.17323  | 0.19\n",
      "[epoch: 1, batch:   4536] loss: 0.12803  | 0.19\n",
      "[epoch: 1, batch:   4538] loss: 0.20063  | 0.18\n",
      "[epoch: 1, batch:   4540] loss: 0.09281  | 0.20\n",
      "[epoch: 1, batch:   4542] loss: 0.93441  | 0.19\n",
      "[epoch: 1, batch:   4544] loss: 0.60451  | 0.18\n",
      "[epoch: 1, batch:   4546] loss: 0.06384  | 0.19\n",
      "[epoch: 1, batch:   4548] loss: 0.29070  | 0.19\n",
      "[epoch: 1, batch:   4550] loss: 0.04580  | 0.18\n",
      "[epoch: 1, batch:   4552] loss: 0.30028  | 0.18\n",
      "[epoch: 1, batch:   4554] loss: 0.42131  | 0.18\n",
      "[epoch: 1, batch:   4556] loss: 0.58150  | 0.18\n",
      "[epoch: 1, batch:   4558] loss: 0.28759  | 0.18\n",
      "[epoch: 1, batch:   4560] loss: 0.42948  | 0.19\n",
      "[epoch: 1, batch:   4562] loss: 0.42383  | 0.20\n",
      "[epoch: 1, batch:   4564] loss: 0.63302  | 0.20\n",
      "[epoch: 1, batch:   4566] loss: 1.00773  | 0.18\n",
      "[epoch: 1, batch:   4568] loss: 0.14288  | 0.18\n",
      "[epoch: 1, batch:   4570] loss: 0.36770  | 0.18\n",
      "[epoch: 1, batch:   4572] loss: 0.13486  | 0.18\n",
      "[epoch: 1, batch:   4574] loss: 0.07725  | 0.18\n",
      "[epoch: 1, batch:   4576] loss: 0.24371  | 0.18\n",
      "[epoch: 1, batch:   4578] loss: 0.21731  | 0.18\n",
      "[epoch: 1, batch:   4580] loss: 0.67112  | 0.18\n",
      "[epoch: 1, batch:   4582] loss: 0.42162  | 0.18\n",
      "[epoch: 1, batch:   4584] loss: 0.10928  | 0.20\n",
      "[epoch: 1, batch:   4586] loss: 0.78439  | 0.19\n",
      "[epoch: 1, batch:   4588] loss: 0.10635  | 0.18\n",
      "[epoch: 1, batch:   4590] loss: 0.19766  | 0.19\n",
      "[epoch: 1, batch:   4592] loss: 0.43350  | 0.19\n",
      "[epoch: 1, batch:   4594] loss: 0.40546  | 0.18\n",
      "[epoch: 1, batch:   4596] loss: 0.62285  | 0.18\n",
      "[epoch: 1, batch:   4598] loss: 0.33215  | 0.18\n",
      "[epoch: 1, batch:   4600] loss: 0.28169  | 0.18\n",
      "[epoch: 1, batch:   4602] loss: 0.41106  | 0.18\n",
      "[epoch: 1, batch:   4604] loss: 0.50962  | 0.18\n",
      "[epoch: 1, batch:   4606] loss: 0.15421  | 0.18\n",
      "[epoch: 1, batch:   4608] loss: 0.27748  | 0.18\n",
      "[epoch: 1, batch:   4610] loss: 0.55830  | 0.18\n",
      "[epoch: 1, batch:   4612] loss: 0.15636  | 0.18\n",
      "[epoch: 1, batch:   4614] loss: 0.20775  | 0.18\n",
      "[epoch: 1, batch:   4616] loss: 0.13159  | 0.18\n",
      "[epoch: 1, batch:   4618] loss: 0.09129  | 0.18\n",
      "[epoch: 1, batch:   4620] loss: 0.34276  | 0.18\n",
      "[epoch: 1, batch:   4622] loss: 0.33436  | 0.18\n",
      "[epoch: 1, batch:   4624] loss: 0.25484  | 0.18\n",
      "[epoch: 1, batch:   4626] loss: 0.58269  | 0.18\n",
      "[epoch: 1, batch:   4628] loss: 0.18089  | 0.19\n",
      "[epoch: 1, batch:   4630] loss: 0.41376  | 0.18\n",
      "[epoch: 1, batch:   4632] loss: 0.17236  | 0.18\n",
      "[epoch: 1, batch:   4634] loss: 0.49174  | 0.18\n",
      "[epoch: 1, batch:   4636] loss: 0.10846  | 0.18\n",
      "[epoch: 1, batch:   4638] loss: 0.31941  | 0.18\n",
      "[epoch: 1, batch:   4640] loss: 0.33396  | 0.18\n",
      "[epoch: 1, batch:   4642] loss: 0.46372  | 0.18\n",
      "[epoch: 1, batch:   4644] loss: 0.38887  | 0.18\n",
      "[epoch: 1, batch:   4646] loss: 0.65039  | 0.18\n",
      "[epoch: 1, batch:   4648] loss: 0.19298  | 0.18\n",
      "[epoch: 1, batch:   4650] loss: 0.64472  | 0.18\n",
      "[epoch: 1, batch:   4652] loss: 0.73412  | 0.18\n",
      "[epoch: 1, batch:   4654] loss: 0.45846  | 0.18\n",
      "[epoch: 1, batch:   4656] loss: 0.06793  | 0.18\n",
      "[epoch: 1, batch:   4658] loss: 0.42191  | 0.18\n",
      "[epoch: 1, batch:   4660] loss: 0.57200  | 0.18\n",
      "[epoch: 1, batch:   4662] loss: 0.09980  | 0.18\n",
      "[epoch: 1, batch:   4664] loss: 0.19690  | 0.18\n",
      "[epoch: 1, batch:   4666] loss: 0.87696  | 0.18\n",
      "[epoch: 1, batch:   4668] loss: 0.12990  | 0.18\n",
      "[epoch: 1, batch:   4670] loss: 0.39774  | 0.18\n",
      "[epoch: 1, batch:   4672] loss: 0.08311  | 0.18\n",
      "[epoch: 1, batch:   4674] loss: 0.35938  | 0.18\n",
      "[epoch: 1, batch:   4676] loss: 0.60210  | 0.18\n",
      "[epoch: 1, batch:   4678] loss: 0.71652  | 0.18\n",
      "[epoch: 1, batch:   4680] loss: 0.15795  | 0.19\n",
      "[epoch: 1, batch:   4682] loss: 0.75494  | 0.17\n",
      "[epoch: 1, batch:   4684] loss: 1.36235  | 0.18\n",
      "[epoch: 1, batch:   4686] loss: 0.47712  | 0.18\n",
      "[epoch: 1, batch:   4688] loss: 0.09619  | 0.18\n",
      "[epoch: 1, batch:   4690] loss: 0.39431  | 0.18\n",
      "[epoch: 1, batch:   4692] loss: 0.20133  | 0.18\n",
      "[epoch: 1, batch:   4694] loss: 0.29490  | 0.19\n",
      "[epoch: 1, batch:   4696] loss: 0.33908  | 0.18\n",
      "[epoch: 1, batch:   4698] loss: 0.24688  | 0.17\n",
      "[epoch: 1, batch:   4700] loss: 0.40140  | 0.18\n",
      "[epoch: 1, batch:   4702] loss: 0.50565  | 0.18\n",
      "[epoch: 1, batch:   4704] loss: 0.17163  | 0.18\n",
      "[epoch: 1, batch:   4706] loss: 0.78866  | 0.18\n",
      "[epoch: 1, batch:   4708] loss: 0.02823  | 0.18\n",
      "[epoch: 1, batch:   4710] loss: 0.59010  | 0.18\n",
      "[epoch: 1, batch:   4712] loss: 0.18779  | 0.18\n",
      "[epoch: 1, batch:   4714] loss: 0.36208  | 0.18\n",
      "[epoch: 1, batch:   4716] loss: 0.08871  | 0.18\n",
      "[epoch: 1, batch:   4718] loss: 0.14251  | 0.18\n",
      "[epoch: 1, batch:   4720] loss: 0.10702  | 0.18\n",
      "[epoch: 1, batch:   4722] loss: 0.12149  | 0.18\n",
      "[epoch: 1, batch:   4724] loss: 0.43427  | 0.18\n",
      "[epoch: 1, batch:   4726] loss: 0.09750  | 0.18\n",
      "[epoch: 1, batch:   4728] loss: 0.07219  | 0.19\n",
      "[epoch: 1, batch:   4730] loss: 0.14723  | 0.18\n",
      "[epoch: 1, batch:   4732] loss: 0.13131  | 0.18\n",
      "[epoch: 1, batch:   4734] loss: 0.64934  | 0.18\n",
      "[epoch: 1, batch:   4736] loss: 1.91149  | 0.18\n",
      "[epoch: 1, batch:   4738] loss: 0.30493  | 0.19\n",
      "[epoch: 1, batch:   4740] loss: 0.11340  | 0.19\n",
      "[epoch: 1, batch:   4742] loss: 0.31558  | 0.18\n",
      "[epoch: 1, batch:   4744] loss: 0.03297  | 0.18\n",
      "[epoch: 1, batch:   4746] loss: 0.83120  | 0.18\n",
      "[epoch: 1, batch:   4748] loss: 0.67636  | 0.18\n",
      "[epoch: 1, batch:   4750] loss: 0.49699  | 0.18\n",
      "[epoch: 1, batch:   4752] loss: 0.76930  | 0.18\n",
      "[epoch: 1, batch:   4754] loss: 0.26421  | 0.18\n",
      "[epoch: 1, batch:   4756] loss: 0.38799  | 0.18\n",
      "[epoch: 1, batch:   4758] loss: 0.72353  | 0.18\n",
      "[epoch: 1, batch:   4760] loss: 0.37975  | 0.18\n",
      "[epoch: 1, batch:   4762] loss: 0.21991  | 0.18\n",
      "[epoch: 1, batch:   4764] loss: 0.27994  | 0.18\n",
      "[epoch: 1, batch:   4766] loss: 0.30605  | 0.18\n",
      "[epoch: 1, batch:   4768] loss: 0.08521  | 0.18\n",
      "[epoch: 1, batch:   4770] loss: 0.39567  | 0.18\n",
      "[epoch: 1, batch:   4772] loss: 0.21102  | 0.18\n",
      "[epoch: 1, batch:   4774] loss: 0.27073  | 0.18\n",
      "[epoch: 1, batch:   4776] loss: 0.16839  | 0.18\n",
      "[epoch: 1, batch:   4778] loss: 0.10785  | 0.18\n",
      "[epoch: 1, batch:   4780] loss: 0.11298  | 0.18\n",
      "[epoch: 1, batch:   4782] loss: 0.13648  | 0.18\n",
      "[epoch: 1, batch:   4784] loss: 0.50565  | 0.18\n",
      "[epoch: 1, batch:   4786] loss: 0.21490  | 0.18\n",
      "[epoch: 1, batch:   4788] loss: 0.25658  | 0.18\n",
      "[epoch: 1, batch:   4790] loss: 1.26934  | 0.18\n",
      "[epoch: 1, batch:   4792] loss: 0.63104  | 0.20\n",
      "[epoch: 1, batch:   4794] loss: 0.55279  | 0.18\n",
      "[epoch: 1, batch:   4796] loss: 0.03833  | 0.18\n",
      "[epoch: 1, batch:   4798] loss: 1.11739  | 0.18\n",
      "[epoch: 1, batch:   4800] loss: 0.61855  | 0.18\n",
      "[epoch: 1, batch:   4802] loss: 0.41053  | 0.18\n",
      "[epoch: 1, batch:   4804] loss: 0.74779  | 0.18\n",
      "[epoch: 1, batch:   4806] loss: 0.19684  | 0.20\n",
      "[epoch: 1, batch:   4808] loss: 0.28533  | 0.18\n",
      "[epoch: 1, batch:   4810] loss: 0.15547  | 0.18\n",
      "[epoch: 1, batch:   4812] loss: 1.02519  | 0.18\n",
      "[epoch: 1, batch:   4814] loss: 0.51901  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch:   4816] loss: 0.21325  | 0.18\n",
      "[epoch: 1, batch:   4818] loss: 0.34388  | 0.18\n",
      "[epoch: 1, batch:   4820] loss: 0.61759  | 0.18\n",
      "[epoch: 1, batch:   4822] loss: 0.17800  | 0.18\n",
      "[epoch: 1, batch:   4824] loss: 0.43104  | 0.18\n",
      "[epoch: 1, batch:   4826] loss: 0.45533  | 0.18\n",
      "[epoch: 1, batch:   4828] loss: 0.39435  | 0.18\n",
      "[epoch: 1, batch:   4830] loss: 0.58127  | 0.19\n",
      "[epoch: 1, batch:   4832] loss: 0.28309  | 0.20\n",
      "[epoch: 1, batch:   4834] loss: 0.06857  | 0.18\n",
      "[epoch: 1, batch:   4836] loss: 0.12829  | 0.18\n",
      "[epoch: 1, batch:   4838] loss: 0.38099  | 0.18\n",
      "[epoch: 1, batch:   4840] loss: 0.70636  | 0.18\n",
      "[epoch: 1, batch:   4842] loss: 0.04627  | 0.18\n",
      "[epoch: 1, batch:   4844] loss: 0.35451  | 0.18\n",
      "[epoch: 1, batch:   4846] loss: 0.79677  | 0.18\n",
      "[epoch: 1, batch:   4848] loss: 0.23334  | 0.19\n",
      "[epoch: 1, batch:   4850] loss: 0.64397  | 0.18\n",
      "[epoch: 1, batch:   4852] loss: 0.23993  | 0.18\n",
      "[epoch: 1, batch:   4854] loss: 0.13808  | 0.18\n",
      "[epoch: 1, batch:   4856] loss: 0.15952  | 0.18\n",
      "[epoch: 1, batch:   4858] loss: 0.68120  | 0.18\n",
      "[epoch: 1, batch:   4860] loss: 0.31314  | 0.19\n",
      "[epoch: 1, batch:   4862] loss: 0.35030  | 0.18\n",
      "[epoch: 1, batch:   4864] loss: 0.05383  | 0.18\n",
      "[epoch: 1, batch:   4866] loss: 0.39146  | 0.19\n",
      "[epoch: 1, batch:   4868] loss: 0.29636  | 0.18\n",
      "[epoch: 1, batch:   4870] loss: 0.55096  | 0.18\n",
      "[epoch: 1, batch:   4872] loss: 0.82087  | 0.18\n",
      "[epoch: 1, batch:   4874] loss: 0.36993  | 0.18\n",
      "[epoch: 1, batch:   4876] loss: 0.36049  | 0.18\n",
      "[epoch: 1, batch:   4878] loss: 0.20773  | 0.18\n",
      "[epoch: 1, batch:   4880] loss: 0.56055  | 0.18\n",
      "[epoch: 1, batch:   4882] loss: 0.15707  | 0.18\n",
      "[epoch: 1, batch:   4884] loss: 0.50835  | 0.18\n",
      "[epoch: 1, batch:   4886] loss: 0.46395  | 0.18\n",
      "[epoch: 1, batch:   4888] loss: 0.50620  | 0.18\n",
      "[epoch: 1, batch:   4890] loss: 0.42572  | 0.18\n",
      "[epoch: 1, batch:   4892] loss: 0.19720  | 0.18\n",
      "[epoch: 1, batch:   4894] loss: 0.15216  | 0.18\n",
      "[epoch: 1, batch:   4896] loss: 0.17862  | 0.18\n",
      "[epoch: 1, batch:   4898] loss: 0.08513  | 0.18\n",
      "[epoch: 1, batch:   4900] loss: 0.35644  | 0.18\n",
      "[epoch: 1, batch:   4902] loss: 0.82258  | 0.18\n",
      "[epoch: 1, batch:   4904] loss: 0.55639  | 0.18\n",
      "[epoch: 1, batch:   4906] loss: 0.05516  | 0.18\n",
      "[epoch: 1, batch:   4908] loss: 0.28075  | 0.18\n",
      "[epoch: 1, batch:   4910] loss: 0.79548  | 0.18\n",
      "[epoch: 1, batch:   4912] loss: 0.52154  | 0.18\n",
      "[epoch: 1, batch:   4914] loss: 0.42602  | 0.18\n",
      "[epoch: 1, batch:   4916] loss: 0.19269  | 0.18\n",
      "[epoch: 1, batch:   4918] loss: 0.65683  | 0.18\n",
      "[epoch: 1, batch:   4920] loss: 0.22947  | 0.18\n",
      "[epoch: 1, batch:   4922] loss: 0.52817  | 0.20\n",
      "[epoch: 1, batch:   4924] loss: 0.06071  | 0.19\n",
      "[epoch: 1, batch:   4926] loss: 1.19641  | 0.18\n",
      "[epoch: 1, batch:   4928] loss: 0.31287  | 0.19\n",
      "[epoch: 1, batch:   4930] loss: 0.27234  | 0.20\n",
      "[epoch: 1, batch:   4932] loss: 0.45238  | 0.19\n",
      "[epoch: 1, batch:   4934] loss: 0.22304  | 0.19\n",
      "[epoch: 1, batch:   4936] loss: 0.18566  | 0.19\n",
      "[epoch: 1, batch:   4938] loss: 0.51430  | 0.20\n",
      "[epoch: 1, batch:   4940] loss: 1.82480  | 0.19\n",
      "[epoch: 1, batch:   4942] loss: 0.24163  | 0.20\n",
      "[epoch: 1, batch:   4944] loss: 0.48226  | 0.19\n",
      "[epoch: 1, batch:   4946] loss: 0.92853  | 0.19\n",
      "[epoch: 1, batch:   4948] loss: 0.09432  | 0.19\n",
      "[epoch: 1, batch:   4950] loss: 0.10127  | 0.19\n",
      "[epoch: 1, batch:   4952] loss: 0.64900  | 0.19\n",
      "[epoch: 1, batch:   4954] loss: 0.29219  | 0.19\n",
      "[epoch: 1, batch:   4956] loss: 0.35200  | 0.19\n",
      "[epoch: 1, batch:   4958] loss: 0.64776  | 0.19\n",
      "[epoch: 1, batch:   4960] loss: 0.16173  | 0.19\n",
      "[epoch: 1, batch:   4962] loss: 0.35860  | 0.19\n",
      "[epoch: 1, batch:   4964] loss: 0.49651  | 0.18\n",
      "[epoch: 1, batch:   4966] loss: 0.41625  | 0.19\n",
      "[epoch: 1, batch:   4968] loss: 0.37824  | 0.20\n",
      "[epoch: 1, batch:   4970] loss: 0.47537  | 0.19\n",
      "[epoch: 1, batch:   4972] loss: 0.60085  | 0.18\n",
      "[epoch: 1, batch:   4974] loss: 0.52802  | 0.18\n",
      "[epoch: 1, batch:   4976] loss: 0.35408  | 0.18\n",
      "[epoch: 1, batch:   4978] loss: 0.12942  | 0.19\n",
      "[epoch: 1, batch:   4980] loss: 0.63300  | 0.18\n",
      "[epoch: 1, batch:   4982] loss: 0.17890  | 0.20\n",
      "[epoch: 1, batch:   4984] loss: 0.67767  | 0.19\n",
      "[epoch: 1, batch:   4986] loss: 0.60644  | 0.18\n",
      "[epoch: 1, batch:   4988] loss: 0.21052  | 0.18\n",
      "[epoch: 1, batch:   4990] loss: 0.23802  | 0.19\n",
      "[epoch: 1, batch:   4992] loss: 0.26107  | 0.18\n",
      "[epoch: 1, batch:   4994] loss: 0.10571  | 0.18\n",
      "[epoch: 1, batch:   4996] loss: 0.04478  | 0.18\n",
      "[epoch: 1, batch:   4998] loss: 0.21778  | 0.18\n",
      "[epoch: 1, batch:   5000] loss: 0.04476  | 0.18\n",
      "[epoch: 2, batch:      2] loss: 0.55437  | 0.54\n",
      "[epoch: 2, batch:      4] loss: 0.20319  | 0.19\n",
      "[epoch: 2, batch:      6] loss: 0.35935  | 0.19\n",
      "[epoch: 2, batch:      8] loss: 0.56358  | 0.18\n",
      "[epoch: 2, batch:     10] loss: 0.33535  | 0.18\n",
      "[epoch: 2, batch:     12] loss: 0.63626  | 0.17\n",
      "[epoch: 2, batch:     14] loss: 0.33404  | 0.18\n",
      "[epoch: 2, batch:     16] loss: 1.55066  | 0.18\n",
      "[epoch: 2, batch:     18] loss: 1.04317  | 0.18\n",
      "[epoch: 2, batch:     20] loss: 0.36466  | 0.18\n",
      "[epoch: 2, batch:     22] loss: 1.08700  | 0.19\n",
      "[epoch: 2, batch:     24] loss: 1.01542  | 0.18\n",
      "[epoch: 2, batch:     26] loss: 0.09598  | 0.18\n",
      "[epoch: 2, batch:     28] loss: 0.53543  | 0.18\n",
      "[epoch: 2, batch:     30] loss: 0.71028  | 0.18\n",
      "[epoch: 2, batch:     32] loss: 0.30100  | 0.18\n",
      "[epoch: 2, batch:     34] loss: 0.20862  | 0.18\n",
      "[epoch: 2, batch:     36] loss: 2.06418  | 0.18\n",
      "[epoch: 2, batch:     38] loss: 0.14696  | 0.18\n",
      "[epoch: 2, batch:     40] loss: 0.64610  | 0.18\n",
      "[epoch: 2, batch:     42] loss: 0.94812  | 0.18\n",
      "[epoch: 2, batch:     44] loss: 0.48319  | 0.18\n",
      "[epoch: 2, batch:     46] loss: 0.19399  | 0.18\n",
      "[epoch: 2, batch:     48] loss: 0.30107  | 0.18\n",
      "[epoch: 2, batch:     50] loss: 0.04048  | 0.18\n",
      "[epoch: 2, batch:     52] loss: 0.45640  | 0.18\n",
      "[epoch: 2, batch:     54] loss: 0.37968  | 0.18\n",
      "[epoch: 2, batch:     56] loss: 0.24674  | 0.18\n",
      "[epoch: 2, batch:     58] loss: 1.29224  | 0.18\n",
      "[epoch: 2, batch:     60] loss: 0.21351  | 0.18\n",
      "[epoch: 2, batch:     62] loss: 0.08274  | 0.19\n",
      "[epoch: 2, batch:     64] loss: 0.47464  | 0.18\n",
      "[epoch: 2, batch:     66] loss: 0.35824  | 0.19\n",
      "[epoch: 2, batch:     68] loss: 0.10729  | 0.18\n",
      "[epoch: 2, batch:     70] loss: 0.07827  | 0.19\n",
      "[epoch: 2, batch:     72] loss: 0.60478  | 0.19\n",
      "[epoch: 2, batch:     74] loss: 0.09149  | 0.18\n",
      "[epoch: 2, batch:     76] loss: 0.67532  | 0.18\n",
      "[epoch: 2, batch:     78] loss: 0.45384  | 0.19\n",
      "[epoch: 2, batch:     80] loss: 0.15949  | 0.18\n",
      "[epoch: 2, batch:     82] loss: 0.02835  | 0.18\n",
      "[epoch: 2, batch:     84] loss: 0.14362  | 0.18\n",
      "[epoch: 2, batch:     86] loss: 1.57310  | 0.18\n",
      "[epoch: 2, batch:     88] loss: 0.75907  | 0.18\n",
      "[epoch: 2, batch:     90] loss: 0.36022  | 0.18\n",
      "[epoch: 2, batch:     92] loss: 0.56547  | 0.18\n",
      "[epoch: 2, batch:     94] loss: 0.69092  | 0.18\n",
      "[epoch: 2, batch:     96] loss: 0.29719  | 0.18\n",
      "[epoch: 2, batch:     98] loss: 0.07486  | 0.18\n",
      "[epoch: 2, batch:    100] loss: 0.98318  | 0.18\n",
      "[epoch: 2, batch:    102] loss: 0.28231  | 0.18\n",
      "[epoch: 2, batch:    104] loss: 0.44452  | 0.18\n",
      "[epoch: 2, batch:    106] loss: 0.50522  | 0.18\n",
      "[epoch: 2, batch:    108] loss: 0.64430  | 0.18\n",
      "[epoch: 2, batch:    110] loss: 0.28695  | 0.18\n",
      "[epoch: 2, batch:    112] loss: 0.78210  | 0.18\n",
      "[epoch: 2, batch:    114] loss: 0.62328  | 0.19\n",
      "[epoch: 2, batch:    116] loss: 0.21592  | 0.18\n",
      "[epoch: 2, batch:    118] loss: 0.68102  | 0.18\n",
      "[epoch: 2, batch:    120] loss: 0.22027  | 0.18\n",
      "[epoch: 2, batch:    122] loss: 0.09272  | 0.19\n",
      "[epoch: 2, batch:    124] loss: 0.44686  | 0.18\n",
      "[epoch: 2, batch:    126] loss: 0.15180  | 0.19\n",
      "[epoch: 2, batch:    128] loss: 0.25064  | 0.19\n",
      "[epoch: 2, batch:    130] loss: 0.09022  | 0.18\n",
      "[epoch: 2, batch:    132] loss: 0.24799  | 0.18\n",
      "[epoch: 2, batch:    134] loss: 0.24425  | 0.18\n",
      "[epoch: 2, batch:    136] loss: 0.13081  | 0.18\n",
      "[epoch: 2, batch:    138] loss: 0.76228  | 0.18\n",
      "[epoch: 2, batch:    140] loss: 0.23900  | 0.18\n",
      "[epoch: 2, batch:    142] loss: 0.59561  | 0.18\n",
      "[epoch: 2, batch:    144] loss: 0.42742  | 0.18\n",
      "[epoch: 2, batch:    146] loss: 0.44534  | 0.18\n",
      "[epoch: 2, batch:    148] loss: 0.39086  | 0.18\n",
      "[epoch: 2, batch:    150] loss: 0.66667  | 0.18\n",
      "[epoch: 2, batch:    152] loss: 0.28404  | 0.18\n",
      "[epoch: 2, batch:    154] loss: 0.30966  | 0.18\n",
      "[epoch: 2, batch:    156] loss: 0.54103  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 2, batch:    158] loss: 0.38238  | 0.18\n",
      "[epoch: 2, batch:    160] loss: 0.69921  | 0.18\n",
      "[epoch: 2, batch:    162] loss: 0.25236  | 0.18\n",
      "[epoch: 2, batch:    164] loss: 0.33431  | 0.18\n",
      "[epoch: 2, batch:    166] loss: 0.75715  | 0.19\n",
      "[epoch: 2, batch:    168] loss: 0.20784  | 0.18\n",
      "[epoch: 2, batch:    170] loss: 0.13806  | 0.18\n",
      "[epoch: 2, batch:    172] loss: 0.09180  | 0.18\n",
      "[epoch: 2, batch:    174] loss: 0.30786  | 0.18\n",
      "[epoch: 2, batch:    176] loss: 0.78689  | 0.18\n",
      "[epoch: 2, batch:    178] loss: 0.28090  | 0.18\n",
      "[epoch: 2, batch:    180] loss: 0.13634  | 0.18\n",
      "[epoch: 2, batch:    182] loss: 0.16217  | 0.18\n",
      "[epoch: 2, batch:    184] loss: 0.62814  | 0.18\n",
      "[epoch: 2, batch:    186] loss: 0.37063  | 0.19\n",
      "[epoch: 2, batch:    188] loss: 0.62459  | 0.18\n",
      "[epoch: 2, batch:    190] loss: 0.23286  | 0.19\n",
      "[epoch: 2, batch:    192] loss: 0.48099  | 0.18\n",
      "[epoch: 2, batch:    194] loss: 0.51066  | 0.18\n",
      "[epoch: 2, batch:    196] loss: 0.26604  | 0.18\n",
      "[epoch: 2, batch:    198] loss: 0.37951  | 0.19\n",
      "[epoch: 2, batch:    200] loss: 0.37948  | 0.18\n",
      "[epoch: 2, batch:    202] loss: 0.48354  | 0.18\n",
      "[epoch: 2, batch:    204] loss: 0.07815  | 0.18\n",
      "[epoch: 2, batch:    206] loss: 0.23876  | 0.18\n",
      "[epoch: 2, batch:    208] loss: 0.07563  | 0.18\n",
      "[epoch: 2, batch:    210] loss: 0.10597  | 0.19\n",
      "[epoch: 2, batch:    212] loss: 0.24835  | 0.18\n",
      "[epoch: 2, batch:    214] loss: 0.54840  | 0.18\n",
      "[epoch: 2, batch:    216] loss: 0.67540  | 0.18\n",
      "[epoch: 2, batch:    218] loss: 0.13793  | 0.19\n",
      "[epoch: 2, batch:    220] loss: 0.10862  | 0.18\n",
      "[epoch: 2, batch:    222] loss: 0.76044  | 0.18\n",
      "[epoch: 2, batch:    224] loss: 0.17306  | 0.18\n",
      "[epoch: 2, batch:    226] loss: 0.58928  | 0.18\n",
      "[epoch: 2, batch:    228] loss: 0.14766  | 0.18\n",
      "[epoch: 2, batch:    230] loss: 0.16543  | 0.18\n",
      "[epoch: 2, batch:    232] loss: 0.06754  | 0.18\n",
      "[epoch: 2, batch:    234] loss: 0.28934  | 0.18\n",
      "[epoch: 2, batch:    236] loss: 0.20335  | 0.18\n",
      "[epoch: 2, batch:    238] loss: 0.12234  | 0.19\n",
      "[epoch: 2, batch:    240] loss: 0.35864  | 0.18\n",
      "[epoch: 2, batch:    242] loss: 0.43861  | 0.18\n",
      "[epoch: 2, batch:    244] loss: 0.25997  | 0.18\n",
      "[epoch: 2, batch:    246] loss: 0.39479  | 0.18\n",
      "[epoch: 2, batch:    248] loss: 0.38535  | 0.18\n",
      "[epoch: 2, batch:    250] loss: 0.39991  | 0.18\n",
      "[epoch: 2, batch:    252] loss: 1.24821  | 0.18\n",
      "[epoch: 2, batch:    254] loss: 0.48596  | 0.18\n",
      "[epoch: 2, batch:    256] loss: 0.19125  | 0.18\n",
      "[epoch: 2, batch:    258] loss: 0.18898  | 0.18\n",
      "[epoch: 2, batch:    260] loss: 0.42594  | 0.18\n",
      "[epoch: 2, batch:    262] loss: 0.31273  | 0.18\n",
      "[epoch: 2, batch:    264] loss: 0.03725  | 0.18\n",
      "[epoch: 2, batch:    266] loss: 0.15442  | 0.18\n",
      "[epoch: 2, batch:    268] loss: 0.09424  | 0.18\n",
      "[epoch: 2, batch:    270] loss: 0.35515  | 0.18\n",
      "[epoch: 2, batch:    272] loss: 0.42676  | 0.18\n",
      "[epoch: 2, batch:    274] loss: 0.30645  | 0.18\n",
      "[epoch: 2, batch:    276] loss: 0.18798  | 0.18\n",
      "[epoch: 2, batch:    278] loss: 0.65530  | 0.18\n",
      "[epoch: 2, batch:    280] loss: 0.30000  | 0.18\n",
      "[epoch: 2, batch:    282] loss: 0.82146  | 0.18\n",
      "[epoch: 2, batch:    284] loss: 0.73769  | 0.18\n",
      "[epoch: 2, batch:    286] loss: 0.48727  | 0.18\n",
      "[epoch: 2, batch:    288] loss: 0.58094  | 0.18\n",
      "[epoch: 2, batch:    290] loss: 0.11716  | 0.18\n",
      "[epoch: 2, batch:    292] loss: 0.03262  | 0.18\n",
      "[epoch: 2, batch:    294] loss: 1.42104  | 0.18\n",
      "[epoch: 2, batch:    296] loss: 0.21885  | 0.18\n",
      "[epoch: 2, batch:    298] loss: 0.46777  | 0.18\n",
      "[epoch: 2, batch:    300] loss: 0.46935  | 0.18\n",
      "[epoch: 2, batch:    302] loss: 0.48294  | 0.18\n",
      "[epoch: 2, batch:    304] loss: 1.12466  | 0.18\n",
      "[epoch: 2, batch:    306] loss: 0.17025  | 0.18\n",
      "[epoch: 2, batch:    308] loss: 0.43716  | 0.18\n",
      "[epoch: 2, batch:    310] loss: 0.20536  | 0.18\n",
      "[epoch: 2, batch:    312] loss: 0.42117  | 0.18\n",
      "[epoch: 2, batch:    314] loss: 0.42473  | 0.18\n",
      "[epoch: 2, batch:    316] loss: 0.15880  | 0.18\n",
      "[epoch: 2, batch:    318] loss: 0.66541  | 0.18\n",
      "[epoch: 2, batch:    320] loss: 0.26620  | 0.18\n",
      "[epoch: 2, batch:    322] loss: 0.12487  | 0.18\n",
      "[epoch: 2, batch:    324] loss: 0.26343  | 0.18\n",
      "[epoch: 2, batch:    326] loss: 0.35245  | 0.18\n",
      "[epoch: 2, batch:    328] loss: 0.41903  | 0.18\n",
      "[epoch: 2, batch:    330] loss: 0.38897  | 0.18\n",
      "[epoch: 2, batch:    332] loss: 0.20326  | 0.19\n",
      "[epoch: 2, batch:    334] loss: 0.28908  | 0.19\n",
      "[epoch: 2, batch:    336] loss: 0.14747  | 0.19\n",
      "[epoch: 2, batch:    338] loss: 0.10831  | 0.19\n",
      "[epoch: 2, batch:    340] loss: 0.12077  | 0.19\n",
      "[epoch: 2, batch:    342] loss: 0.56080  | 0.18\n",
      "[epoch: 2, batch:    344] loss: 0.37508  | 0.19\n",
      "[epoch: 2, batch:    346] loss: 0.17760  | 0.19\n",
      "[epoch: 2, batch:    348] loss: 1.13428  | 0.18\n",
      "[epoch: 2, batch:    350] loss: 0.20093  | 0.18\n",
      "[epoch: 2, batch:    352] loss: 0.56080  | 0.18\n",
      "[epoch: 2, batch:    354] loss: 0.68681  | 0.18\n",
      "[epoch: 2, batch:    356] loss: 0.59642  | 0.18\n",
      "[epoch: 2, batch:    358] loss: 0.23283  | 0.19\n",
      "[epoch: 2, batch:    360] loss: 0.32710  | 0.19\n",
      "[epoch: 2, batch:    362] loss: 0.15194  | 0.19\n",
      "[epoch: 2, batch:    364] loss: 0.10185  | 0.18\n",
      "[epoch: 2, batch:    366] loss: 0.26813  | 0.18\n",
      "[epoch: 2, batch:    368] loss: 0.19838  | 0.19\n",
      "[epoch: 2, batch:    370] loss: 0.25673  | 0.19\n",
      "[epoch: 2, batch:    372] loss: 0.48346  | 0.18\n",
      "[epoch: 2, batch:    374] loss: 0.15888  | 0.19\n",
      "[epoch: 2, batch:    376] loss: 0.27935  | 0.18\n",
      "[epoch: 2, batch:    378] loss: 0.32011  | 0.19\n",
      "[epoch: 2, batch:    380] loss: 0.68727  | 0.19\n",
      "[epoch: 2, batch:    382] loss: 0.32494  | 0.19\n",
      "[epoch: 2, batch:    384] loss: 0.02766  | 0.18\n",
      "[epoch: 2, batch:    386] loss: 0.15447  | 0.18\n",
      "[epoch: 2, batch:    388] loss: 0.12628  | 0.19\n",
      "[epoch: 2, batch:    390] loss: 0.38676  | 0.20\n",
      "[epoch: 2, batch:    392] loss: 0.02994  | 0.20\n",
      "[epoch: 2, batch:    394] loss: 0.64068  | 0.19\n",
      "[epoch: 2, batch:    396] loss: 0.34026  | 0.18\n",
      "[epoch: 2, batch:    398] loss: 0.32826  | 0.18\n",
      "[epoch: 2, batch:    400] loss: 0.35680  | 0.18\n",
      "[epoch: 2, batch:    402] loss: 0.28772  | 0.18\n",
      "[epoch: 2, batch:    404] loss: 0.27852  | 0.18\n",
      "[epoch: 2, batch:    406] loss: 0.46807  | 0.18\n",
      "[epoch: 2, batch:    408] loss: 0.34898  | 0.18\n",
      "[epoch: 2, batch:    410] loss: 0.31658  | 0.18\n",
      "[epoch: 2, batch:    412] loss: 0.30073  | 0.18\n",
      "[epoch: 2, batch:    414] loss: 0.50891  | 0.18\n",
      "[epoch: 2, batch:    416] loss: 0.12152  | 0.18\n",
      "[epoch: 2, batch:    418] loss: 0.20860  | 0.19\n",
      "[epoch: 2, batch:    420] loss: 0.33210  | 0.20\n",
      "[epoch: 2, batch:    422] loss: 0.67652  | 0.19\n",
      "[epoch: 2, batch:    424] loss: 0.49158  | 0.19\n",
      "[epoch: 2, batch:    426] loss: 0.49277  | 0.19\n",
      "[epoch: 2, batch:    428] loss: 0.58110  | 0.19\n",
      "[epoch: 2, batch:    430] loss: 0.71520  | 0.19\n",
      "[epoch: 2, batch:    432] loss: 0.03901  | 0.18\n",
      "[epoch: 2, batch:    434] loss: 0.14724  | 0.18\n",
      "[epoch: 2, batch:    436] loss: 0.30552  | 0.18\n",
      "[epoch: 2, batch:    438] loss: 0.12908  | 0.18\n",
      "[epoch: 2, batch:    440] loss: 0.54953  | 0.18\n",
      "[epoch: 2, batch:    442] loss: 0.18317  | 0.18\n",
      "[epoch: 2, batch:    444] loss: 0.05963  | 0.19\n",
      "[epoch: 2, batch:    446] loss: 0.75531  | 0.18\n",
      "[epoch: 2, batch:    448] loss: 0.14049  | 0.19\n",
      "[epoch: 2, batch:    450] loss: 0.20256  | 0.19\n",
      "[epoch: 2, batch:    452] loss: 0.21273  | 0.20\n",
      "[epoch: 2, batch:    454] loss: 0.02934  | 0.19\n",
      "[epoch: 2, batch:    456] loss: 0.14205  | 0.19\n",
      "[epoch: 2, batch:    458] loss: 0.24046  | 0.19\n",
      "[epoch: 2, batch:    460] loss: 0.28649  | 0.19\n",
      "[epoch: 2, batch:    462] loss: 0.23633  | 0.18\n",
      "[epoch: 2, batch:    464] loss: 0.11233  | 0.18\n",
      "[epoch: 2, batch:    466] loss: 0.43933  | 0.19\n",
      "[epoch: 2, batch:    468] loss: 0.37477  | 0.19\n",
      "[epoch: 2, batch:    470] loss: 0.32237  | 0.18\n",
      "[epoch: 2, batch:    472] loss: 0.36860  | 0.18\n",
      "[epoch: 2, batch:    474] loss: 0.20791  | 0.18\n",
      "[epoch: 2, batch:    476] loss: 0.13006  | 0.18\n",
      "[epoch: 2, batch:    478] loss: 0.22554  | 0.18\n",
      "[epoch: 2, batch:    480] loss: 0.33603  | 0.18\n",
      "[epoch: 2, batch:    482] loss: 1.53510  | 0.18\n",
      "[epoch: 2, batch:    484] loss: 0.14129  | 0.18\n",
      "[epoch: 2, batch:    486] loss: 1.42596  | 0.18\n",
      "[epoch: 2, batch:    488] loss: 0.35185  | 0.18\n",
      "[epoch: 2, batch:    490] loss: 0.51948  | 0.18\n",
      "[epoch: 2, batch:    492] loss: 0.75015  | 0.18\n",
      "[epoch: 2, batch:    494] loss: 0.13455  | 0.18\n",
      "[epoch: 2, batch:    496] loss: 0.30488  | 0.18\n",
      "[epoch: 2, batch:    498] loss: 0.40740  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 2, batch:    500] loss: 1.09027  | 0.18\n",
      "[epoch: 2, batch:    502] loss: 0.12276  | 0.18\n",
      "[epoch: 2, batch:    504] loss: 0.28060  | 0.18\n",
      "[epoch: 2, batch:    506] loss: 0.82654  | 0.18\n",
      "[epoch: 2, batch:    508] loss: 0.19422  | 0.18\n",
      "[epoch: 2, batch:    510] loss: 1.16247  | 0.18\n",
      "[epoch: 2, batch:    512] loss: 0.10021  | 0.18\n",
      "[epoch: 2, batch:    514] loss: 0.31799  | 0.18\n",
      "[epoch: 2, batch:    516] loss: 0.17268  | 0.18\n",
      "[epoch: 2, batch:    518] loss: 0.20582  | 0.18\n",
      "[epoch: 2, batch:    520] loss: 0.27011  | 0.18\n",
      "[epoch: 2, batch:    522] loss: 0.24323  | 0.18\n",
      "[epoch: 2, batch:    524] loss: 0.01335  | 0.18\n",
      "[epoch: 2, batch:    526] loss: 0.30497  | 0.18\n",
      "[epoch: 2, batch:    528] loss: 0.37091  | 0.18\n",
      "[epoch: 2, batch:    530] loss: 0.13495  | 0.18\n",
      "[epoch: 2, batch:    532] loss: 0.46990  | 0.18\n",
      "[epoch: 2, batch:    534] loss: 0.60845  | 0.18\n",
      "[epoch: 2, batch:    536] loss: 0.45072  | 0.18\n",
      "[epoch: 2, batch:    538] loss: 0.29095  | 0.18\n",
      "[epoch: 2, batch:    540] loss: 0.23259  | 0.18\n",
      "[epoch: 2, batch:    542] loss: 0.20826  | 0.18\n",
      "[epoch: 2, batch:    544] loss: 0.19273  | 0.18\n",
      "[epoch: 2, batch:    546] loss: 0.32449  | 0.18\n",
      "[epoch: 2, batch:    548] loss: 0.28067  | 0.18\n",
      "[epoch: 2, batch:    550] loss: 0.07604  | 0.18\n",
      "[epoch: 2, batch:    552] loss: 0.13300  | 0.18\n",
      "[epoch: 2, batch:    554] loss: 0.25401  | 0.18\n",
      "[epoch: 2, batch:    556] loss: 0.47664  | 0.18\n",
      "[epoch: 2, batch:    558] loss: 0.13893  | 0.18\n",
      "[epoch: 2, batch:    560] loss: 0.07229  | 0.18\n",
      "[epoch: 2, batch:    562] loss: 0.37599  | 0.18\n",
      "[epoch: 2, batch:    564] loss: 0.53366  | 0.18\n",
      "[epoch: 2, batch:    566] loss: 0.55246  | 0.18\n",
      "[epoch: 2, batch:    568] loss: 0.19552  | 0.18\n",
      "[epoch: 2, batch:    570] loss: 0.34646  | 0.18\n",
      "[epoch: 2, batch:    572] loss: 0.05823  | 0.18\n",
      "[epoch: 2, batch:    574] loss: 1.05408  | 0.18\n",
      "[epoch: 2, batch:    576] loss: 0.36525  | 0.18\n",
      "[epoch: 2, batch:    578] loss: 0.85529  | 0.18\n",
      "[epoch: 2, batch:    580] loss: 0.16486  | 0.18\n",
      "[epoch: 2, batch:    582] loss: 1.00432  | 0.18\n",
      "[epoch: 2, batch:    584] loss: 0.19757  | 0.18\n",
      "[epoch: 2, batch:    586] loss: 0.28696  | 0.18\n",
      "[epoch: 2, batch:    588] loss: 0.22050  | 0.18\n",
      "[epoch: 2, batch:    590] loss: 0.54592  | 0.18\n",
      "[epoch: 2, batch:    592] loss: 0.11249  | 0.18\n",
      "[epoch: 2, batch:    594] loss: 0.28656  | 0.18\n",
      "[epoch: 2, batch:    596] loss: 0.34062  | 0.18\n",
      "[epoch: 2, batch:    598] loss: 0.63910  | 0.18\n",
      "[epoch: 2, batch:    600] loss: 1.01984  | 0.18\n",
      "[epoch: 2, batch:    602] loss: 0.65548  | 0.18\n",
      "[epoch: 2, batch:    604] loss: 0.68806  | 0.18\n",
      "[epoch: 2, batch:    606] loss: 0.68705  | 0.18\n",
      "[epoch: 2, batch:    608] loss: 0.16401  | 0.18\n",
      "[epoch: 2, batch:    610] loss: 1.79602  | 0.18\n",
      "[epoch: 2, batch:    612] loss: 0.47702  | 0.18\n",
      "[epoch: 2, batch:    614] loss: 0.37379  | 0.18\n",
      "[epoch: 2, batch:    616] loss: 0.31198  | 0.18\n",
      "[epoch: 2, batch:    618] loss: 0.09351  | 0.18\n",
      "[epoch: 2, batch:    620] loss: 0.47362  | 0.18\n",
      "[epoch: 2, batch:    622] loss: 0.27455  | 0.18\n",
      "[epoch: 2, batch:    624] loss: 0.42362  | 0.18\n",
      "[epoch: 2, batch:    626] loss: 0.35324  | 0.18\n",
      "[epoch: 2, batch:    628] loss: 0.19180  | 0.18\n",
      "[epoch: 2, batch:    630] loss: 0.09821  | 0.18\n",
      "[epoch: 2, batch:    632] loss: 0.30175  | 0.18\n",
      "[epoch: 2, batch:    634] loss: 0.53685  | 0.18\n",
      "[epoch: 2, batch:    636] loss: 0.47442  | 0.18\n",
      "[epoch: 2, batch:    638] loss: 0.14001  | 0.18\n",
      "[epoch: 2, batch:    640] loss: 0.15143  | 0.18\n",
      "[epoch: 2, batch:    642] loss: 0.19654  | 0.18\n",
      "[epoch: 2, batch:    644] loss: 0.34131  | 0.18\n",
      "[epoch: 2, batch:    646] loss: 0.56896  | 0.18\n",
      "[epoch: 2, batch:    648] loss: 0.21063  | 0.18\n",
      "[epoch: 2, batch:    650] loss: 0.33833  | 0.18\n",
      "[epoch: 2, batch:    652] loss: 0.28678  | 0.18\n",
      "[epoch: 2, batch:    654] loss: 0.30924  | 0.18\n",
      "[epoch: 2, batch:    656] loss: 0.22102  | 0.18\n",
      "[epoch: 2, batch:    658] loss: 1.29637  | 0.18\n",
      "[epoch: 2, batch:    660] loss: 0.12667  | 0.18\n",
      "[epoch: 2, batch:    662] loss: 0.09552  | 0.18\n",
      "[epoch: 2, batch:    664] loss: 0.40428  | 0.18\n",
      "[epoch: 2, batch:    666] loss: 0.53939  | 0.18\n",
      "[epoch: 2, batch:    668] loss: 0.01730  | 0.18\n",
      "[epoch: 2, batch:    670] loss: 0.99632  | 0.18\n",
      "[epoch: 2, batch:    672] loss: 0.05340  | 0.18\n",
      "[epoch: 2, batch:    674] loss: 0.04648  | 0.18\n",
      "[epoch: 2, batch:    676] loss: 0.42700  | 0.18\n",
      "[epoch: 2, batch:    678] loss: 1.11070  | 0.18\n",
      "[epoch: 2, batch:    680] loss: 0.76005  | 0.18\n",
      "[epoch: 2, batch:    682] loss: 0.60564  | 0.18\n",
      "[epoch: 2, batch:    684] loss: 0.15798  | 0.18\n",
      "[epoch: 2, batch:    686] loss: 0.41203  | 0.18\n",
      "[epoch: 2, batch:    688] loss: 0.47556  | 0.18\n",
      "[epoch: 2, batch:    690] loss: 0.29221  | 0.18\n",
      "[epoch: 2, batch:    692] loss: 0.38782  | 0.18\n",
      "[epoch: 2, batch:    694] loss: 1.25802  | 0.18\n",
      "[epoch: 2, batch:    696] loss: 0.27342  | 0.18\n",
      "[epoch: 2, batch:    698] loss: 0.38332  | 0.18\n",
      "[epoch: 2, batch:    700] loss: 0.54334  | 0.18\n",
      "[epoch: 2, batch:    702] loss: 0.17438  | 0.18\n",
      "[epoch: 2, batch:    704] loss: 0.09459  | 0.18\n",
      "[epoch: 2, batch:    706] loss: 0.22324  | 0.18\n",
      "[epoch: 2, batch:    708] loss: 0.73850  | 0.18\n",
      "[epoch: 2, batch:    710] loss: 0.71985  | 0.18\n",
      "[epoch: 2, batch:    712] loss: 0.57191  | 0.18\n",
      "[epoch: 2, batch:    714] loss: 1.72147  | 0.18\n",
      "[epoch: 2, batch:    716] loss: 0.32409  | 0.18\n",
      "[epoch: 2, batch:    718] loss: 0.32329  | 0.18\n",
      "[epoch: 2, batch:    720] loss: 0.41581  | 0.18\n",
      "[epoch: 2, batch:    722] loss: 0.27755  | 0.18\n",
      "[epoch: 2, batch:    724] loss: 0.18551  | 0.18\n",
      "[epoch: 2, batch:    726] loss: 0.32326  | 0.18\n",
      "[epoch: 2, batch:    728] loss: 1.13372  | 0.18\n",
      "[epoch: 2, batch:    730] loss: 1.29308  | 0.18\n",
      "[epoch: 2, batch:    732] loss: 0.58802  | 0.18\n",
      "[epoch: 2, batch:    734] loss: 0.59965  | 0.18\n",
      "[epoch: 2, batch:    736] loss: 0.55823  | 0.18\n",
      "[epoch: 2, batch:    738] loss: 0.79805  | 0.18\n",
      "[epoch: 2, batch:    740] loss: 0.10651  | 0.18\n",
      "[epoch: 2, batch:    742] loss: 0.17625  | 0.18\n",
      "[epoch: 2, batch:    744] loss: 0.11595  | 0.18\n",
      "[epoch: 2, batch:    746] loss: 0.12639  | 0.18\n",
      "[epoch: 2, batch:    748] loss: 1.47323  | 0.18\n",
      "[epoch: 2, batch:    750] loss: 0.13590  | 0.18\n",
      "[epoch: 2, batch:    752] loss: 0.50956  | 0.18\n",
      "[epoch: 2, batch:    754] loss: 0.28880  | 0.18\n",
      "[epoch: 2, batch:    756] loss: 0.67691  | 0.18\n",
      "[epoch: 2, batch:    758] loss: 0.17341  | 0.18\n",
      "[epoch: 2, batch:    760] loss: 0.17472  | 0.18\n",
      "[epoch: 2, batch:    762] loss: 0.38484  | 0.18\n",
      "[epoch: 2, batch:    764] loss: 0.21419  | 0.18\n",
      "[epoch: 2, batch:    766] loss: 0.71010  | 0.18\n",
      "[epoch: 2, batch:    768] loss: 0.16685  | 0.18\n",
      "[epoch: 2, batch:    770] loss: 0.38574  | 0.18\n",
      "[epoch: 2, batch:    772] loss: 0.11769  | 0.18\n",
      "[epoch: 2, batch:    774] loss: 0.04720  | 0.18\n",
      "[epoch: 2, batch:    776] loss: 0.85317  | 0.18\n",
      "[epoch: 2, batch:    778] loss: 0.21014  | 0.18\n",
      "[epoch: 2, batch:    780] loss: 0.34737  | 0.18\n",
      "[epoch: 2, batch:    782] loss: 0.59968  | 0.18\n",
      "[epoch: 2, batch:    784] loss: 1.04739  | 0.18\n",
      "[epoch: 2, batch:    786] loss: 0.24409  | 0.18\n",
      "[epoch: 2, batch:    788] loss: 0.67788  | 0.18\n",
      "[epoch: 2, batch:    790] loss: 0.24194  | 0.18\n",
      "[epoch: 2, batch:    792] loss: 0.86910  | 0.18\n",
      "[epoch: 2, batch:    794] loss: 0.38624  | 0.18\n",
      "[epoch: 2, batch:    796] loss: 0.23554  | 0.18\n",
      "[epoch: 2, batch:    798] loss: 0.49398  | 0.18\n",
      "[epoch: 2, batch:    800] loss: 0.39515  | 0.18\n",
      "[epoch: 2, batch:    802] loss: 0.61429  | 0.18\n",
      "[epoch: 2, batch:    804] loss: 0.19730  | 0.18\n",
      "[epoch: 2, batch:    806] loss: 0.60485  | 0.18\n",
      "[epoch: 2, batch:    808] loss: 0.05728  | 0.18\n",
      "[epoch: 2, batch:    810] loss: 0.36390  | 0.18\n",
      "[epoch: 2, batch:    812] loss: 0.27855  | 0.18\n",
      "[epoch: 2, batch:    814] loss: 0.23741  | 0.18\n",
      "[epoch: 2, batch:    816] loss: 0.18064  | 0.18\n",
      "[epoch: 2, batch:    818] loss: 0.04917  | 0.18\n",
      "[epoch: 2, batch:    820] loss: 0.55454  | 0.18\n",
      "[epoch: 2, batch:    822] loss: 0.36308  | 0.18\n",
      "[epoch: 2, batch:    824] loss: 0.28280  | 0.18\n",
      "[epoch: 2, batch:    826] loss: 0.63246  | 0.18\n",
      "[epoch: 2, batch:    828] loss: 0.14599  | 0.18\n",
      "[epoch: 2, batch:    830] loss: 0.74567  | 0.18\n",
      "[epoch: 2, batch:    832] loss: 0.20658  | 0.18\n",
      "[epoch: 2, batch:    834] loss: 0.13220  | 0.18\n",
      "[epoch: 2, batch:    836] loss: 0.26167  | 0.18\n",
      "[epoch: 2, batch:    838] loss: 0.13570  | 0.18\n",
      "[epoch: 2, batch:    840] loss: 1.02118  | 0.18\n",
      "[epoch: 2, batch:    842] loss: 0.22018  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 2, batch:    844] loss: 0.17336  | 0.18\n",
      "[epoch: 2, batch:    846] loss: 0.04408  | 0.18\n",
      "[epoch: 2, batch:    848] loss: 0.30229  | 0.18\n",
      "[epoch: 2, batch:    850] loss: 0.10390  | 0.18\n",
      "[epoch: 2, batch:    852] loss: 0.30408  | 0.18\n",
      "[epoch: 2, batch:    854] loss: 0.29615  | 0.18\n",
      "[epoch: 2, batch:    856] loss: 0.20782  | 0.18\n",
      "[epoch: 2, batch:    858] loss: 0.82317  | 0.18\n",
      "[epoch: 2, batch:    860] loss: 0.37947  | 0.18\n",
      "[epoch: 2, batch:    862] loss: 0.12223  | 0.18\n",
      "[epoch: 2, batch:    864] loss: 0.55960  | 0.18\n",
      "[epoch: 2, batch:    866] loss: 0.09714  | 0.18\n",
      "[epoch: 2, batch:    868] loss: 1.39123  | 0.18\n",
      "[epoch: 2, batch:    870] loss: 0.08035  | 0.18\n",
      "[epoch: 2, batch:    872] loss: 0.42783  | 0.18\n",
      "[epoch: 2, batch:    874] loss: 0.10561  | 0.18\n",
      "[epoch: 2, batch:    876] loss: 0.25385  | 0.18\n",
      "[epoch: 2, batch:    878] loss: 1.27580  | 0.18\n",
      "[epoch: 2, batch:    880] loss: 0.18122  | 0.18\n",
      "[epoch: 2, batch:    882] loss: 0.40586  | 0.18\n",
      "[epoch: 2, batch:    884] loss: 0.57901  | 0.18\n",
      "[epoch: 2, batch:    886] loss: 0.04616  | 0.18\n",
      "[epoch: 2, batch:    888] loss: 0.22689  | 0.18\n",
      "[epoch: 2, batch:    890] loss: 0.32569  | 0.18\n",
      "[epoch: 2, batch:    892] loss: 0.11833  | 0.18\n",
      "[epoch: 2, batch:    894] loss: 0.27980  | 0.18\n",
      "[epoch: 2, batch:    896] loss: 0.34493  | 0.18\n",
      "[epoch: 2, batch:    898] loss: 0.06779  | 0.18\n",
      "[epoch: 2, batch:    900] loss: 0.23916  | 0.18\n",
      "[epoch: 2, batch:    902] loss: 0.17140  | 0.18\n",
      "[epoch: 2, batch:    904] loss: 0.06897  | 0.18\n",
      "[epoch: 2, batch:    906] loss: 0.22818  | 0.18\n",
      "[epoch: 2, batch:    908] loss: 0.61138  | 0.18\n",
      "[epoch: 2, batch:    910] loss: 0.29586  | 0.18\n",
      "[epoch: 2, batch:    912] loss: 0.53454  | 0.18\n",
      "[epoch: 2, batch:    914] loss: 0.53009  | 0.18\n",
      "[epoch: 2, batch:    916] loss: 0.49019  | 0.18\n",
      "[epoch: 2, batch:    918] loss: 0.41362  | 0.18\n",
      "[epoch: 2, batch:    920] loss: 0.58038  | 0.18\n",
      "[epoch: 2, batch:    922] loss: 0.42454  | 0.18\n",
      "[epoch: 2, batch:    924] loss: 0.34970  | 0.18\n",
      "[epoch: 2, batch:    926] loss: 0.16650  | 0.18\n",
      "[epoch: 2, batch:    928] loss: 0.84031  | 0.18\n",
      "[epoch: 2, batch:    930] loss: 0.08021  | 0.18\n",
      "[epoch: 2, batch:    932] loss: 0.44813  | 0.18\n",
      "[epoch: 2, batch:    934] loss: 0.20392  | 0.18\n",
      "[epoch: 2, batch:    936] loss: 0.32972  | 0.18\n",
      "[epoch: 2, batch:    938] loss: 0.39254  | 0.18\n",
      "[epoch: 2, batch:    940] loss: 1.17921  | 0.18\n",
      "[epoch: 2, batch:    942] loss: 0.30283  | 0.18\n",
      "[epoch: 2, batch:    944] loss: 0.41257  | 0.18\n",
      "[epoch: 2, batch:    946] loss: 0.41082  | 0.18\n",
      "[epoch: 2, batch:    948] loss: 0.52286  | 0.18\n",
      "[epoch: 2, batch:    950] loss: 0.76099  | 0.18\n",
      "[epoch: 2, batch:    952] loss: 0.45965  | 0.18\n",
      "[epoch: 2, batch:    954] loss: 0.03165  | 0.18\n",
      "[epoch: 2, batch:    956] loss: 0.33385  | 0.18\n",
      "[epoch: 2, batch:    958] loss: 0.64211  | 0.18\n",
      "[epoch: 2, batch:    960] loss: 0.16021  | 0.18\n",
      "[epoch: 2, batch:    962] loss: 0.35806  | 0.18\n",
      "[epoch: 2, batch:    964] loss: 0.49086  | 0.18\n",
      "[epoch: 2, batch:    966] loss: 0.68811  | 0.18\n",
      "[epoch: 2, batch:    968] loss: 0.37682  | 0.18\n",
      "[epoch: 2, batch:    970] loss: 0.14225  | 0.18\n",
      "[epoch: 2, batch:    972] loss: 0.34719  | 0.18\n",
      "[epoch: 2, batch:    974] loss: 0.59625  | 0.18\n",
      "[epoch: 2, batch:    976] loss: 0.05283  | 0.18\n",
      "[epoch: 2, batch:    978] loss: 0.40915  | 0.18\n",
      "[epoch: 2, batch:    980] loss: 0.50978  | 0.18\n",
      "[epoch: 2, batch:    982] loss: 0.12213  | 0.18\n",
      "[epoch: 2, batch:    984] loss: 0.25929  | 0.18\n",
      "[epoch: 2, batch:    986] loss: 0.43385  | 0.18\n",
      "[epoch: 2, batch:    988] loss: 0.13175  | 0.18\n",
      "[epoch: 2, batch:    990] loss: 0.09611  | 0.18\n",
      "[epoch: 2, batch:    992] loss: 0.49543  | 0.18\n",
      "[epoch: 2, batch:    994] loss: 1.24287  | 0.18\n",
      "[epoch: 2, batch:    996] loss: 0.22234  | 0.18\n",
      "[epoch: 2, batch:    998] loss: 0.35306  | 0.18\n",
      "[epoch: 2, batch:   1000] loss: 0.26313  | 0.18\n",
      "[epoch: 2, batch:   1002] loss: 0.35173  | 0.18\n",
      "[epoch: 2, batch:   1004] loss: 0.18688  | 0.18\n",
      "[epoch: 2, batch:   1006] loss: 0.10999  | 0.18\n",
      "[epoch: 2, batch:   1008] loss: 0.59380  | 0.18\n",
      "[epoch: 2, batch:   1010] loss: 0.11988  | 0.18\n",
      "[epoch: 2, batch:   1012] loss: 0.40334  | 0.18\n",
      "[epoch: 2, batch:   1014] loss: 0.08994  | 0.18\n",
      "[epoch: 2, batch:   1016] loss: 0.47019  | 0.18\n",
      "[epoch: 2, batch:   1018] loss: 0.21988  | 0.18\n",
      "[epoch: 2, batch:   1020] loss: 0.14294  | 0.18\n",
      "[epoch: 2, batch:   1022] loss: 0.06013  | 0.18\n",
      "[epoch: 2, batch:   1024] loss: 0.21418  | 0.18\n",
      "[epoch: 2, batch:   1026] loss: 0.07264  | 0.18\n",
      "[epoch: 2, batch:   1028] loss: 0.49107  | 0.18\n",
      "[epoch: 2, batch:   1030] loss: 0.16683  | 0.18\n",
      "[epoch: 2, batch:   1032] loss: 0.43757  | 0.18\n",
      "[epoch: 2, batch:   1034] loss: 0.60021  | 0.18\n",
      "[epoch: 2, batch:   1036] loss: 0.17178  | 0.18\n",
      "[epoch: 2, batch:   1038] loss: 0.15724  | 0.18\n",
      "[epoch: 2, batch:   1040] loss: 0.41650  | 0.18\n",
      "[epoch: 2, batch:   1042] loss: 0.57877  | 0.18\n",
      "[epoch: 2, batch:   1044] loss: 0.37952  | 0.18\n",
      "[epoch: 2, batch:   1046] loss: 0.41498  | 0.18\n",
      "[epoch: 2, batch:   1048] loss: 0.69056  | 0.18\n",
      "[epoch: 2, batch:   1050] loss: 0.75493  | 0.18\n",
      "[epoch: 2, batch:   1052] loss: 0.81767  | 0.18\n",
      "[epoch: 2, batch:   1054] loss: 0.25384  | 0.18\n",
      "[epoch: 2, batch:   1056] loss: 0.23513  | 0.18\n",
      "[epoch: 2, batch:   1058] loss: 0.41410  | 0.18\n",
      "[epoch: 2, batch:   1060] loss: 0.71940  | 0.18\n",
      "[epoch: 2, batch:   1062] loss: 0.67956  | 0.18\n",
      "[epoch: 2, batch:   1064] loss: 0.32359  | 0.18\n",
      "[epoch: 2, batch:   1066] loss: 0.42835  | 0.18\n",
      "[epoch: 2, batch:   1068] loss: 0.22102  | 0.18\n",
      "[epoch: 2, batch:   1070] loss: 0.23864  | 0.18\n",
      "[epoch: 2, batch:   1072] loss: 1.36665  | 0.18\n",
      "[epoch: 2, batch:   1074] loss: 0.20741  | 0.18\n",
      "[epoch: 2, batch:   1076] loss: 0.06203  | 0.18\n",
      "[epoch: 2, batch:   1078] loss: 0.35613  | 0.18\n",
      "[epoch: 2, batch:   1080] loss: 0.12312  | 0.18\n",
      "[epoch: 2, batch:   1082] loss: 0.63515  | 0.18\n",
      "[epoch: 2, batch:   1084] loss: 0.08406  | 0.18\n",
      "[epoch: 2, batch:   1086] loss: 0.10040  | 0.19\n",
      "[epoch: 2, batch:   1088] loss: 0.55997  | 0.18\n",
      "[epoch: 2, batch:   1090] loss: 0.67904  | 0.18\n",
      "[epoch: 2, batch:   1092] loss: 0.33153  | 0.18\n",
      "[epoch: 2, batch:   1094] loss: 0.47242  | 0.18\n",
      "[epoch: 2, batch:   1096] loss: 0.15717  | 0.18\n",
      "[epoch: 2, batch:   1098] loss: 0.92733  | 0.18\n",
      "[epoch: 2, batch:   1100] loss: 0.54780  | 0.18\n",
      "[epoch: 2, batch:   1102] loss: 0.18156  | 0.18\n",
      "[epoch: 2, batch:   1104] loss: 1.27289  | 0.18\n",
      "[epoch: 2, batch:   1106] loss: 0.33093  | 0.18\n",
      "[epoch: 2, batch:   1108] loss: 0.52459  | 0.19\n",
      "[epoch: 2, batch:   1110] loss: 0.32107  | 0.18\n",
      "[epoch: 2, batch:   1112] loss: 0.37719  | 0.18\n",
      "[epoch: 2, batch:   1114] loss: 0.62728  | 0.18\n",
      "[epoch: 2, batch:   1116] loss: 0.32876  | 0.18\n",
      "[epoch: 2, batch:   1118] loss: 0.43305  | 0.18\n",
      "[epoch: 2, batch:   1120] loss: 0.13704  | 0.18\n",
      "[epoch: 2, batch:   1122] loss: 0.13338  | 0.18\n",
      "[epoch: 2, batch:   1124] loss: 0.24803  | 0.18\n",
      "[epoch: 2, batch:   1126] loss: 0.36657  | 0.18\n",
      "[epoch: 2, batch:   1128] loss: 0.12177  | 0.18\n",
      "[epoch: 2, batch:   1130] loss: 0.36320  | 0.18\n",
      "[epoch: 2, batch:   1132] loss: 0.12763  | 0.18\n",
      "[epoch: 2, batch:   1134] loss: 0.64479  | 0.18\n",
      "[epoch: 2, batch:   1136] loss: 0.73506  | 0.18\n",
      "[epoch: 2, batch:   1138] loss: 0.48361  | 0.18\n",
      "[epoch: 2, batch:   1140] loss: 1.28015  | 0.18\n",
      "[epoch: 2, batch:   1142] loss: 0.27728  | 0.18\n",
      "[epoch: 2, batch:   1144] loss: 1.22066  | 0.18\n",
      "[epoch: 2, batch:   1146] loss: 0.64992  | 0.18\n",
      "[epoch: 2, batch:   1148] loss: 0.07248  | 0.18\n",
      "[epoch: 2, batch:   1150] loss: 0.11939  | 0.18\n",
      "[epoch: 2, batch:   1152] loss: 0.46444  | 0.18\n",
      "[epoch: 2, batch:   1154] loss: 0.45289  | 0.18\n",
      "[epoch: 2, batch:   1156] loss: 0.12688  | 0.18\n",
      "[epoch: 2, batch:   1158] loss: 0.39399  | 0.18\n",
      "[epoch: 2, batch:   1160] loss: 0.05796  | 0.18\n",
      "[epoch: 2, batch:   1162] loss: 0.02848  | 0.18\n",
      "[epoch: 2, batch:   1164] loss: 0.17624  | 0.18\n",
      "[epoch: 2, batch:   1166] loss: 0.05332  | 0.18\n",
      "[epoch: 2, batch:   1168] loss: 0.09281  | 0.18\n",
      "[epoch: 2, batch:   1170] loss: 0.49210  | 0.18\n",
      "[epoch: 2, batch:   1172] loss: 0.29220  | 0.18\n",
      "[epoch: 2, batch:   1174] loss: 0.41374  | 0.18\n",
      "[epoch: 2, batch:   1176] loss: 0.06229  | 0.18\n",
      "[epoch: 2, batch:   1178] loss: 1.42554  | 0.18\n",
      "[epoch: 2, batch:   1180] loss: 0.12734  | 0.18\n",
      "[epoch: 2, batch:   1182] loss: 0.44653  | 0.18\n",
      "[epoch: 2, batch:   1184] loss: 0.16395  | 0.18\n",
      "[epoch: 2, batch:   1186] loss: 1.22707  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 2, batch:   1188] loss: 0.39615  | 0.18\n",
      "[epoch: 2, batch:   1190] loss: 0.75950  | 0.18\n",
      "[epoch: 2, batch:   1192] loss: 0.55346  | 0.18\n",
      "[epoch: 2, batch:   1194] loss: 0.05431  | 0.18\n",
      "[epoch: 2, batch:   1196] loss: 0.38803  | 0.18\n",
      "[epoch: 2, batch:   1198] loss: 0.20146  | 0.18\n",
      "[epoch: 2, batch:   1200] loss: 0.13480  | 0.18\n",
      "[epoch: 2, batch:   1202] loss: 0.60795  | 0.18\n",
      "[epoch: 2, batch:   1204] loss: 0.33077  | 0.18\n",
      "[epoch: 2, batch:   1206] loss: 0.20063  | 0.18\n",
      "[epoch: 2, batch:   1208] loss: 0.35920  | 0.18\n",
      "[epoch: 2, batch:   1210] loss: 0.10334  | 0.18\n",
      "[epoch: 2, batch:   1212] loss: 0.28583  | 0.18\n",
      "[epoch: 2, batch:   1214] loss: 0.34806  | 0.18\n",
      "[epoch: 2, batch:   1216] loss: 0.27778  | 0.18\n",
      "[epoch: 2, batch:   1218] loss: 0.13388  | 0.18\n",
      "[epoch: 2, batch:   1220] loss: 1.06748  | 0.18\n",
      "[epoch: 2, batch:   1222] loss: 0.13613  | 0.18\n",
      "[epoch: 2, batch:   1224] loss: 0.30641  | 0.18\n",
      "[epoch: 2, batch:   1226] loss: 0.51632  | 0.18\n",
      "[epoch: 2, batch:   1228] loss: 0.32540  | 0.18\n",
      "[epoch: 2, batch:   1230] loss: 0.09254  | 0.18\n",
      "[epoch: 2, batch:   1232] loss: 0.31660  | 0.18\n",
      "[epoch: 2, batch:   1234] loss: 0.19925  | 0.18\n",
      "[epoch: 2, batch:   1236] loss: 0.37713  | 0.19\n",
      "[epoch: 2, batch:   1238] loss: 0.50952  | 0.18\n",
      "[epoch: 2, batch:   1240] loss: 0.22541  | 0.18\n",
      "[epoch: 2, batch:   1242] loss: 0.10113  | 0.18\n",
      "[epoch: 2, batch:   1244] loss: 0.53930  | 0.18\n",
      "[epoch: 2, batch:   1246] loss: 0.81575  | 0.18\n",
      "[epoch: 2, batch:   1248] loss: 0.23983  | 0.18\n",
      "[epoch: 2, batch:   1250] loss: 0.05105  | 0.18\n",
      "[epoch: 2, batch:   1252] loss: 0.14373  | 0.18\n",
      "[epoch: 2, batch:   1254] loss: 0.75139  | 0.18\n",
      "[epoch: 2, batch:   1256] loss: 0.22847  | 0.18\n",
      "[epoch: 2, batch:   1258] loss: 0.42569  | 0.18\n",
      "[epoch: 2, batch:   1260] loss: 0.14401  | 0.18\n",
      "[epoch: 2, batch:   1262] loss: 0.55418  | 0.18\n",
      "[epoch: 2, batch:   1264] loss: 0.10317  | 0.18\n",
      "[epoch: 2, batch:   1266] loss: 0.23710  | 0.18\n",
      "[epoch: 2, batch:   1268] loss: 0.25497  | 0.18\n",
      "[epoch: 2, batch:   1270] loss: 0.64128  | 0.18\n",
      "[epoch: 2, batch:   1272] loss: 0.12571  | 0.18\n",
      "[epoch: 2, batch:   1274] loss: 0.75402  | 0.18\n",
      "[epoch: 2, batch:   1276] loss: 0.18314  | 0.18\n",
      "[epoch: 2, batch:   1278] loss: 0.22314  | 0.18\n",
      "[epoch: 2, batch:   1280] loss: 0.11608  | 0.18\n",
      "[epoch: 2, batch:   1282] loss: 0.06948  | 0.18\n",
      "[epoch: 2, batch:   1284] loss: 0.42560  | 0.18\n",
      "[epoch: 2, batch:   1286] loss: 0.64177  | 0.18\n",
      "[epoch: 2, batch:   1288] loss: 0.06980  | 0.18\n",
      "[epoch: 2, batch:   1290] loss: 0.41280  | 0.18\n",
      "[epoch: 2, batch:   1292] loss: 0.15004  | 0.18\n",
      "[epoch: 2, batch:   1294] loss: 0.25112  | 0.18\n",
      "[epoch: 2, batch:   1296] loss: 0.34082  | 0.18\n",
      "[epoch: 2, batch:   1298] loss: 0.12716  | 0.18\n",
      "[epoch: 2, batch:   1300] loss: 0.38512  | 0.18\n",
      "[epoch: 2, batch:   1302] loss: 0.34142  | 0.18\n",
      "[epoch: 2, batch:   1304] loss: 0.25191  | 0.18\n",
      "[epoch: 2, batch:   1306] loss: 0.44502  | 0.18\n",
      "[epoch: 2, batch:   1308] loss: 0.29120  | 0.18\n",
      "[epoch: 2, batch:   1310] loss: 0.15858  | 0.18\n",
      "[epoch: 2, batch:   1312] loss: 0.07216  | 0.18\n",
      "[epoch: 2, batch:   1314] loss: 0.68078  | 0.18\n",
      "[epoch: 2, batch:   1316] loss: 0.24593  | 0.18\n",
      "[epoch: 2, batch:   1318] loss: 0.20215  | 0.18\n",
      "[epoch: 2, batch:   1320] loss: 0.26705  | 0.18\n",
      "[epoch: 2, batch:   1322] loss: 0.35921  | 0.18\n",
      "[epoch: 2, batch:   1324] loss: 0.19132  | 0.19\n",
      "[epoch: 2, batch:   1326] loss: 0.66327  | 0.18\n",
      "[epoch: 2, batch:   1328] loss: 0.67318  | 0.18\n",
      "[epoch: 2, batch:   1330] loss: 0.55772  | 0.18\n",
      "[epoch: 2, batch:   1332] loss: 0.33311  | 0.18\n",
      "[epoch: 2, batch:   1334] loss: 0.87646  | 0.18\n",
      "[epoch: 2, batch:   1336] loss: 0.17802  | 0.18\n",
      "[epoch: 2, batch:   1338] loss: 1.10294  | 0.18\n",
      "[epoch: 2, batch:   1340] loss: 0.20827  | 0.18\n",
      "[epoch: 2, batch:   1342] loss: 0.15253  | 0.18\n",
      "[epoch: 2, batch:   1344] loss: 0.39570  | 0.18\n",
      "[epoch: 2, batch:   1346] loss: 0.51012  | 0.18\n",
      "[epoch: 2, batch:   1348] loss: 0.27732  | 0.18\n",
      "[epoch: 2, batch:   1350] loss: 0.51414  | 0.18\n",
      "[epoch: 2, batch:   1352] loss: 0.18210  | 0.18\n",
      "[epoch: 2, batch:   1354] loss: 0.12886  | 0.18\n",
      "[epoch: 2, batch:   1356] loss: 0.19731  | 0.18\n",
      "[epoch: 2, batch:   1358] loss: 0.35979  | 0.18\n",
      "[epoch: 2, batch:   1360] loss: 0.14175  | 0.18\n",
      "[epoch: 2, batch:   1362] loss: 0.20459  | 0.18\n",
      "[epoch: 2, batch:   1364] loss: 0.48101  | 0.18\n",
      "[epoch: 2, batch:   1366] loss: 0.24254  | 0.18\n",
      "[epoch: 2, batch:   1368] loss: 0.31254  | 0.18\n",
      "[epoch: 2, batch:   1370] loss: 0.28140  | 0.18\n",
      "[epoch: 2, batch:   1372] loss: 0.26774  | 0.18\n",
      "[epoch: 2, batch:   1374] loss: 0.34684  | 0.18\n",
      "[epoch: 2, batch:   1376] loss: 0.83815  | 0.18\n",
      "[epoch: 2, batch:   1378] loss: 0.60763  | 0.18\n",
      "[epoch: 2, batch:   1380] loss: 0.23836  | 0.18\n",
      "[epoch: 2, batch:   1382] loss: 0.11915  | 0.18\n",
      "[epoch: 2, batch:   1384] loss: 0.27061  | 0.18\n",
      "[epoch: 2, batch:   1386] loss: 0.21213  | 0.18\n",
      "[epoch: 2, batch:   1388] loss: 0.26687  | 0.18\n",
      "[epoch: 2, batch:   1390] loss: 0.13497  | 0.18\n",
      "[epoch: 2, batch:   1392] loss: 0.30741  | 0.18\n",
      "[epoch: 2, batch:   1394] loss: 0.07608  | 0.18\n",
      "[epoch: 2, batch:   1396] loss: 0.20842  | 0.18\n",
      "[epoch: 2, batch:   1398] loss: 0.05330  | 0.18\n",
      "[epoch: 2, batch:   1400] loss: 0.43272  | 0.18\n",
      "[epoch: 2, batch:   1402] loss: 0.39512  | 0.18\n",
      "[epoch: 2, batch:   1404] loss: 0.12272  | 0.18\n",
      "[epoch: 2, batch:   1406] loss: 0.60884  | 0.18\n",
      "[epoch: 2, batch:   1408] loss: 0.50861  | 0.18\n",
      "[epoch: 2, batch:   1410] loss: 0.39644  | 0.18\n",
      "[epoch: 2, batch:   1412] loss: 0.64350  | 0.18\n",
      "[epoch: 2, batch:   1414] loss: 0.13720  | 0.18\n",
      "[epoch: 2, batch:   1416] loss: 0.12942  | 0.18\n",
      "[epoch: 2, batch:   1418] loss: 0.33341  | 0.18\n",
      "[epoch: 2, batch:   1420] loss: 0.17771  | 0.18\n",
      "[epoch: 2, batch:   1422] loss: 0.26469  | 0.18\n",
      "[epoch: 2, batch:   1424] loss: 0.35009  | 0.18\n",
      "[epoch: 2, batch:   1426] loss: 0.46268  | 0.18\n",
      "[epoch: 2, batch:   1428] loss: 0.13770  | 0.18\n",
      "[epoch: 2, batch:   1430] loss: 0.90850  | 0.18\n",
      "[epoch: 2, batch:   1432] loss: 0.56038  | 0.18\n",
      "[epoch: 2, batch:   1434] loss: 0.04065  | 0.18\n",
      "[epoch: 2, batch:   1436] loss: 0.16176  | 0.18\n",
      "[epoch: 2, batch:   1438] loss: 0.18323  | 0.18\n",
      "[epoch: 2, batch:   1440] loss: 0.20258  | 0.18\n",
      "[epoch: 2, batch:   1442] loss: 0.97436  | 0.18\n",
      "[epoch: 2, batch:   1444] loss: 0.07462  | 0.18\n",
      "[epoch: 2, batch:   1446] loss: 0.11739  | 0.18\n",
      "[epoch: 2, batch:   1448] loss: 0.77381  | 0.18\n",
      "[epoch: 2, batch:   1450] loss: 0.50187  | 0.18\n",
      "[epoch: 2, batch:   1452] loss: 0.03101  | 0.18\n",
      "[epoch: 2, batch:   1454] loss: 0.13554  | 0.18\n",
      "[epoch: 2, batch:   1456] loss: 0.39359  | 0.18\n",
      "[epoch: 2, batch:   1458] loss: 1.77756  | 0.18\n",
      "[epoch: 2, batch:   1460] loss: 0.41072  | 0.18\n",
      "[epoch: 2, batch:   1462] loss: 0.12141  | 0.18\n",
      "[epoch: 2, batch:   1464] loss: 0.09547  | 0.18\n",
      "[epoch: 2, batch:   1466] loss: 0.33718  | 0.18\n",
      "[epoch: 2, batch:   1468] loss: 0.49169  | 0.18\n",
      "[epoch: 2, batch:   1470] loss: 0.15432  | 0.18\n",
      "[epoch: 2, batch:   1472] loss: 0.46610  | 0.18\n",
      "[epoch: 2, batch:   1474] loss: 0.77052  | 0.18\n",
      "[epoch: 2, batch:   1476] loss: 0.49857  | 0.18\n",
      "[epoch: 2, batch:   1478] loss: 0.44657  | 0.18\n",
      "[epoch: 2, batch:   1480] loss: 0.56156  | 0.18\n",
      "[epoch: 2, batch:   1482] loss: 0.16610  | 0.18\n",
      "[epoch: 2, batch:   1484] loss: 0.22420  | 0.18\n",
      "[epoch: 2, batch:   1486] loss: 0.39378  | 0.18\n",
      "[epoch: 2, batch:   1488] loss: 0.49935  | 0.18\n",
      "[epoch: 2, batch:   1490] loss: 0.13505  | 0.18\n",
      "[epoch: 2, batch:   1492] loss: 0.11449  | 0.18\n",
      "[epoch: 2, batch:   1494] loss: 0.31561  | 0.18\n",
      "[epoch: 2, batch:   1496] loss: 1.12111  | 0.18\n",
      "[epoch: 2, batch:   1498] loss: 0.70973  | 0.18\n",
      "[epoch: 2, batch:   1500] loss: 0.38503  | 0.18\n",
      "[epoch: 2, batch:   1502] loss: 0.40901  | 0.18\n",
      "[epoch: 2, batch:   1504] loss: 0.08441  | 0.18\n",
      "[epoch: 2, batch:   1506] loss: 0.26647  | 0.18\n",
      "[epoch: 2, batch:   1508] loss: 0.12997  | 0.18\n",
      "[epoch: 2, batch:   1510] loss: 0.34272  | 0.18\n",
      "[epoch: 2, batch:   1512] loss: 0.46950  | 0.18\n",
      "[epoch: 2, batch:   1514] loss: 0.12467  | 0.18\n",
      "[epoch: 2, batch:   1516] loss: 0.74389  | 0.18\n",
      "[epoch: 2, batch:   1518] loss: 0.57006  | 0.18\n",
      "[epoch: 2, batch:   1520] loss: 0.35105  | 0.18\n",
      "[epoch: 2, batch:   1522] loss: 0.29320  | 0.18\n",
      "[epoch: 2, batch:   1524] loss: 0.06745  | 0.18\n",
      "[epoch: 2, batch:   1526] loss: 2.12033  | 0.18\n",
      "[epoch: 2, batch:   1528] loss: 0.21938  | 0.18\n",
      "[epoch: 2, batch:   1530] loss: 0.20636  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 2, batch:   1532] loss: 0.98105  | 0.18\n",
      "[epoch: 2, batch:   1534] loss: 0.09992  | 0.18\n",
      "[epoch: 2, batch:   1536] loss: 0.26459  | 0.18\n",
      "[epoch: 2, batch:   1538] loss: 0.20350  | 0.18\n",
      "[epoch: 2, batch:   1540] loss: 0.11665  | 0.18\n",
      "[epoch: 2, batch:   1542] loss: 0.81719  | 0.18\n",
      "[epoch: 2, batch:   1544] loss: 0.26616  | 0.18\n",
      "[epoch: 2, batch:   1546] loss: 0.60924  | 0.18\n",
      "[epoch: 2, batch:   1548] loss: 0.05035  | 0.18\n",
      "[epoch: 2, batch:   1550] loss: 0.09617  | 0.18\n",
      "[epoch: 2, batch:   1552] loss: 0.22746  | 0.18\n",
      "[epoch: 2, batch:   1554] loss: 0.89918  | 0.18\n",
      "[epoch: 2, batch:   1556] loss: 0.24353  | 0.18\n",
      "[epoch: 2, batch:   1558] loss: 0.06473  | 0.18\n",
      "[epoch: 2, batch:   1560] loss: 0.78243  | 0.18\n",
      "[epoch: 2, batch:   1562] loss: 0.33144  | 0.18\n",
      "[epoch: 2, batch:   1564] loss: 0.52350  | 0.18\n",
      "[epoch: 2, batch:   1566] loss: 0.41365  | 0.18\n",
      "[epoch: 2, batch:   1568] loss: 0.45094  | 0.18\n",
      "[epoch: 2, batch:   1570] loss: 0.22649  | 0.18\n",
      "[epoch: 2, batch:   1572] loss: 0.36175  | 0.18\n",
      "[epoch: 2, batch:   1574] loss: 0.45907  | 0.18\n",
      "[epoch: 2, batch:   1576] loss: 0.53374  | 0.18\n",
      "[epoch: 2, batch:   1578] loss: 0.14386  | 0.18\n",
      "[epoch: 2, batch:   1580] loss: 1.07217  | 0.18\n",
      "[epoch: 2, batch:   1582] loss: 0.39934  | 0.18\n",
      "[epoch: 2, batch:   1584] loss: 0.31763  | 0.18\n",
      "[epoch: 2, batch:   1586] loss: 0.46773  | 0.18\n",
      "[epoch: 2, batch:   1588] loss: 0.68750  | 0.18\n",
      "[epoch: 2, batch:   1590] loss: 0.62520  | 0.18\n",
      "[epoch: 2, batch:   1592] loss: 0.55370  | 0.18\n",
      "[epoch: 2, batch:   1594] loss: 0.22554  | 0.18\n",
      "[epoch: 2, batch:   1596] loss: 0.05119  | 0.18\n",
      "[epoch: 2, batch:   1598] loss: 0.87595  | 0.18\n",
      "[epoch: 2, batch:   1600] loss: 0.19383  | 0.18\n",
      "[epoch: 2, batch:   1602] loss: 0.05069  | 0.18\n",
      "[epoch: 2, batch:   1604] loss: 0.30486  | 0.18\n",
      "[epoch: 2, batch:   1606] loss: 0.17146  | 0.18\n",
      "[epoch: 2, batch:   1608] loss: 0.16610  | 0.18\n",
      "[epoch: 2, batch:   1610] loss: 0.23588  | 0.18\n",
      "[epoch: 2, batch:   1612] loss: 0.06139  | 0.18\n",
      "[epoch: 2, batch:   1614] loss: 0.45212  | 0.18\n",
      "[epoch: 2, batch:   1616] loss: 0.41072  | 0.18\n",
      "[epoch: 2, batch:   1618] loss: 0.92083  | 0.18\n",
      "[epoch: 2, batch:   1620] loss: 0.66644  | 0.18\n",
      "[epoch: 2, batch:   1622] loss: 1.75575  | 0.18\n",
      "[epoch: 2, batch:   1624] loss: 0.08195  | 0.18\n",
      "[epoch: 2, batch:   1626] loss: 0.26119  | 0.18\n",
      "[epoch: 2, batch:   1628] loss: 0.33244  | 0.18\n",
      "[epoch: 2, batch:   1630] loss: 0.62935  | 0.18\n",
      "[epoch: 2, batch:   1632] loss: 0.11073  | 0.18\n",
      "[epoch: 2, batch:   1634] loss: 0.08681  | 0.18\n",
      "[epoch: 2, batch:   1636] loss: 0.15634  | 0.18\n",
      "[epoch: 2, batch:   1638] loss: 0.32499  | 0.18\n",
      "[epoch: 2, batch:   1640] loss: 0.16836  | 0.18\n",
      "[epoch: 2, batch:   1642] loss: 0.28512  | 0.18\n",
      "[epoch: 2, batch:   1644] loss: 1.63295  | 0.18\n",
      "[epoch: 2, batch:   1646] loss: 0.43085  | 0.18\n",
      "[epoch: 2, batch:   1648] loss: 0.40160  | 0.18\n",
      "[epoch: 2, batch:   1650] loss: 0.22928  | 0.18\n",
      "[epoch: 2, batch:   1652] loss: 0.07962  | 0.18\n",
      "[epoch: 2, batch:   1654] loss: 0.21515  | 0.18\n",
      "[epoch: 2, batch:   1656] loss: 0.47892  | 0.18\n",
      "[epoch: 2, batch:   1658] loss: 1.77083  | 0.18\n",
      "[epoch: 2, batch:   1660] loss: 0.42495  | 0.18\n",
      "[epoch: 2, batch:   1662] loss: 0.29303  | 0.18\n",
      "[epoch: 2, batch:   1664] loss: 0.18327  | 0.18\n",
      "[epoch: 2, batch:   1666] loss: 0.13507  | 0.18\n",
      "[epoch: 2, batch:   1668] loss: 0.12265  | 0.18\n",
      "[epoch: 2, batch:   1670] loss: 0.10279  | 0.18\n",
      "[epoch: 2, batch:   1672] loss: 0.23108  | 0.18\n",
      "[epoch: 2, batch:   1674] loss: 0.10761  | 0.18\n",
      "[epoch: 2, batch:   1676] loss: 0.35488  | 0.18\n",
      "[epoch: 2, batch:   1678] loss: 0.46313  | 0.18\n",
      "[epoch: 2, batch:   1680] loss: 0.11914  | 0.18\n",
      "[epoch: 2, batch:   1682] loss: 0.07178  | 0.18\n",
      "[epoch: 2, batch:   1684] loss: 0.03635  | 0.18\n",
      "[epoch: 2, batch:   1686] loss: 0.17088  | 0.19\n",
      "[epoch: 2, batch:   1688] loss: 0.07975  | 0.18\n",
      "[epoch: 2, batch:   1690] loss: 0.56008  | 0.18\n",
      "[epoch: 2, batch:   1692] loss: 0.10729  | 0.18\n",
      "[epoch: 2, batch:   1694] loss: 0.18126  | 0.18\n",
      "[epoch: 2, batch:   1696] loss: 0.21165  | 0.18\n",
      "[epoch: 2, batch:   1698] loss: 0.79614  | 0.18\n",
      "[epoch: 2, batch:   1700] loss: 0.43808  | 0.18\n",
      "[epoch: 2, batch:   1702] loss: 0.28302  | 0.18\n",
      "[epoch: 2, batch:   1704] loss: 0.33141  | 0.18\n",
      "[epoch: 2, batch:   1706] loss: 0.66381  | 0.18\n",
      "[epoch: 2, batch:   1708] loss: 0.14946  | 0.18\n",
      "[epoch: 2, batch:   1710] loss: 1.01317  | 0.18\n",
      "[epoch: 2, batch:   1712] loss: 0.06327  | 0.18\n",
      "[epoch: 2, batch:   1714] loss: 0.83920  | 0.18\n",
      "[epoch: 2, batch:   1716] loss: 0.30210  | 0.18\n",
      "[epoch: 2, batch:   1718] loss: 0.45326  | 0.18\n",
      "[epoch: 2, batch:   1720] loss: 0.39478  | 0.18\n",
      "[epoch: 2, batch:   1722] loss: 1.71650  | 0.18\n",
      "[epoch: 2, batch:   1724] loss: 0.42239  | 0.18\n",
      "[epoch: 2, batch:   1726] loss: 0.14021  | 0.18\n",
      "[epoch: 2, batch:   1728] loss: 0.44054  | 0.18\n",
      "[epoch: 2, batch:   1730] loss: 0.31103  | 0.18\n",
      "[epoch: 2, batch:   1732] loss: 0.54446  | 0.18\n",
      "[epoch: 2, batch:   1734] loss: 0.34428  | 0.18\n",
      "[epoch: 2, batch:   1736] loss: 0.13455  | 0.18\n",
      "[epoch: 2, batch:   1738] loss: 0.30692  | 0.18\n",
      "[epoch: 2, batch:   1740] loss: 0.24977  | 0.18\n",
      "[epoch: 2, batch:   1742] loss: 0.41880  | 0.18\n",
      "[epoch: 2, batch:   1744] loss: 1.07611  | 0.18\n",
      "[epoch: 2, batch:   1746] loss: 0.23223  | 0.18\n",
      "[epoch: 2, batch:   1748] loss: 0.33067  | 0.18\n",
      "[epoch: 2, batch:   1750] loss: 0.07931  | 0.18\n",
      "[epoch: 2, batch:   1752] loss: 0.20694  | 0.18\n",
      "[epoch: 2, batch:   1754] loss: 0.06010  | 0.18\n",
      "[epoch: 2, batch:   1756] loss: 0.34998  | 0.18\n",
      "[epoch: 2, batch:   1758] loss: 0.03144  | 0.18\n",
      "[epoch: 2, batch:   1760] loss: 0.64137  | 0.18\n",
      "[epoch: 2, batch:   1762] loss: 0.04573  | 0.18\n",
      "[epoch: 2, batch:   1764] loss: 0.31412  | 0.18\n",
      "[epoch: 2, batch:   1766] loss: 0.59902  | 0.18\n",
      "[epoch: 2, batch:   1768] loss: 0.05224  | 0.18\n",
      "[epoch: 2, batch:   1770] loss: 0.25347  | 0.18\n",
      "[epoch: 2, batch:   1772] loss: 0.34297  | 0.18\n",
      "[epoch: 2, batch:   1774] loss: 0.51932  | 0.18\n",
      "[epoch: 2, batch:   1776] loss: 0.37758  | 0.18\n",
      "[epoch: 2, batch:   1778] loss: 0.12443  | 0.18\n",
      "[epoch: 2, batch:   1780] loss: 0.11247  | 0.18\n",
      "[epoch: 2, batch:   1782] loss: 0.03540  | 0.18\n",
      "[epoch: 2, batch:   1784] loss: 0.07994  | 0.18\n",
      "[epoch: 2, batch:   1786] loss: 0.26245  | 0.18\n",
      "[epoch: 2, batch:   1788] loss: 0.11468  | 0.18\n",
      "[epoch: 2, batch:   1790] loss: 0.12549  | 0.18\n",
      "[epoch: 2, batch:   1792] loss: 0.93045  | 0.18\n",
      "[epoch: 2, batch:   1794] loss: 0.39008  | 0.18\n",
      "[epoch: 2, batch:   1796] loss: 0.07079  | 0.18\n",
      "[epoch: 2, batch:   1798] loss: 0.95888  | 0.18\n",
      "[epoch: 2, batch:   1800] loss: 0.04350  | 0.18\n",
      "[epoch: 2, batch:   1802] loss: 0.12834  | 0.18\n",
      "[epoch: 2, batch:   1804] loss: 0.33170  | 0.18\n",
      "[epoch: 2, batch:   1806] loss: 0.41714  | 0.18\n",
      "[epoch: 2, batch:   1808] loss: 0.30452  | 0.18\n",
      "[epoch: 2, batch:   1810] loss: 0.44183  | 0.18\n",
      "[epoch: 2, batch:   1812] loss: 0.10530  | 0.18\n",
      "[epoch: 2, batch:   1814] loss: 0.17578  | 0.18\n",
      "[epoch: 2, batch:   1816] loss: 0.20727  | 0.18\n",
      "[epoch: 2, batch:   1818] loss: 0.46044  | 0.18\n",
      "[epoch: 2, batch:   1820] loss: 0.58859  | 0.18\n",
      "[epoch: 2, batch:   1822] loss: 0.49612  | 0.18\n",
      "[epoch: 2, batch:   1824] loss: 0.32331  | 0.18\n",
      "[epoch: 2, batch:   1826] loss: 0.30178  | 0.18\n",
      "[epoch: 2, batch:   1828] loss: 0.01754  | 0.18\n",
      "[epoch: 2, batch:   1830] loss: 0.59792  | 0.18\n",
      "[epoch: 2, batch:   1832] loss: 0.09087  | 0.18\n",
      "[epoch: 2, batch:   1834] loss: 0.38282  | 0.18\n",
      "[epoch: 2, batch:   1836] loss: 0.72077  | 0.18\n",
      "[epoch: 2, batch:   1838] loss: 0.11098  | 0.18\n",
      "[epoch: 2, batch:   1840] loss: 0.26159  | 0.18\n",
      "[epoch: 2, batch:   1842] loss: 0.18432  | 0.18\n",
      "[epoch: 2, batch:   1844] loss: 0.42645  | 0.18\n",
      "[epoch: 2, batch:   1846] loss: 0.22423  | 0.18\n",
      "[epoch: 2, batch:   1848] loss: 0.27980  | 0.18\n",
      "[epoch: 2, batch:   1850] loss: 1.13348  | 0.18\n",
      "[epoch: 2, batch:   1852] loss: 0.19544  | 0.18\n",
      "[epoch: 2, batch:   1854] loss: 0.10264  | 0.18\n",
      "[epoch: 2, batch:   1856] loss: 0.32909  | 0.18\n",
      "[epoch: 2, batch:   1858] loss: 0.56918  | 0.18\n",
      "[epoch: 2, batch:   1860] loss: 0.40665  | 0.18\n",
      "[epoch: 2, batch:   1862] loss: 0.77940  | 0.18\n",
      "[epoch: 2, batch:   1864] loss: 0.70665  | 0.18\n",
      "[epoch: 2, batch:   1866] loss: 0.46467  | 0.18\n",
      "[epoch: 2, batch:   1868] loss: 0.13191  | 0.18\n",
      "[epoch: 2, batch:   1870] loss: 0.12260  | 0.18\n",
      "[epoch: 2, batch:   1872] loss: 0.31075  | 0.18\n",
      "[epoch: 2, batch:   1874] loss: 0.79316  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 2, batch:   1876] loss: 0.27242  | 0.18\n",
      "[epoch: 2, batch:   1878] loss: 0.04204  | 0.18\n",
      "[epoch: 2, batch:   1880] loss: 0.04265  | 0.18\n",
      "[epoch: 2, batch:   1882] loss: 0.46298  | 0.18\n",
      "[epoch: 2, batch:   1884] loss: 0.21373  | 0.18\n",
      "[epoch: 2, batch:   1886] loss: 0.48322  | 0.18\n",
      "[epoch: 2, batch:   1888] loss: 0.08870  | 0.18\n",
      "[epoch: 2, batch:   1890] loss: 0.06434  | 0.18\n",
      "[epoch: 2, batch:   1892] loss: 0.14302  | 0.18\n",
      "[epoch: 2, batch:   1894] loss: 0.65575  | 0.18\n",
      "[epoch: 2, batch:   1896] loss: 0.68535  | 0.18\n",
      "[epoch: 2, batch:   1898] loss: 0.79399  | 0.18\n",
      "[epoch: 2, batch:   1900] loss: 0.54045  | 0.18\n",
      "[epoch: 2, batch:   1902] loss: 0.20282  | 0.18\n",
      "[epoch: 2, batch:   1904] loss: 0.25745  | 0.18\n",
      "[epoch: 2, batch:   1906] loss: 0.29212  | 0.18\n",
      "[epoch: 2, batch:   1908] loss: 0.32800  | 0.18\n",
      "[epoch: 2, batch:   1910] loss: 0.35288  | 0.18\n",
      "[epoch: 2, batch:   1912] loss: 0.09645  | 0.18\n",
      "[epoch: 2, batch:   1914] loss: 0.19188  | 0.18\n",
      "[epoch: 2, batch:   1916] loss: 0.26800  | 0.18\n",
      "[epoch: 2, batch:   1918] loss: 0.18054  | 0.18\n",
      "[epoch: 2, batch:   1920] loss: 0.28810  | 0.18\n",
      "[epoch: 2, batch:   1922] loss: 0.39568  | 0.18\n",
      "[epoch: 2, batch:   1924] loss: 0.62410  | 0.18\n",
      "[epoch: 2, batch:   1926] loss: 0.20541  | 0.18\n",
      "[epoch: 2, batch:   1928] loss: 0.79243  | 0.18\n",
      "[epoch: 2, batch:   1930] loss: 0.23828  | 0.18\n",
      "[epoch: 2, batch:   1932] loss: 0.68234  | 0.18\n",
      "[epoch: 2, batch:   1934] loss: 0.12130  | 0.18\n",
      "[epoch: 2, batch:   1936] loss: 0.03906  | 0.18\n",
      "[epoch: 2, batch:   1938] loss: 0.33320  | 0.18\n",
      "[epoch: 2, batch:   1940] loss: 0.55636  | 0.18\n",
      "[epoch: 2, batch:   1942] loss: 0.82896  | 0.18\n",
      "[epoch: 2, batch:   1944] loss: 0.57742  | 0.18\n",
      "[epoch: 2, batch:   1946] loss: 0.27601  | 0.18\n",
      "[epoch: 2, batch:   1948] loss: 0.44315  | 0.18\n",
      "[epoch: 2, batch:   1950] loss: 0.36770  | 0.18\n",
      "[epoch: 2, batch:   1952] loss: 0.15252  | 0.18\n",
      "[epoch: 2, batch:   1954] loss: 0.13325  | 0.18\n",
      "[epoch: 2, batch:   1956] loss: 0.63177  | 0.18\n",
      "[epoch: 2, batch:   1958] loss: 0.43671  | 0.18\n",
      "[epoch: 2, batch:   1960] loss: 0.38850  | 0.18\n",
      "[epoch: 2, batch:   1962] loss: 0.33269  | 0.18\n",
      "[epoch: 2, batch:   1964] loss: 0.47049  | 0.18\n",
      "[epoch: 2, batch:   1966] loss: 0.29148  | 0.18\n",
      "[epoch: 2, batch:   1968] loss: 0.17645  | 0.18\n",
      "[epoch: 2, batch:   1970] loss: 0.61564  | 0.18\n",
      "[epoch: 2, batch:   1972] loss: 1.35552  | 0.18\n",
      "[epoch: 2, batch:   1974] loss: 0.31356  | 0.18\n",
      "[epoch: 2, batch:   1976] loss: 0.39760  | 0.18\n",
      "[epoch: 2, batch:   1978] loss: 0.08774  | 0.18\n",
      "[epoch: 2, batch:   1980] loss: 0.12351  | 0.18\n",
      "[epoch: 2, batch:   1982] loss: 0.32756  | 0.18\n",
      "[epoch: 2, batch:   1984] loss: 0.64892  | 0.18\n",
      "[epoch: 2, batch:   1986] loss: 0.25305  | 0.18\n",
      "[epoch: 2, batch:   1988] loss: 0.12945  | 0.18\n",
      "[epoch: 2, batch:   1990] loss: 0.15091  | 0.18\n",
      "[epoch: 2, batch:   1992] loss: 0.56033  | 0.18\n",
      "[epoch: 2, batch:   1994] loss: 0.47147  | 0.18\n",
      "[epoch: 2, batch:   1996] loss: 0.22767  | 0.18\n",
      "[epoch: 2, batch:   1998] loss: 0.19530  | 0.18\n",
      "[epoch: 2, batch:   2000] loss: 0.30876  | 0.18\n",
      "[epoch: 2, batch:   2002] loss: 0.62302  | 0.18\n",
      "[epoch: 2, batch:   2004] loss: 0.25545  | 0.18\n",
      "[epoch: 2, batch:   2006] loss: 1.63033  | 0.18\n",
      "[epoch: 2, batch:   2008] loss: 0.17884  | 0.18\n",
      "[epoch: 2, batch:   2010] loss: 0.54030  | 0.18\n",
      "[epoch: 2, batch:   2012] loss: 0.23906  | 0.18\n",
      "[epoch: 2, batch:   2014] loss: 0.61725  | 0.18\n",
      "[epoch: 2, batch:   2016] loss: 0.15399  | 0.18\n",
      "[epoch: 2, batch:   2018] loss: 0.20909  | 0.18\n",
      "[epoch: 2, batch:   2020] loss: 0.36251  | 0.18\n",
      "[epoch: 2, batch:   2022] loss: 0.13516  | 0.18\n",
      "[epoch: 2, batch:   2024] loss: 0.75695  | 0.18\n",
      "[epoch: 2, batch:   2026] loss: 0.28450  | 0.18\n",
      "[epoch: 2, batch:   2028] loss: 0.43253  | 0.18\n",
      "[epoch: 2, batch:   2030] loss: 0.34121  | 0.18\n",
      "[epoch: 2, batch:   2032] loss: 0.05394  | 0.18\n",
      "[epoch: 2, batch:   2034] loss: 0.45186  | 0.18\n",
      "[epoch: 2, batch:   2036] loss: 0.13949  | 0.18\n",
      "[epoch: 2, batch:   2038] loss: 0.76068  | 0.18\n",
      "[epoch: 2, batch:   2040] loss: 0.78498  | 0.18\n",
      "[epoch: 2, batch:   2042] loss: 1.05401  | 0.18\n",
      "[epoch: 2, batch:   2044] loss: 0.29684  | 0.18\n",
      "[epoch: 2, batch:   2046] loss: 0.15188  | 0.18\n",
      "[epoch: 2, batch:   2048] loss: 0.27283  | 0.18\n",
      "[epoch: 2, batch:   2050] loss: 0.22369  | 0.18\n",
      "[epoch: 2, batch:   2052] loss: 0.21031  | 0.18\n",
      "[epoch: 2, batch:   2054] loss: 0.08206  | 0.18\n",
      "[epoch: 2, batch:   2056] loss: 0.31740  | 0.18\n",
      "[epoch: 2, batch:   2058] loss: 0.17668  | 0.18\n",
      "[epoch: 2, batch:   2060] loss: 0.22710  | 0.18\n",
      "[epoch: 2, batch:   2062] loss: 0.27289  | 0.18\n",
      "[epoch: 2, batch:   2064] loss: 0.21856  | 0.18\n",
      "[epoch: 2, batch:   2066] loss: 0.05433  | 0.18\n",
      "[epoch: 2, batch:   2068] loss: 0.59425  | 0.18\n",
      "[epoch: 2, batch:   2070] loss: 1.11835  | 0.18\n",
      "[epoch: 2, batch:   2072] loss: 0.20933  | 0.18\n",
      "[epoch: 2, batch:   2074] loss: 0.20473  | 0.18\n",
      "[epoch: 2, batch:   2076] loss: 0.26185  | 0.18\n",
      "[epoch: 2, batch:   2078] loss: 0.42293  | 0.18\n",
      "[epoch: 2, batch:   2080] loss: 0.56777  | 0.18\n",
      "[epoch: 2, batch:   2082] loss: 0.30441  | 0.18\n",
      "[epoch: 2, batch:   2084] loss: 0.32647  | 0.18\n",
      "[epoch: 2, batch:   2086] loss: 0.73622  | 0.18\n",
      "[epoch: 2, batch:   2088] loss: 0.12598  | 0.18\n",
      "[epoch: 2, batch:   2090] loss: 0.15644  | 0.18\n",
      "[epoch: 2, batch:   2092] loss: 0.12541  | 0.18\n",
      "[epoch: 2, batch:   2094] loss: 0.39228  | 0.18\n",
      "[epoch: 2, batch:   2096] loss: 0.03767  | 0.18\n",
      "[epoch: 2, batch:   2098] loss: 0.05723  | 0.18\n",
      "[epoch: 2, batch:   2100] loss: 0.22062  | 0.18\n",
      "[epoch: 2, batch:   2102] loss: 0.66631  | 0.18\n",
      "[epoch: 2, batch:   2104] loss: 0.20263  | 0.18\n",
      "[epoch: 2, batch:   2106] loss: 0.12262  | 0.18\n",
      "[epoch: 2, batch:   2108] loss: 0.22308  | 0.18\n",
      "[epoch: 2, batch:   2110] loss: 0.42565  | 0.18\n",
      "[epoch: 2, batch:   2112] loss: 0.21679  | 0.18\n",
      "[epoch: 2, batch:   2114] loss: 0.12361  | 0.18\n",
      "[epoch: 2, batch:   2116] loss: 0.11221  | 0.18\n",
      "[epoch: 2, batch:   2118] loss: 0.18734  | 0.18\n",
      "[epoch: 2, batch:   2120] loss: 0.35399  | 0.18\n",
      "[epoch: 2, batch:   2122] loss: 0.15909  | 0.18\n",
      "[epoch: 2, batch:   2124] loss: 0.38392  | 0.18\n",
      "[epoch: 2, batch:   2126] loss: 0.04076  | 0.18\n",
      "[epoch: 2, batch:   2128] loss: 0.21328  | 0.18\n",
      "[epoch: 2, batch:   2130] loss: 0.36920  | 0.18\n",
      "[epoch: 2, batch:   2132] loss: 0.23322  | 0.18\n",
      "[epoch: 2, batch:   2134] loss: 0.44952  | 0.18\n",
      "[epoch: 2, batch:   2136] loss: 0.19104  | 0.18\n",
      "[epoch: 2, batch:   2138] loss: 0.13255  | 0.18\n",
      "[epoch: 2, batch:   2140] loss: 0.49812  | 0.18\n",
      "[epoch: 2, batch:   2142] loss: 0.07505  | 0.18\n",
      "[epoch: 2, batch:   2144] loss: 0.72894  | 0.18\n",
      "[epoch: 2, batch:   2146] loss: 0.32252  | 0.18\n",
      "[epoch: 2, batch:   2148] loss: 0.16778  | 0.18\n",
      "[epoch: 2, batch:   2150] loss: 0.34662  | 0.18\n",
      "[epoch: 2, batch:   2152] loss: 0.51074  | 0.18\n",
      "[epoch: 2, batch:   2154] loss: 0.63387  | 0.18\n",
      "[epoch: 2, batch:   2156] loss: 0.28788  | 0.18\n",
      "[epoch: 2, batch:   2158] loss: 1.68466  | 0.18\n",
      "[epoch: 2, batch:   2160] loss: 0.79753  | 0.18\n",
      "[epoch: 2, batch:   2162] loss: 0.70229  | 0.18\n",
      "[epoch: 2, batch:   2164] loss: 0.42129  | 0.18\n",
      "[epoch: 2, batch:   2166] loss: 0.12962  | 0.18\n",
      "[epoch: 2, batch:   2168] loss: 0.22048  | 0.18\n",
      "[epoch: 2, batch:   2170] loss: 0.16040  | 0.18\n",
      "[epoch: 2, batch:   2172] loss: 0.26559  | 0.18\n",
      "[epoch: 2, batch:   2174] loss: 0.17528  | 0.18\n",
      "[epoch: 2, batch:   2176] loss: 0.18473  | 0.18\n",
      "[epoch: 2, batch:   2178] loss: 0.34372  | 0.18\n",
      "[epoch: 2, batch:   2180] loss: 0.28602  | 0.18\n",
      "[epoch: 2, batch:   2182] loss: 0.08669  | 0.18\n",
      "[epoch: 2, batch:   2184] loss: 0.65742  | 0.18\n",
      "[epoch: 2, batch:   2186] loss: 0.30579  | 0.18\n",
      "[epoch: 2, batch:   2188] loss: 0.22180  | 0.18\n",
      "[epoch: 2, batch:   2190] loss: 0.39787  | 0.18\n",
      "[epoch: 2, batch:   2192] loss: 0.44496  | 0.18\n",
      "[epoch: 2, batch:   2194] loss: 0.23421  | 0.18\n",
      "[epoch: 2, batch:   2196] loss: 0.80296  | 0.18\n",
      "[epoch: 2, batch:   2198] loss: 0.60370  | 0.18\n",
      "[epoch: 2, batch:   2200] loss: 0.09084  | 0.18\n",
      "[epoch: 2, batch:   2202] loss: 0.35573  | 0.18\n",
      "[epoch: 2, batch:   2204] loss: 0.20958  | 0.18\n",
      "[epoch: 2, batch:   2206] loss: 0.36006  | 0.18\n",
      "[epoch: 2, batch:   2208] loss: 0.16443  | 0.18\n",
      "[epoch: 2, batch:   2210] loss: 0.03733  | 0.18\n",
      "[epoch: 2, batch:   2212] loss: 0.05526  | 0.18\n",
      "[epoch: 2, batch:   2214] loss: 0.45369  | 0.18\n",
      "[epoch: 2, batch:   2216] loss: 0.25066  | 0.18\n",
      "[epoch: 2, batch:   2218] loss: 0.30546  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 2, batch:   2220] loss: 0.08574  | 0.18\n",
      "[epoch: 2, batch:   2222] loss: 0.20478  | 0.18\n",
      "[epoch: 2, batch:   2224] loss: 0.14152  | 0.18\n",
      "[epoch: 2, batch:   2226] loss: 0.18698  | 0.18\n",
      "[epoch: 2, batch:   2228] loss: 0.42441  | 0.18\n",
      "[epoch: 2, batch:   2230] loss: 0.40999  | 0.18\n",
      "[epoch: 2, batch:   2232] loss: 0.57174  | 0.18\n",
      "[epoch: 2, batch:   2234] loss: 0.11681  | 0.18\n",
      "[epoch: 2, batch:   2236] loss: 0.05513  | 0.18\n",
      "[epoch: 2, batch:   2238] loss: 0.88276  | 0.18\n",
      "[epoch: 2, batch:   2240] loss: 1.22237  | 0.18\n",
      "[epoch: 2, batch:   2242] loss: 0.63130  | 0.18\n",
      "[epoch: 2, batch:   2244] loss: 0.25038  | 0.18\n",
      "[epoch: 2, batch:   2246] loss: 0.04625  | 0.18\n",
      "[epoch: 2, batch:   2248] loss: 0.55404  | 0.18\n",
      "[epoch: 2, batch:   2250] loss: 0.15146  | 0.18\n",
      "[epoch: 2, batch:   2252] loss: 0.81303  | 0.18\n",
      "[epoch: 2, batch:   2254] loss: 0.67041  | 0.18\n",
      "[epoch: 2, batch:   2256] loss: 0.12486  | 0.18\n",
      "[epoch: 2, batch:   2258] loss: 0.32456  | 0.18\n",
      "[epoch: 2, batch:   2260] loss: 0.92225  | 0.18\n",
      "[epoch: 2, batch:   2262] loss: 0.10600  | 0.18\n",
      "[epoch: 2, batch:   2264] loss: 0.38388  | 0.18\n",
      "[epoch: 2, batch:   2266] loss: 0.10703  | 0.18\n",
      "[epoch: 2, batch:   2268] loss: 0.47256  | 0.18\n",
      "[epoch: 2, batch:   2270] loss: 0.55484  | 0.18\n",
      "[epoch: 2, batch:   2272] loss: 0.58652  | 0.18\n",
      "[epoch: 2, batch:   2274] loss: 0.18983  | 0.18\n",
      "[epoch: 2, batch:   2276] loss: 0.24890  | 0.18\n",
      "[epoch: 2, batch:   2278] loss: 0.25140  | 0.18\n",
      "[epoch: 2, batch:   2280] loss: 0.51444  | 0.18\n",
      "[epoch: 2, batch:   2282] loss: 0.39436  | 0.18\n",
      "[epoch: 2, batch:   2284] loss: 0.71954  | 0.18\n",
      "[epoch: 2, batch:   2286] loss: 0.02427  | 0.18\n",
      "[epoch: 2, batch:   2288] loss: 0.21798  | 0.18\n",
      "[epoch: 2, batch:   2290] loss: 0.32359  | 0.18\n",
      "[epoch: 2, batch:   2292] loss: 0.84042  | 0.18\n",
      "[epoch: 2, batch:   2294] loss: 0.13697  | 0.18\n",
      "[epoch: 2, batch:   2296] loss: 0.17356  | 0.18\n",
      "[epoch: 2, batch:   2298] loss: 0.46544  | 0.18\n",
      "[epoch: 2, batch:   2300] loss: 0.29774  | 0.18\n",
      "[epoch: 2, batch:   2302] loss: 0.54330  | 0.18\n",
      "[epoch: 2, batch:   2304] loss: 0.17492  | 0.18\n",
      "[epoch: 2, batch:   2306] loss: 0.07233  | 0.18\n",
      "[epoch: 2, batch:   2308] loss: 0.65379  | 0.18\n",
      "[epoch: 2, batch:   2310] loss: 0.20493  | 0.18\n",
      "[epoch: 2, batch:   2312] loss: 0.30326  | 0.18\n",
      "[epoch: 2, batch:   2314] loss: 0.77822  | 0.18\n",
      "[epoch: 2, batch:   2316] loss: 0.90938  | 0.18\n",
      "[epoch: 2, batch:   2318] loss: 0.13273  | 0.18\n",
      "[epoch: 2, batch:   2320] loss: 0.38739  | 0.18\n",
      "[epoch: 2, batch:   2322] loss: 0.74019  | 0.18\n",
      "[epoch: 2, batch:   2324] loss: 0.58606  | 0.18\n",
      "[epoch: 2, batch:   2326] loss: 0.28979  | 0.18\n",
      "[epoch: 2, batch:   2328] loss: 0.64460  | 0.18\n",
      "[epoch: 2, batch:   2330] loss: 0.14494  | 0.18\n",
      "[epoch: 2, batch:   2332] loss: 0.15560  | 0.18\n",
      "[epoch: 2, batch:   2334] loss: 0.20262  | 0.18\n",
      "[epoch: 2, batch:   2336] loss: 0.14709  | 0.18\n",
      "[epoch: 2, batch:   2338] loss: 0.48082  | 0.18\n",
      "[epoch: 2, batch:   2340] loss: 1.09681  | 0.18\n",
      "[epoch: 2, batch:   2342] loss: 0.69251  | 0.18\n",
      "[epoch: 2, batch:   2344] loss: 0.22094  | 0.18\n",
      "[epoch: 2, batch:   2346] loss: 0.37120  | 0.18\n",
      "[epoch: 2, batch:   2348] loss: 0.12164  | 0.18\n",
      "[epoch: 2, batch:   2350] loss: 0.27877  | 0.18\n",
      "[epoch: 2, batch:   2352] loss: 1.04250  | 0.18\n",
      "[epoch: 2, batch:   2354] loss: 0.08672  | 0.18\n",
      "[epoch: 2, batch:   2356] loss: 0.25128  | 0.18\n",
      "[epoch: 2, batch:   2358] loss: 0.08584  | 0.18\n",
      "[epoch: 2, batch:   2360] loss: 0.44989  | 0.18\n",
      "[epoch: 2, batch:   2362] loss: 0.29054  | 0.18\n",
      "[epoch: 2, batch:   2364] loss: 0.36343  | 0.18\n",
      "[epoch: 2, batch:   2366] loss: 0.38092  | 0.18\n",
      "[epoch: 2, batch:   2368] loss: 0.11928  | 0.18\n",
      "[epoch: 2, batch:   2370] loss: 0.18075  | 0.18\n",
      "[epoch: 2, batch:   2372] loss: 0.53608  | 0.18\n",
      "[epoch: 2, batch:   2374] loss: 0.10533  | 0.18\n",
      "[epoch: 2, batch:   2376] loss: 0.11598  | 0.18\n",
      "[epoch: 2, batch:   2378] loss: 0.31010  | 0.18\n",
      "[epoch: 2, batch:   2380] loss: 0.30639  | 0.18\n",
      "[epoch: 2, batch:   2382] loss: 0.19457  | 0.18\n",
      "[epoch: 2, batch:   2384] loss: 0.03591  | 0.18\n",
      "[epoch: 2, batch:   2386] loss: 0.11523  | 0.18\n",
      "[epoch: 2, batch:   2388] loss: 0.36898  | 0.18\n",
      "[epoch: 2, batch:   2390] loss: 0.02558  | 0.18\n",
      "[epoch: 2, batch:   2392] loss: 0.18026  | 0.18\n",
      "[epoch: 2, batch:   2394] loss: 0.21806  | 0.18\n",
      "[epoch: 2, batch:   2396] loss: 0.31061  | 0.18\n",
      "[epoch: 2, batch:   2398] loss: 0.15513  | 0.18\n",
      "[epoch: 2, batch:   2400] loss: 0.40627  | 0.18\n",
      "[epoch: 2, batch:   2402] loss: 0.26723  | 0.18\n",
      "[epoch: 2, batch:   2404] loss: 0.18668  | 0.18\n",
      "[epoch: 2, batch:   2406] loss: 0.23317  | 0.18\n",
      "[epoch: 2, batch:   2408] loss: 0.17496  | 0.19\n",
      "[epoch: 2, batch:   2410] loss: 0.17434  | 0.18\n",
      "[epoch: 2, batch:   2412] loss: 0.25045  | 0.18\n",
      "[epoch: 2, batch:   2414] loss: 0.08373  | 0.18\n",
      "[epoch: 2, batch:   2416] loss: 0.13630  | 0.18\n",
      "[epoch: 2, batch:   2418] loss: 0.28619  | 0.18\n",
      "[epoch: 2, batch:   2420] loss: 0.06180  | 0.18\n",
      "[epoch: 2, batch:   2422] loss: 0.62671  | 0.18\n",
      "[epoch: 2, batch:   2424] loss: 0.15224  | 0.18\n",
      "[epoch: 2, batch:   2426] loss: 0.09076  | 0.18\n",
      "[epoch: 2, batch:   2428] loss: 0.55503  | 0.18\n",
      "[epoch: 2, batch:   2430] loss: 0.57041  | 0.19\n",
      "[epoch: 2, batch:   2432] loss: 0.41148  | 0.18\n",
      "[epoch: 2, batch:   2434] loss: 0.14013  | 0.18\n",
      "[epoch: 2, batch:   2436] loss: 0.09275  | 0.18\n",
      "[epoch: 2, batch:   2438] loss: 0.03676  | 0.18\n",
      "[epoch: 2, batch:   2440] loss: 0.16947  | 0.18\n",
      "[epoch: 2, batch:   2442] loss: 0.56011  | 0.18\n",
      "[epoch: 2, batch:   2444] loss: 0.16952  | 0.18\n",
      "[epoch: 2, batch:   2446] loss: 0.62240  | 0.18\n",
      "[epoch: 2, batch:   2448] loss: 0.20920  | 0.18\n",
      "[epoch: 2, batch:   2450] loss: 0.09833  | 0.18\n",
      "[epoch: 2, batch:   2452] loss: 0.43909  | 0.18\n",
      "[epoch: 2, batch:   2454] loss: 0.64842  | 0.18\n",
      "[epoch: 2, batch:   2456] loss: 0.94044  | 0.18\n",
      "[epoch: 2, batch:   2458] loss: 0.06264  | 0.18\n",
      "[epoch: 2, batch:   2460] loss: 0.36586  | 0.18\n",
      "[epoch: 2, batch:   2462] loss: 0.07950  | 0.18\n",
      "[epoch: 2, batch:   2464] loss: 0.08711  | 0.18\n",
      "[epoch: 2, batch:   2466] loss: 0.22596  | 0.18\n",
      "[epoch: 2, batch:   2468] loss: 0.23726  | 0.18\n",
      "[epoch: 2, batch:   2470] loss: 0.15234  | 0.18\n",
      "[epoch: 2, batch:   2472] loss: 0.14567  | 0.18\n",
      "[epoch: 2, batch:   2474] loss: 0.28061  | 0.18\n",
      "[epoch: 2, batch:   2476] loss: 0.58403  | 0.18\n",
      "[epoch: 2, batch:   2478] loss: 1.38425  | 0.18\n",
      "[epoch: 2, batch:   2480] loss: 0.34009  | 0.18\n",
      "[epoch: 2, batch:   2482] loss: 0.41114  | 0.18\n",
      "[epoch: 2, batch:   2484] loss: 0.08275  | 0.18\n",
      "[epoch: 2, batch:   2486] loss: 0.36429  | 0.18\n",
      "[epoch: 2, batch:   2488] loss: 0.81943  | 0.18\n",
      "[epoch: 2, batch:   2490] loss: 0.15855  | 0.18\n",
      "[epoch: 2, batch:   2492] loss: 0.38590  | 0.18\n",
      "[epoch: 2, batch:   2494] loss: 0.19271  | 0.18\n",
      "[epoch: 2, batch:   2496] loss: 0.07465  | 0.18\n",
      "[epoch: 2, batch:   2498] loss: 0.07067  | 0.18\n",
      "[epoch: 2, batch:   2500] loss: 0.28402  | 0.18\n",
      "[epoch: 2, batch:   2502] loss: 0.49290  | 0.18\n",
      "[epoch: 2, batch:   2504] loss: 0.68618  | 0.18\n",
      "[epoch: 2, batch:   2506] loss: 0.36909  | 0.18\n",
      "[epoch: 2, batch:   2508] loss: 0.16738  | 0.18\n",
      "[epoch: 2, batch:   2510] loss: 0.36751  | 0.18\n",
      "[epoch: 2, batch:   2512] loss: 0.63621  | 0.18\n",
      "[epoch: 2, batch:   2514] loss: 0.04913  | 0.18\n",
      "[epoch: 2, batch:   2516] loss: 0.43758  | 0.18\n",
      "[epoch: 2, batch:   2518] loss: 0.37490  | 0.18\n",
      "[epoch: 2, batch:   2520] loss: 0.28018  | 0.18\n",
      "[epoch: 2, batch:   2522] loss: 0.58805  | 0.18\n",
      "[epoch: 2, batch:   2524] loss: 0.47799  | 0.18\n",
      "[epoch: 2, batch:   2526] loss: 0.78085  | 0.18\n",
      "[epoch: 2, batch:   2528] loss: 0.73612  | 0.18\n",
      "[epoch: 2, batch:   2530] loss: 0.20088  | 0.18\n",
      "[epoch: 2, batch:   2532] loss: 1.67493  | 0.18\n",
      "[epoch: 2, batch:   2534] loss: 0.22554  | 0.18\n",
      "[epoch: 2, batch:   2536] loss: 0.44805  | 0.18\n",
      "[epoch: 2, batch:   2538] loss: 0.20657  | 0.18\n",
      "[epoch: 2, batch:   2540] loss: 0.19726  | 0.18\n",
      "[epoch: 2, batch:   2542] loss: 0.08275  | 0.18\n",
      "[epoch: 2, batch:   2544] loss: 0.35795  | 0.18\n",
      "[epoch: 2, batch:   2546] loss: 0.12498  | 0.18\n",
      "[epoch: 2, batch:   2548] loss: 0.13869  | 0.18\n",
      "[epoch: 2, batch:   2550] loss: 0.50180  | 0.18\n",
      "[epoch: 2, batch:   2552] loss: 1.03948  | 0.18\n",
      "[epoch: 2, batch:   2554] loss: 0.42733  | 0.18\n",
      "[epoch: 2, batch:   2556] loss: 1.38954  | 0.18\n",
      "[epoch: 2, batch:   2558] loss: 0.25197  | 0.18\n",
      "[epoch: 2, batch:   2560] loss: 0.07191  | 0.18\n",
      "[epoch: 2, batch:   2562] loss: 0.09769  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 2, batch:   2564] loss: 0.25246  | 0.18\n",
      "[epoch: 2, batch:   2566] loss: 0.46064  | 0.18\n",
      "[epoch: 2, batch:   2568] loss: 0.53109  | 0.18\n",
      "[epoch: 2, batch:   2570] loss: 0.69781  | 0.18\n",
      "[epoch: 2, batch:   2572] loss: 0.05235  | 0.18\n",
      "[epoch: 2, batch:   2574] loss: 0.03052  | 0.18\n",
      "[epoch: 2, batch:   2576] loss: 0.55628  | 0.18\n",
      "[epoch: 2, batch:   2578] loss: 0.07191  | 0.18\n",
      "[epoch: 2, batch:   2580] loss: 0.18066  | 0.18\n",
      "[epoch: 2, batch:   2582] loss: 0.66047  | 0.18\n",
      "[epoch: 2, batch:   2584] loss: 0.42947  | 0.18\n",
      "[epoch: 2, batch:   2586] loss: 1.07795  | 0.18\n",
      "[epoch: 2, batch:   2588] loss: 0.36823  | 0.18\n",
      "[epoch: 2, batch:   2590] loss: 0.43234  | 0.18\n",
      "[epoch: 2, batch:   2592] loss: 0.50334  | 0.18\n",
      "[epoch: 2, batch:   2594] loss: 0.49354  | 0.18\n",
      "[epoch: 2, batch:   2596] loss: 0.41918  | 0.18\n",
      "[epoch: 2, batch:   2598] loss: 0.32159  | 0.18\n",
      "[epoch: 2, batch:   2600] loss: 0.10308  | 0.18\n",
      "[epoch: 2, batch:   2602] loss: 0.29297  | 0.18\n",
      "[epoch: 2, batch:   2604] loss: 0.22373  | 0.18\n",
      "[epoch: 2, batch:   2606] loss: 0.28758  | 0.18\n",
      "[epoch: 2, batch:   2608] loss: 0.15403  | 0.18\n",
      "[epoch: 2, batch:   2610] loss: 0.29326  | 0.18\n",
      "[epoch: 2, batch:   2612] loss: 0.61413  | 0.18\n",
      "[epoch: 2, batch:   2614] loss: 0.13922  | 0.18\n",
      "[epoch: 2, batch:   2616] loss: 0.53115  | 0.19\n",
      "[epoch: 2, batch:   2618] loss: 0.19165  | 0.18\n",
      "[epoch: 2, batch:   2620] loss: 0.10215  | 0.18\n",
      "[epoch: 2, batch:   2622] loss: 0.49838  | 0.19\n",
      "[epoch: 2, batch:   2624] loss: 0.50389  | 0.20\n",
      "[epoch: 2, batch:   2626] loss: 0.42391  | 0.18\n",
      "[epoch: 2, batch:   2628] loss: 0.09086  | 0.18\n",
      "[epoch: 2, batch:   2630] loss: 0.28195  | 0.18\n",
      "[epoch: 2, batch:   2632] loss: 0.31294  | 0.18\n",
      "[epoch: 2, batch:   2634] loss: 0.30599  | 0.18\n",
      "[epoch: 2, batch:   2636] loss: 0.25102  | 0.18\n",
      "[epoch: 2, batch:   2638] loss: 0.20862  | 0.18\n",
      "[epoch: 2, batch:   2640] loss: 0.28679  | 0.19\n",
      "[epoch: 2, batch:   2642] loss: 0.12362  | 0.19\n",
      "[epoch: 2, batch:   2644] loss: 1.33407  | 0.19\n",
      "[epoch: 2, batch:   2646] loss: 0.72933  | 0.19\n",
      "[epoch: 2, batch:   2648] loss: 0.14914  | 0.18\n",
      "[epoch: 2, batch:   2650] loss: 0.32887  | 0.18\n",
      "[epoch: 2, batch:   2652] loss: 0.46920  | 0.18\n",
      "[epoch: 2, batch:   2654] loss: 0.28830  | 0.18\n",
      "[epoch: 2, batch:   2656] loss: 0.03263  | 0.18\n",
      "[epoch: 2, batch:   2658] loss: 0.09700  | 0.18\n",
      "[epoch: 2, batch:   2660] loss: 0.56832  | 0.18\n",
      "[epoch: 2, batch:   2662] loss: 1.01681  | 0.19\n",
      "[epoch: 2, batch:   2664] loss: 0.55457  | 0.20\n",
      "[epoch: 2, batch:   2666] loss: 0.45002  | 0.20\n",
      "[epoch: 2, batch:   2668] loss: 0.34336  | 0.19\n",
      "[epoch: 2, batch:   2670] loss: 0.17699  | 0.18\n",
      "[epoch: 2, batch:   2672] loss: 0.15686  | 0.18\n",
      "[epoch: 2, batch:   2674] loss: 0.36000  | 0.18\n",
      "[epoch: 2, batch:   2676] loss: 0.84497  | 0.18\n",
      "[epoch: 2, batch:   2678] loss: 0.38761  | 0.18\n",
      "[epoch: 2, batch:   2680] loss: 0.03774  | 0.18\n",
      "[epoch: 2, batch:   2682] loss: 0.21960  | 0.18\n",
      "[epoch: 2, batch:   2684] loss: 0.14204  | 0.18\n",
      "[epoch: 2, batch:   2686] loss: 0.66898  | 0.18\n",
      "[epoch: 2, batch:   2688] loss: 0.22800  | 0.18\n",
      "[epoch: 2, batch:   2690] loss: 0.09135  | 0.18\n",
      "[epoch: 2, batch:   2692] loss: 0.60530  | 0.18\n",
      "[epoch: 2, batch:   2694] loss: 0.14682  | 0.18\n",
      "[epoch: 2, batch:   2696] loss: 0.34725  | 0.18\n",
      "[epoch: 2, batch:   2698] loss: 0.52021  | 0.19\n",
      "[epoch: 2, batch:   2700] loss: 0.21492  | 0.18\n",
      "[epoch: 2, batch:   2702] loss: 0.35653  | 0.18\n",
      "[epoch: 2, batch:   2704] loss: 1.12634  | 0.18\n",
      "[epoch: 2, batch:   2706] loss: 0.17532  | 0.19\n",
      "[epoch: 2, batch:   2708] loss: 0.46852  | 0.19\n",
      "[epoch: 2, batch:   2710] loss: 0.53588  | 0.19\n",
      "[epoch: 2, batch:   2712] loss: 0.04882  | 0.19\n",
      "[epoch: 2, batch:   2714] loss: 0.01453  | 0.19\n",
      "[epoch: 2, batch:   2716] loss: 0.62977  | 0.19\n",
      "[epoch: 2, batch:   2718] loss: 0.28116  | 0.19\n",
      "[epoch: 2, batch:   2720] loss: 0.60386  | 0.19\n",
      "[epoch: 2, batch:   2722] loss: 0.91369  | 0.19\n",
      "[epoch: 2, batch:   2724] loss: 0.30801  | 0.19\n",
      "[epoch: 2, batch:   2726] loss: 0.27250  | 0.19\n",
      "[epoch: 2, batch:   2728] loss: 0.34484  | 0.19\n",
      "[epoch: 2, batch:   2730] loss: 0.47552  | 0.18\n",
      "[epoch: 2, batch:   2732] loss: 0.23962  | 0.19\n",
      "[epoch: 2, batch:   2734] loss: 0.14387  | 0.19\n",
      "[epoch: 2, batch:   2736] loss: 0.24198  | 0.19\n",
      "[epoch: 2, batch:   2738] loss: 1.04622  | 0.19\n",
      "[epoch: 2, batch:   2740] loss: 0.56163  | 0.19\n",
      "[epoch: 2, batch:   2742] loss: 0.14811  | 0.19\n",
      "[epoch: 2, batch:   2744] loss: 0.76200  | 0.19\n",
      "[epoch: 2, batch:   2746] loss: 0.20257  | 0.19\n",
      "[epoch: 2, batch:   2748] loss: 0.36050  | 0.19\n",
      "[epoch: 2, batch:   2750] loss: 0.10163  | 0.20\n",
      "[epoch: 2, batch:   2752] loss: 0.34407  | 0.19\n",
      "[epoch: 2, batch:   2754] loss: 0.34076  | 0.19\n",
      "[epoch: 2, batch:   2756] loss: 0.62246  | 0.19\n",
      "[epoch: 2, batch:   2758] loss: 0.08096  | 0.19\n",
      "[epoch: 2, batch:   2760] loss: 0.06837  | 0.18\n",
      "[epoch: 2, batch:   2762] loss: 0.89686  | 0.18\n",
      "[epoch: 2, batch:   2764] loss: 0.42776  | 0.18\n",
      "[epoch: 2, batch:   2766] loss: 0.21928  | 0.19\n",
      "[epoch: 2, batch:   2768] loss: 0.14622  | 0.18\n",
      "[epoch: 2, batch:   2770] loss: 0.65443  | 0.18\n",
      "[epoch: 2, batch:   2772] loss: 0.21396  | 0.19\n",
      "[epoch: 2, batch:   2774] loss: 0.34280  | 0.20\n",
      "[epoch: 2, batch:   2776] loss: 0.42678  | 0.20\n",
      "[epoch: 2, batch:   2778] loss: 0.37001  | 0.20\n",
      "[epoch: 2, batch:   2780] loss: 0.10168  | 0.20\n",
      "[epoch: 2, batch:   2782] loss: 0.17038  | 0.19\n",
      "[epoch: 2, batch:   2784] loss: 0.95933  | 0.19\n",
      "[epoch: 2, batch:   2786] loss: 0.21804  | 0.18\n",
      "[epoch: 2, batch:   2788] loss: 0.09863  | 0.18\n",
      "[epoch: 2, batch:   2790] loss: 0.20517  | 0.20\n",
      "[epoch: 2, batch:   2792] loss: 0.11649  | 0.20\n",
      "[epoch: 2, batch:   2794] loss: 0.48456  | 0.20\n",
      "[epoch: 2, batch:   2796] loss: 0.14569  | 0.20\n",
      "[epoch: 2, batch:   2798] loss: 0.25211  | 0.19\n",
      "[epoch: 2, batch:   2800] loss: 0.25284  | 0.18\n",
      "[epoch: 2, batch:   2802] loss: 0.65708  | 0.19\n",
      "[epoch: 2, batch:   2804] loss: 1.13802  | 0.18\n",
      "[epoch: 2, batch:   2806] loss: 0.63347  | 0.19\n",
      "[epoch: 2, batch:   2808] loss: 0.50908  | 0.18\n",
      "[epoch: 2, batch:   2810] loss: 0.45816  | 0.19\n",
      "[epoch: 2, batch:   2812] loss: 0.33265  | 0.19\n",
      "[epoch: 2, batch:   2814] loss: 0.24762  | 0.19\n",
      "[epoch: 2, batch:   2816] loss: 0.11567  | 0.18\n",
      "[epoch: 2, batch:   2818] loss: 0.22576  | 0.19\n",
      "[epoch: 2, batch:   2820] loss: 0.60447  | 0.18\n",
      "[epoch: 2, batch:   2822] loss: 0.16060  | 0.18\n",
      "[epoch: 2, batch:   2824] loss: 0.09389  | 0.18\n",
      "[epoch: 2, batch:   2826] loss: 0.43528  | 0.20\n",
      "[epoch: 2, batch:   2828] loss: 0.21240  | 0.18\n",
      "[epoch: 2, batch:   2830] loss: 0.08019  | 0.18\n",
      "[epoch: 2, batch:   2832] loss: 0.15853  | 0.18\n",
      "[epoch: 2, batch:   2834] loss: 0.65829  | 0.19\n",
      "[epoch: 2, batch:   2836] loss: 0.10327  | 0.19\n",
      "[epoch: 2, batch:   2838] loss: 0.51631  | 0.19\n",
      "[epoch: 2, batch:   2840] loss: 0.32423  | 0.18\n",
      "[epoch: 2, batch:   2842] loss: 0.26076  | 0.19\n",
      "[epoch: 2, batch:   2844] loss: 0.39103  | 0.18\n",
      "[epoch: 2, batch:   2846] loss: 0.18896  | 0.18\n",
      "[epoch: 2, batch:   2848] loss: 0.26970  | 0.18\n",
      "[epoch: 2, batch:   2850] loss: 0.73401  | 0.18\n",
      "[epoch: 2, batch:   2852] loss: 0.16063  | 0.18\n",
      "[epoch: 2, batch:   2854] loss: 0.35860  | 0.19\n",
      "[epoch: 2, batch:   2856] loss: 0.81998  | 0.18\n",
      "[epoch: 2, batch:   2858] loss: 0.36516  | 0.18\n",
      "[epoch: 2, batch:   2860] loss: 0.16890  | 0.18\n",
      "[epoch: 2, batch:   2862] loss: 0.42600  | 0.18\n",
      "[epoch: 2, batch:   2864] loss: 0.17899  | 0.18\n",
      "[epoch: 2, batch:   2866] loss: 0.30606  | 0.19\n",
      "[epoch: 2, batch:   2868] loss: 0.29264  | 0.17\n",
      "[epoch: 2, batch:   2870] loss: 0.47469  | 0.18\n",
      "[epoch: 2, batch:   2872] loss: 0.07883  | 0.18\n",
      "[epoch: 2, batch:   2874] loss: 0.19176  | 0.18\n",
      "[epoch: 2, batch:   2876] loss: 0.58251  | 0.18\n",
      "[epoch: 2, batch:   2878] loss: 0.10065  | 0.19\n",
      "[epoch: 2, batch:   2880] loss: 0.07860  | 0.18\n",
      "[epoch: 2, batch:   2882] loss: 0.21376  | 0.18\n",
      "[epoch: 2, batch:   2884] loss: 0.07885  | 0.18\n",
      "[epoch: 2, batch:   2886] loss: 0.30575  | 0.18\n",
      "[epoch: 2, batch:   2888] loss: 1.07345  | 0.18\n",
      "[epoch: 2, batch:   2890] loss: 0.73767  | 0.18\n",
      "[epoch: 2, batch:   2892] loss: 0.33396  | 0.18\n",
      "[epoch: 2, batch:   2894] loss: 0.28702  | 0.18\n",
      "[epoch: 2, batch:   2896] loss: 0.11792  | 0.18\n",
      "[epoch: 2, batch:   2898] loss: 0.57410  | 0.18\n",
      "[epoch: 2, batch:   2900] loss: 0.10240  | 0.18\n",
      "[epoch: 2, batch:   2902] loss: 0.26968  | 0.18\n",
      "[epoch: 2, batch:   2904] loss: 0.44130  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 2, batch:   2906] loss: 0.61957  | 0.18\n",
      "[epoch: 2, batch:   2908] loss: 0.07943  | 0.18\n",
      "[epoch: 2, batch:   2910] loss: 0.48460  | 0.18\n",
      "[epoch: 2, batch:   2912] loss: 0.36091  | 0.18\n",
      "[epoch: 2, batch:   2914] loss: 0.15392  | 0.18\n",
      "[epoch: 2, batch:   2916] loss: 0.36990  | 0.18\n",
      "[epoch: 2, batch:   2918] loss: 0.46340  | 0.18\n",
      "[epoch: 2, batch:   2920] loss: 0.29951  | 0.18\n",
      "[epoch: 2, batch:   2922] loss: 0.47542  | 0.18\n",
      "[epoch: 2, batch:   2924] loss: 0.11184  | 0.18\n",
      "[epoch: 2, batch:   2926] loss: 0.13073  | 0.18\n",
      "[epoch: 2, batch:   2928] loss: 0.50061  | 0.18\n",
      "[epoch: 2, batch:   2930] loss: 0.36306  | 0.18\n",
      "[epoch: 2, batch:   2932] loss: 1.14660  | 0.18\n",
      "[epoch: 2, batch:   2934] loss: 0.02086  | 0.18\n",
      "[epoch: 2, batch:   2936] loss: 0.14863  | 0.19\n",
      "[epoch: 2, batch:   2938] loss: 0.17910  | 0.18\n",
      "[epoch: 2, batch:   2940] loss: 0.16467  | 0.18\n",
      "[epoch: 2, batch:   2942] loss: 0.27987  | 0.18\n",
      "[epoch: 2, batch:   2944] loss: 0.26140  | 0.18\n",
      "[epoch: 2, batch:   2946] loss: 0.14493  | 0.18\n",
      "[epoch: 2, batch:   2948] loss: 0.13672  | 0.18\n",
      "[epoch: 2, batch:   2950] loss: 0.11254  | 0.18\n",
      "[epoch: 2, batch:   2952] loss: 0.54054  | 0.18\n",
      "[epoch: 2, batch:   2954] loss: 0.49801  | 0.18\n",
      "[epoch: 2, batch:   2956] loss: 0.44623  | 0.18\n",
      "[epoch: 2, batch:   2958] loss: 0.15663  | 0.18\n",
      "[epoch: 2, batch:   2960] loss: 1.12854  | 0.18\n",
      "[epoch: 2, batch:   2962] loss: 0.00370  | 0.18\n",
      "[epoch: 2, batch:   2964] loss: 0.15571  | 0.18\n",
      "[epoch: 2, batch:   2966] loss: 0.41115  | 0.18\n",
      "[epoch: 2, batch:   2968] loss: 0.21406  | 0.18\n",
      "[epoch: 2, batch:   2970] loss: 0.66106  | 0.18\n",
      "[epoch: 2, batch:   2972] loss: 0.48542  | 0.18\n",
      "[epoch: 2, batch:   2974] loss: 0.11972  | 0.18\n",
      "[epoch: 2, batch:   2976] loss: 0.31808  | 0.18\n",
      "[epoch: 2, batch:   2978] loss: 0.85163  | 0.18\n",
      "[epoch: 2, batch:   2980] loss: 0.31651  | 0.19\n",
      "[epoch: 2, batch:   2982] loss: 0.57272  | 0.19\n",
      "[epoch: 2, batch:   2984] loss: 0.16786  | 0.18\n",
      "[epoch: 2, batch:   2986] loss: 1.29302  | 0.18\n",
      "[epoch: 2, batch:   2988] loss: 0.39507  | 0.18\n",
      "[epoch: 2, batch:   2990] loss: 0.47472  | 0.18\n",
      "[epoch: 2, batch:   2992] loss: 0.48339  | 0.18\n",
      "[epoch: 2, batch:   2994] loss: 0.22458  | 0.18\n",
      "[epoch: 2, batch:   2996] loss: 0.36241  | 0.18\n",
      "[epoch: 2, batch:   2998] loss: 0.44093  | 0.18\n",
      "[epoch: 2, batch:   3000] loss: 0.06318  | 0.18\n",
      "[epoch: 2, batch:   3002] loss: 0.07841  | 0.18\n",
      "[epoch: 2, batch:   3004] loss: 0.39065  | 0.18\n",
      "[epoch: 2, batch:   3006] loss: 0.06492  | 0.19\n",
      "[epoch: 2, batch:   3008] loss: 0.10746  | 0.18\n",
      "[epoch: 2, batch:   3010] loss: 0.13806  | 0.18\n",
      "[epoch: 2, batch:   3012] loss: 0.11246  | 0.18\n",
      "[epoch: 2, batch:   3014] loss: 0.34724  | 0.19\n",
      "[epoch: 2, batch:   3016] loss: 0.12954  | 0.18\n",
      "[epoch: 2, batch:   3018] loss: 0.61121  | 0.18\n",
      "[epoch: 2, batch:   3020] loss: 0.10308  | 0.18\n",
      "[epoch: 2, batch:   3022] loss: 0.02837  | 0.19\n",
      "[epoch: 2, batch:   3024] loss: 0.67843  | 0.19\n",
      "[epoch: 2, batch:   3026] loss: 0.57798  | 0.18\n",
      "[epoch: 2, batch:   3028] loss: 1.01377  | 0.18\n",
      "[epoch: 2, batch:   3030] loss: 0.36441  | 0.19\n",
      "[epoch: 2, batch:   3032] loss: 0.42011  | 0.19\n",
      "[epoch: 2, batch:   3034] loss: 0.18548  | 0.19\n",
      "[epoch: 2, batch:   3036] loss: 0.22812  | 0.19\n",
      "[epoch: 2, batch:   3038] loss: 0.48654  | 0.20\n",
      "[epoch: 2, batch:   3040] loss: 0.13133  | 0.19\n",
      "[epoch: 2, batch:   3042] loss: 0.19493  | 0.20\n",
      "[epoch: 2, batch:   3044] loss: 0.22745  | 0.19\n",
      "[epoch: 2, batch:   3046] loss: 0.83456  | 0.20\n",
      "[epoch: 2, batch:   3048] loss: 0.46782  | 0.19\n",
      "[epoch: 2, batch:   3050] loss: 0.56231  | 0.19\n",
      "[epoch: 2, batch:   3052] loss: 0.27499  | 0.19\n",
      "[epoch: 2, batch:   3054] loss: 1.23055  | 0.19\n",
      "[epoch: 2, batch:   3056] loss: 0.06135  | 0.18\n",
      "[epoch: 2, batch:   3058] loss: 0.77061  | 0.18\n",
      "[epoch: 2, batch:   3060] loss: 0.37151  | 0.18\n",
      "[epoch: 2, batch:   3062] loss: 0.16026  | 0.19\n",
      "[epoch: 2, batch:   3064] loss: 0.26279  | 0.18\n",
      "[epoch: 2, batch:   3066] loss: 0.07627  | 0.18\n",
      "[epoch: 2, batch:   3068] loss: 0.40305  | 0.18\n",
      "[epoch: 2, batch:   3070] loss: 0.53029  | 0.18\n",
      "[epoch: 2, batch:   3072] loss: 0.29943  | 0.18\n",
      "[epoch: 2, batch:   3074] loss: 0.32146  | 0.18\n",
      "[epoch: 2, batch:   3076] loss: 0.32376  | 0.18\n",
      "[epoch: 2, batch:   3078] loss: 0.26197  | 0.18\n",
      "[epoch: 2, batch:   3080] loss: 0.22419  | 0.18\n",
      "[epoch: 2, batch:   3082] loss: 0.19917  | 0.18\n",
      "[epoch: 2, batch:   3084] loss: 0.23126  | 0.18\n",
      "[epoch: 2, batch:   3086] loss: 0.14706  | 0.18\n",
      "[epoch: 2, batch:   3088] loss: 0.24932  | 0.18\n",
      "[epoch: 2, batch:   3090] loss: 0.33160  | 0.18\n",
      "[epoch: 2, batch:   3092] loss: 0.07227  | 0.18\n",
      "[epoch: 2, batch:   3094] loss: 0.26327  | 0.18\n",
      "[epoch: 2, batch:   3096] loss: 0.27397  | 0.18\n",
      "[epoch: 2, batch:   3098] loss: 0.14187  | 0.18\n",
      "[epoch: 2, batch:   3100] loss: 0.62147  | 0.18\n",
      "[epoch: 2, batch:   3102] loss: 0.11159  | 0.18\n",
      "[epoch: 2, batch:   3104] loss: 0.23861  | 0.18\n",
      "[epoch: 2, batch:   3106] loss: 0.47093  | 0.18\n",
      "[epoch: 2, batch:   3108] loss: 0.24929  | 0.18\n",
      "[epoch: 2, batch:   3110] loss: 1.76202  | 0.18\n",
      "[epoch: 2, batch:   3112] loss: 0.22725  | 0.18\n",
      "[epoch: 2, batch:   3114] loss: 1.03413  | 0.19\n",
      "[epoch: 2, batch:   3116] loss: 0.59741  | 0.18\n",
      "[epoch: 2, batch:   3118] loss: 0.11160  | 0.19\n",
      "[epoch: 2, batch:   3120] loss: 0.16050  | 0.18\n",
      "[epoch: 2, batch:   3122] loss: 0.17807  | 0.20\n",
      "[epoch: 2, batch:   3124] loss: 0.15321  | 0.18\n",
      "[epoch: 2, batch:   3126] loss: 0.13362  | 0.19\n",
      "[epoch: 2, batch:   3128] loss: 0.05209  | 0.18\n",
      "[epoch: 2, batch:   3130] loss: 0.14804  | 0.18\n",
      "[epoch: 2, batch:   3132] loss: 0.94270  | 0.18\n",
      "[epoch: 2, batch:   3134] loss: 0.36426  | 0.18\n",
      "[epoch: 2, batch:   3136] loss: 0.13485  | 0.18\n",
      "[epoch: 2, batch:   3138] loss: 0.89544  | 0.18\n",
      "[epoch: 2, batch:   3140] loss: 0.20689  | 0.19\n",
      "[epoch: 2, batch:   3142] loss: 0.15558  | 0.18\n",
      "[epoch: 2, batch:   3144] loss: 0.17845  | 0.18\n",
      "[epoch: 2, batch:   3146] loss: 0.47352  | 0.18\n",
      "[epoch: 2, batch:   3148] loss: 0.22677  | 0.18\n",
      "[epoch: 2, batch:   3150] loss: 0.38083  | 0.18\n",
      "[epoch: 2, batch:   3152] loss: 1.31878  | 0.18\n",
      "[epoch: 2, batch:   3154] loss: 0.09335  | 0.18\n",
      "[epoch: 2, batch:   3156] loss: 0.58497  | 0.18\n",
      "[epoch: 2, batch:   3158] loss: 0.27712  | 0.18\n",
      "[epoch: 2, batch:   3160] loss: 0.26343  | 0.18\n",
      "[epoch: 2, batch:   3162] loss: 0.22337  | 0.18\n",
      "[epoch: 2, batch:   3164] loss: 0.46988  | 0.18\n",
      "[epoch: 2, batch:   3166] loss: 1.26577  | 0.18\n",
      "[epoch: 2, batch:   3168] loss: 0.31340  | 0.18\n",
      "[epoch: 2, batch:   3170] loss: 0.33679  | 0.18\n",
      "[epoch: 2, batch:   3172] loss: 0.08358  | 0.18\n",
      "[epoch: 2, batch:   3174] loss: 0.10360  | 0.18\n",
      "[epoch: 2, batch:   3176] loss: 0.45354  | 0.18\n",
      "[epoch: 2, batch:   3178] loss: 0.06378  | 0.18\n",
      "[epoch: 2, batch:   3180] loss: 0.49805  | 0.18\n",
      "[epoch: 2, batch:   3182] loss: 0.60991  | 0.18\n",
      "[epoch: 2, batch:   3184] loss: 0.39115  | 0.18\n",
      "[epoch: 2, batch:   3186] loss: 0.07917  | 0.18\n",
      "[epoch: 2, batch:   3188] loss: 0.51002  | 0.18\n",
      "[epoch: 2, batch:   3190] loss: 0.08573  | 0.18\n",
      "[epoch: 2, batch:   3192] loss: 1.70069  | 0.18\n",
      "[epoch: 2, batch:   3194] loss: 0.35747  | 0.18\n",
      "[epoch: 2, batch:   3196] loss: 0.12103  | 0.18\n",
      "[epoch: 2, batch:   3198] loss: 0.06817  | 0.18\n",
      "[epoch: 2, batch:   3200] loss: 0.36259  | 0.18\n",
      "[epoch: 2, batch:   3202] loss: 0.37634  | 0.18\n",
      "[epoch: 2, batch:   3204] loss: 0.79204  | 0.18\n",
      "[epoch: 2, batch:   3206] loss: 0.67876  | 0.18\n",
      "[epoch: 2, batch:   3208] loss: 0.13916  | 0.18\n",
      "[epoch: 2, batch:   3210] loss: 0.11737  | 0.18\n",
      "[epoch: 2, batch:   3212] loss: 0.25772  | 0.18\n",
      "[epoch: 2, batch:   3214] loss: 0.23494  | 0.18\n",
      "[epoch: 2, batch:   3216] loss: 0.57759  | 0.18\n",
      "[epoch: 2, batch:   3218] loss: 0.01585  | 0.18\n",
      "[epoch: 2, batch:   3220] loss: 0.04234  | 0.18\n",
      "[epoch: 2, batch:   3222] loss: 0.23178  | 0.18\n",
      "[epoch: 2, batch:   3224] loss: 0.51470  | 0.18\n",
      "[epoch: 2, batch:   3226] loss: 0.08318  | 0.18\n",
      "[epoch: 2, batch:   3228] loss: 0.52167  | 0.18\n",
      "[epoch: 2, batch:   3230] loss: 0.13721  | 0.18\n",
      "[epoch: 2, batch:   3232] loss: 0.11004  | 0.18\n",
      "[epoch: 2, batch:   3234] loss: 0.49327  | 0.18\n",
      "[epoch: 2, batch:   3236] loss: 0.45571  | 0.18\n",
      "[epoch: 2, batch:   3238] loss: 0.46155  | 0.18\n",
      "[epoch: 2, batch:   3240] loss: 0.04785  | 0.18\n",
      "[epoch: 2, batch:   3242] loss: 0.70258  | 0.18\n",
      "[epoch: 2, batch:   3244] loss: 0.40865  | 0.18\n",
      "[epoch: 2, batch:   3246] loss: 0.20827  | 0.18\n",
      "[epoch: 2, batch:   3248] loss: 0.04607  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 2, batch:   3250] loss: 0.31346  | 0.18\n",
      "[epoch: 2, batch:   3252] loss: 0.12120  | 0.18\n",
      "[epoch: 2, batch:   3254] loss: 1.08466  | 0.18\n",
      "[epoch: 2, batch:   3256] loss: 0.29393  | 0.18\n",
      "[epoch: 2, batch:   3258] loss: 0.13674  | 0.18\n",
      "[epoch: 2, batch:   3260] loss: 0.22691  | 0.18\n",
      "[epoch: 2, batch:   3262] loss: 0.21483  | 0.18\n",
      "[epoch: 2, batch:   3264] loss: 0.16744  | 0.18\n",
      "[epoch: 2, batch:   3266] loss: 0.39138  | 0.18\n",
      "[epoch: 2, batch:   3268] loss: 0.38122  | 0.18\n",
      "[epoch: 2, batch:   3270] loss: 0.18450  | 0.18\n",
      "[epoch: 2, batch:   3272] loss: 0.19309  | 0.18\n",
      "[epoch: 2, batch:   3274] loss: 0.08716  | 0.18\n",
      "[epoch: 2, batch:   3276] loss: 0.26325  | 0.18\n",
      "[epoch: 2, batch:   3278] loss: 0.08816  | 0.18\n",
      "[epoch: 2, batch:   3280] loss: 0.13242  | 0.18\n",
      "[epoch: 2, batch:   3282] loss: 0.10078  | 0.18\n",
      "[epoch: 2, batch:   3284] loss: 0.77979  | 0.18\n",
      "[epoch: 2, batch:   3286] loss: 0.04664  | 0.18\n",
      "[epoch: 2, batch:   3288] loss: 0.63095  | 0.18\n",
      "[epoch: 2, batch:   3290] loss: 0.65213  | 0.18\n",
      "[epoch: 2, batch:   3292] loss: 0.08929  | 0.18\n",
      "[epoch: 2, batch:   3294] loss: 0.13340  | 0.18\n",
      "[epoch: 2, batch:   3296] loss: 0.67860  | 0.18\n",
      "[epoch: 2, batch:   3298] loss: 0.61971  | 0.18\n",
      "[epoch: 2, batch:   3300] loss: 0.33835  | 0.18\n",
      "[epoch: 2, batch:   3302] loss: 0.15164  | 0.18\n",
      "[epoch: 2, batch:   3304] loss: 0.13714  | 0.18\n",
      "[epoch: 2, batch:   3306] loss: 0.11471  | 0.18\n",
      "[epoch: 2, batch:   3308] loss: 0.05740  | 0.19\n",
      "[epoch: 2, batch:   3310] loss: 0.35255  | 0.18\n",
      "[epoch: 2, batch:   3312] loss: 0.45273  | 0.19\n",
      "[epoch: 2, batch:   3314] loss: 0.43304  | 0.18\n",
      "[epoch: 2, batch:   3316] loss: 0.03596  | 0.18\n",
      "[epoch: 2, batch:   3318] loss: 0.36469  | 0.18\n",
      "[epoch: 2, batch:   3320] loss: 0.55604  | 0.18\n",
      "[epoch: 2, batch:   3322] loss: 0.15077  | 0.18\n",
      "[epoch: 2, batch:   3324] loss: 0.73165  | 0.18\n",
      "[epoch: 2, batch:   3326] loss: 0.07448  | 0.18\n",
      "[epoch: 2, batch:   3328] loss: 0.27081  | 0.18\n",
      "[epoch: 2, batch:   3330] loss: 0.56392  | 0.18\n",
      "[epoch: 2, batch:   3332] loss: 0.28366  | 0.18\n",
      "[epoch: 2, batch:   3334] loss: 0.38373  | 0.18\n",
      "[epoch: 2, batch:   3336] loss: 0.28133  | 0.18\n",
      "[epoch: 2, batch:   3338] loss: 0.52082  | 0.18\n",
      "[epoch: 2, batch:   3340] loss: 0.29566  | 0.18\n",
      "[epoch: 2, batch:   3342] loss: 0.18328  | 0.18\n",
      "[epoch: 2, batch:   3344] loss: 0.27489  | 0.18\n",
      "[epoch: 2, batch:   3346] loss: 0.09779  | 0.18\n",
      "[epoch: 2, batch:   3348] loss: 0.35026  | 0.18\n",
      "[epoch: 2, batch:   3350] loss: 0.15280  | 0.18\n",
      "[epoch: 2, batch:   3352] loss: 0.21071  | 0.18\n",
      "[epoch: 2, batch:   3354] loss: 0.42946  | 0.18\n",
      "[epoch: 2, batch:   3356] loss: 0.46755  | 0.18\n",
      "[epoch: 2, batch:   3358] loss: 0.04195  | 0.18\n",
      "[epoch: 2, batch:   3360] loss: 0.49690  | 0.18\n",
      "[epoch: 2, batch:   3362] loss: 0.13598  | 0.18\n",
      "[epoch: 2, batch:   3364] loss: 0.71048  | 0.18\n",
      "[epoch: 2, batch:   3366] loss: 0.15995  | 0.18\n",
      "[epoch: 2, batch:   3368] loss: 0.07761  | 0.18\n",
      "[epoch: 2, batch:   3370] loss: 0.55382  | 0.18\n",
      "[epoch: 2, batch:   3372] loss: 0.22688  | 0.18\n",
      "[epoch: 2, batch:   3374] loss: 0.08203  | 0.18\n",
      "[epoch: 2, batch:   3376] loss: 0.11436  | 0.18\n",
      "[epoch: 2, batch:   3378] loss: 0.20259  | 0.18\n",
      "[epoch: 2, batch:   3380] loss: 0.32280  | 0.18\n",
      "[epoch: 2, batch:   3382] loss: 0.08485  | 0.18\n",
      "[epoch: 2, batch:   3384] loss: 0.13741  | 0.18\n",
      "[epoch: 2, batch:   3386] loss: 0.47061  | 0.18\n",
      "[epoch: 2, batch:   3388] loss: 0.31499  | 0.18\n",
      "[epoch: 2, batch:   3390] loss: 0.21759  | 0.18\n",
      "[epoch: 2, batch:   3392] loss: 0.16145  | 0.18\n",
      "[epoch: 2, batch:   3394] loss: 0.32813  | 0.18\n",
      "[epoch: 2, batch:   3396] loss: 0.67234  | 0.18\n",
      "[epoch: 2, batch:   3398] loss: 0.12555  | 0.18\n",
      "[epoch: 2, batch:   3400] loss: 0.08343  | 0.18\n",
      "[epoch: 2, batch:   3402] loss: 0.11094  | 0.18\n",
      "[epoch: 2, batch:   3404] loss: 0.72907  | 0.18\n",
      "[epoch: 2, batch:   3406] loss: 0.70215  | 0.18\n",
      "[epoch: 2, batch:   3408] loss: 0.23057  | 0.18\n",
      "[epoch: 2, batch:   3410] loss: 0.54992  | 0.18\n",
      "[epoch: 2, batch:   3412] loss: 0.42723  | 0.18\n",
      "[epoch: 2, batch:   3414] loss: 0.34856  | 0.18\n",
      "[epoch: 2, batch:   3416] loss: 0.16937  | 0.18\n",
      "[epoch: 2, batch:   3418] loss: 0.93387  | 0.18\n",
      "[epoch: 2, batch:   3420] loss: 0.65258  | 0.18\n",
      "[epoch: 2, batch:   3422] loss: 0.16957  | 0.18\n",
      "[epoch: 2, batch:   3424] loss: 0.65224  | 0.18\n",
      "[epoch: 2, batch:   3426] loss: 0.26829  | 0.18\n",
      "[epoch: 2, batch:   3428] loss: 0.04599  | 0.18\n",
      "[epoch: 2, batch:   3430] loss: 0.20486  | 0.18\n",
      "[epoch: 2, batch:   3432] loss: 0.40761  | 0.18\n",
      "[epoch: 2, batch:   3434] loss: 0.11914  | 0.18\n",
      "[epoch: 2, batch:   3436] loss: 0.16736  | 0.18\n",
      "[epoch: 2, batch:   3438] loss: 0.18953  | 0.18\n",
      "[epoch: 2, batch:   3440] loss: 0.18272  | 0.18\n",
      "[epoch: 2, batch:   3442] loss: 0.27476  | 0.18\n",
      "[epoch: 2, batch:   3444] loss: 0.24587  | 0.18\n",
      "[epoch: 2, batch:   3446] loss: 0.21921  | 0.18\n",
      "[epoch: 2, batch:   3448] loss: 0.50820  | 0.18\n",
      "[epoch: 2, batch:   3450] loss: 0.68960  | 0.18\n",
      "[epoch: 2, batch:   3452] loss: 0.06797  | 0.18\n",
      "[epoch: 2, batch:   3454] loss: 0.25459  | 0.18\n",
      "[epoch: 2, batch:   3456] loss: 0.72478  | 0.18\n",
      "[epoch: 2, batch:   3458] loss: 0.14851  | 0.18\n",
      "[epoch: 2, batch:   3460] loss: 0.06636  | 0.18\n",
      "[epoch: 2, batch:   3462] loss: 0.27041  | 0.18\n",
      "[epoch: 2, batch:   3464] loss: 0.11803  | 0.18\n",
      "[epoch: 2, batch:   3466] loss: 0.45881  | 0.18\n",
      "[epoch: 2, batch:   3468] loss: 0.40616  | 0.18\n",
      "[epoch: 2, batch:   3470] loss: 0.36319  | 0.18\n",
      "[epoch: 2, batch:   3472] loss: 0.06282  | 0.18\n",
      "[epoch: 2, batch:   3474] loss: 0.43885  | 0.18\n",
      "[epoch: 2, batch:   3476] loss: 0.38125  | 0.18\n",
      "[epoch: 2, batch:   3478] loss: 0.40274  | 0.18\n",
      "[epoch: 2, batch:   3480] loss: 0.29929  | 0.18\n",
      "[epoch: 2, batch:   3482] loss: 0.83933  | 0.18\n",
      "[epoch: 2, batch:   3484] loss: 0.14557  | 0.18\n",
      "[epoch: 2, batch:   3486] loss: 0.32813  | 0.18\n",
      "[epoch: 2, batch:   3488] loss: 0.06242  | 0.18\n",
      "[epoch: 2, batch:   3490] loss: 0.20648  | 0.18\n",
      "[epoch: 2, batch:   3492] loss: 0.68898  | 0.18\n",
      "[epoch: 2, batch:   3494] loss: 0.70443  | 0.18\n",
      "[epoch: 2, batch:   3496] loss: 1.60811  | 0.18\n",
      "[epoch: 2, batch:   3498] loss: 0.03575  | 0.18\n",
      "[epoch: 2, batch:   3500] loss: 1.08958  | 0.18\n",
      "[epoch: 2, batch:   3502] loss: 0.03933  | 0.18\n",
      "[epoch: 2, batch:   3504] loss: 0.12816  | 0.18\n",
      "[epoch: 2, batch:   3506] loss: 0.55399  | 0.18\n",
      "[epoch: 2, batch:   3508] loss: 0.55183  | 0.18\n",
      "[epoch: 2, batch:   3510] loss: 0.30936  | 0.18\n",
      "[epoch: 2, batch:   3512] loss: 0.11179  | 0.18\n",
      "[epoch: 2, batch:   3514] loss: 0.19488  | 0.18\n",
      "[epoch: 2, batch:   3516] loss: 0.28711  | 0.18\n",
      "[epoch: 2, batch:   3518] loss: 0.10127  | 0.18\n",
      "[epoch: 2, batch:   3520] loss: 0.02764  | 0.18\n",
      "[epoch: 2, batch:   3522] loss: 0.34803  | 0.18\n",
      "[epoch: 2, batch:   3524] loss: 0.11743  | 0.18\n",
      "[epoch: 2, batch:   3526] loss: 0.18821  | 0.18\n",
      "[epoch: 2, batch:   3528] loss: 0.01410  | 0.18\n",
      "[epoch: 2, batch:   3530] loss: 0.19117  | 0.18\n",
      "[epoch: 2, batch:   3532] loss: 0.47214  | 0.18\n",
      "[epoch: 2, batch:   3534] loss: 0.27313  | 0.18\n",
      "[epoch: 2, batch:   3536] loss: 0.18439  | 0.18\n",
      "[epoch: 2, batch:   3538] loss: 0.23626  | 0.18\n",
      "[epoch: 2, batch:   3540] loss: 0.21575  | 0.18\n",
      "[epoch: 2, batch:   3542] loss: 0.64401  | 0.18\n",
      "[epoch: 2, batch:   3544] loss: 0.30234  | 0.18\n",
      "[epoch: 2, batch:   3546] loss: 0.12804  | 0.18\n",
      "[epoch: 2, batch:   3548] loss: 0.45996  | 0.18\n",
      "[epoch: 2, batch:   3550] loss: 0.24444  | 0.18\n",
      "[epoch: 2, batch:   3552] loss: 0.34108  | 0.18\n",
      "[epoch: 2, batch:   3554] loss: 0.46821  | 0.18\n",
      "[epoch: 2, batch:   3556] loss: 0.29203  | 0.18\n",
      "[epoch: 2, batch:   3558] loss: 1.16332  | 0.18\n",
      "[epoch: 2, batch:   3560] loss: 0.73858  | 0.18\n",
      "[epoch: 2, batch:   3562] loss: 0.11504  | 0.18\n",
      "[epoch: 2, batch:   3564] loss: 0.41718  | 0.18\n",
      "[epoch: 2, batch:   3566] loss: 0.35155  | 0.18\n",
      "[epoch: 2, batch:   3568] loss: 0.07357  | 0.18\n",
      "[epoch: 2, batch:   3570] loss: 0.54730  | 0.19\n",
      "[epoch: 2, batch:   3572] loss: 0.83662  | 0.18\n",
      "[epoch: 2, batch:   3574] loss: 0.08002  | 0.19\n",
      "[epoch: 2, batch:   3576] loss: 0.14674  | 0.18\n",
      "[epoch: 2, batch:   3578] loss: 0.83268  | 0.18\n",
      "[epoch: 2, batch:   3580] loss: 0.41891  | 0.18\n",
      "[epoch: 2, batch:   3582] loss: 1.08288  | 0.18\n",
      "[epoch: 2, batch:   3584] loss: 0.63889  | 0.18\n",
      "[epoch: 2, batch:   3586] loss: 0.70287  | 0.18\n",
      "[epoch: 2, batch:   3588] loss: 0.59741  | 0.18\n",
      "[epoch: 2, batch:   3590] loss: 0.19826  | 0.18\n",
      "[epoch: 2, batch:   3592] loss: 0.19061  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 2, batch:   3594] loss: 0.29052  | 0.18\n",
      "[epoch: 2, batch:   3596] loss: 0.47748  | 0.18\n",
      "[epoch: 2, batch:   3598] loss: 0.60771  | 0.18\n",
      "[epoch: 2, batch:   3600] loss: 0.51937  | 0.19\n",
      "[epoch: 2, batch:   3602] loss: 1.12961  | 0.18\n",
      "[epoch: 2, batch:   3604] loss: 0.03317  | 0.18\n",
      "[epoch: 2, batch:   3606] loss: 0.06983  | 0.18\n",
      "[epoch: 2, batch:   3608] loss: 0.02803  | 0.18\n",
      "[epoch: 2, batch:   3610] loss: 0.33558  | 0.18\n",
      "[epoch: 2, batch:   3612] loss: 0.12333  | 0.18\n",
      "[epoch: 2, batch:   3614] loss: 0.34476  | 0.18\n",
      "[epoch: 2, batch:   3616] loss: 0.38382  | 0.18\n",
      "[epoch: 2, batch:   3618] loss: 0.27395  | 0.18\n",
      "[epoch: 2, batch:   3620] loss: 0.48924  | 0.18\n",
      "[epoch: 2, batch:   3622] loss: 1.90696  | 0.18\n",
      "[epoch: 2, batch:   3624] loss: 0.27220  | 0.18\n",
      "[epoch: 2, batch:   3626] loss: 0.15463  | 0.18\n",
      "[epoch: 2, batch:   3628] loss: 0.25438  | 0.18\n",
      "[epoch: 2, batch:   3630] loss: 0.10072  | 0.18\n",
      "[epoch: 2, batch:   3632] loss: 0.20263  | 0.18\n",
      "[epoch: 2, batch:   3634] loss: 0.17213  | 0.18\n",
      "[epoch: 2, batch:   3636] loss: 0.06579  | 0.18\n",
      "[epoch: 2, batch:   3638] loss: 0.77770  | 0.18\n",
      "[epoch: 2, batch:   3640] loss: 0.22188  | 0.18\n",
      "[epoch: 2, batch:   3642] loss: 0.43772  | 0.18\n",
      "[epoch: 2, batch:   3644] loss: 0.09552  | 0.18\n",
      "[epoch: 2, batch:   3646] loss: 0.11524  | 0.18\n",
      "[epoch: 2, batch:   3648] loss: 0.10591  | 0.18\n",
      "[epoch: 2, batch:   3650] loss: 0.06481  | 0.18\n",
      "[epoch: 2, batch:   3652] loss: 0.08367  | 0.18\n",
      "[epoch: 2, batch:   3654] loss: 0.45143  | 0.18\n",
      "[epoch: 2, batch:   3656] loss: 0.47716  | 0.18\n",
      "[epoch: 2, batch:   3658] loss: 0.09300  | 0.18\n",
      "[epoch: 2, batch:   3660] loss: 0.15260  | 0.18\n",
      "[epoch: 2, batch:   3662] loss: 1.03855  | 0.18\n",
      "[epoch: 2, batch:   3664] loss: 0.06395  | 0.18\n",
      "[epoch: 2, batch:   3666] loss: 0.46124  | 0.18\n",
      "[epoch: 2, batch:   3668] loss: 0.03533  | 0.18\n",
      "[epoch: 2, batch:   3670] loss: 0.16297  | 0.18\n",
      "[epoch: 2, batch:   3672] loss: 0.48317  | 0.18\n",
      "[epoch: 2, batch:   3674] loss: 0.13682  | 0.18\n",
      "[epoch: 2, batch:   3676] loss: 0.19030  | 0.18\n",
      "[epoch: 2, batch:   3678] loss: 0.10183  | 0.18\n",
      "[epoch: 2, batch:   3680] loss: 0.51082  | 0.18\n",
      "[epoch: 2, batch:   3682] loss: 0.12059  | 0.18\n",
      "[epoch: 2, batch:   3684] loss: 0.35936  | 0.18\n",
      "[epoch: 2, batch:   3686] loss: 0.95761  | 0.18\n",
      "[epoch: 2, batch:   3688] loss: 0.27047  | 0.18\n",
      "[epoch: 2, batch:   3690] loss: 0.20758  | 0.18\n",
      "[epoch: 2, batch:   3692] loss: 0.08065  | 0.18\n",
      "[epoch: 2, batch:   3694] loss: 0.41856  | 0.18\n",
      "[epoch: 2, batch:   3696] loss: 0.21694  | 0.18\n",
      "[epoch: 2, batch:   3698] loss: 0.59213  | 0.18\n",
      "[epoch: 2, batch:   3700] loss: 0.10230  | 0.18\n",
      "[epoch: 2, batch:   3702] loss: 0.71530  | 0.18\n",
      "[epoch: 2, batch:   3704] loss: 0.14718  | 0.18\n",
      "[epoch: 2, batch:   3706] loss: 0.15658  | 0.18\n",
      "[epoch: 2, batch:   3708] loss: 0.42335  | 0.18\n",
      "[epoch: 2, batch:   3710] loss: 0.12454  | 0.18\n",
      "[epoch: 2, batch:   3712] loss: 0.36153  | 0.18\n",
      "[epoch: 2, batch:   3714] loss: 0.33692  | 0.18\n",
      "[epoch: 2, batch:   3716] loss: 0.28382  | 0.18\n",
      "[epoch: 2, batch:   3718] loss: 0.19757  | 0.18\n",
      "[epoch: 2, batch:   3720] loss: 0.63039  | 0.18\n",
      "[epoch: 2, batch:   3722] loss: 0.48164  | 0.19\n",
      "[epoch: 2, batch:   3724] loss: 0.14065  | 0.18\n",
      "[epoch: 2, batch:   3726] loss: 0.25637  | 0.18\n",
      "[epoch: 2, batch:   3728] loss: 0.10631  | 0.18\n",
      "[epoch: 2, batch:   3730] loss: 0.44865  | 0.18\n",
      "[epoch: 2, batch:   3732] loss: 0.34757  | 0.18\n",
      "[epoch: 2, batch:   3734] loss: 0.06245  | 0.18\n",
      "[epoch: 2, batch:   3736] loss: 0.24933  | 0.18\n",
      "[epoch: 2, batch:   3738] loss: 0.66493  | 0.18\n",
      "[epoch: 2, batch:   3740] loss: 0.15245  | 0.18\n",
      "[epoch: 2, batch:   3742] loss: 0.22776  | 0.18\n",
      "[epoch: 2, batch:   3744] loss: 0.14208  | 0.19\n",
      "[epoch: 2, batch:   3746] loss: 0.19805  | 0.18\n",
      "[epoch: 2, batch:   3748] loss: 0.26194  | 0.18\n",
      "[epoch: 2, batch:   3750] loss: 0.19427  | 0.18\n",
      "[epoch: 2, batch:   3752] loss: 0.63307  | 0.18\n",
      "[epoch: 2, batch:   3754] loss: 0.06013  | 0.18\n",
      "[epoch: 2, batch:   3756] loss: 0.21849  | 0.18\n",
      "[epoch: 2, batch:   3758] loss: 1.36119  | 0.19\n",
      "[epoch: 2, batch:   3760] loss: 0.16469  | 0.18\n",
      "[epoch: 2, batch:   3762] loss: 0.08434  | 0.18\n",
      "[epoch: 2, batch:   3764] loss: 0.45205  | 0.18\n",
      "[epoch: 2, batch:   3766] loss: 0.40293  | 0.18\n",
      "[epoch: 2, batch:   3768] loss: 0.35286  | 0.18\n",
      "[epoch: 2, batch:   3770] loss: 0.66952  | 0.18\n",
      "[epoch: 2, batch:   3772] loss: 0.32920  | 0.18\n",
      "[epoch: 2, batch:   3774] loss: 0.15541  | 0.18\n",
      "[epoch: 2, batch:   3776] loss: 0.14760  | 0.18\n",
      "[epoch: 2, batch:   3778] loss: 0.13799  | 0.18\n",
      "[epoch: 2, batch:   3780] loss: 0.38398  | 0.18\n",
      "[epoch: 2, batch:   3782] loss: 0.09355  | 0.18\n",
      "[epoch: 2, batch:   3784] loss: 0.91163  | 0.18\n",
      "[epoch: 2, batch:   3786] loss: 0.18884  | 0.18\n",
      "[epoch: 2, batch:   3788] loss: 0.08545  | 0.18\n",
      "[epoch: 2, batch:   3790] loss: 0.01047  | 0.18\n",
      "[epoch: 2, batch:   3792] loss: 0.24436  | 0.18\n",
      "[epoch: 2, batch:   3794] loss: 0.23499  | 0.18\n",
      "[epoch: 2, batch:   3796] loss: 0.05133  | 0.18\n",
      "[epoch: 2, batch:   3798] loss: 0.11989  | 0.18\n",
      "[epoch: 2, batch:   3800] loss: 0.35223  | 0.18\n",
      "[epoch: 2, batch:   3802] loss: 0.22885  | 0.18\n",
      "[epoch: 2, batch:   3804] loss: 0.07509  | 0.18\n",
      "[epoch: 2, batch:   3806] loss: 0.61899  | 0.18\n",
      "[epoch: 2, batch:   3808] loss: 0.22904  | 0.18\n",
      "[epoch: 2, batch:   3810] loss: 0.15155  | 0.18\n",
      "[epoch: 2, batch:   3812] loss: 0.08332  | 0.18\n",
      "[epoch: 2, batch:   3814] loss: 0.09381  | 0.18\n",
      "[epoch: 2, batch:   3816] loss: 0.36267  | 0.18\n",
      "[epoch: 2, batch:   3818] loss: 0.24636  | 0.18\n",
      "[epoch: 2, batch:   3820] loss: 0.29614  | 0.18\n",
      "[epoch: 2, batch:   3822] loss: 0.37275  | 0.18\n",
      "[epoch: 2, batch:   3824] loss: 0.49573  | 0.18\n",
      "[epoch: 2, batch:   3826] loss: 0.57838  | 0.18\n",
      "[epoch: 2, batch:   3828] loss: 1.18995  | 0.18\n",
      "[epoch: 2, batch:   3830] loss: 0.41979  | 0.18\n",
      "[epoch: 2, batch:   3832] loss: 0.04813  | 0.18\n",
      "[epoch: 2, batch:   3834] loss: 0.14061  | 0.18\n",
      "[epoch: 2, batch:   3836] loss: 0.15509  | 0.18\n",
      "[epoch: 2, batch:   3838] loss: 0.17281  | 0.18\n",
      "[epoch: 2, batch:   3840] loss: 0.07082  | 0.18\n",
      "[epoch: 2, batch:   3842] loss: 0.12302  | 0.18\n",
      "[epoch: 2, batch:   3844] loss: 0.10804  | 0.18\n",
      "[epoch: 2, batch:   3846] loss: 0.12782  | 0.18\n",
      "[epoch: 2, batch:   3848] loss: 0.40010  | 0.18\n",
      "[epoch: 2, batch:   3850] loss: 0.34820  | 0.18\n",
      "[epoch: 2, batch:   3852] loss: 0.11579  | 0.18\n",
      "[epoch: 2, batch:   3854] loss: 0.31152  | 0.18\n",
      "[epoch: 2, batch:   3856] loss: 0.39615  | 0.18\n",
      "[epoch: 2, batch:   3858] loss: 0.24728  | 0.18\n",
      "[epoch: 2, batch:   3860] loss: 0.29463  | 0.18\n",
      "[epoch: 2, batch:   3862] loss: 0.30617  | 0.18\n",
      "[epoch: 2, batch:   3864] loss: 0.10386  | 0.18\n",
      "[epoch: 2, batch:   3866] loss: 0.49670  | 0.18\n",
      "[epoch: 2, batch:   3868] loss: 0.35187  | 0.18\n",
      "[epoch: 2, batch:   3870] loss: 0.46243  | 0.18\n",
      "[epoch: 2, batch:   3872] loss: 0.42310  | 0.18\n",
      "[epoch: 2, batch:   3874] loss: 1.00639  | 0.18\n",
      "[epoch: 2, batch:   3876] loss: 0.07610  | 0.18\n",
      "[epoch: 2, batch:   3878] loss: 0.15163  | 0.18\n",
      "[epoch: 2, batch:   3880] loss: 0.11840  | 0.18\n",
      "[epoch: 2, batch:   3882] loss: 0.39520  | 0.18\n",
      "[epoch: 2, batch:   3884] loss: 0.14640  | 0.18\n",
      "[epoch: 2, batch:   3886] loss: 0.16242  | 0.18\n",
      "[epoch: 2, batch:   3888] loss: 1.44161  | 0.18\n",
      "[epoch: 2, batch:   3890] loss: 0.36239  | 0.18\n",
      "[epoch: 2, batch:   3892] loss: 0.16287  | 0.18\n",
      "[epoch: 2, batch:   3894] loss: 0.10412  | 0.18\n",
      "[epoch: 2, batch:   3896] loss: 0.51241  | 0.18\n",
      "[epoch: 2, batch:   3898] loss: 0.38962  | 0.18\n",
      "[epoch: 2, batch:   3900] loss: 0.05976  | 0.18\n",
      "[epoch: 2, batch:   3902] loss: 0.26805  | 0.18\n",
      "[epoch: 2, batch:   3904] loss: 0.26741  | 0.18\n",
      "[epoch: 2, batch:   3906] loss: 0.11475  | 0.18\n",
      "[epoch: 2, batch:   3908] loss: 0.98324  | 0.18\n",
      "[epoch: 2, batch:   3910] loss: 0.16997  | 0.18\n",
      "[epoch: 2, batch:   3912] loss: 0.13955  | 0.18\n",
      "[epoch: 2, batch:   3914] loss: 0.09260  | 0.18\n",
      "[epoch: 2, batch:   3916] loss: 0.40442  | 0.18\n",
      "[epoch: 2, batch:   3918] loss: 0.28731  | 0.18\n",
      "[epoch: 2, batch:   3920] loss: 0.09662  | 0.18\n",
      "[epoch: 2, batch:   3922] loss: 0.58569  | 0.18\n",
      "[epoch: 2, batch:   3924] loss: 0.97223  | 0.18\n",
      "[epoch: 2, batch:   3926] loss: 0.40955  | 0.18\n",
      "[epoch: 2, batch:   3928] loss: 0.40597  | 0.18\n",
      "[epoch: 2, batch:   3930] loss: 0.36958  | 0.18\n",
      "[epoch: 2, batch:   3932] loss: 0.26837  | 0.18\n",
      "[epoch: 2, batch:   3934] loss: 0.78595  | 0.18\n",
      "[epoch: 2, batch:   3936] loss: 0.11613  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 2, batch:   3938] loss: 0.18249  | 0.18\n",
      "[epoch: 2, batch:   3940] loss: 0.24213  | 0.18\n",
      "[epoch: 2, batch:   3942] loss: 0.10101  | 0.18\n",
      "[epoch: 2, batch:   3944] loss: 0.07420  | 0.18\n",
      "[epoch: 2, batch:   3946] loss: 0.16398  | 0.18\n",
      "[epoch: 2, batch:   3948] loss: 0.30397  | 0.18\n",
      "[epoch: 2, batch:   3950] loss: 0.28185  | 0.18\n",
      "[epoch: 2, batch:   3952] loss: 0.09211  | 0.18\n",
      "[epoch: 2, batch:   3954] loss: 0.29134  | 0.18\n",
      "[epoch: 2, batch:   3956] loss: 0.14308  | 0.18\n",
      "[epoch: 2, batch:   3958] loss: 0.30050  | 0.18\n",
      "[epoch: 2, batch:   3960] loss: 0.64700  | 0.18\n",
      "[epoch: 2, batch:   3962] loss: 0.62899  | 0.19\n",
      "[epoch: 2, batch:   3964] loss: 0.13256  | 0.18\n",
      "[epoch: 2, batch:   3966] loss: 0.10232  | 0.18\n",
      "[epoch: 2, batch:   3968] loss: 0.05874  | 0.18\n",
      "[epoch: 2, batch:   3970] loss: 0.64673  | 0.18\n",
      "[epoch: 2, batch:   3972] loss: 0.82475  | 0.18\n",
      "[epoch: 2, batch:   3974] loss: 0.34241  | 0.18\n",
      "[epoch: 2, batch:   3976] loss: 0.47742  | 0.20\n",
      "[epoch: 2, batch:   3978] loss: 0.41934  | 0.19\n",
      "[epoch: 2, batch:   3980] loss: 0.45959  | 0.18\n",
      "[epoch: 2, batch:   3982] loss: 0.17800  | 0.18\n",
      "[epoch: 2, batch:   3984] loss: 0.21537  | 0.18\n",
      "[epoch: 2, batch:   3986] loss: 0.13581  | 0.18\n",
      "[epoch: 2, batch:   3988] loss: 0.17422  | 0.18\n",
      "[epoch: 2, batch:   3990] loss: 1.36146  | 0.18\n",
      "[epoch: 2, batch:   3992] loss: 0.52977  | 0.18\n",
      "[epoch: 2, batch:   3994] loss: 0.21879  | 0.18\n",
      "[epoch: 2, batch:   3996] loss: 0.09737  | 0.18\n",
      "[epoch: 2, batch:   3998] loss: 1.00518  | 0.18\n",
      "[epoch: 2, batch:   4000] loss: 0.61489  | 0.18\n",
      "[epoch: 2, batch:   4002] loss: 0.11326  | 0.18\n",
      "[epoch: 2, batch:   4004] loss: 0.27949  | 0.18\n",
      "[epoch: 2, batch:   4006] loss: 0.27316  | 0.18\n",
      "[epoch: 2, batch:   4008] loss: 0.27392  | 0.18\n",
      "[epoch: 2, batch:   4010] loss: 0.05375  | 0.19\n",
      "[epoch: 2, batch:   4012] loss: 0.22549  | 0.18\n",
      "[epoch: 2, batch:   4014] loss: 0.74838  | 0.18\n",
      "[epoch: 2, batch:   4016] loss: 0.16992  | 0.18\n",
      "[epoch: 2, batch:   4018] loss: 0.52311  | 0.18\n",
      "[epoch: 2, batch:   4020] loss: 0.16865  | 0.18\n",
      "[epoch: 2, batch:   4022] loss: 0.07904  | 0.19\n",
      "[epoch: 2, batch:   4024] loss: 0.24160  | 0.18\n",
      "[epoch: 2, batch:   4026] loss: 0.58808  | 0.18\n",
      "[epoch: 2, batch:   4028] loss: 0.25420  | 0.18\n",
      "[epoch: 2, batch:   4030] loss: 0.15224  | 0.18\n",
      "[epoch: 2, batch:   4032] loss: 0.13671  | 0.18\n",
      "[epoch: 2, batch:   4034] loss: 0.58022  | 0.18\n",
      "[epoch: 2, batch:   4036] loss: 0.69675  | 0.18\n",
      "[epoch: 2, batch:   4038] loss: 0.44125  | 0.18\n",
      "[epoch: 2, batch:   4040] loss: 0.45366  | 0.18\n",
      "[epoch: 2, batch:   4042] loss: 0.03495  | 0.18\n",
      "[epoch: 2, batch:   4044] loss: 0.39286  | 0.18\n",
      "[epoch: 2, batch:   4046] loss: 2.06608  | 0.18\n",
      "[epoch: 2, batch:   4048] loss: 1.45755  | 0.18\n",
      "[epoch: 2, batch:   4050] loss: 0.27018  | 0.18\n",
      "[epoch: 2, batch:   4052] loss: 0.40427  | 0.18\n",
      "[epoch: 2, batch:   4054] loss: 0.22129  | 0.18\n",
      "[epoch: 2, batch:   4056] loss: 0.11242  | 0.18\n",
      "[epoch: 2, batch:   4058] loss: 1.16456  | 0.18\n",
      "[epoch: 2, batch:   4060] loss: 0.05373  | 0.18\n",
      "[epoch: 2, batch:   4062] loss: 0.07270  | 0.18\n",
      "[epoch: 2, batch:   4064] loss: 0.05237  | 0.18\n",
      "[epoch: 2, batch:   4066] loss: 0.13693  | 0.18\n",
      "[epoch: 2, batch:   4068] loss: 0.41847  | 0.18\n",
      "[epoch: 2, batch:   4070] loss: 0.29132  | 0.18\n",
      "[epoch: 2, batch:   4072] loss: 0.51774  | 0.18\n",
      "[epoch: 2, batch:   4074] loss: 0.15676  | 0.18\n",
      "[epoch: 2, batch:   4076] loss: 0.49723  | 0.18\n",
      "[epoch: 2, batch:   4078] loss: 0.10458  | 0.18\n",
      "[epoch: 2, batch:   4080] loss: 0.49997  | 0.18\n",
      "[epoch: 2, batch:   4082] loss: 0.14616  | 0.18\n",
      "[epoch: 2, batch:   4084] loss: 1.01925  | 0.18\n",
      "[epoch: 2, batch:   4086] loss: 0.23133  | 0.18\n",
      "[epoch: 2, batch:   4088] loss: 0.01552  | 0.18\n",
      "[epoch: 2, batch:   4090] loss: 0.10389  | 0.18\n",
      "[epoch: 2, batch:   4092] loss: 0.04047  | 0.18\n",
      "[epoch: 2, batch:   4094] loss: 0.67104  | 0.18\n",
      "[epoch: 2, batch:   4096] loss: 0.18528  | 0.18\n",
      "[epoch: 2, batch:   4098] loss: 0.45687  | 0.18\n",
      "[epoch: 2, batch:   4100] loss: 0.17055  | 0.18\n",
      "[epoch: 2, batch:   4102] loss: 0.08050  | 0.18\n",
      "[epoch: 2, batch:   4104] loss: 0.38271  | 0.18\n",
      "[epoch: 2, batch:   4106] loss: 0.55682  | 0.18\n",
      "[epoch: 2, batch:   4108] loss: 0.01027  | 0.18\n",
      "[epoch: 2, batch:   4110] loss: 0.45350  | 0.18\n",
      "[epoch: 2, batch:   4112] loss: 0.33656  | 0.18\n",
      "[epoch: 2, batch:   4114] loss: 0.17749  | 0.18\n",
      "[epoch: 2, batch:   4116] loss: 0.06649  | 0.18\n",
      "[epoch: 2, batch:   4118] loss: 0.82589  | 0.18\n",
      "[epoch: 2, batch:   4120] loss: 1.98262  | 0.18\n",
      "[epoch: 2, batch:   4122] loss: 0.73493  | 0.18\n",
      "[epoch: 2, batch:   4124] loss: 0.39970  | 0.18\n",
      "[epoch: 2, batch:   4126] loss: 0.13754  | 0.18\n",
      "[epoch: 2, batch:   4128] loss: 0.21939  | 0.18\n",
      "[epoch: 2, batch:   4130] loss: 0.23527  | 0.18\n",
      "[epoch: 2, batch:   4132] loss: 0.26214  | 0.18\n",
      "[epoch: 2, batch:   4134] loss: 0.18316  | 0.18\n",
      "[epoch: 2, batch:   4136] loss: 0.18521  | 0.18\n",
      "[epoch: 2, batch:   4138] loss: 0.10980  | 0.18\n",
      "[epoch: 2, batch:   4140] loss: 0.39111  | 0.18\n",
      "[epoch: 2, batch:   4142] loss: 0.66739  | 0.18\n",
      "[epoch: 2, batch:   4144] loss: 0.25995  | 0.18\n",
      "[epoch: 2, batch:   4146] loss: 0.70016  | 0.18\n",
      "[epoch: 2, batch:   4148] loss: 0.10458  | 0.18\n",
      "[epoch: 2, batch:   4150] loss: 0.18006  | 0.18\n",
      "[epoch: 2, batch:   4152] loss: 0.15930  | 0.18\n",
      "[epoch: 2, batch:   4154] loss: 0.43155  | 0.19\n",
      "[epoch: 2, batch:   4156] loss: 0.13689  | 0.18\n",
      "[epoch: 2, batch:   4158] loss: 0.49066  | 0.18\n",
      "[epoch: 2, batch:   4160] loss: 0.73312  | 0.18\n",
      "[epoch: 2, batch:   4162] loss: 0.09457  | 0.18\n",
      "[epoch: 2, batch:   4164] loss: 0.15914  | 0.18\n",
      "[epoch: 2, batch:   4166] loss: 0.09045  | 0.18\n",
      "[epoch: 2, batch:   4168] loss: 0.13064  | 0.18\n",
      "[epoch: 2, batch:   4170] loss: 0.71161  | 0.18\n",
      "[epoch: 2, batch:   4172] loss: 0.04291  | 0.18\n",
      "[epoch: 2, batch:   4174] loss: 0.39658  | 0.18\n",
      "[epoch: 2, batch:   4176] loss: 0.25593  | 0.18\n",
      "[epoch: 2, batch:   4178] loss: 0.06016  | 0.18\n",
      "[epoch: 2, batch:   4180] loss: 0.39191  | 0.18\n",
      "[epoch: 2, batch:   4182] loss: 0.32723  | 0.18\n",
      "[epoch: 2, batch:   4184] loss: 0.27576  | 0.18\n",
      "[epoch: 2, batch:   4186] loss: 0.14357  | 0.18\n",
      "[epoch: 2, batch:   4188] loss: 0.48815  | 0.18\n",
      "[epoch: 2, batch:   4190] loss: 0.86323  | 0.18\n",
      "[epoch: 2, batch:   4192] loss: 0.15397  | 0.18\n",
      "[epoch: 2, batch:   4194] loss: 0.24947  | 0.18\n",
      "[epoch: 2, batch:   4196] loss: 0.19302  | 0.18\n",
      "[epoch: 2, batch:   4198] loss: 0.32303  | 0.18\n",
      "[epoch: 2, batch:   4200] loss: 0.70515  | 0.18\n",
      "[epoch: 2, batch:   4202] loss: 0.46269  | 0.18\n",
      "[epoch: 2, batch:   4204] loss: 0.93192  | 0.18\n",
      "[epoch: 2, batch:   4206] loss: 0.10308  | 0.18\n",
      "[epoch: 2, batch:   4208] loss: 0.76342  | 0.18\n",
      "[epoch: 2, batch:   4210] loss: 0.05175  | 0.18\n",
      "[epoch: 2, batch:   4212] loss: 1.54989  | 0.18\n",
      "[epoch: 2, batch:   4214] loss: 0.23091  | 0.18\n",
      "[epoch: 2, batch:   4216] loss: 0.32910  | 0.18\n",
      "[epoch: 2, batch:   4218] loss: 0.54925  | 0.18\n",
      "[epoch: 2, batch:   4220] loss: 0.78813  | 0.18\n",
      "[epoch: 2, batch:   4222] loss: 0.17138  | 0.18\n",
      "[epoch: 2, batch:   4224] loss: 0.19790  | 0.18\n",
      "[epoch: 2, batch:   4226] loss: 0.09583  | 0.18\n",
      "[epoch: 2, batch:   4228] loss: 0.12320  | 0.18\n",
      "[epoch: 2, batch:   4230] loss: 0.06859  | 0.18\n",
      "[epoch: 2, batch:   4232] loss: 0.28334  | 0.18\n",
      "[epoch: 2, batch:   4234] loss: 0.09948  | 0.18\n",
      "[epoch: 2, batch:   4236] loss: 0.15014  | 0.18\n",
      "[epoch: 2, batch:   4238] loss: 0.25441  | 0.18\n",
      "[epoch: 2, batch:   4240] loss: 0.16749  | 0.18\n",
      "[epoch: 2, batch:   4242] loss: 0.72239  | 0.18\n",
      "[epoch: 2, batch:   4244] loss: 0.47831  | 0.18\n",
      "[epoch: 2, batch:   4246] loss: 0.92395  | 0.18\n",
      "[epoch: 2, batch:   4248] loss: 0.75512  | 0.18\n",
      "[epoch: 2, batch:   4250] loss: 0.19365  | 0.18\n",
      "[epoch: 2, batch:   4252] loss: 0.51771  | 0.18\n",
      "[epoch: 2, batch:   4254] loss: 0.28273  | 0.18\n",
      "[epoch: 2, batch:   4256] loss: 0.28081  | 0.18\n",
      "[epoch: 2, batch:   4258] loss: 0.21765  | 0.18\n",
      "[epoch: 2, batch:   4260] loss: 0.50371  | 0.18\n",
      "[epoch: 2, batch:   4262] loss: 0.12606  | 0.18\n",
      "[epoch: 2, batch:   4264] loss: 0.75986  | 0.18\n",
      "[epoch: 2, batch:   4266] loss: 0.22131  | 0.18\n",
      "[epoch: 2, batch:   4268] loss: 0.28428  | 0.18\n",
      "[epoch: 2, batch:   4270] loss: 0.13815  | 0.18\n",
      "[epoch: 2, batch:   4272] loss: 0.21671  | 0.18\n",
      "[epoch: 2, batch:   4274] loss: 0.07944  | 0.18\n",
      "[epoch: 2, batch:   4276] loss: 0.08064  | 0.18\n",
      "[epoch: 2, batch:   4278] loss: 0.23607  | 0.18\n",
      "[epoch: 2, batch:   4280] loss: 0.15121  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 2, batch:   4282] loss: 0.17947  | 0.18\n",
      "[epoch: 2, batch:   4284] loss: 0.43964  | 0.18\n",
      "[epoch: 2, batch:   4286] loss: 0.35564  | 0.18\n",
      "[epoch: 2, batch:   4288] loss: 0.26885  | 0.18\n",
      "[epoch: 2, batch:   4290] loss: 0.25445  | 0.18\n",
      "[epoch: 2, batch:   4292] loss: 0.14686  | 0.18\n",
      "[epoch: 2, batch:   4294] loss: 0.24381  | 0.18\n",
      "[epoch: 2, batch:   4296] loss: 0.31074  | 0.18\n",
      "[epoch: 2, batch:   4298] loss: 0.43860  | 0.18\n",
      "[epoch: 2, batch:   4300] loss: 0.00794  | 0.18\n",
      "[epoch: 2, batch:   4302] loss: 0.08456  | 0.18\n",
      "[epoch: 2, batch:   4304] loss: 0.09989  | 0.18\n",
      "[epoch: 2, batch:   4306] loss: 0.41686  | 0.18\n",
      "[epoch: 2, batch:   4308] loss: 0.27810  | 0.18\n",
      "[epoch: 2, batch:   4310] loss: 0.53234  | 0.18\n",
      "[epoch: 2, batch:   4312] loss: 0.23351  | 0.18\n",
      "[epoch: 2, batch:   4314] loss: 0.21227  | 0.18\n",
      "[epoch: 2, batch:   4316] loss: 0.25313  | 0.18\n",
      "[epoch: 2, batch:   4318] loss: 0.73676  | 0.18\n",
      "[epoch: 2, batch:   4320] loss: 0.03999  | 0.18\n",
      "[epoch: 2, batch:   4322] loss: 1.13534  | 0.18\n",
      "[epoch: 2, batch:   4324] loss: 0.39351  | 0.18\n",
      "[epoch: 2, batch:   4326] loss: 0.66616  | 0.18\n",
      "[epoch: 2, batch:   4328] loss: 0.24422  | 0.18\n",
      "[epoch: 2, batch:   4330] loss: 0.27099  | 0.18\n",
      "[epoch: 2, batch:   4332] loss: 0.05157  | 0.18\n",
      "[epoch: 2, batch:   4334] loss: 0.21715  | 0.18\n",
      "[epoch: 2, batch:   4336] loss: 0.28226  | 0.18\n",
      "[epoch: 2, batch:   4338] loss: 0.05940  | 0.18\n",
      "[epoch: 2, batch:   4340] loss: 0.19837  | 0.18\n",
      "[epoch: 2, batch:   4342] loss: 0.78234  | 0.18\n",
      "[epoch: 2, batch:   4344] loss: 0.15515  | 0.18\n",
      "[epoch: 2, batch:   4346] loss: 1.18049  | 0.18\n",
      "[epoch: 2, batch:   4348] loss: 0.25230  | 0.18\n",
      "[epoch: 2, batch:   4350] loss: 0.36525  | 0.18\n",
      "[epoch: 2, batch:   4352] loss: 0.28166  | 0.18\n",
      "[epoch: 2, batch:   4354] loss: 0.16364  | 0.18\n",
      "[epoch: 2, batch:   4356] loss: 1.07662  | 0.18\n",
      "[epoch: 2, batch:   4358] loss: 0.42297  | 0.18\n",
      "[epoch: 2, batch:   4360] loss: 0.65923  | 0.18\n",
      "[epoch: 2, batch:   4362] loss: 0.91372  | 0.18\n",
      "[epoch: 2, batch:   4364] loss: 1.51347  | 0.18\n",
      "[epoch: 2, batch:   4366] loss: 0.40673  | 0.18\n",
      "[epoch: 2, batch:   4368] loss: 0.16159  | 0.18\n",
      "[epoch: 2, batch:   4370] loss: 0.04209  | 0.18\n",
      "[epoch: 2, batch:   4372] loss: 0.12985  | 0.18\n",
      "[epoch: 2, batch:   4374] loss: 0.12989  | 0.18\n",
      "[epoch: 2, batch:   4376] loss: 0.19196  | 0.18\n",
      "[epoch: 2, batch:   4378] loss: 0.19262  | 0.18\n",
      "[epoch: 2, batch:   4380] loss: 0.31667  | 0.18\n",
      "[epoch: 2, batch:   4382] loss: 0.10710  | 0.18\n",
      "[epoch: 2, batch:   4384] loss: 0.14449  | 0.18\n",
      "[epoch: 2, batch:   4386] loss: 0.44249  | 0.18\n",
      "[epoch: 2, batch:   4388] loss: 0.15585  | 0.18\n",
      "[epoch: 2, batch:   4390] loss: 0.67679  | 0.18\n",
      "[epoch: 2, batch:   4392] loss: 0.26527  | 0.18\n",
      "[epoch: 2, batch:   4394] loss: 0.07017  | 0.18\n",
      "[epoch: 2, batch:   4396] loss: 0.08895  | 0.18\n",
      "[epoch: 2, batch:   4398] loss: 0.45712  | 0.18\n",
      "[epoch: 2, batch:   4400] loss: 0.22288  | 0.18\n",
      "[epoch: 2, batch:   4402] loss: 0.70927  | 0.18\n",
      "[epoch: 2, batch:   4404] loss: 0.25750  | 0.18\n",
      "[epoch: 2, batch:   4406] loss: 0.74762  | 0.18\n",
      "[epoch: 2, batch:   4408] loss: 0.06008  | 0.18\n",
      "[epoch: 2, batch:   4410] loss: 0.17215  | 0.18\n",
      "[epoch: 2, batch:   4412] loss: 0.30641  | 0.18\n",
      "[epoch: 2, batch:   4414] loss: 0.26674  | 0.18\n",
      "[epoch: 2, batch:   4416] loss: 0.09190  | 0.18\n",
      "[epoch: 2, batch:   4418] loss: 0.12506  | 0.18\n",
      "[epoch: 2, batch:   4420] loss: 0.05078  | 0.18\n",
      "[epoch: 2, batch:   4422] loss: 0.22024  | 0.18\n",
      "[epoch: 2, batch:   4424] loss: 0.18764  | 0.18\n",
      "[epoch: 2, batch:   4426] loss: 0.70693  | 0.18\n",
      "[epoch: 2, batch:   4428] loss: 0.25590  | 0.18\n",
      "[epoch: 2, batch:   4430] loss: 0.35746  | 0.18\n",
      "[epoch: 2, batch:   4432] loss: 0.31787  | 0.18\n",
      "[epoch: 2, batch:   4434] loss: 0.55391  | 0.18\n",
      "[epoch: 2, batch:   4436] loss: 0.34519  | 0.18\n",
      "[epoch: 2, batch:   4438] loss: 0.48790  | 0.19\n",
      "[epoch: 2, batch:   4440] loss: 0.12575  | 0.18\n",
      "[epoch: 2, batch:   4442] loss: 0.22225  | 0.18\n",
      "[epoch: 2, batch:   4444] loss: 0.17660  | 0.18\n",
      "[epoch: 2, batch:   4446] loss: 0.41406  | 0.18\n",
      "[epoch: 2, batch:   4448] loss: 0.36586  | 0.18\n",
      "[epoch: 2, batch:   4450] loss: 0.03658  | 0.18\n",
      "[epoch: 2, batch:   4452] loss: 0.62423  | 0.18\n",
      "[epoch: 2, batch:   4454] loss: 0.31223  | 0.18\n",
      "[epoch: 2, batch:   4456] loss: 0.01228  | 0.18\n",
      "[epoch: 2, batch:   4458] loss: 0.04487  | 0.18\n",
      "[epoch: 2, batch:   4460] loss: 0.51839  | 0.18\n",
      "[epoch: 2, batch:   4462] loss: 0.33699  | 0.18\n",
      "[epoch: 2, batch:   4464] loss: 0.39704  | 0.18\n",
      "[epoch: 2, batch:   4466] loss: 0.06994  | 0.18\n",
      "[epoch: 2, batch:   4468] loss: 0.14188  | 0.18\n",
      "[epoch: 2, batch:   4470] loss: 0.24322  | 0.18\n",
      "[epoch: 2, batch:   4472] loss: 0.04889  | 0.18\n",
      "[epoch: 2, batch:   4474] loss: 0.04040  | 0.18\n",
      "[epoch: 2, batch:   4476] loss: 0.07988  | 0.18\n",
      "[epoch: 2, batch:   4478] loss: 0.15399  | 0.18\n",
      "[epoch: 2, batch:   4480] loss: 0.11512  | 0.18\n",
      "[epoch: 2, batch:   4482] loss: 0.69563  | 0.18\n",
      "[epoch: 2, batch:   4484] loss: 0.32018  | 0.18\n",
      "[epoch: 2, batch:   4486] loss: 0.07357  | 0.18\n",
      "[epoch: 2, batch:   4488] loss: 0.24045  | 0.18\n",
      "[epoch: 2, batch:   4490] loss: 0.63029  | 0.18\n",
      "[epoch: 2, batch:   4492] loss: 0.19705  | 0.18\n",
      "[epoch: 2, batch:   4494] loss: 0.16439  | 0.18\n",
      "[epoch: 2, batch:   4496] loss: 0.49374  | 0.18\n",
      "[epoch: 2, batch:   4498] loss: 0.09200  | 0.18\n",
      "[epoch: 2, batch:   4500] loss: 0.15862  | 0.18\n",
      "[epoch: 2, batch:   4502] loss: 0.17373  | 0.18\n",
      "[epoch: 2, batch:   4504] loss: 0.53985  | 0.18\n",
      "[epoch: 2, batch:   4506] loss: 0.23068  | 0.18\n",
      "[epoch: 2, batch:   4508] loss: 0.25605  | 0.18\n",
      "[epoch: 2, batch:   4510] loss: 0.40387  | 0.18\n",
      "[epoch: 2, batch:   4512] loss: 0.16237  | 0.18\n",
      "[epoch: 2, batch:   4514] loss: 0.11453  | 0.18\n",
      "[epoch: 2, batch:   4516] loss: 0.68883  | 0.18\n",
      "[epoch: 2, batch:   4518] loss: 0.34201  | 0.18\n",
      "[epoch: 2, batch:   4520] loss: 0.34504  | 0.18\n",
      "[epoch: 2, batch:   4522] loss: 0.18810  | 0.18\n",
      "[epoch: 2, batch:   4524] loss: 0.34598  | 0.18\n",
      "[epoch: 2, batch:   4526] loss: 0.21137  | 0.18\n",
      "[epoch: 2, batch:   4528] loss: 0.34351  | 0.18\n",
      "[epoch: 2, batch:   4530] loss: 0.14830  | 0.18\n",
      "[epoch: 2, batch:   4532] loss: 0.21754  | 0.18\n",
      "[epoch: 2, batch:   4534] loss: 0.14533  | 0.18\n",
      "[epoch: 2, batch:   4536] loss: 0.08335  | 0.18\n",
      "[epoch: 2, batch:   4538] loss: 0.13733  | 0.18\n",
      "[epoch: 2, batch:   4540] loss: 0.06655  | 0.18\n",
      "[epoch: 2, batch:   4542] loss: 0.75719  | 0.18\n",
      "[epoch: 2, batch:   4544] loss: 0.31998  | 0.18\n",
      "[epoch: 2, batch:   4546] loss: 0.01273  | 0.18\n",
      "[epoch: 2, batch:   4548] loss: 0.08777  | 0.18\n",
      "[epoch: 2, batch:   4550] loss: 0.04681  | 0.18\n",
      "[epoch: 2, batch:   4552] loss: 0.11782  | 0.18\n",
      "[epoch: 2, batch:   4554] loss: 0.29610  | 0.18\n",
      "[epoch: 2, batch:   4556] loss: 0.62787  | 0.18\n",
      "[epoch: 2, batch:   4558] loss: 0.05172  | 0.18\n",
      "[epoch: 2, batch:   4560] loss: 0.32362  | 0.18\n",
      "[epoch: 2, batch:   4562] loss: 0.41944  | 0.18\n",
      "[epoch: 2, batch:   4564] loss: 0.32175  | 0.18\n",
      "[epoch: 2, batch:   4566] loss: 0.78366  | 0.18\n",
      "[epoch: 2, batch:   4568] loss: 0.11907  | 0.18\n",
      "[epoch: 2, batch:   4570] loss: 0.15118  | 0.18\n",
      "[epoch: 2, batch:   4572] loss: 0.22468  | 0.18\n",
      "[epoch: 2, batch:   4574] loss: 0.13323  | 0.18\n",
      "[epoch: 2, batch:   4576] loss: 0.12674  | 0.18\n",
      "[epoch: 2, batch:   4578] loss: 0.14119  | 0.18\n",
      "[epoch: 2, batch:   4580] loss: 0.46842  | 0.18\n",
      "[epoch: 2, batch:   4582] loss: 0.37696  | 0.18\n",
      "[epoch: 2, batch:   4584] loss: 0.09704  | 0.18\n",
      "[epoch: 2, batch:   4586] loss: 0.66698  | 0.18\n",
      "[epoch: 2, batch:   4588] loss: 0.11100  | 0.18\n",
      "[epoch: 2, batch:   4590] loss: 0.08672  | 0.18\n",
      "[epoch: 2, batch:   4592] loss: 0.19984  | 0.18\n",
      "[epoch: 2, batch:   4594] loss: 0.15983  | 0.18\n",
      "[epoch: 2, batch:   4596] loss: 0.59756  | 0.18\n",
      "[epoch: 2, batch:   4598] loss: 0.26951  | 0.18\n",
      "[epoch: 2, batch:   4600] loss: 0.04976  | 0.18\n",
      "[epoch: 2, batch:   4602] loss: 0.43484  | 0.18\n",
      "[epoch: 2, batch:   4604] loss: 0.17679  | 0.18\n",
      "[epoch: 2, batch:   4606] loss: 0.10402  | 0.18\n",
      "[epoch: 2, batch:   4608] loss: 0.10499  | 0.18\n",
      "[epoch: 2, batch:   4610] loss: 0.37110  | 0.18\n",
      "[epoch: 2, batch:   4612] loss: 0.06329  | 0.18\n",
      "[epoch: 2, batch:   4614] loss: 0.19365  | 0.18\n",
      "[epoch: 2, batch:   4616] loss: 0.25873  | 0.18\n",
      "[epoch: 2, batch:   4618] loss: 0.04719  | 0.18\n",
      "[epoch: 2, batch:   4620] loss: 0.29686  | 0.18\n",
      "[epoch: 2, batch:   4622] loss: 0.23507  | 0.18\n",
      "[epoch: 2, batch:   4624] loss: 0.13804  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 2, batch:   4626] loss: 0.41334  | 0.18\n",
      "[epoch: 2, batch:   4628] loss: 0.16701  | 0.18\n",
      "[epoch: 2, batch:   4630] loss: 0.46868  | 0.18\n",
      "[epoch: 2, batch:   4632] loss: 0.22136  | 0.18\n",
      "[epoch: 2, batch:   4634] loss: 0.07282  | 0.18\n",
      "[epoch: 2, batch:   4636] loss: 0.09287  | 0.18\n",
      "[epoch: 2, batch:   4638] loss: 0.15892  | 0.18\n",
      "[epoch: 2, batch:   4640] loss: 0.20399  | 0.18\n",
      "[epoch: 2, batch:   4642] loss: 0.48202  | 0.18\n",
      "[epoch: 2, batch:   4644] loss: 0.28083  | 0.18\n",
      "[epoch: 2, batch:   4646] loss: 0.48699  | 0.18\n",
      "[epoch: 2, batch:   4648] loss: 0.11608  | 0.18\n",
      "[epoch: 2, batch:   4650] loss: 0.63480  | 0.18\n",
      "[epoch: 2, batch:   4652] loss: 0.45670  | 0.18\n",
      "[epoch: 2, batch:   4654] loss: 0.42547  | 0.18\n",
      "[epoch: 2, batch:   4656] loss: 0.05903  | 0.18\n",
      "[epoch: 2, batch:   4658] loss: 0.09452  | 0.18\n",
      "[epoch: 2, batch:   4660] loss: 0.42763  | 0.18\n",
      "[epoch: 2, batch:   4662] loss: 0.15578  | 0.18\n",
      "[epoch: 2, batch:   4664] loss: 0.01161  | 0.18\n",
      "[epoch: 2, batch:   4666] loss: 0.81307  | 0.18\n",
      "[epoch: 2, batch:   4668] loss: 0.12477  | 0.18\n",
      "[epoch: 2, batch:   4670] loss: 0.19590  | 0.18\n",
      "[epoch: 2, batch:   4672] loss: 0.13511  | 0.18\n",
      "[epoch: 2, batch:   4674] loss: 0.26204  | 0.18\n",
      "[epoch: 2, batch:   4676] loss: 0.51725  | 0.18\n",
      "[epoch: 2, batch:   4678] loss: 0.58149  | 0.18\n",
      "[epoch: 2, batch:   4680] loss: 0.16678  | 0.18\n",
      "[epoch: 2, batch:   4682] loss: 0.60810  | 0.18\n",
      "[epoch: 2, batch:   4684] loss: 1.29823  | 0.18\n",
      "[epoch: 2, batch:   4686] loss: 0.45508  | 0.18\n",
      "[epoch: 2, batch:   4688] loss: 0.18321  | 0.18\n",
      "[epoch: 2, batch:   4690] loss: 0.20388  | 0.18\n",
      "[epoch: 2, batch:   4692] loss: 0.21069  | 0.18\n",
      "[epoch: 2, batch:   4694] loss: 0.16358  | 0.18\n",
      "[epoch: 2, batch:   4696] loss: 0.10212  | 0.18\n",
      "[epoch: 2, batch:   4698] loss: 0.18021  | 0.18\n",
      "[epoch: 2, batch:   4700] loss: 0.31588  | 0.18\n",
      "[epoch: 2, batch:   4702] loss: 0.43169  | 0.18\n",
      "[epoch: 2, batch:   4704] loss: 0.09999  | 0.18\n",
      "[epoch: 2, batch:   4706] loss: 0.55828  | 0.18\n",
      "[epoch: 2, batch:   4708] loss: 0.07015  | 0.18\n",
      "[epoch: 2, batch:   4710] loss: 0.63104  | 0.18\n",
      "[epoch: 2, batch:   4712] loss: 0.11377  | 0.18\n",
      "[epoch: 2, batch:   4714] loss: 0.15887  | 0.18\n",
      "[epoch: 2, batch:   4716] loss: 0.04467  | 0.18\n",
      "[epoch: 2, batch:   4718] loss: 0.10277  | 0.18\n",
      "[epoch: 2, batch:   4720] loss: 0.07945  | 0.18\n",
      "[epoch: 2, batch:   4722] loss: 0.11713  | 0.18\n",
      "[epoch: 2, batch:   4724] loss: 0.37881  | 0.18\n",
      "[epoch: 2, batch:   4726] loss: 0.05286  | 0.18\n",
      "[epoch: 2, batch:   4728] loss: 0.03420  | 0.18\n",
      "[epoch: 2, batch:   4730] loss: 0.11345  | 0.18\n",
      "[epoch: 2, batch:   4732] loss: 0.17590  | 0.18\n",
      "[epoch: 2, batch:   4734] loss: 0.70126  | 0.18\n",
      "[epoch: 2, batch:   4736] loss: 1.89331  | 0.18\n",
      "[epoch: 2, batch:   4738] loss: 0.16902  | 0.18\n",
      "[epoch: 2, batch:   4740] loss: 0.05406  | 0.18\n",
      "[epoch: 2, batch:   4742] loss: 0.25545  | 0.18\n",
      "[epoch: 2, batch:   4744] loss: 0.09036  | 0.18\n",
      "[epoch: 2, batch:   4746] loss: 0.75509  | 0.18\n",
      "[epoch: 2, batch:   4748] loss: 0.53614  | 0.18\n",
      "[epoch: 2, batch:   4750] loss: 0.32657  | 0.18\n",
      "[epoch: 2, batch:   4752] loss: 0.66010  | 0.18\n",
      "[epoch: 2, batch:   4754] loss: 0.12126  | 0.18\n",
      "[epoch: 2, batch:   4756] loss: 0.32211  | 0.18\n",
      "[epoch: 2, batch:   4758] loss: 0.62578  | 0.18\n",
      "[epoch: 2, batch:   4760] loss: 0.21596  | 0.18\n",
      "[epoch: 2, batch:   4762] loss: 0.17654  | 0.18\n",
      "[epoch: 2, batch:   4764] loss: 0.26824  | 0.18\n",
      "[epoch: 2, batch:   4766] loss: 0.19696  | 0.18\n",
      "[epoch: 2, batch:   4768] loss: 0.11000  | 0.18\n",
      "[epoch: 2, batch:   4770] loss: 0.24050  | 0.18\n",
      "[epoch: 2, batch:   4772] loss: 0.29198  | 0.18\n",
      "[epoch: 2, batch:   4774] loss: 0.14730  | 0.18\n",
      "[epoch: 2, batch:   4776] loss: 0.20569  | 0.18\n",
      "[epoch: 2, batch:   4778] loss: 0.08075  | 0.18\n",
      "[epoch: 2, batch:   4780] loss: 0.06012  | 0.18\n",
      "[epoch: 2, batch:   4782] loss: 0.05016  | 0.18\n",
      "[epoch: 2, batch:   4784] loss: 0.56312  | 0.18\n",
      "[epoch: 2, batch:   4786] loss: 0.22894  | 0.18\n",
      "[epoch: 2, batch:   4788] loss: 0.16574  | 0.18\n",
      "[epoch: 2, batch:   4790] loss: 1.31096  | 0.18\n",
      "[epoch: 2, batch:   4792] loss: 0.51077  | 0.18\n",
      "[epoch: 2, batch:   4794] loss: 0.38536  | 0.18\n",
      "[epoch: 2, batch:   4796] loss: 0.03053  | 0.18\n",
      "[epoch: 2, batch:   4798] loss: 0.93875  | 0.18\n",
      "[epoch: 2, batch:   4800] loss: 0.72090  | 0.18\n",
      "[epoch: 2, batch:   4802] loss: 0.27182  | 0.18\n",
      "[epoch: 2, batch:   4804] loss: 0.61437  | 0.18\n",
      "[epoch: 2, batch:   4806] loss: 0.10790  | 0.18\n",
      "[epoch: 2, batch:   4808] loss: 0.19807  | 0.18\n",
      "[epoch: 2, batch:   4810] loss: 0.05847  | 0.18\n",
      "[epoch: 2, batch:   4812] loss: 0.86065  | 0.18\n",
      "[epoch: 2, batch:   4814] loss: 0.43508  | 0.18\n",
      "[epoch: 2, batch:   4816] loss: 0.04549  | 0.18\n",
      "[epoch: 2, batch:   4818] loss: 0.22692  | 0.18\n",
      "[epoch: 2, batch:   4820] loss: 0.42884  | 0.18\n",
      "[epoch: 2, batch:   4822] loss: 0.09031  | 0.18\n",
      "[epoch: 2, batch:   4824] loss: 0.17828  | 0.18\n",
      "[epoch: 2, batch:   4826] loss: 0.35104  | 0.18\n",
      "[epoch: 2, batch:   4828] loss: 0.25718  | 0.18\n",
      "[epoch: 2, batch:   4830] loss: 0.42717  | 0.18\n",
      "[epoch: 2, batch:   4832] loss: 0.14131  | 0.18\n",
      "[epoch: 2, batch:   4834] loss: 0.06526  | 0.18\n",
      "[epoch: 2, batch:   4836] loss: 0.15306  | 0.18\n",
      "[epoch: 2, batch:   4838] loss: 0.31088  | 0.18\n",
      "[epoch: 2, batch:   4840] loss: 0.58554  | 0.18\n",
      "[epoch: 2, batch:   4842] loss: 0.01885  | 0.18\n",
      "[epoch: 2, batch:   4844] loss: 0.36922  | 0.18\n",
      "[epoch: 2, batch:   4846] loss: 0.77489  | 0.18\n",
      "[epoch: 2, batch:   4848] loss: 0.28273  | 0.18\n",
      "[epoch: 2, batch:   4850] loss: 0.39207  | 0.18\n",
      "[epoch: 2, batch:   4852] loss: 0.18032  | 0.18\n",
      "[epoch: 2, batch:   4854] loss: 0.19866  | 0.18\n",
      "[epoch: 2, batch:   4856] loss: 0.14155  | 0.18\n",
      "[epoch: 2, batch:   4858] loss: 0.57270  | 0.18\n",
      "[epoch: 2, batch:   4860] loss: 0.37033  | 0.18\n",
      "[epoch: 2, batch:   4862] loss: 0.22654  | 0.18\n",
      "[epoch: 2, batch:   4864] loss: 0.05159  | 0.18\n",
      "[epoch: 2, batch:   4866] loss: 0.14721  | 0.18\n",
      "[epoch: 2, batch:   4868] loss: 0.06671  | 0.18\n",
      "[epoch: 2, batch:   4870] loss: 0.64662  | 0.18\n",
      "[epoch: 2, batch:   4872] loss: 0.58939  | 0.18\n",
      "[epoch: 2, batch:   4874] loss: 0.33367  | 0.18\n",
      "[epoch: 2, batch:   4876] loss: 0.24026  | 0.18\n",
      "[epoch: 2, batch:   4878] loss: 0.20733  | 0.18\n",
      "[epoch: 2, batch:   4880] loss: 0.50382  | 0.18\n",
      "[epoch: 2, batch:   4882] loss: 0.23568  | 0.18\n",
      "[epoch: 2, batch:   4884] loss: 0.35433  | 0.18\n",
      "[epoch: 2, batch:   4886] loss: 0.30087  | 0.18\n",
      "[epoch: 2, batch:   4888] loss: 0.28334  | 0.18\n",
      "[epoch: 2, batch:   4890] loss: 0.22847  | 0.18\n",
      "[epoch: 2, batch:   4892] loss: 0.14696  | 0.18\n",
      "[epoch: 2, batch:   4894] loss: 0.04983  | 0.18\n",
      "[epoch: 2, batch:   4896] loss: 0.13676  | 0.18\n",
      "[epoch: 2, batch:   4898] loss: 0.11224  | 0.18\n",
      "[epoch: 2, batch:   4900] loss: 0.11171  | 0.18\n",
      "[epoch: 2, batch:   4902] loss: 0.66991  | 0.18\n",
      "[epoch: 2, batch:   4904] loss: 0.60821  | 0.18\n",
      "[epoch: 2, batch:   4906] loss: 0.02198  | 0.18\n",
      "[epoch: 2, batch:   4908] loss: 0.11140  | 0.18\n",
      "[epoch: 2, batch:   4910] loss: 0.84599  | 0.18\n",
      "[epoch: 2, batch:   4912] loss: 0.43353  | 0.18\n",
      "[epoch: 2, batch:   4914] loss: 0.29380  | 0.18\n",
      "[epoch: 2, batch:   4916] loss: 0.13486  | 0.18\n",
      "[epoch: 2, batch:   4918] loss: 0.65456  | 0.18\n",
      "[epoch: 2, batch:   4920] loss: 0.04038  | 0.18\n",
      "[epoch: 2, batch:   4922] loss: 0.31110  | 0.18\n",
      "[epoch: 2, batch:   4924] loss: 0.04309  | 0.18\n",
      "[epoch: 2, batch:   4926] loss: 1.23566  | 0.18\n",
      "[epoch: 2, batch:   4928] loss: 0.19565  | 0.18\n",
      "[epoch: 2, batch:   4930] loss: 0.20794  | 0.18\n",
      "[epoch: 2, batch:   4932] loss: 0.57218  | 0.18\n",
      "[epoch: 2, batch:   4934] loss: 0.12668  | 0.18\n",
      "[epoch: 2, batch:   4936] loss: 0.05454  | 0.18\n",
      "[epoch: 2, batch:   4938] loss: 0.37588  | 0.18\n",
      "[epoch: 2, batch:   4940] loss: 1.98843  | 0.18\n",
      "[epoch: 2, batch:   4942] loss: 0.16546  | 0.18\n",
      "[epoch: 2, batch:   4944] loss: 0.53197  | 0.18\n",
      "[epoch: 2, batch:   4946] loss: 0.93409  | 0.18\n",
      "[epoch: 2, batch:   4948] loss: 0.03776  | 0.18\n",
      "[epoch: 2, batch:   4950] loss: 0.12588  | 0.18\n",
      "[epoch: 2, batch:   4952] loss: 0.44428  | 0.18\n",
      "[epoch: 2, batch:   4954] loss: 0.12296  | 0.18\n",
      "[epoch: 2, batch:   4956] loss: 0.30205  | 0.18\n",
      "[epoch: 2, batch:   4958] loss: 0.47785  | 0.18\n",
      "[epoch: 2, batch:   4960] loss: 0.09696  | 0.18\n",
      "[epoch: 2, batch:   4962] loss: 0.19350  | 0.18\n",
      "[epoch: 2, batch:   4964] loss: 0.34052  | 0.18\n",
      "[epoch: 2, batch:   4966] loss: 0.45278  | 0.18\n",
      "[epoch: 2, batch:   4968] loss: 0.20679  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 2, batch:   4970] loss: 0.36272  | 0.18\n",
      "[epoch: 2, batch:   4972] loss: 0.56649  | 0.18\n",
      "[epoch: 2, batch:   4974] loss: 0.43047  | 0.18\n",
      "[epoch: 2, batch:   4976] loss: 0.36997  | 0.18\n",
      "[epoch: 2, batch:   4978] loss: 0.20052  | 0.18\n",
      "[epoch: 2, batch:   4980] loss: 0.52241  | 0.18\n",
      "[epoch: 2, batch:   4982] loss: 0.14391  | 0.18\n",
      "[epoch: 2, batch:   4984] loss: 0.67039  | 0.18\n",
      "[epoch: 2, batch:   4986] loss: 0.64725  | 0.18\n",
      "[epoch: 2, batch:   4988] loss: 0.18221  | 0.18\n",
      "[epoch: 2, batch:   4990] loss: 0.27894  | 0.18\n",
      "[epoch: 2, batch:   4992] loss: 0.19913  | 0.18\n",
      "[epoch: 2, batch:   4994] loss: 0.15443  | 0.18\n",
      "[epoch: 2, batch:   4996] loss: 0.03600  | 0.18\n",
      "[epoch: 2, batch:   4998] loss: 0.10987  | 0.18\n",
      "[epoch: 2, batch:   5000] loss: 0.10476  | 0.18\n",
      "[epoch: 3, batch:      2] loss: 0.48445  | 2.04\n",
      "[epoch: 3, batch:      4] loss: 0.10017  | 0.17\n",
      "[epoch: 3, batch:      6] loss: 0.29404  | 0.18\n",
      "[epoch: 3, batch:      8] loss: 0.44355  | 0.18\n",
      "[epoch: 3, batch:     10] loss: 0.28774  | 0.21\n",
      "[epoch: 3, batch:     12] loss: 0.57887  | 0.18\n",
      "[epoch: 3, batch:     14] loss: 0.29532  | 0.18\n",
      "[epoch: 3, batch:     16] loss: 1.62656  | 0.18\n",
      "[epoch: 3, batch:     18] loss: 0.98347  | 0.19\n",
      "[epoch: 3, batch:     20] loss: 0.21890  | 0.18\n",
      "[epoch: 3, batch:     22] loss: 1.13942  | 0.17\n",
      "[epoch: 3, batch:     24] loss: 0.83641  | 0.19\n",
      "[epoch: 3, batch:     26] loss: 0.08935  | 0.18\n",
      "[epoch: 3, batch:     28] loss: 0.31558  | 0.18\n",
      "[epoch: 3, batch:     30] loss: 0.46609  | 0.18\n",
      "[epoch: 3, batch:     32] loss: 0.21427  | 0.18\n",
      "[epoch: 3, batch:     34] loss: 0.14875  | 0.18\n",
      "[epoch: 3, batch:     36] loss: 2.01985  | 0.18\n",
      "[epoch: 3, batch:     38] loss: 0.07984  | 0.18\n",
      "[epoch: 3, batch:     40] loss: 0.48091  | 0.18\n",
      "[epoch: 3, batch:     42] loss: 0.96005  | 0.18\n",
      "[epoch: 3, batch:     44] loss: 0.24965  | 0.18\n",
      "[epoch: 3, batch:     46] loss: 0.14116  | 0.19\n",
      "[epoch: 3, batch:     48] loss: 0.18475  | 0.18\n",
      "[epoch: 3, batch:     50] loss: 0.06076  | 0.18\n",
      "[epoch: 3, batch:     52] loss: 0.27120  | 0.18\n",
      "[epoch: 3, batch:     54] loss: 0.47476  | 0.18\n",
      "[epoch: 3, batch:     56] loss: 0.23351  | 0.18\n",
      "[epoch: 3, batch:     58] loss: 1.27679  | 0.18\n",
      "[epoch: 3, batch:     60] loss: 0.21827  | 0.18\n",
      "[epoch: 3, batch:     62] loss: 0.12834  | 0.18\n",
      "[epoch: 3, batch:     64] loss: 0.49112  | 0.18\n",
      "[epoch: 3, batch:     66] loss: 0.36584  | 0.18\n",
      "[epoch: 3, batch:     68] loss: 0.19559  | 0.18\n",
      "[epoch: 3, batch:     70] loss: 0.02076  | 0.18\n",
      "[epoch: 3, batch:     72] loss: 0.51879  | 0.18\n",
      "[epoch: 3, batch:     74] loss: 0.11808  | 0.18\n",
      "[epoch: 3, batch:     76] loss: 0.60332  | 0.18\n",
      "[epoch: 3, batch:     78] loss: 0.41985  | 0.18\n",
      "[epoch: 3, batch:     80] loss: 0.05592  | 0.18\n",
      "[epoch: 3, batch:     82] loss: 0.03465  | 0.18\n",
      "[epoch: 3, batch:     84] loss: 0.10836  | 0.18\n",
      "[epoch: 3, batch:     86] loss: 1.46729  | 0.18\n",
      "[epoch: 3, batch:     88] loss: 0.41650  | 0.18\n",
      "[epoch: 3, batch:     90] loss: 0.29521  | 0.18\n",
      "[epoch: 3, batch:     92] loss: 0.47246  | 0.18\n",
      "[epoch: 3, batch:     94] loss: 0.59057  | 0.18\n",
      "[epoch: 3, batch:     96] loss: 0.26750  | 0.18\n",
      "[epoch: 3, batch:     98] loss: 0.03115  | 0.18\n",
      "[epoch: 3, batch:    100] loss: 0.90605  | 0.18\n",
      "[epoch: 3, batch:    102] loss: 0.33362  | 0.19\n",
      "[epoch: 3, batch:    104] loss: 0.18276  | 0.18\n",
      "[epoch: 3, batch:    106] loss: 0.32974  | 0.18\n",
      "[epoch: 3, batch:    108] loss: 0.49572  | 0.18\n",
      "[epoch: 3, batch:    110] loss: 0.21026  | 0.18\n",
      "[epoch: 3, batch:    112] loss: 0.67294  | 0.18\n",
      "[epoch: 3, batch:    114] loss: 0.48306  | 0.18\n",
      "[epoch: 3, batch:    116] loss: 0.18145  | 0.18\n",
      "[epoch: 3, batch:    118] loss: 0.48467  | 0.18\n",
      "[epoch: 3, batch:    120] loss: 0.18494  | 0.18\n",
      "[epoch: 3, batch:    122] loss: 0.08145  | 0.18\n",
      "[epoch: 3, batch:    124] loss: 0.28728  | 0.18\n",
      "[epoch: 3, batch:    126] loss: 0.06582  | 0.18\n",
      "[epoch: 3, batch:    128] loss: 0.12421  | 0.18\n",
      "[epoch: 3, batch:    130] loss: 0.10674  | 0.18\n",
      "[epoch: 3, batch:    132] loss: 0.08675  | 0.18\n",
      "[epoch: 3, batch:    134] loss: 0.15291  | 0.18\n",
      "[epoch: 3, batch:    136] loss: 0.05162  | 0.18\n",
      "[epoch: 3, batch:    138] loss: 0.64910  | 0.18\n",
      "[epoch: 3, batch:    140] loss: 0.18909  | 0.18\n",
      "[epoch: 3, batch:    142] loss: 0.36100  | 0.18\n",
      "[epoch: 3, batch:    144] loss: 0.28909  | 0.18\n",
      "[epoch: 3, batch:    146] loss: 0.35334  | 0.18\n",
      "[epoch: 3, batch:    148] loss: 0.43749  | 0.18\n",
      "[epoch: 3, batch:    150] loss: 0.53399  | 0.18\n",
      "[epoch: 3, batch:    152] loss: 0.24967  | 0.18\n",
      "[epoch: 3, batch:    154] loss: 0.17438  | 0.18\n",
      "[epoch: 3, batch:    156] loss: 0.37981  | 0.18\n",
      "[epoch: 3, batch:    158] loss: 0.39920  | 0.18\n",
      "[epoch: 3, batch:    160] loss: 0.59714  | 0.18\n",
      "[epoch: 3, batch:    162] loss: 0.16479  | 0.18\n",
      "[epoch: 3, batch:    164] loss: 0.28818  | 0.18\n",
      "[epoch: 3, batch:    166] loss: 0.52325  | 0.18\n",
      "[epoch: 3, batch:    168] loss: 0.24380  | 0.18\n",
      "[epoch: 3, batch:    170] loss: 0.09482  | 0.18\n",
      "[epoch: 3, batch:    172] loss: 0.07954  | 0.18\n",
      "[epoch: 3, batch:    174] loss: 0.20838  | 0.18\n",
      "[epoch: 3, batch:    176] loss: 0.66862  | 0.18\n",
      "[epoch: 3, batch:    178] loss: 0.25280  | 0.18\n",
      "[epoch: 3, batch:    180] loss: 0.08582  | 0.18\n",
      "[epoch: 3, batch:    182] loss: 0.24503  | 0.18\n",
      "[epoch: 3, batch:    184] loss: 0.48056  | 0.18\n",
      "[epoch: 3, batch:    186] loss: 0.41346  | 0.18\n",
      "[epoch: 3, batch:    188] loss: 0.63744  | 0.18\n",
      "[epoch: 3, batch:    190] loss: 0.20310  | 0.18\n",
      "[epoch: 3, batch:    192] loss: 0.38242  | 0.18\n",
      "[epoch: 3, batch:    194] loss: 0.52362  | 0.18\n",
      "[epoch: 3, batch:    196] loss: 0.25094  | 0.18\n",
      "[epoch: 3, batch:    198] loss: 0.11252  | 0.18\n",
      "[epoch: 3, batch:    200] loss: 0.35032  | 0.18\n",
      "[epoch: 3, batch:    202] loss: 0.40951  | 0.18\n",
      "[epoch: 3, batch:    204] loss: 0.06949  | 0.18\n",
      "[epoch: 3, batch:    206] loss: 0.10296  | 0.18\n",
      "[epoch: 3, batch:    208] loss: 0.06075  | 0.18\n",
      "[epoch: 3, batch:    210] loss: 0.07429  | 0.18\n",
      "[epoch: 3, batch:    212] loss: 0.29038  | 0.18\n",
      "[epoch: 3, batch:    214] loss: 0.39884  | 0.18\n",
      "[epoch: 3, batch:    216] loss: 0.58320  | 0.18\n",
      "[epoch: 3, batch:    218] loss: 0.10964  | 0.18\n",
      "[epoch: 3, batch:    220] loss: 0.14100  | 0.18\n",
      "[epoch: 3, batch:    222] loss: 0.63931  | 0.18\n",
      "[epoch: 3, batch:    224] loss: 0.03911  | 0.18\n",
      "[epoch: 3, batch:    226] loss: 0.56621  | 0.18\n",
      "[epoch: 3, batch:    228] loss: 0.07909  | 0.18\n",
      "[epoch: 3, batch:    230] loss: 0.16432  | 0.18\n",
      "[epoch: 3, batch:    232] loss: 0.11369  | 0.18\n",
      "[epoch: 3, batch:    234] loss: 0.38724  | 0.18\n",
      "[epoch: 3, batch:    236] loss: 0.13034  | 0.18\n",
      "[epoch: 3, batch:    238] loss: 0.04068  | 0.18\n",
      "[epoch: 3, batch:    240] loss: 0.25861  | 0.18\n",
      "[epoch: 3, batch:    242] loss: 0.46586  | 0.18\n",
      "[epoch: 3, batch:    244] loss: 0.23507  | 0.18\n",
      "[epoch: 3, batch:    246] loss: 0.37061  | 0.18\n",
      "[epoch: 3, batch:    248] loss: 0.33431  | 0.18\n",
      "[epoch: 3, batch:    250] loss: 0.23414  | 0.18\n",
      "[epoch: 3, batch:    252] loss: 1.22791  | 0.18\n",
      "[epoch: 3, batch:    254] loss: 0.43262  | 0.18\n",
      "[epoch: 3, batch:    256] loss: 0.07500  | 0.18\n",
      "[epoch: 3, batch:    258] loss: 0.19968  | 0.18\n",
      "[epoch: 3, batch:    260] loss: 0.35386  | 0.18\n",
      "[epoch: 3, batch:    262] loss: 0.21088  | 0.18\n",
      "[epoch: 3, batch:    264] loss: 0.01890  | 0.18\n",
      "[epoch: 3, batch:    266] loss: 0.12624  | 0.18\n",
      "[epoch: 3, batch:    268] loss: 0.06975  | 0.18\n",
      "[epoch: 3, batch:    270] loss: 0.21560  | 0.18\n",
      "[epoch: 3, batch:    272] loss: 0.23520  | 0.18\n",
      "[epoch: 3, batch:    274] loss: 0.22638  | 0.18\n",
      "[epoch: 3, batch:    276] loss: 0.16717  | 0.18\n",
      "[epoch: 3, batch:    278] loss: 0.60901  | 0.18\n",
      "[epoch: 3, batch:    280] loss: 0.14043  | 0.18\n",
      "[epoch: 3, batch:    282] loss: 0.72438  | 0.18\n",
      "[epoch: 3, batch:    284] loss: 0.70347  | 0.18\n",
      "[epoch: 3, batch:    286] loss: 0.47176  | 0.18\n",
      "[epoch: 3, batch:    288] loss: 0.54120  | 0.18\n",
      "[epoch: 3, batch:    290] loss: 0.04176  | 0.18\n",
      "[epoch: 3, batch:    292] loss: 0.03099  | 0.18\n",
      "[epoch: 3, batch:    294] loss: 1.27237  | 0.18\n",
      "[epoch: 3, batch:    296] loss: 0.16309  | 0.18\n",
      "[epoch: 3, batch:    298] loss: 0.46362  | 0.18\n",
      "[epoch: 3, batch:    300] loss: 0.48390  | 0.18\n",
      "[epoch: 3, batch:    302] loss: 0.49800  | 0.18\n",
      "[epoch: 3, batch:    304] loss: 1.07873  | 0.18\n",
      "[epoch: 3, batch:    306] loss: 0.21130  | 0.18\n",
      "[epoch: 3, batch:    308] loss: 0.41428  | 0.18\n",
      "[epoch: 3, batch:    310] loss: 0.20806  | 0.18\n",
      "[epoch: 3, batch:    312] loss: 0.35810  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 3, batch:    314] loss: 0.34386  | 0.18\n",
      "[epoch: 3, batch:    316] loss: 0.17873  | 0.18\n",
      "[epoch: 3, batch:    318] loss: 0.47149  | 0.18\n",
      "[epoch: 3, batch:    320] loss: 0.13821  | 0.18\n",
      "[epoch: 3, batch:    322] loss: 0.06808  | 0.18\n",
      "[epoch: 3, batch:    324] loss: 0.14984  | 0.18\n",
      "[epoch: 3, batch:    326] loss: 0.31560  | 0.18\n",
      "[epoch: 3, batch:    328] loss: 0.32782  | 0.18\n",
      "[epoch: 3, batch:    330] loss: 0.51876  | 0.18\n",
      "[epoch: 3, batch:    332] loss: 0.20284  | 0.18\n",
      "[epoch: 3, batch:    334] loss: 0.29017  | 0.18\n",
      "[epoch: 3, batch:    336] loss: 0.08148  | 0.18\n",
      "[epoch: 3, batch:    338] loss: 0.04317  | 0.18\n",
      "[epoch: 3, batch:    340] loss: 0.13543  | 0.18\n",
      "[epoch: 3, batch:    342] loss: 0.28551  | 0.18\n",
      "[epoch: 3, batch:    344] loss: 0.20741  | 0.18\n",
      "[epoch: 3, batch:    346] loss: 0.05855  | 0.18\n",
      "[epoch: 3, batch:    348] loss: 0.99203  | 0.18\n",
      "[epoch: 3, batch:    350] loss: 0.20777  | 0.18\n",
      "[epoch: 3, batch:    352] loss: 0.45979  | 0.18\n",
      "[epoch: 3, batch:    354] loss: 0.61242  | 0.18\n",
      "[epoch: 3, batch:    356] loss: 0.53715  | 0.18\n",
      "[epoch: 3, batch:    358] loss: 0.10774  | 0.18\n",
      "[epoch: 3, batch:    360] loss: 0.17807  | 0.18\n",
      "[epoch: 3, batch:    362] loss: 0.12250  | 0.18\n",
      "[epoch: 3, batch:    364] loss: 0.10264  | 0.18\n",
      "[epoch: 3, batch:    366] loss: 0.24253  | 0.18\n",
      "[epoch: 3, batch:    368] loss: 0.09247  | 0.18\n",
      "[epoch: 3, batch:    370] loss: 0.19244  | 0.18\n",
      "[epoch: 3, batch:    372] loss: 0.34004  | 0.18\n",
      "[epoch: 3, batch:    374] loss: 0.04842  | 0.18\n",
      "[epoch: 3, batch:    376] loss: 0.18841  | 0.18\n",
      "[epoch: 3, batch:    378] loss: 0.28680  | 0.18\n",
      "[epoch: 3, batch:    380] loss: 0.61627  | 0.18\n",
      "[epoch: 3, batch:    382] loss: 0.23108  | 0.18\n",
      "[epoch: 3, batch:    384] loss: 0.03890  | 0.18\n",
      "[epoch: 3, batch:    386] loss: 0.10208  | 0.18\n",
      "[epoch: 3, batch:    388] loss: 0.07369  | 0.18\n",
      "[epoch: 3, batch:    390] loss: 0.32300  | 0.18\n",
      "[epoch: 3, batch:    392] loss: 0.03541  | 0.18\n",
      "[epoch: 3, batch:    394] loss: 0.43893  | 0.18\n",
      "[epoch: 3, batch:    396] loss: 0.24778  | 0.18\n",
      "[epoch: 3, batch:    398] loss: 0.23680  | 0.18\n",
      "[epoch: 3, batch:    400] loss: 0.21227  | 0.18\n",
      "[epoch: 3, batch:    402] loss: 0.11727  | 0.18\n",
      "[epoch: 3, batch:    404] loss: 0.23785  | 0.18\n",
      "[epoch: 3, batch:    406] loss: 0.42525  | 0.18\n",
      "[epoch: 3, batch:    408] loss: 0.28451  | 0.18\n",
      "[epoch: 3, batch:    410] loss: 0.44394  | 0.18\n",
      "[epoch: 3, batch:    412] loss: 0.27057  | 0.18\n",
      "[epoch: 3, batch:    414] loss: 0.46756  | 0.18\n",
      "[epoch: 3, batch:    416] loss: 0.04911  | 0.18\n",
      "[epoch: 3, batch:    418] loss: 0.13985  | 0.18\n",
      "[epoch: 3, batch:    420] loss: 0.21806  | 0.18\n",
      "[epoch: 3, batch:    422] loss: 0.63286  | 0.18\n",
      "[epoch: 3, batch:    424] loss: 0.42300  | 0.18\n",
      "[epoch: 3, batch:    426] loss: 0.39746  | 0.18\n",
      "[epoch: 3, batch:    428] loss: 0.50103  | 0.18\n",
      "[epoch: 3, batch:    430] loss: 0.67986  | 0.18\n",
      "[epoch: 3, batch:    432] loss: 0.01708  | 0.18\n",
      "[epoch: 3, batch:    434] loss: 0.18969  | 0.18\n",
      "[epoch: 3, batch:    436] loss: 0.22822  | 0.18\n",
      "[epoch: 3, batch:    438] loss: 0.10891  | 0.18\n",
      "[epoch: 3, batch:    440] loss: 0.37180  | 0.18\n",
      "[epoch: 3, batch:    442] loss: 0.21131  | 0.18\n",
      "[epoch: 3, batch:    444] loss: 0.10690  | 0.18\n",
      "[epoch: 3, batch:    446] loss: 0.65987  | 0.18\n",
      "[epoch: 3, batch:    448] loss: 0.17669  | 0.18\n",
      "[epoch: 3, batch:    450] loss: 0.10846  | 0.18\n",
      "[epoch: 3, batch:    452] loss: 0.13877  | 0.18\n",
      "[epoch: 3, batch:    454] loss: 0.06265  | 0.18\n",
      "[epoch: 3, batch:    456] loss: 0.13844  | 0.18\n",
      "[epoch: 3, batch:    458] loss: 0.18296  | 0.19\n",
      "[epoch: 3, batch:    460] loss: 0.17310  | 0.18\n",
      "[epoch: 3, batch:    462] loss: 0.15070  | 0.18\n",
      "[epoch: 3, batch:    464] loss: 0.03937  | 0.18\n",
      "[epoch: 3, batch:    466] loss: 0.43451  | 0.18\n",
      "[epoch: 3, batch:    468] loss: 0.21018  | 0.18\n",
      "[epoch: 3, batch:    470] loss: 0.22820  | 0.18\n",
      "[epoch: 3, batch:    472] loss: 0.25628  | 0.18\n",
      "[epoch: 3, batch:    474] loss: 0.23886  | 0.18\n",
      "[epoch: 3, batch:    476] loss: 0.10967  | 0.18\n",
      "[epoch: 3, batch:    478] loss: 0.12112  | 0.18\n",
      "[epoch: 3, batch:    480] loss: 0.20943  | 0.18\n",
      "[epoch: 3, batch:    482] loss: 1.38039  | 0.18\n",
      "[epoch: 3, batch:    484] loss: 0.14081  | 0.18\n",
      "[epoch: 3, batch:    486] loss: 1.39893  | 0.18\n",
      "[epoch: 3, batch:    488] loss: 0.39258  | 0.18\n",
      "[epoch: 3, batch:    490] loss: 0.47011  | 0.18\n",
      "[epoch: 3, batch:    492] loss: 0.47599  | 0.18\n",
      "[epoch: 3, batch:    494] loss: 0.11139  | 0.18\n",
      "[epoch: 3, batch:    496] loss: 0.22553  | 0.18\n",
      "[epoch: 3, batch:    498] loss: 0.38158  | 0.18\n",
      "[epoch: 3, batch:    500] loss: 1.01231  | 0.18\n",
      "[epoch: 3, batch:    502] loss: 0.08875  | 0.18\n",
      "[epoch: 3, batch:    504] loss: 0.28086  | 0.18\n",
      "[epoch: 3, batch:    506] loss: 0.63959  | 0.18\n",
      "[epoch: 3, batch:    508] loss: 0.15249  | 0.18\n",
      "[epoch: 3, batch:    510] loss: 1.02800  | 0.18\n",
      "[epoch: 3, batch:    512] loss: 0.08757  | 0.18\n",
      "[epoch: 3, batch:    514] loss: 0.14117  | 0.18\n",
      "[epoch: 3, batch:    516] loss: 0.15999  | 0.18\n",
      "[epoch: 3, batch:    518] loss: 0.09774  | 0.18\n",
      "[epoch: 3, batch:    520] loss: 0.20944  | 0.18\n",
      "[epoch: 3, batch:    522] loss: 0.16235  | 0.18\n",
      "[epoch: 3, batch:    524] loss: 0.04697  | 0.18\n",
      "[epoch: 3, batch:    526] loss: 0.24438  | 0.18\n",
      "[epoch: 3, batch:    528] loss: 0.35204  | 0.18\n",
      "[epoch: 3, batch:    530] loss: 0.06725  | 0.18\n",
      "[epoch: 3, batch:    532] loss: 0.40523  | 0.18\n",
      "[epoch: 3, batch:    534] loss: 0.51749  | 0.18\n",
      "[epoch: 3, batch:    536] loss: 0.33716  | 0.18\n",
      "[epoch: 3, batch:    538] loss: 0.23443  | 0.18\n",
      "[epoch: 3, batch:    540] loss: 0.20936  | 0.18\n",
      "[epoch: 3, batch:    542] loss: 0.10474  | 0.18\n",
      "[epoch: 3, batch:    544] loss: 0.14739  | 0.18\n",
      "[epoch: 3, batch:    546] loss: 0.16608  | 0.18\n",
      "[epoch: 3, batch:    548] loss: 0.25248  | 0.18\n",
      "[epoch: 3, batch:    550] loss: 0.06022  | 0.18\n",
      "[epoch: 3, batch:    552] loss: 0.09109  | 0.18\n",
      "[epoch: 3, batch:    554] loss: 0.20627  | 0.18\n",
      "[epoch: 3, batch:    556] loss: 0.43155  | 0.18\n",
      "[epoch: 3, batch:    558] loss: 0.19100  | 0.18\n",
      "[epoch: 3, batch:    560] loss: 0.06427  | 0.18\n",
      "[epoch: 3, batch:    562] loss: 0.32713  | 0.18\n",
      "[epoch: 3, batch:    564] loss: 0.33753  | 0.18\n",
      "[epoch: 3, batch:    566] loss: 0.45687  | 0.18\n",
      "[epoch: 3, batch:    568] loss: 0.18499  | 0.18\n",
      "[epoch: 3, batch:    570] loss: 0.31054  | 0.18\n",
      "[epoch: 3, batch:    572] loss: 0.03879  | 0.18\n",
      "[epoch: 3, batch:    574] loss: 0.82439  | 0.18\n",
      "[epoch: 3, batch:    576] loss: 0.31120  | 0.18\n",
      "[epoch: 3, batch:    578] loss: 0.60395  | 0.18\n",
      "[epoch: 3, batch:    580] loss: 0.17614  | 0.18\n",
      "[epoch: 3, batch:    582] loss: 0.86798  | 0.18\n",
      "[epoch: 3, batch:    584] loss: 0.08404  | 0.18\n",
      "[epoch: 3, batch:    586] loss: 0.11999  | 0.18\n",
      "[epoch: 3, batch:    588] loss: 0.11016  | 0.18\n",
      "[epoch: 3, batch:    590] loss: 0.57510  | 0.18\n",
      "[epoch: 3, batch:    592] loss: 0.13589  | 0.18\n",
      "[epoch: 3, batch:    594] loss: 0.13965  | 0.18\n",
      "[epoch: 3, batch:    596] loss: 0.21759  | 0.18\n",
      "[epoch: 3, batch:    598] loss: 0.54907  | 0.18\n",
      "[epoch: 3, batch:    600] loss: 0.96107  | 0.18\n",
      "[epoch: 3, batch:    602] loss: 0.46226  | 0.18\n",
      "[epoch: 3, batch:    604] loss: 0.59270  | 0.18\n",
      "[epoch: 3, batch:    606] loss: 0.51634  | 0.18\n",
      "[epoch: 3, batch:    608] loss: 0.09108  | 0.18\n",
      "[epoch: 3, batch:    610] loss: 1.54676  | 0.18\n",
      "[epoch: 3, batch:    612] loss: 0.31450  | 0.18\n",
      "[epoch: 3, batch:    614] loss: 0.38321  | 0.18\n",
      "[epoch: 3, batch:    616] loss: 0.16763  | 0.18\n",
      "[epoch: 3, batch:    618] loss: 0.16759  | 0.18\n",
      "[epoch: 3, batch:    620] loss: 0.45838  | 0.18\n",
      "[epoch: 3, batch:    622] loss: 0.17148  | 0.18\n",
      "[epoch: 3, batch:    624] loss: 0.16883  | 0.18\n",
      "[epoch: 3, batch:    626] loss: 0.36117  | 0.18\n",
      "[epoch: 3, batch:    628] loss: 0.18596  | 0.18\n",
      "[epoch: 3, batch:    630] loss: 0.10659  | 0.18\n",
      "[epoch: 3, batch:    632] loss: 0.20355  | 0.18\n",
      "[epoch: 3, batch:    634] loss: 0.48643  | 0.18\n",
      "[epoch: 3, batch:    636] loss: 0.50550  | 0.18\n",
      "[epoch: 3, batch:    638] loss: 0.06556  | 0.18\n",
      "[epoch: 3, batch:    640] loss: 0.04049  | 0.18\n",
      "[epoch: 3, batch:    642] loss: 0.19113  | 0.18\n",
      "[epoch: 3, batch:    644] loss: 0.28384  | 0.18\n",
      "[epoch: 3, batch:    646] loss: 0.64606  | 0.18\n",
      "[epoch: 3, batch:    648] loss: 0.02633  | 0.18\n",
      "[epoch: 3, batch:    650] loss: 0.22059  | 0.18\n",
      "[epoch: 3, batch:    652] loss: 0.34236  | 0.18\n",
      "[epoch: 3, batch:    654] loss: 0.17774  | 0.19\n",
      "[epoch: 3, batch:    656] loss: 0.07491  | 0.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 3, batch:    658] loss: 1.33718  | 0.18\n",
      "[epoch: 3, batch:    660] loss: 0.15980  | 0.18\n",
      "[epoch: 3, batch:    662] loss: 0.03136  | 0.18\n",
      "[epoch: 3, batch:    664] loss: 0.34496  | 0.18\n",
      "[epoch: 3, batch:    666] loss: 0.47346  | 0.18\n",
      "[epoch: 3, batch:    668] loss: 0.02623  | 0.18\n",
      "[epoch: 3, batch:    670] loss: 0.89359  | 0.18\n",
      "[epoch: 3, batch:    672] loss: 0.06972  | 0.18\n",
      "[epoch: 3, batch:    674] loss: 0.07426  | 0.18\n",
      "[epoch: 3, batch:    676] loss: 0.20748  | 0.18\n",
      "[epoch: 3, batch:    678] loss: 1.03629  | 0.18\n",
      "[epoch: 3, batch:    680] loss: 0.65675  | 0.18\n",
      "[epoch: 3, batch:    682] loss: 0.43772  | 0.18\n",
      "[epoch: 3, batch:    684] loss: 0.06876  | 0.18\n",
      "[epoch: 3, batch:    686] loss: 0.27549  | 0.18\n",
      "[epoch: 3, batch:    688] loss: 0.52125  | 0.18\n",
      "[epoch: 3, batch:    690] loss: 0.21239  | 0.18\n",
      "[epoch: 3, batch:    692] loss: 0.50440  | 0.18\n",
      "[epoch: 3, batch:    694] loss: 1.03199  | 0.18\n",
      "[epoch: 3, batch:    696] loss: 0.13175  | 0.18\n",
      "[epoch: 3, batch:    698] loss: 0.24170  | 0.19\n",
      "[epoch: 3, batch:    700] loss: 0.55987  | 0.18\n",
      "[epoch: 3, batch:    702] loss: 0.06547  | 0.18\n",
      "[epoch: 3, batch:    704] loss: 0.07722  | 0.18\n",
      "[epoch: 3, batch:    706] loss: 0.10582  | 0.18\n",
      "[epoch: 3, batch:    708] loss: 0.70324  | 0.19\n",
      "[epoch: 3, batch:    710] loss: 0.58982  | 0.20\n",
      "[epoch: 3, batch:    712] loss: 0.54267  | 0.18\n",
      "[epoch: 3, batch:    714] loss: 1.51636  | 0.18\n",
      "[epoch: 3, batch:    716] loss: 0.29626  | 0.18\n",
      "[epoch: 3, batch:    718] loss: 0.31477  | 0.18\n",
      "[epoch: 3, batch:    720] loss: 0.32732  | 0.18\n",
      "[epoch: 3, batch:    722] loss: 0.16913  | 0.18\n",
      "[epoch: 3, batch:    724] loss: 0.16873  | 0.18\n",
      "[epoch: 3, batch:    726] loss: 0.43144  | 0.18\n",
      "[epoch: 3, batch:    728] loss: 1.22644  | 0.18\n",
      "[epoch: 3, batch:    730] loss: 1.23197  | 0.19\n",
      "[epoch: 3, batch:    732] loss: 0.48598  | 0.32\n",
      "[epoch: 3, batch:    734] loss: 0.56149  | 0.17\n",
      "[epoch: 3, batch:    736] loss: 0.41365  | 0.17\n",
      "[epoch: 3, batch:    738] loss: 0.73354  | 0.17\n",
      "[epoch: 3, batch:    740] loss: 0.09296  | 0.18\n",
      "[epoch: 3, batch:    742] loss: 0.11319  | 0.17\n",
      "[epoch: 3, batch:    744] loss: 0.02940  | 0.18\n",
      "[epoch: 3, batch:    746] loss: 0.16499  | 0.18\n",
      "[epoch: 3, batch:    748] loss: 1.36045  | 0.18\n",
      "[epoch: 3, batch:    750] loss: 0.08737  | 0.18\n",
      "[epoch: 3, batch:    752] loss: 0.42234  | 0.18\n",
      "[epoch: 3, batch:    754] loss: 0.43184  | 0.18\n",
      "[epoch: 3, batch:    756] loss: 0.63598  | 0.18\n",
      "[epoch: 3, batch:    758] loss: 0.13991  | 0.18\n",
      "[epoch: 3, batch:    760] loss: 0.08623  | 0.18\n",
      "[epoch: 3, batch:    762] loss: 0.27497  | 0.19\n",
      "[epoch: 3, batch:    764] loss: 0.13045  | 0.18\n",
      "[epoch: 3, batch:    766] loss: 0.53709  | 0.17\n",
      "[epoch: 3, batch:    768] loss: 0.17215  | 0.19\n",
      "[epoch: 3, batch:    770] loss: 0.34554  | 0.18\n",
      "[epoch: 3, batch:    772] loss: 0.08361  | 0.18\n",
      "[epoch: 3, batch:    774] loss: 0.01796  | 0.18\n",
      "[epoch: 3, batch:    776] loss: 0.85783  | 0.18\n",
      "[epoch: 3, batch:    778] loss: 0.05670  | 0.18\n",
      "[epoch: 3, batch:    780] loss: 0.19020  | 0.18\n",
      "[epoch: 3, batch:    782] loss: 0.49735  | 0.18\n",
      "[epoch: 3, batch:    784] loss: 0.93894  | 0.19\n",
      "[epoch: 3, batch:    786] loss: 0.06973  | 0.17\n",
      "[epoch: 3, batch:    788] loss: 0.71389  | 0.18\n",
      "[epoch: 3, batch:    790] loss: 0.12558  | 0.18\n",
      "[epoch: 3, batch:    792] loss: 0.43591  | 0.18\n",
      "[epoch: 3, batch:    794] loss: 0.26051  | 0.20\n",
      "[epoch: 3, batch:    796] loss: 0.25392  | 0.17\n",
      "[epoch: 3, batch:    798] loss: 0.33555  | 0.17\n",
      "[epoch: 3, batch:    800] loss: 0.22773  | 0.18\n",
      "[epoch: 3, batch:    802] loss: 0.58707  | 0.18\n",
      "[epoch: 3, batch:    804] loss: 0.17875  | 0.19\n",
      "[epoch: 3, batch:    806] loss: 0.61022  | 0.17\n",
      "[epoch: 3, batch:    808] loss: 0.02521  | 0.18\n",
      "[epoch: 3, batch:    810] loss: 0.31176  | 0.18\n",
      "[epoch: 3, batch:    812] loss: 0.26216  | 0.19\n",
      "[epoch: 3, batch:    814] loss: 0.16040  | 0.17\n",
      "[epoch: 3, batch:    816] loss: 0.13710  | 0.18\n",
      "[epoch: 3, batch:    818] loss: 0.06866  | 0.18\n",
      "[epoch: 3, batch:    820] loss: 0.46599  | 0.18\n",
      "[epoch: 3, batch:    822] loss: 0.43038  | 0.17\n",
      "[epoch: 3, batch:    824] loss: 0.24069  | 0.18\n",
      "[epoch: 3, batch:    826] loss: 0.54936  | 0.18\n",
      "[epoch: 3, batch:    828] loss: 0.08002  | 0.18\n",
      "[epoch: 3, batch:    830] loss: 0.61125  | 0.18\n",
      "[epoch: 3, batch:    832] loss: 0.18375  | 0.19\n",
      "[epoch: 3, batch:    834] loss: 0.13658  | 0.17\n",
      "[epoch: 3, batch:    836] loss: 0.16320  | 0.18\n",
      "[epoch: 3, batch:    838] loss: 0.10207  | 0.17\n",
      "[epoch: 3, batch:    840] loss: 1.01615  | 0.18\n",
      "[epoch: 3, batch:    842] loss: 0.04030  | 0.65\n",
      "[epoch: 3, batch:    844] loss: 0.17610  | 0.18\n",
      "[epoch: 3, batch:    846] loss: 0.09094  | 0.18\n",
      "[epoch: 3, batch:    848] loss: 0.18987  | 0.17\n",
      "[epoch: 3, batch:    850] loss: 0.11206  | 0.18\n",
      "[epoch: 3, batch:    852] loss: 0.30933  | 0.18\n",
      "[epoch: 3, batch:    854] loss: 0.22174  | 0.18\n",
      "[epoch: 3, batch:    856] loss: 0.03945  | 0.17\n",
      "[epoch: 3, batch:    858] loss: 0.62388  | 0.18\n",
      "[epoch: 3, batch:    860] loss: 0.25454  | 0.42\n",
      "[epoch: 3, batch:    862] loss: 0.02736  | 0.17\n",
      "[epoch: 3, batch:    864] loss: 0.44944  | 0.18\n",
      "[epoch: 3, batch:    866] loss: 0.01571  | 0.17\n",
      "[epoch: 3, batch:    868] loss: 1.29232  | 0.18\n",
      "[epoch: 3, batch:    870] loss: 0.05951  | 0.18\n",
      "[epoch: 3, batch:    872] loss: 0.34805  | 0.18\n",
      "[epoch: 3, batch:    874] loss: 0.07034  | 0.17\n",
      "[epoch: 3, batch:    876] loss: 0.21366  | 0.18\n",
      "[epoch: 3, batch:    878] loss: 1.24929  | 0.18\n",
      "[epoch: 3, batch:    880] loss: 0.15723  | 0.65\n",
      "[epoch: 3, batch:    882] loss: 0.16696  | 0.17\n",
      "[epoch: 3, batch:    884] loss: 0.54653  | 0.18\n",
      "[epoch: 3, batch:    886] loss: 0.01573  | 0.18\n",
      "[epoch: 3, batch:    888] loss: 0.24432  | 0.18\n",
      "[epoch: 3, batch:    890] loss: 0.33179  | 0.17\n",
      "[epoch: 3, batch:    892] loss: 0.03988  | 0.18\n",
      "[epoch: 3, batch:    894] loss: 0.18192  | 0.18\n",
      "[epoch: 3, batch:    896] loss: 0.30650  | 0.18\n",
      "[epoch: 3, batch:    898] loss: 0.02731  | 0.19\n",
      "[epoch: 3, batch:    900] loss: 0.11819  | 0.18\n",
      "[epoch: 3, batch:    902] loss: 0.19244  | 0.18\n",
      "[epoch: 3, batch:    904] loss: 0.01607  | 0.19\n",
      "[epoch: 3, batch:    906] loss: 0.19239  | 0.18\n",
      "[epoch: 3, batch:    908] loss: 0.64180  | 0.18\n",
      "[epoch: 3, batch:    910] loss: 0.19720  | 0.18\n",
      "[epoch: 3, batch:    912] loss: 0.44047  | 0.18\n",
      "[epoch: 3, batch:    914] loss: 0.45230  | 0.17\n",
      "[epoch: 3, batch:    916] loss: 0.37944  | 0.18\n",
      "[epoch: 3, batch:    918] loss: 0.33228  | 0.18\n",
      "[epoch: 3, batch:    920] loss: 0.38459  | 0.18\n",
      "[epoch: 3, batch:    922] loss: 0.42150  | 0.18\n",
      "[epoch: 3, batch:    924] loss: 0.29492  | 0.18\n",
      "[epoch: 3, batch:    926] loss: 0.18819  | 0.20\n",
      "[epoch: 3, batch:    928] loss: 0.68356  | 0.18\n",
      "[epoch: 3, batch:    930] loss: 0.05610  | 0.18\n",
      "[epoch: 3, batch:    932] loss: 0.46208  | 0.18\n",
      "[epoch: 3, batch:    934] loss: 0.19679  | 0.18\n",
      "[epoch: 3, batch:    936] loss: 0.21073  | 0.18\n",
      "[epoch: 3, batch:    938] loss: 0.16064  | 0.18\n",
      "[epoch: 3, batch:    940] loss: 1.16534  | 0.18\n",
      "[epoch: 3, batch:    942] loss: 0.33219  | 0.18\n",
      "[epoch: 3, batch:    944] loss: 0.39032  | 0.18\n",
      "[epoch: 3, batch:    946] loss: 0.24418  | 0.18\n",
      "[epoch: 3, batch:    948] loss: 0.35821  | 0.18\n",
      "[epoch: 3, batch:    950] loss: 0.61169  | 0.18\n",
      "[epoch: 3, batch:    952] loss: 0.44682  | 0.18\n",
      "[epoch: 3, batch:    954] loss: 0.06909  | 0.18\n",
      "[epoch: 3, batch:    956] loss: 0.23606  | 0.18\n",
      "[epoch: 3, batch:    958] loss: 0.60954  | 0.18\n",
      "[epoch: 3, batch:    960] loss: 0.17937  | 0.18\n",
      "[epoch: 3, batch:    962] loss: 0.35808  | 0.18\n",
      "[epoch: 3, batch:    964] loss: 0.47173  | 0.18\n",
      "[epoch: 3, batch:    966] loss: 0.44320  | 0.18\n",
      "[epoch: 3, batch:    968] loss: 0.23440  | 0.18\n",
      "[epoch: 3, batch:    970] loss: 0.13412  | 0.18\n",
      "[epoch: 3, batch:    972] loss: 0.34735  | 0.18\n",
      "[epoch: 3, batch:    974] loss: 0.48703  | 0.18\n",
      "[epoch: 3, batch:    976] loss: 0.06878  | 0.18\n",
      "[epoch: 3, batch:    978] loss: 0.31475  | 0.18\n",
      "[epoch: 3, batch:    980] loss: 0.38063  | 0.18\n",
      "[epoch: 3, batch:    982] loss: 0.11430  | 0.18\n",
      "[epoch: 3, batch:    984] loss: 0.32947  | 0.18\n",
      "[epoch: 3, batch:    986] loss: 0.19920  | 0.18\n",
      "[epoch: 3, batch:    988] loss: 0.14744  | 0.18\n",
      "[epoch: 3, batch:    990] loss: 0.10624  | 0.18\n",
      "[epoch: 3, batch:    992] loss: 0.59107  | 0.18\n",
      "[epoch: 3, batch:    994] loss: 1.02724  | 0.18\n",
      "[epoch: 3, batch:    996] loss: 0.14947  | 0.18\n",
      "[epoch: 3, batch:    998] loss: 0.31420  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 3, batch:   1000] loss: 0.28454  | 0.18\n",
      "[epoch: 3, batch:   1002] loss: 0.23394  | 0.18\n",
      "[epoch: 3, batch:   1004] loss: 0.16265  | 0.18\n",
      "[epoch: 3, batch:   1006] loss: 0.14170  | 0.18\n",
      "[epoch: 3, batch:   1008] loss: 0.46529  | 0.18\n",
      "[epoch: 3, batch:   1010] loss: 0.11291  | 0.18\n",
      "[epoch: 3, batch:   1012] loss: 0.33822  | 0.18\n",
      "[epoch: 3, batch:   1014] loss: 0.08505  | 0.18\n",
      "[epoch: 3, batch:   1016] loss: 0.34734  | 0.18\n",
      "[epoch: 3, batch:   1018] loss: 0.09716  | 0.18\n",
      "[epoch: 3, batch:   1020] loss: 0.14051  | 0.18\n",
      "[epoch: 3, batch:   1022] loss: 0.06302  | 0.18\n",
      "[epoch: 3, batch:   1024] loss: 0.21009  | 0.18\n",
      "[epoch: 3, batch:   1026] loss: 0.06252  | 0.18\n",
      "[epoch: 3, batch:   1028] loss: 0.46073  | 0.18\n",
      "[epoch: 3, batch:   1030] loss: 0.17592  | 0.18\n",
      "[epoch: 3, batch:   1032] loss: 0.33562  | 0.18\n",
      "[epoch: 3, batch:   1034] loss: 0.61634  | 0.18\n",
      "[epoch: 3, batch:   1036] loss: 0.04511  | 0.18\n",
      "[epoch: 3, batch:   1038] loss: 0.12739  | 0.18\n",
      "[epoch: 3, batch:   1040] loss: 0.35395  | 0.18\n",
      "[epoch: 3, batch:   1042] loss: 0.32926  | 0.18\n",
      "[epoch: 3, batch:   1044] loss: 0.22698  | 0.18\n",
      "[epoch: 3, batch:   1046] loss: 0.36707  | 0.18\n",
      "[epoch: 3, batch:   1048] loss: 0.56919  | 0.20\n",
      "[epoch: 3, batch:   1050] loss: 0.83854  | 0.17\n",
      "[epoch: 3, batch:   1052] loss: 0.83223  | 0.18\n",
      "[epoch: 3, batch:   1054] loss: 0.24558  | 0.17\n",
      "[epoch: 3, batch:   1056] loss: 0.23266  | 0.18\n",
      "[epoch: 3, batch:   1058] loss: 0.29144  | 0.20\n",
      "[epoch: 3, batch:   1060] loss: 0.76273  | 0.18\n",
      "[epoch: 3, batch:   1062] loss: 0.53693  | 0.18\n",
      "[epoch: 3, batch:   1064] loss: 0.20417  | 0.18\n",
      "[epoch: 3, batch:   1066] loss: 0.29463  | 0.18\n",
      "[epoch: 3, batch:   1068] loss: 0.08175  | 0.18\n",
      "[epoch: 3, batch:   1070] loss: 0.09389  | 0.18\n",
      "[epoch: 3, batch:   1072] loss: 1.26316  | 0.18\n",
      "[epoch: 3, batch:   1074] loss: 0.15898  | 0.18\n",
      "[epoch: 3, batch:   1076] loss: 0.09265  | 0.18\n",
      "[epoch: 3, batch:   1078] loss: 0.31367  | 0.18\n",
      "[epoch: 3, batch:   1080] loss: 0.07401  | 0.18\n",
      "[epoch: 3, batch:   1082] loss: 0.58689  | 0.18\n",
      "[epoch: 3, batch:   1084] loss: 0.02604  | 0.18\n",
      "[epoch: 3, batch:   1086] loss: 0.04314  | 0.18\n",
      "[epoch: 3, batch:   1088] loss: 0.56602  | 0.18\n",
      "[epoch: 3, batch:   1090] loss: 0.56108  | 0.18\n",
      "[epoch: 3, batch:   1092] loss: 0.26209  | 0.18\n",
      "[epoch: 3, batch:   1094] loss: 0.39559  | 0.18\n",
      "[epoch: 3, batch:   1096] loss: 0.10090  | 0.18\n",
      "[epoch: 3, batch:   1098] loss: 0.73329  | 0.18\n",
      "[epoch: 3, batch:   1100] loss: 0.44891  | 0.18\n",
      "[epoch: 3, batch:   1102] loss: 0.08776  | 0.18\n",
      "[epoch: 3, batch:   1104] loss: 1.21023  | 0.18\n",
      "[epoch: 3, batch:   1106] loss: 0.32252  | 0.18\n",
      "[epoch: 3, batch:   1108] loss: 0.37604  | 0.18\n",
      "[epoch: 3, batch:   1110] loss: 0.20708  | 0.18\n",
      "[epoch: 3, batch:   1112] loss: 0.34540  | 0.18\n",
      "[epoch: 3, batch:   1114] loss: 0.51794  | 0.18\n",
      "[epoch: 3, batch:   1116] loss: 0.42813  | 0.18\n",
      "[epoch: 3, batch:   1118] loss: 0.40532  | 0.18\n",
      "[epoch: 3, batch:   1120] loss: 0.14275  | 0.18\n",
      "[epoch: 3, batch:   1122] loss: 0.08514  | 0.18\n",
      "[epoch: 3, batch:   1124] loss: 0.16593  | 0.18\n",
      "[epoch: 3, batch:   1126] loss: 0.41616  | 0.18\n",
      "[epoch: 3, batch:   1128] loss: 0.15338  | 0.18\n",
      "[epoch: 3, batch:   1130] loss: 0.17144  | 0.18\n",
      "[epoch: 3, batch:   1132] loss: 0.05200  | 0.18\n",
      "[epoch: 3, batch:   1134] loss: 0.53438  | 0.18\n",
      "[epoch: 3, batch:   1136] loss: 0.63420  | 0.18\n",
      "[epoch: 3, batch:   1138] loss: 0.32904  | 0.18\n",
      "[epoch: 3, batch:   1140] loss: 1.14309  | 0.18\n",
      "[epoch: 3, batch:   1142] loss: 0.16862  | 0.18\n",
      "[epoch: 3, batch:   1144] loss: 1.15835  | 0.18\n",
      "[epoch: 3, batch:   1146] loss: 0.47367  | 0.18\n",
      "[epoch: 3, batch:   1148] loss: 0.06135  | 0.18\n",
      "[epoch: 3, batch:   1150] loss: 0.09386  | 0.18\n",
      "[epoch: 3, batch:   1152] loss: 0.37902  | 0.18\n",
      "[epoch: 3, batch:   1154] loss: 0.37384  | 0.18\n",
      "[epoch: 3, batch:   1156] loss: 0.13445  | 0.18\n",
      "[epoch: 3, batch:   1158] loss: 0.42635  | 0.18\n",
      "[epoch: 3, batch:   1160] loss: 0.01236  | 0.18\n",
      "[epoch: 3, batch:   1162] loss: 0.04492  | 0.18\n",
      "[epoch: 3, batch:   1164] loss: 0.05612  | 0.18\n",
      "[epoch: 3, batch:   1166] loss: 0.07859  | 0.18\n",
      "[epoch: 3, batch:   1168] loss: 0.13893  | 0.18\n",
      "[epoch: 3, batch:   1170] loss: 0.52517  | 0.18\n",
      "[epoch: 3, batch:   1172] loss: 0.31572  | 0.18\n",
      "[epoch: 3, batch:   1174] loss: 0.42855  | 0.18\n",
      "[epoch: 3, batch:   1176] loss: 0.05411  | 0.18\n",
      "[epoch: 3, batch:   1178] loss: 1.31676  | 0.18\n",
      "[epoch: 3, batch:   1180] loss: 0.11163  | 0.19\n",
      "[epoch: 3, batch:   1182] loss: 0.32992  | 0.18\n",
      "[epoch: 3, batch:   1184] loss: 0.12495  | 0.18\n",
      "[epoch: 3, batch:   1186] loss: 1.25115  | 0.18\n",
      "[epoch: 3, batch:   1188] loss: 0.37046  | 0.18\n",
      "[epoch: 3, batch:   1190] loss: 0.64868  | 0.18\n",
      "[epoch: 3, batch:   1192] loss: 0.33239  | 0.18\n",
      "[epoch: 3, batch:   1194] loss: 0.07023  | 0.18\n",
      "[epoch: 3, batch:   1196] loss: 0.27626  | 0.18\n",
      "[epoch: 3, batch:   1198] loss: 0.13537  | 0.20\n",
      "[epoch: 3, batch:   1200] loss: 0.06877  | 0.17\n",
      "[epoch: 3, batch:   1202] loss: 0.55757  | 0.18\n",
      "[epoch: 3, batch:   1204] loss: 0.16836  | 0.18\n",
      "[epoch: 3, batch:   1206] loss: 0.15959  | 0.18\n",
      "[epoch: 3, batch:   1208] loss: 0.15666  | 0.17\n",
      "[epoch: 3, batch:   1210] loss: 0.10556  | 0.18\n",
      "[epoch: 3, batch:   1212] loss: 0.24894  | 0.18\n",
      "[epoch: 3, batch:   1214] loss: 0.34683  | 0.18\n",
      "[epoch: 3, batch:   1216] loss: 0.19167  | 0.18\n",
      "[epoch: 3, batch:   1218] loss: 0.12833  | 0.18\n",
      "[epoch: 3, batch:   1220] loss: 1.13277  | 0.18\n",
      "[epoch: 3, batch:   1222] loss: 0.11054  | 0.18\n",
      "[epoch: 3, batch:   1224] loss: 0.23607  | 0.18\n",
      "[epoch: 3, batch:   1226] loss: 0.37986  | 0.18\n",
      "[epoch: 3, batch:   1228] loss: 0.25931  | 0.18\n",
      "[epoch: 3, batch:   1230] loss: 0.08316  | 0.18\n",
      "[epoch: 3, batch:   1232] loss: 0.28783  | 0.18\n",
      "[epoch: 3, batch:   1234] loss: 0.13605  | 0.18\n",
      "[epoch: 3, batch:   1236] loss: 0.34069  | 0.18\n",
      "[epoch: 3, batch:   1238] loss: 0.40186  | 0.18\n",
      "[epoch: 3, batch:   1240] loss: 0.19415  | 0.18\n",
      "[epoch: 3, batch:   1242] loss: 0.06471  | 0.18\n",
      "[epoch: 3, batch:   1244] loss: 0.37198  | 0.18\n",
      "[epoch: 3, batch:   1246] loss: 0.71136  | 0.18\n",
      "[epoch: 3, batch:   1248] loss: 0.12570  | 0.18\n",
      "[epoch: 3, batch:   1250] loss: 0.03601  | 0.18\n",
      "[epoch: 3, batch:   1252] loss: 0.08490  | 0.18\n",
      "[epoch: 3, batch:   1254] loss: 0.61927  | 0.18\n",
      "[epoch: 3, batch:   1256] loss: 0.21227  | 0.18\n",
      "[epoch: 3, batch:   1258] loss: 0.26833  | 0.18\n",
      "[epoch: 3, batch:   1260] loss: 0.08211  | 0.18\n",
      "[epoch: 3, batch:   1262] loss: 0.55365  | 0.18\n",
      "[epoch: 3, batch:   1264] loss: 0.13528  | 0.18\n",
      "[epoch: 3, batch:   1266] loss: 0.15959  | 0.18\n",
      "[epoch: 3, batch:   1268] loss: 0.29961  | 0.18\n",
      "[epoch: 3, batch:   1270] loss: 0.34450  | 0.18\n",
      "[epoch: 3, batch:   1272] loss: 0.12507  | 0.18\n",
      "[epoch: 3, batch:   1274] loss: 0.54140  | 0.18\n",
      "[epoch: 3, batch:   1276] loss: 0.09336  | 0.18\n",
      "[epoch: 3, batch:   1278] loss: 0.21087  | 0.18\n",
      "[epoch: 3, batch:   1280] loss: 0.13234  | 0.18\n",
      "[epoch: 3, batch:   1282] loss: 0.04100  | 0.18\n",
      "[epoch: 3, batch:   1284] loss: 0.31148  | 0.18\n",
      "[epoch: 3, batch:   1286] loss: 0.58290  | 0.18\n",
      "[epoch: 3, batch:   1288] loss: 0.06049  | 0.18\n",
      "[epoch: 3, batch:   1290] loss: 0.34453  | 0.18\n",
      "[epoch: 3, batch:   1292] loss: 0.19781  | 0.18\n",
      "[epoch: 3, batch:   1294] loss: 0.12697  | 0.19\n",
      "[epoch: 3, batch:   1296] loss: 0.31739  | 0.18\n",
      "[epoch: 3, batch:   1298] loss: 0.10124  | 0.18\n",
      "[epoch: 3, batch:   1300] loss: 0.25716  | 0.18\n",
      "[epoch: 3, batch:   1302] loss: 0.20546  | 0.18\n",
      "[epoch: 3, batch:   1304] loss: 0.16712  | 0.18\n",
      "[epoch: 3, batch:   1306] loss: 0.29106  | 0.18\n",
      "[epoch: 3, batch:   1308] loss: 0.28627  | 0.18\n",
      "[epoch: 3, batch:   1310] loss: 0.03221  | 0.18\n",
      "[epoch: 3, batch:   1312] loss: 0.08030  | 0.18\n",
      "[epoch: 3, batch:   1314] loss: 0.53912  | 0.19\n",
      "[epoch: 3, batch:   1316] loss: 0.06707  | 0.17\n",
      "[epoch: 3, batch:   1318] loss: 0.16853  | 0.18\n",
      "[epoch: 3, batch:   1320] loss: 0.07429  | 0.18\n",
      "[epoch: 3, batch:   1322] loss: 0.27933  | 0.18\n",
      "[epoch: 3, batch:   1324] loss: 0.11220  | 0.18\n",
      "[epoch: 3, batch:   1326] loss: 0.49803  | 0.18\n",
      "[epoch: 3, batch:   1328] loss: 0.43735  | 0.18\n",
      "[epoch: 3, batch:   1330] loss: 0.33886  | 0.18\n",
      "[epoch: 3, batch:   1332] loss: 0.35711  | 0.18\n",
      "[epoch: 3, batch:   1334] loss: 0.87349  | 0.18\n",
      "[epoch: 3, batch:   1336] loss: 0.13535  | 0.18\n",
      "[epoch: 3, batch:   1338] loss: 1.00038  | 0.18\n",
      "[epoch: 3, batch:   1340] loss: 0.16328  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 3, batch:   1342] loss: 0.05167  | 0.18\n",
      "[epoch: 3, batch:   1344] loss: 0.19265  | 0.18\n",
      "[epoch: 3, batch:   1346] loss: 0.31499  | 0.18\n",
      "[epoch: 3, batch:   1348] loss: 0.13119  | 0.18\n",
      "[epoch: 3, batch:   1350] loss: 0.31609  | 0.18\n",
      "[epoch: 3, batch:   1352] loss: 0.06176  | 0.18\n",
      "[epoch: 3, batch:   1354] loss: 0.05501  | 0.18\n",
      "[epoch: 3, batch:   1356] loss: 0.23517  | 0.18\n",
      "[epoch: 3, batch:   1358] loss: 0.20903  | 0.18\n",
      "[epoch: 3, batch:   1360] loss: 0.07722  | 0.18\n",
      "[epoch: 3, batch:   1362] loss: 0.18853  | 0.19\n",
      "[epoch: 3, batch:   1364] loss: 0.34041  | 0.18\n",
      "[epoch: 3, batch:   1366] loss: 0.11090  | 0.18\n",
      "[epoch: 3, batch:   1368] loss: 0.08515  | 0.18\n",
      "[epoch: 3, batch:   1370] loss: 0.18414  | 0.19\n",
      "[epoch: 3, batch:   1372] loss: 0.13474  | 0.18\n",
      "[epoch: 3, batch:   1374] loss: 0.24466  | 0.18\n",
      "[epoch: 3, batch:   1376] loss: 0.91273  | 0.18\n",
      "[epoch: 3, batch:   1378] loss: 0.59805  | 0.18\n",
      "[epoch: 3, batch:   1380] loss: 0.18426  | 0.18\n",
      "[epoch: 3, batch:   1382] loss: 0.06066  | 0.18\n",
      "[epoch: 3, batch:   1384] loss: 0.22140  | 0.18\n",
      "[epoch: 3, batch:   1386] loss: 0.15289  | 0.18\n",
      "[epoch: 3, batch:   1388] loss: 0.14948  | 0.18\n",
      "[epoch: 3, batch:   1390] loss: 0.03074  | 0.19\n",
      "[epoch: 3, batch:   1392] loss: 0.30463  | 0.18\n",
      "[epoch: 3, batch:   1394] loss: 0.02091  | 0.18\n",
      "[epoch: 3, batch:   1396] loss: 0.16223  | 0.18\n",
      "[epoch: 3, batch:   1398] loss: 0.04961  | 0.18\n",
      "[epoch: 3, batch:   1400] loss: 0.36906  | 0.18\n",
      "[epoch: 3, batch:   1402] loss: 0.36854  | 0.18\n",
      "[epoch: 3, batch:   1404] loss: 0.13923  | 0.18\n",
      "[epoch: 3, batch:   1406] loss: 0.44514  | 0.18\n",
      "[epoch: 3, batch:   1408] loss: 0.38380  | 0.18\n",
      "[epoch: 3, batch:   1410] loss: 0.32324  | 0.18\n",
      "[epoch: 3, batch:   1412] loss: 0.44248  | 0.18\n",
      "[epoch: 3, batch:   1414] loss: 0.07337  | 0.18\n",
      "[epoch: 3, batch:   1416] loss: 0.03908  | 0.18\n",
      "[epoch: 3, batch:   1418] loss: 0.26067  | 0.18\n",
      "[epoch: 3, batch:   1420] loss: 0.09037  | 0.18\n",
      "[epoch: 3, batch:   1422] loss: 0.22034  | 0.18\n",
      "[epoch: 3, batch:   1424] loss: 0.31083  | 0.18\n",
      "[epoch: 3, batch:   1426] loss: 0.34402  | 0.18\n",
      "[epoch: 3, batch:   1428] loss: 0.04147  | 0.18\n",
      "[epoch: 3, batch:   1430] loss: 0.74427  | 0.18\n",
      "[epoch: 3, batch:   1432] loss: 0.34770  | 0.18\n",
      "[epoch: 3, batch:   1434] loss: 0.01319  | 0.18\n",
      "[epoch: 3, batch:   1436] loss: 0.09917  | 0.18\n",
      "[epoch: 3, batch:   1438] loss: 0.18116  | 0.18\n",
      "[epoch: 3, batch:   1440] loss: 0.15029  | 0.18\n",
      "[epoch: 3, batch:   1442] loss: 1.03864  | 0.18\n",
      "[epoch: 3, batch:   1444] loss: 0.05379  | 0.18\n",
      "[epoch: 3, batch:   1446] loss: 0.21704  | 0.18\n",
      "[epoch: 3, batch:   1448] loss: 0.65605  | 0.18\n",
      "[epoch: 3, batch:   1450] loss: 0.34988  | 0.18\n",
      "[epoch: 3, batch:   1452] loss: 0.05691  | 0.18\n",
      "[epoch: 3, batch:   1454] loss: 0.03778  | 0.18\n",
      "[epoch: 3, batch:   1456] loss: 0.31274  | 0.18\n",
      "[epoch: 3, batch:   1458] loss: 1.65006  | 0.18\n",
      "[epoch: 3, batch:   1460] loss: 0.36676  | 0.18\n",
      "[epoch: 3, batch:   1462] loss: 0.13730  | 0.18\n",
      "[epoch: 3, batch:   1464] loss: 0.11666  | 0.18\n",
      "[epoch: 3, batch:   1466] loss: 0.20720  | 0.18\n",
      "[epoch: 3, batch:   1468] loss: 0.29788  | 0.18\n",
      "[epoch: 3, batch:   1470] loss: 0.13841  | 0.18\n",
      "[epoch: 3, batch:   1472] loss: 0.49832  | 0.18\n",
      "[epoch: 3, batch:   1474] loss: 0.75935  | 0.18\n",
      "[epoch: 3, batch:   1476] loss: 0.42826  | 0.18\n",
      "[epoch: 3, batch:   1478] loss: 0.38392  | 0.18\n",
      "[epoch: 3, batch:   1480] loss: 0.38280  | 0.19\n",
      "[epoch: 3, batch:   1482] loss: 0.19563  | 0.18\n",
      "[epoch: 3, batch:   1484] loss: 0.28008  | 0.18\n",
      "[epoch: 3, batch:   1486] loss: 0.36266  | 0.18\n",
      "[epoch: 3, batch:   1488] loss: 0.34459  | 0.18\n",
      "[epoch: 3, batch:   1490] loss: 0.09935  | 0.18\n",
      "[epoch: 3, batch:   1492] loss: 0.04893  | 0.18\n",
      "[epoch: 3, batch:   1494] loss: 0.21436  | 0.18\n",
      "[epoch: 3, batch:   1496] loss: 1.07826  | 0.18\n",
      "[epoch: 3, batch:   1498] loss: 0.50951  | 0.18\n",
      "[epoch: 3, batch:   1500] loss: 0.29528  | 0.19\n",
      "[epoch: 3, batch:   1502] loss: 0.27686  | 0.18\n",
      "[epoch: 3, batch:   1504] loss: 0.06337  | 0.17\n",
      "[epoch: 3, batch:   1506] loss: 0.30806  | 0.18\n",
      "[epoch: 3, batch:   1508] loss: 0.12905  | 0.18\n",
      "[epoch: 3, batch:   1510] loss: 0.16969  | 0.18\n",
      "[epoch: 3, batch:   1512] loss: 0.44461  | 0.18\n",
      "[epoch: 3, batch:   1514] loss: 0.21524  | 0.18\n",
      "[epoch: 3, batch:   1516] loss: 0.55306  | 0.18\n",
      "[epoch: 3, batch:   1518] loss: 0.37677  | 0.19\n",
      "[epoch: 3, batch:   1520] loss: 0.23344  | 0.17\n",
      "[epoch: 3, batch:   1522] loss: 0.23975  | 0.18\n",
      "[epoch: 3, batch:   1524] loss: 0.09057  | 0.17\n",
      "[epoch: 3, batch:   1526] loss: 2.21335  | 0.18\n",
      "[epoch: 3, batch:   1528] loss: 0.11559  | 0.18\n",
      "[epoch: 3, batch:   1530] loss: 0.21258  | 0.18\n",
      "[epoch: 3, batch:   1532] loss: 0.94406  | 0.18\n",
      "[epoch: 3, batch:   1534] loss: 0.05919  | 0.18\n",
      "[epoch: 3, batch:   1536] loss: 0.18345  | 0.18\n",
      "[epoch: 3, batch:   1538] loss: 0.07774  | 0.18\n",
      "[epoch: 3, batch:   1540] loss: 0.10278  | 0.19\n",
      "[epoch: 3, batch:   1542] loss: 0.61950  | 0.18\n",
      "[epoch: 3, batch:   1544] loss: 0.20915  | 0.18\n",
      "[epoch: 3, batch:   1546] loss: 0.46800  | 0.18\n",
      "[epoch: 3, batch:   1548] loss: 0.05871  | 0.18\n",
      "[epoch: 3, batch:   1550] loss: 0.08069  | 0.18\n",
      "[epoch: 3, batch:   1552] loss: 0.26509  | 0.18\n",
      "[epoch: 3, batch:   1554] loss: 0.54806  | 0.18\n",
      "[epoch: 3, batch:   1556] loss: 0.12415  | 0.18\n",
      "[epoch: 3, batch:   1558] loss: 0.06340  | 0.19\n",
      "[epoch: 3, batch:   1560] loss: 0.55398  | 0.17\n",
      "[epoch: 3, batch:   1562] loss: 0.29856  | 0.19\n",
      "[epoch: 3, batch:   1564] loss: 0.43768  | 0.18\n",
      "[epoch: 3, batch:   1566] loss: 0.39611  | 0.18\n",
      "[epoch: 3, batch:   1568] loss: 0.38694  | 0.18\n",
      "[epoch: 3, batch:   1570] loss: 0.14543  | 0.18\n",
      "[epoch: 3, batch:   1572] loss: 0.22534  | 0.18\n",
      "[epoch: 3, batch:   1574] loss: 0.47675  | 0.18\n",
      "[epoch: 3, batch:   1576] loss: 0.47711  | 0.18\n",
      "[epoch: 3, batch:   1578] loss: 0.08328  | 0.18\n",
      "[epoch: 3, batch:   1580] loss: 0.90950  | 0.18\n",
      "[epoch: 3, batch:   1582] loss: 0.31063  | 0.18\n",
      "[epoch: 3, batch:   1584] loss: 0.26693  | 0.18\n",
      "[epoch: 3, batch:   1586] loss: 0.44395  | 0.20\n",
      "[epoch: 3, batch:   1588] loss: 0.54938  | 0.18\n",
      "[epoch: 3, batch:   1590] loss: 0.43335  | 0.18\n",
      "[epoch: 3, batch:   1592] loss: 0.50641  | 0.18\n",
      "[epoch: 3, batch:   1594] loss: 0.15915  | 0.18\n",
      "[epoch: 3, batch:   1596] loss: 0.06423  | 0.18\n",
      "[epoch: 3, batch:   1598] loss: 0.61139  | 0.18\n",
      "[epoch: 3, batch:   1600] loss: 0.12437  | 0.19\n",
      "[epoch: 3, batch:   1602] loss: 0.03212  | 0.18\n",
      "[epoch: 3, batch:   1604] loss: 0.18083  | 0.18\n",
      "[epoch: 3, batch:   1606] loss: 0.10114  | 0.19\n",
      "[epoch: 3, batch:   1608] loss: 0.12110  | 0.17\n",
      "[epoch: 3, batch:   1610] loss: 0.07125  | 0.18\n",
      "[epoch: 3, batch:   1612] loss: 0.04179  | 0.18\n",
      "[epoch: 3, batch:   1614] loss: 0.28422  | 0.18\n",
      "[epoch: 3, batch:   1616] loss: 0.33308  | 0.18\n",
      "[epoch: 3, batch:   1618] loss: 0.86065  | 0.19\n",
      "[epoch: 3, batch:   1620] loss: 0.71759  | 0.17\n",
      "[epoch: 3, batch:   1622] loss: 1.69267  | 0.18\n",
      "[epoch: 3, batch:   1624] loss: 0.06761  | 0.18\n",
      "[epoch: 3, batch:   1626] loss: 0.23054  | 0.18\n",
      "[epoch: 3, batch:   1628] loss: 0.30787  | 0.18\n",
      "[epoch: 3, batch:   1630] loss: 0.53663  | 0.19\n",
      "[epoch: 3, batch:   1632] loss: 0.10792  | 0.18\n",
      "[epoch: 3, batch:   1634] loss: 0.02204  | 0.18\n",
      "[epoch: 3, batch:   1636] loss: 0.14524  | 0.18\n",
      "[epoch: 3, batch:   1638] loss: 0.14451  | 0.18\n",
      "[epoch: 3, batch:   1640] loss: 0.10987  | 0.18\n",
      "[epoch: 3, batch:   1642] loss: 0.12552  | 0.18\n",
      "[epoch: 3, batch:   1644] loss: 1.54856  | 0.18\n",
      "[epoch: 3, batch:   1646] loss: 0.39740  | 0.18\n",
      "[epoch: 3, batch:   1648] loss: 0.35616  | 0.18\n",
      "[epoch: 3, batch:   1650] loss: 0.21325  | 0.18\n",
      "[epoch: 3, batch:   1652] loss: 0.08097  | 0.18\n",
      "[epoch: 3, batch:   1654] loss: 0.17502  | 0.18\n",
      "[epoch: 3, batch:   1656] loss: 0.45327  | 0.18\n",
      "[epoch: 3, batch:   1658] loss: 1.74649  | 0.18\n",
      "[epoch: 3, batch:   1660] loss: 0.33990  | 0.18\n",
      "[epoch: 3, batch:   1662] loss: 0.24107  | 0.18\n",
      "[epoch: 3, batch:   1664] loss: 0.16011  | 0.18\n",
      "[epoch: 3, batch:   1666] loss: 0.09115  | 0.18\n",
      "[epoch: 3, batch:   1668] loss: 0.12268  | 0.18\n",
      "[epoch: 3, batch:   1670] loss: 0.10571  | 0.18\n",
      "[epoch: 3, batch:   1672] loss: 0.18858  | 0.18\n",
      "[epoch: 3, batch:   1674] loss: 0.12928  | 0.19\n",
      "[epoch: 3, batch:   1676] loss: 0.27891  | 0.18\n",
      "[epoch: 3, batch:   1678] loss: 0.29842  | 0.18\n",
      "[epoch: 3, batch:   1680] loss: 0.10442  | 0.18\n",
      "[epoch: 3, batch:   1682] loss: 0.06249  | 0.37\n",
      "[epoch: 3, batch:   1684] loss: 0.02537  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 3, batch:   1686] loss: 0.09080  | 0.18\n",
      "[epoch: 3, batch:   1688] loss: 0.06077  | 0.18\n",
      "[epoch: 3, batch:   1690] loss: 0.36677  | 0.18\n",
      "[epoch: 3, batch:   1692] loss: 0.13234  | 0.18\n",
      "[epoch: 3, batch:   1694] loss: 0.13317  | 0.18\n",
      "[epoch: 3, batch:   1696] loss: 0.09514  | 0.17\n",
      "[epoch: 3, batch:   1698] loss: 0.71506  | 0.18\n",
      "[epoch: 3, batch:   1700] loss: 0.25560  | 0.19\n",
      "[epoch: 3, batch:   1702] loss: 0.28422  | 0.18\n",
      "[epoch: 3, batch:   1704] loss: 0.28861  | 0.17\n",
      "[epoch: 3, batch:   1706] loss: 0.67007  | 0.18\n",
      "[epoch: 3, batch:   1708] loss: 0.10253  | 0.18\n",
      "[epoch: 3, batch:   1710] loss: 0.76391  | 0.19\n",
      "[epoch: 3, batch:   1712] loss: 0.02333  | 0.17\n",
      "[epoch: 3, batch:   1714] loss: 0.65387  | 0.18\n",
      "[epoch: 3, batch:   1716] loss: 0.34127  | 0.18\n",
      "[epoch: 3, batch:   1718] loss: 0.25636  | 0.18\n",
      "[epoch: 3, batch:   1720] loss: 0.37255  | 0.18\n",
      "[epoch: 3, batch:   1722] loss: 1.58147  | 0.18\n",
      "[epoch: 3, batch:   1724] loss: 0.37116  | 0.18\n",
      "[epoch: 3, batch:   1726] loss: 0.15750  | 0.18\n",
      "[epoch: 3, batch:   1728] loss: 0.41606  | 0.18\n",
      "[epoch: 3, batch:   1730] loss: 0.17603  | 0.19\n",
      "[epoch: 3, batch:   1732] loss: 0.46896  | 0.17\n",
      "[epoch: 3, batch:   1734] loss: 0.23902  | 0.18\n",
      "[epoch: 3, batch:   1736] loss: 0.17147  | 0.18\n",
      "[epoch: 3, batch:   1738] loss: 0.27002  | 0.18\n",
      "[epoch: 3, batch:   1740] loss: 0.24191  | 0.18\n",
      "[epoch: 3, batch:   1742] loss: 0.27395  | 0.18\n",
      "[epoch: 3, batch:   1744] loss: 1.02177  | 0.18\n",
      "[epoch: 3, batch:   1746] loss: 0.16581  | 0.18\n",
      "[epoch: 3, batch:   1748] loss: 0.18818  | 0.18\n",
      "[epoch: 3, batch:   1750] loss: 0.03910  | 0.19\n",
      "[epoch: 3, batch:   1752] loss: 0.16593  | 0.17\n",
      "[epoch: 3, batch:   1754] loss: 0.12160  | 0.18\n",
      "[epoch: 3, batch:   1756] loss: 0.36914  | 0.18\n",
      "[epoch: 3, batch:   1758] loss: 0.06403  | 0.18\n",
      "[epoch: 3, batch:   1760] loss: 0.40044  | 0.18\n",
      "[epoch: 3, batch:   1762] loss: 0.04085  | 0.18\n",
      "[epoch: 3, batch:   1764] loss: 0.28949  | 0.18\n",
      "[epoch: 3, batch:   1766] loss: 0.52855  | 0.18\n",
      "[epoch: 3, batch:   1768] loss: 0.06293  | 0.18\n",
      "[epoch: 3, batch:   1770] loss: 0.27926  | 0.18\n",
      "[epoch: 3, batch:   1772] loss: 0.25211  | 0.18\n",
      "[epoch: 3, batch:   1774] loss: 0.40912  | 0.18\n",
      "[epoch: 3, batch:   1776] loss: 0.39037  | 0.19\n",
      "[epoch: 3, batch:   1778] loss: 0.05457  | 0.18\n",
      "[epoch: 3, batch:   1780] loss: 0.03875  | 0.18\n",
      "[epoch: 3, batch:   1782] loss: 0.05106  | 0.18\n",
      "[epoch: 3, batch:   1784] loss: 0.07344  | 0.18\n",
      "[epoch: 3, batch:   1786] loss: 0.17458  | 0.18\n",
      "[epoch: 3, batch:   1788] loss: 0.10055  | 0.19\n",
      "[epoch: 3, batch:   1790] loss: 0.11030  | 0.18\n",
      "[epoch: 3, batch:   1792] loss: 0.91867  | 0.17\n",
      "[epoch: 3, batch:   1794] loss: 0.39474  | 0.18\n",
      "[epoch: 3, batch:   1796] loss: 0.04886  | 0.18\n",
      "[epoch: 3, batch:   1798] loss: 0.92898  | 0.19\n",
      "[epoch: 3, batch:   1800] loss: 0.03486  | 0.18\n",
      "[epoch: 3, batch:   1802] loss: 0.14099  | 0.18\n",
      "[epoch: 3, batch:   1804] loss: 0.26909  | 0.18\n",
      "[epoch: 3, batch:   1806] loss: 0.37372  | 0.18\n",
      "[epoch: 3, batch:   1808] loss: 0.21681  | 0.18\n",
      "[epoch: 3, batch:   1810] loss: 0.36451  | 0.18\n",
      "[epoch: 3, batch:   1812] loss: 0.06732  | 0.18\n",
      "[epoch: 3, batch:   1814] loss: 0.12108  | 0.67\n",
      "[epoch: 3, batch:   1816] loss: 0.06495  | 0.18\n",
      "[epoch: 3, batch:   1818] loss: 0.48004  | 0.18\n",
      "[epoch: 3, batch:   1820] loss: 0.55221  | 0.18\n",
      "[epoch: 3, batch:   1822] loss: 0.42839  | 0.18\n",
      "[epoch: 3, batch:   1824] loss: 0.19062  | 0.17\n",
      "[epoch: 3, batch:   1826] loss: 0.20635  | 0.17\n",
      "[epoch: 3, batch:   1828] loss: 0.01572  | 0.18\n",
      "[epoch: 3, batch:   1830] loss: 0.46024  | 0.19\n",
      "[epoch: 3, batch:   1832] loss: 0.05664  | 0.19\n",
      "[epoch: 3, batch:   1834] loss: 0.35677  | 0.17\n",
      "[epoch: 3, batch:   1836] loss: 0.76687  | 0.17\n",
      "[epoch: 3, batch:   1838] loss: 0.12554  | 0.18\n",
      "[epoch: 3, batch:   1840] loss: 0.07809  | 0.19\n",
      "[epoch: 3, batch:   1842] loss: 0.13536  | 0.17\n",
      "[epoch: 3, batch:   1844] loss: 0.40154  | 0.18\n",
      "[epoch: 3, batch:   1846] loss: 0.22421  | 0.18\n",
      "[epoch: 3, batch:   1848] loss: 0.11912  | 0.18\n",
      "[epoch: 3, batch:   1850] loss: 1.11897  | 0.18\n",
      "[epoch: 3, batch:   1852] loss: 0.12502  | 0.18\n",
      "[epoch: 3, batch:   1854] loss: 0.08089  | 0.18\n",
      "[epoch: 3, batch:   1856] loss: 0.29284  | 0.18\n",
      "[epoch: 3, batch:   1858] loss: 0.38856  | 0.18\n",
      "[epoch: 3, batch:   1860] loss: 0.23739  | 0.18\n",
      "[epoch: 3, batch:   1862] loss: 0.80060  | 0.18\n",
      "[epoch: 3, batch:   1864] loss: 0.59206  | 0.18\n",
      "[epoch: 3, batch:   1866] loss: 0.35639  | 0.18\n",
      "[epoch: 3, batch:   1868] loss: 0.14093  | 0.17\n",
      "[epoch: 3, batch:   1870] loss: 0.07641  | 0.18\n",
      "[epoch: 3, batch:   1872] loss: 0.16381  | 0.18\n",
      "[epoch: 3, batch:   1874] loss: 0.83754  | 0.18\n",
      "[epoch: 3, batch:   1876] loss: 0.22395  | 0.18\n",
      "[epoch: 3, batch:   1878] loss: 0.03575  | 0.18\n",
      "[epoch: 3, batch:   1880] loss: 0.06012  | 0.29\n",
      "[epoch: 3, batch:   1882] loss: 0.44636  | 0.18\n",
      "[epoch: 3, batch:   1884] loss: 0.07805  | 0.27\n",
      "[epoch: 3, batch:   1886] loss: 0.36580  | 0.18\n",
      "[epoch: 3, batch:   1888] loss: 0.10767  | 0.18\n",
      "[epoch: 3, batch:   1890] loss: 0.04882  | 0.18\n",
      "[epoch: 3, batch:   1892] loss: 0.09454  | 0.18\n",
      "[epoch: 3, batch:   1894] loss: 0.61523  | 0.18\n",
      "[epoch: 3, batch:   1896] loss: 0.46053  | 0.83\n",
      "[epoch: 3, batch:   1898] loss: 0.83027  | 0.17\n",
      "[epoch: 3, batch:   1900] loss: 0.41079  | 0.18\n",
      "[epoch: 3, batch:   1902] loss: 0.06767  | 0.17\n",
      "[epoch: 3, batch:   1904] loss: 0.24528  | 0.35\n",
      "[epoch: 3, batch:   1906] loss: 0.19658  | 0.18\n",
      "[epoch: 3, batch:   1908] loss: 0.23686  | 0.18\n",
      "[epoch: 3, batch:   1910] loss: 0.26894  | 0.17\n",
      "[epoch: 3, batch:   1912] loss: 0.10029  | 0.19\n",
      "[epoch: 3, batch:   1914] loss: 0.07502  | 0.18\n",
      "[epoch: 3, batch:   1916] loss: 0.16516  | 0.18\n",
      "[epoch: 3, batch:   1918] loss: 0.12426  | 0.17\n",
      "[epoch: 3, batch:   1920] loss: 0.14051  | 0.19\n",
      "[epoch: 3, batch:   1922] loss: 0.33122  | 0.60\n",
      "[epoch: 3, batch:   1924] loss: 0.56459  | 0.18\n",
      "[epoch: 3, batch:   1926] loss: 0.12034  | 0.18\n",
      "[epoch: 3, batch:   1928] loss: 0.61874  | 0.17\n",
      "[epoch: 3, batch:   1930] loss: 0.07350  | 0.18\n",
      "[epoch: 3, batch:   1932] loss: 0.54291  | 0.18\n",
      "[epoch: 3, batch:   1934] loss: 0.13036  | 0.18\n",
      "[epoch: 3, batch:   1936] loss: 0.05503  | 0.17\n",
      "[epoch: 3, batch:   1938] loss: 0.35431  | 0.18\n",
      "[epoch: 3, batch:   1940] loss: 0.63736  | 0.18\n",
      "[epoch: 3, batch:   1942] loss: 0.80454  | 0.18\n",
      "[epoch: 3, batch:   1944] loss: 0.40622  | 0.20\n",
      "[epoch: 3, batch:   1946] loss: 0.15490  | 0.18\n",
      "[epoch: 3, batch:   1948] loss: 0.41586  | 0.17\n",
      "[epoch: 3, batch:   1950] loss: 0.20353  | 0.18\n",
      "[epoch: 3, batch:   1952] loss: 0.07913  | 0.18\n",
      "[epoch: 3, batch:   1954] loss: 0.08650  | 0.17\n",
      "[epoch: 3, batch:   1956] loss: 0.47574  | 0.19\n",
      "[epoch: 3, batch:   1958] loss: 0.18002  | 0.18\n",
      "[epoch: 3, batch:   1960] loss: 0.30441  | 0.18\n",
      "[epoch: 3, batch:   1962] loss: 0.20850  | 0.18\n",
      "[epoch: 3, batch:   1964] loss: 0.19357  | 0.18\n",
      "[epoch: 3, batch:   1966] loss: 0.12294  | 0.18\n",
      "[epoch: 3, batch:   1968] loss: 0.18698  | 0.18\n",
      "[epoch: 3, batch:   1970] loss: 0.54712  | 0.19\n",
      "[epoch: 3, batch:   1972] loss: 1.26029  | 0.17\n",
      "[epoch: 3, batch:   1974] loss: 0.22282  | 0.18\n",
      "[epoch: 3, batch:   1976] loss: 0.27225  | 0.20\n",
      "[epoch: 3, batch:   1978] loss: 0.08417  | 0.18\n",
      "[epoch: 3, batch:   1980] loss: 0.06830  | 0.17\n",
      "[epoch: 3, batch:   1982] loss: 0.29375  | 0.18\n",
      "[epoch: 3, batch:   1984] loss: 0.52053  | 0.19\n",
      "[epoch: 3, batch:   1986] loss: 0.24568  | 0.18\n",
      "[epoch: 3, batch:   1988] loss: 0.04061  | 0.17\n",
      "[epoch: 3, batch:   1990] loss: 0.11316  | 0.18\n",
      "[epoch: 3, batch:   1992] loss: 0.40992  | 0.18\n",
      "[epoch: 3, batch:   1994] loss: 0.29502  | 0.18\n",
      "[epoch: 3, batch:   1996] loss: 0.13011  | 0.17\n",
      "[epoch: 3, batch:   1998] loss: 0.09534  | 0.18\n",
      "[epoch: 3, batch:   2000] loss: 0.17140  | 0.18\n",
      "[epoch: 3, batch:   2002] loss: 0.40505  | 0.18\n",
      "[epoch: 3, batch:   2004] loss: 0.29010  | 0.18\n",
      "[epoch: 3, batch:   2006] loss: 1.62458  | 0.18\n",
      "[epoch: 3, batch:   2008] loss: 0.22599  | 0.19\n",
      "[epoch: 3, batch:   2010] loss: 0.45002  | 0.18\n",
      "[epoch: 3, batch:   2012] loss: 0.16359  | 0.18\n",
      "[epoch: 3, batch:   2014] loss: 0.55748  | 0.18\n",
      "[epoch: 3, batch:   2016] loss: 0.05296  | 0.18\n",
      "[epoch: 3, batch:   2018] loss: 0.14470  | 0.18\n",
      "[epoch: 3, batch:   2020] loss: 0.27242  | 0.18\n",
      "[epoch: 3, batch:   2022] loss: 0.09646  | 0.18\n",
      "[epoch: 3, batch:   2024] loss: 0.62922  | 0.18\n",
      "[epoch: 3, batch:   2026] loss: 0.16485  | 0.18\n",
      "[epoch: 3, batch:   2028] loss: 0.40289  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 3, batch:   2030] loss: 0.36127  | 0.18\n",
      "[epoch: 3, batch:   2032] loss: 0.14054  | 0.18\n",
      "[epoch: 3, batch:   2034] loss: 0.33134  | 0.18\n",
      "[epoch: 3, batch:   2036] loss: 0.06117  | 0.18\n",
      "[epoch: 3, batch:   2038] loss: 0.72115  | 0.18\n",
      "[epoch: 3, batch:   2040] loss: 0.58024  | 0.18\n",
      "[epoch: 3, batch:   2042] loss: 0.93537  | 0.18\n",
      "[epoch: 3, batch:   2044] loss: 0.19308  | 0.18\n",
      "[epoch: 3, batch:   2046] loss: 0.10920  | 0.18\n",
      "[epoch: 3, batch:   2048] loss: 0.17666  | 0.18\n",
      "[epoch: 3, batch:   2050] loss: 0.10420  | 0.18\n",
      "[epoch: 3, batch:   2052] loss: 0.10559  | 0.18\n",
      "[epoch: 3, batch:   2054] loss: 0.03891  | 0.18\n",
      "[epoch: 3, batch:   2056] loss: 0.31456  | 0.18\n",
      "[epoch: 3, batch:   2058] loss: 0.13182  | 0.18\n",
      "[epoch: 3, batch:   2060] loss: 0.13234  | 0.18\n",
      "[epoch: 3, batch:   2062] loss: 0.16137  | 0.18\n",
      "[epoch: 3, batch:   2064] loss: 0.11299  | 0.18\n",
      "[epoch: 3, batch:   2066] loss: 0.02382  | 0.18\n",
      "[epoch: 3, batch:   2068] loss: 0.50739  | 0.18\n",
      "[epoch: 3, batch:   2070] loss: 1.04836  | 0.18\n",
      "[epoch: 3, batch:   2072] loss: 0.12426  | 0.18\n",
      "[epoch: 3, batch:   2074] loss: 0.16667  | 0.18\n",
      "[epoch: 3, batch:   2076] loss: 0.11908  | 0.18\n",
      "[epoch: 3, batch:   2078] loss: 0.39275  | 0.18\n",
      "[epoch: 3, batch:   2080] loss: 0.56714  | 0.18\n",
      "[epoch: 3, batch:   2082] loss: 0.12311  | 0.18\n",
      "[epoch: 3, batch:   2084] loss: 0.23997  | 0.18\n",
      "[epoch: 3, batch:   2086] loss: 0.62371  | 0.18\n",
      "[epoch: 3, batch:   2088] loss: 0.08456  | 0.18\n",
      "[epoch: 3, batch:   2090] loss: 0.15532  | 0.18\n",
      "[epoch: 3, batch:   2092] loss: 0.09843  | 0.18\n",
      "[epoch: 3, batch:   2094] loss: 0.23105  | 0.18\n",
      "[epoch: 3, batch:   2096] loss: 0.04413  | 0.18\n",
      "[epoch: 3, batch:   2098] loss: 0.04140  | 0.18\n",
      "[epoch: 3, batch:   2100] loss: 0.09790  | 0.18\n",
      "[epoch: 3, batch:   2102] loss: 0.43565  | 0.19\n",
      "[epoch: 3, batch:   2104] loss: 0.24402  | 0.18\n",
      "[epoch: 3, batch:   2106] loss: 0.05551  | 0.18\n",
      "[epoch: 3, batch:   2108] loss: 0.10664  | 0.20\n",
      "[epoch: 3, batch:   2110] loss: 0.38140  | 0.18\n",
      "[epoch: 3, batch:   2112] loss: 0.06587  | 0.18\n",
      "[epoch: 3, batch:   2114] loss: 0.03390  | 0.18\n",
      "[epoch: 3, batch:   2116] loss: 0.10755  | 0.19\n",
      "[epoch: 3, batch:   2118] loss: 0.08129  | 0.18\n",
      "[epoch: 3, batch:   2120] loss: 0.26899  | 0.17\n",
      "[epoch: 3, batch:   2122] loss: 0.07509  | 0.18\n",
      "[epoch: 3, batch:   2124] loss: 0.18023  | 0.19\n",
      "[epoch: 3, batch:   2126] loss: 0.04903  | 0.18\n",
      "[epoch: 3, batch:   2128] loss: 0.16974  | 0.18\n",
      "[epoch: 3, batch:   2130] loss: 0.34877  | 0.18\n",
      "[epoch: 3, batch:   2132] loss: 0.03166  | 0.18\n",
      "[epoch: 3, batch:   2134] loss: 0.36919  | 0.18\n",
      "[epoch: 3, batch:   2136] loss: 0.13724  | 0.18\n",
      "[epoch: 3, batch:   2138] loss: 0.08646  | 0.18\n",
      "[epoch: 3, batch:   2140] loss: 0.43913  | 0.96\n",
      "[epoch: 3, batch:   2142] loss: 0.05270  | 0.18\n",
      "[epoch: 3, batch:   2144] loss: 0.54286  | 0.18\n",
      "[epoch: 3, batch:   2146] loss: 0.30912  | 0.19\n",
      "[epoch: 3, batch:   2148] loss: 0.08075  | 0.18\n",
      "[epoch: 3, batch:   2150] loss: 0.31285  | 0.17\n",
      "[epoch: 3, batch:   2152] loss: 0.32195  | 0.18\n",
      "[epoch: 3, batch:   2154] loss: 0.44934  | 0.18\n",
      "[epoch: 3, batch:   2156] loss: 0.26278  | 0.18\n",
      "[epoch: 3, batch:   2158] loss: 1.57828  | 0.18\n",
      "[epoch: 3, batch:   2160] loss: 0.66843  | 0.18\n",
      "[epoch: 3, batch:   2162] loss: 0.43315  | 0.18\n",
      "[epoch: 3, batch:   2164] loss: 0.31989  | 0.18\n",
      "[epoch: 3, batch:   2166] loss: 0.05725  | 0.18\n",
      "[epoch: 3, batch:   2168] loss: 0.10324  | 0.18\n",
      "[epoch: 3, batch:   2170] loss: 0.06871  | 0.18\n",
      "[epoch: 3, batch:   2172] loss: 0.08578  | 0.18\n",
      "[epoch: 3, batch:   2174] loss: 0.04994  | 0.18\n",
      "[epoch: 3, batch:   2176] loss: 0.09588  | 0.18\n",
      "[epoch: 3, batch:   2178] loss: 0.28126  | 0.18\n",
      "[epoch: 3, batch:   2180] loss: 0.16978  | 0.18\n",
      "[epoch: 3, batch:   2182] loss: 0.02701  | 0.18\n",
      "[epoch: 3, batch:   2184] loss: 0.66807  | 0.60\n",
      "[epoch: 3, batch:   2186] loss: 0.24378  | 0.18\n",
      "[epoch: 3, batch:   2188] loss: 0.14643  | 0.18\n",
      "[epoch: 3, batch:   2190] loss: 0.32794  | 0.18\n",
      "[epoch: 3, batch:   2192] loss: 0.42000  | 0.18\n",
      "[epoch: 3, batch:   2194] loss: 0.26518  | 0.18\n",
      "[epoch: 3, batch:   2196] loss: 0.54691  | 0.18\n",
      "[epoch: 3, batch:   2198] loss: 0.47609  | 0.18\n",
      "[epoch: 3, batch:   2200] loss: 0.07955  | 0.18\n",
      "[epoch: 3, batch:   2202] loss: 0.14960  | 0.18\n",
      "[epoch: 3, batch:   2204] loss: 0.12949  | 0.72\n",
      "[epoch: 3, batch:   2206] loss: 0.21607  | 0.17\n",
      "[epoch: 3, batch:   2208] loss: 0.07696  | 0.18\n",
      "[epoch: 3, batch:   2210] loss: 0.03993  | 0.18\n",
      "[epoch: 3, batch:   2212] loss: 0.03315  | 0.18\n",
      "[epoch: 3, batch:   2214] loss: 0.36213  | 0.17\n",
      "[epoch: 3, batch:   2216] loss: 0.12189  | 0.18\n",
      "[epoch: 3, batch:   2218] loss: 0.12135  | 0.18\n",
      "[epoch: 3, batch:   2220] loss: 0.10299  | 0.18\n",
      "[epoch: 3, batch:   2222] loss: 0.17143  | 0.18\n",
      "[epoch: 3, batch:   2224] loss: 0.08012  | 0.18\n",
      "[epoch: 3, batch:   2226] loss: 0.09960  | 1.19\n",
      "[epoch: 3, batch:   2228] loss: 0.20954  | 0.17\n",
      "[epoch: 3, batch:   2230] loss: 0.45079  | 0.18\n",
      "[epoch: 3, batch:   2232] loss: 0.49171  | 0.18\n",
      "[epoch: 3, batch:   2234] loss: 0.06423  | 0.65\n",
      "[epoch: 3, batch:   2236] loss: 0.02633  | 0.18\n",
      "[epoch: 3, batch:   2238] loss: 0.80314  | 0.18\n",
      "[epoch: 3, batch:   2240] loss: 1.04547  | 0.17\n",
      "[epoch: 3, batch:   2242] loss: 0.63491  | 0.18\n",
      "[epoch: 3, batch:   2244] loss: 0.16440  | 0.18\n",
      "[epoch: 3, batch:   2246] loss: 0.04394  | 0.18\n",
      "[epoch: 3, batch:   2248] loss: 0.44022  | 0.17\n",
      "[epoch: 3, batch:   2250] loss: 0.07164  | 0.18\n",
      "[epoch: 3, batch:   2252] loss: 0.73927  | 0.19\n",
      "[epoch: 3, batch:   2254] loss: 0.74294  | 0.18\n",
      "[epoch: 3, batch:   2256] loss: 0.05471  | 0.17\n",
      "[epoch: 3, batch:   2258] loss: 0.18497  | 0.18\n",
      "[epoch: 3, batch:   2260] loss: 0.78821  | 0.40\n",
      "[epoch: 3, batch:   2262] loss: 0.08302  | 0.18\n",
      "[epoch: 3, batch:   2264] loss: 0.30396  | 0.18\n",
      "[epoch: 3, batch:   2266] loss: 0.06278  | 0.17\n",
      "[epoch: 3, batch:   2268] loss: 0.25563  | 0.18\n",
      "[epoch: 3, batch:   2270] loss: 0.36007  | 0.18\n",
      "[epoch: 3, batch:   2272] loss: 0.48593  | 0.19\n",
      "[epoch: 3, batch:   2274] loss: 0.24282  | 0.17\n",
      "[epoch: 3, batch:   2276] loss: 0.15908  | 0.50\n",
      "[epoch: 3, batch:   2278] loss: 0.21805  | 0.18\n",
      "[epoch: 3, batch:   2280] loss: 0.28860  | 0.18\n",
      "[epoch: 3, batch:   2282] loss: 0.30617  | 0.18\n",
      "[epoch: 3, batch:   2284] loss: 0.68301  | 0.19\n",
      "[epoch: 3, batch:   2286] loss: 0.01840  | 0.17\n",
      "[epoch: 3, batch:   2288] loss: 0.20791  | 0.18\n",
      "[epoch: 3, batch:   2290] loss: 0.17756  | 0.18\n",
      "[epoch: 3, batch:   2292] loss: 0.68696  | 0.18\n",
      "[epoch: 3, batch:   2294] loss: 0.13144  | 0.18\n",
      "[epoch: 3, batch:   2296] loss: 0.11306  | 0.18\n",
      "[epoch: 3, batch:   2298] loss: 0.46801  | 0.18\n",
      "[epoch: 3, batch:   2300] loss: 0.39811  | 0.38\n",
      "[epoch: 3, batch:   2302] loss: 0.35876  | 0.17\n",
      "[epoch: 3, batch:   2304] loss: 0.13341  | 0.18\n",
      "[epoch: 3, batch:   2306] loss: 0.01271  | 0.18\n",
      "[epoch: 3, batch:   2308] loss: 0.64520  | 0.42\n",
      "[epoch: 3, batch:   2310] loss: 0.16423  | 0.17\n",
      "[epoch: 3, batch:   2312] loss: 0.21738  | 0.17\n",
      "[epoch: 3, batch:   2314] loss: 0.63194  | 0.18\n",
      "[epoch: 3, batch:   2316] loss: 0.83720  | 0.19\n",
      "[epoch: 3, batch:   2318] loss: 0.03706  | 0.17\n",
      "[epoch: 3, batch:   2320] loss: 0.34868  | 0.17\n",
      "[epoch: 3, batch:   2322] loss: 0.58220  | 0.18\n",
      "[epoch: 3, batch:   2324] loss: 0.59292  | 0.18\n",
      "[epoch: 3, batch:   2326] loss: 0.04576  | 0.33\n",
      "[epoch: 3, batch:   2328] loss: 0.65925  | 0.17\n",
      "[epoch: 3, batch:   2330] loss: 0.20484  | 0.17\n",
      "[epoch: 3, batch:   2332] loss: 0.07809  | 0.18\n",
      "[epoch: 3, batch:   2334] loss: 0.13670  | 0.19\n",
      "[epoch: 3, batch:   2336] loss: 0.10819  | 0.17\n",
      "[epoch: 3, batch:   2338] loss: 0.39983  | 0.96\n",
      "[epoch: 3, batch:   2340] loss: 1.04853  | 0.18\n",
      "[epoch: 3, batch:   2342] loss: 0.72005  | 0.17\n",
      "[epoch: 3, batch:   2344] loss: 0.13039  | 0.17\n",
      "[epoch: 3, batch:   2346] loss: 0.30668  | 0.18\n",
      "[epoch: 3, batch:   2348] loss: 0.08267  | 0.18\n",
      "[epoch: 3, batch:   2350] loss: 0.20716  | 0.18\n",
      "[epoch: 3, batch:   2352] loss: 0.85790  | 0.18\n",
      "[epoch: 3, batch:   2354] loss: 0.11533  | 0.18\n",
      "[epoch: 3, batch:   2356] loss: 0.17889  | 0.18\n",
      "[epoch: 3, batch:   2358] loss: 0.10708  | 0.19\n",
      "[epoch: 3, batch:   2360] loss: 0.42440  | 0.17\n",
      "[epoch: 3, batch:   2362] loss: 0.24857  | 0.17\n",
      "[epoch: 3, batch:   2364] loss: 0.19956  | 0.18\n",
      "[epoch: 3, batch:   2366] loss: 0.33173  | 0.18\n",
      "[epoch: 3, batch:   2368] loss: 0.08484  | 0.17\n",
      "[epoch: 3, batch:   2370] loss: 0.13318  | 0.18\n",
      "[epoch: 3, batch:   2372] loss: 0.49342  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 3, batch:   2374] loss: 0.03407  | 0.18\n",
      "[epoch: 3, batch:   2376] loss: 0.11120  | 0.18\n",
      "[epoch: 3, batch:   2378] loss: 0.27440  | 0.18\n",
      "[epoch: 3, batch:   2380] loss: 0.23813  | 0.17\n",
      "[epoch: 3, batch:   2382] loss: 0.12382  | 0.18\n",
      "[epoch: 3, batch:   2384] loss: 0.03151  | 0.18\n",
      "[epoch: 3, batch:   2386] loss: 0.14318  | 0.18\n",
      "[epoch: 3, batch:   2388] loss: 0.17295  | 0.19\n",
      "[epoch: 3, batch:   2390] loss: 0.02711  | 0.18\n",
      "[epoch: 3, batch:   2392] loss: 0.19343  | 0.17\n",
      "[epoch: 3, batch:   2394] loss: 0.23818  | 0.18\n",
      "[epoch: 3, batch:   2396] loss: 0.17551  | 0.19\n",
      "[epoch: 3, batch:   2398] loss: 0.12369  | 0.30\n",
      "[epoch: 3, batch:   2400] loss: 0.35024  | 0.18\n",
      "[epoch: 3, batch:   2402] loss: 0.11938  | 0.18\n",
      "[epoch: 3, batch:   2404] loss: 0.06209  | 0.17\n",
      "[epoch: 3, batch:   2406] loss: 0.12220  | 0.18\n",
      "[epoch: 3, batch:   2408] loss: 0.16129  | 0.17\n",
      "[epoch: 3, batch:   2410] loss: 0.15353  | 0.18\n",
      "[epoch: 3, batch:   2412] loss: 0.13184  | 0.17\n",
      "[epoch: 3, batch:   2414] loss: 0.08129  | 0.18\n",
      "[epoch: 3, batch:   2416] loss: 0.09019  | 0.73\n",
      "[epoch: 3, batch:   2418] loss: 0.18970  | 0.17\n",
      "[epoch: 3, batch:   2420] loss: 0.05243  | 0.18\n",
      "[epoch: 3, batch:   2422] loss: 0.57680  | 0.17\n",
      "[epoch: 3, batch:   2424] loss: 0.05829  | 0.18\n",
      "[epoch: 3, batch:   2426] loss: 0.07143  | 0.18\n",
      "[epoch: 3, batch:   2428] loss: 0.44468  | 0.18\n",
      "[epoch: 3, batch:   2430] loss: 0.43819  | 0.17\n",
      "[epoch: 3, batch:   2432] loss: 0.36825  | 0.18\n",
      "[epoch: 3, batch:   2434] loss: 0.12826  | 0.18\n",
      "[epoch: 3, batch:   2436] loss: 0.07177  | 0.19\n",
      "[epoch: 3, batch:   2438] loss: 0.03908  | 0.18\n",
      "[epoch: 3, batch:   2440] loss: 0.16003  | 0.18\n",
      "[epoch: 3, batch:   2442] loss: 0.45279  | 0.18\n",
      "[epoch: 3, batch:   2444] loss: 0.12558  | 0.18\n",
      "[epoch: 3, batch:   2446] loss: 0.44770  | 0.53\n",
      "[epoch: 3, batch:   2448] loss: 0.06265  | 0.18\n",
      "[epoch: 3, batch:   2450] loss: 0.06011  | 0.18\n",
      "[epoch: 3, batch:   2452] loss: 0.22148  | 0.17\n",
      "[epoch: 3, batch:   2454] loss: 0.61162  | 0.18\n",
      "[epoch: 3, batch:   2456] loss: 0.86035  | 0.18\n",
      "[epoch: 3, batch:   2458] loss: 0.02660  | 0.19\n",
      "[epoch: 3, batch:   2460] loss: 0.18575  | 0.17\n",
      "[epoch: 3, batch:   2462] loss: 0.02328  | 0.18\n",
      "[epoch: 3, batch:   2464] loss: 0.05109  | 0.18\n",
      "[epoch: 3, batch:   2466] loss: 0.12779  | 0.19\n",
      "[epoch: 3, batch:   2468] loss: 0.24838  | 0.17\n",
      "[epoch: 3, batch:   2470] loss: 0.03967  | 0.19\n",
      "[epoch: 3, batch:   2472] loss: 0.08290  | 0.18\n",
      "[epoch: 3, batch:   2474] loss: 0.12996  | 0.18\n",
      "[epoch: 3, batch:   2476] loss: 0.41712  | 0.19\n",
      "[epoch: 3, batch:   2478] loss: 1.28286  | 0.18\n",
      "[epoch: 3, batch:   2480] loss: 0.35963  | 0.17\n",
      "[epoch: 3, batch:   2482] loss: 0.26865  | 0.18\n",
      "[epoch: 3, batch:   2484] loss: 0.07209  | 0.18\n",
      "[epoch: 3, batch:   2486] loss: 0.30775  | 0.18\n",
      "[epoch: 3, batch:   2488] loss: 0.75206  | 0.19\n",
      "[epoch: 3, batch:   2490] loss: 0.10202  | 0.18\n",
      "[epoch: 3, batch:   2492] loss: 0.35925  | 0.18\n",
      "[epoch: 3, batch:   2494] loss: 0.09411  | 0.18\n",
      "[epoch: 3, batch:   2496] loss: 0.07419  | 0.18\n",
      "[epoch: 3, batch:   2498] loss: 0.04785  | 0.18\n",
      "[epoch: 3, batch:   2500] loss: 0.21497  | 0.18\n",
      "[epoch: 3, batch:   2502] loss: 0.43973  | 0.18\n",
      "[epoch: 3, batch:   2504] loss: 0.55633  | 0.18\n",
      "[epoch: 3, batch:   2506] loss: 0.28340  | 0.18\n",
      "[epoch: 3, batch:   2508] loss: 0.10966  | 0.18\n",
      "[epoch: 3, batch:   2510] loss: 0.26517  | 0.18\n",
      "[epoch: 3, batch:   2512] loss: 0.55348  | 0.18\n",
      "[epoch: 3, batch:   2514] loss: 0.01927  | 0.18\n",
      "[epoch: 3, batch:   2516] loss: 0.30817  | 0.18\n",
      "[epoch: 3, batch:   2518] loss: 0.30660  | 0.18\n",
      "[epoch: 3, batch:   2520] loss: 0.08623  | 0.20\n",
      "[epoch: 3, batch:   2522] loss: 0.54345  | 0.18\n",
      "[epoch: 3, batch:   2524] loss: 0.34805  | 0.17\n",
      "[epoch: 3, batch:   2526] loss: 0.62473  | 0.18\n",
      "[epoch: 3, batch:   2528] loss: 0.76999  | 0.19\n",
      "[epoch: 3, batch:   2530] loss: 0.06285  | 0.18\n",
      "[epoch: 3, batch:   2532] loss: 1.42800  | 0.18\n",
      "[epoch: 3, batch:   2534] loss: 0.09960  | 0.18\n",
      "[epoch: 3, batch:   2536] loss: 0.34907  | 0.19\n",
      "[epoch: 3, batch:   2538] loss: 0.12920  | 0.35\n",
      "[epoch: 3, batch:   2540] loss: 0.06432  | 0.60\n",
      "[epoch: 3, batch:   2542] loss: 0.04719  | 0.17\n",
      "[epoch: 3, batch:   2544] loss: 0.18628  | 0.18\n",
      "[epoch: 3, batch:   2546] loss: 0.11827  | 0.18\n",
      "[epoch: 3, batch:   2548] loss: 0.08109  | 0.18\n",
      "[epoch: 3, batch:   2550] loss: 0.27250  | 0.17\n",
      "[epoch: 3, batch:   2552] loss: 1.04750  | 0.18\n",
      "[epoch: 3, batch:   2554] loss: 0.32924  | 0.19\n",
      "[epoch: 3, batch:   2556] loss: 1.35565  | 0.18\n",
      "[epoch: 3, batch:   2558] loss: 0.16248  | 0.19\n",
      "[epoch: 3, batch:   2560] loss: 0.04512  | 0.18\n",
      "[epoch: 3, batch:   2562] loss: 0.08001  | 0.18\n",
      "[epoch: 3, batch:   2564] loss: 0.22638  | 0.18\n",
      "[epoch: 3, batch:   2566] loss: 0.43801  | 0.18\n",
      "[epoch: 3, batch:   2568] loss: 0.38476  | 0.17\n",
      "[epoch: 3, batch:   2570] loss: 0.71321  | 0.19\n",
      "[epoch: 3, batch:   2572] loss: 0.01757  | 0.17\n",
      "[epoch: 3, batch:   2574] loss: 0.01111  | 0.18\n",
      "[epoch: 3, batch:   2576] loss: 0.48638  | 0.17\n",
      "[epoch: 3, batch:   2578] loss: 0.06926  | 0.18\n",
      "[epoch: 3, batch:   2580] loss: 0.07523  | 0.38\n",
      "[epoch: 3, batch:   2582] loss: 0.54225  | 0.17\n",
      "[epoch: 3, batch:   2584] loss: 0.36624  | 0.18\n",
      "[epoch: 3, batch:   2586] loss: 1.02446  | 0.18\n",
      "[epoch: 3, batch:   2588] loss: 0.28303  | 0.19\n",
      "[epoch: 3, batch:   2590] loss: 0.25372  | 0.17\n",
      "[epoch: 3, batch:   2592] loss: 0.44069  | 0.17\n",
      "[epoch: 3, batch:   2594] loss: 0.33352  | 0.17\n",
      "[epoch: 3, batch:   2596] loss: 0.38516  | 0.19\n",
      "[epoch: 3, batch:   2598] loss: 0.25970  | 0.18\n",
      "[epoch: 3, batch:   2600] loss: 0.06400  | 0.18\n",
      "[epoch: 3, batch:   2602] loss: 0.20316  | 0.18\n",
      "[epoch: 3, batch:   2604] loss: 0.10531  | 0.18\n",
      "[epoch: 3, batch:   2606] loss: 0.18423  | 0.18\n",
      "[epoch: 3, batch:   2608] loss: 0.07469  | 0.30\n",
      "[epoch: 3, batch:   2610] loss: 0.20404  | 0.17\n",
      "[epoch: 3, batch:   2612] loss: 0.45277  | 0.18\n",
      "[epoch: 3, batch:   2614] loss: 0.08747  | 0.18\n",
      "[epoch: 3, batch:   2616] loss: 0.49493  | 0.19\n",
      "[epoch: 3, batch:   2618] loss: 0.15450  | 0.18\n",
      "[epoch: 3, batch:   2620] loss: 0.10729  | 0.18\n",
      "[epoch: 3, batch:   2622] loss: 0.35717  | 0.18\n",
      "[epoch: 3, batch:   2624] loss: 0.33214  | 0.19\n",
      "[epoch: 3, batch:   2626] loss: 0.36187  | 0.17\n",
      "[epoch: 3, batch:   2628] loss: 0.02845  | 0.18\n",
      "[epoch: 3, batch:   2630] loss: 0.14568  | 0.18\n",
      "[epoch: 3, batch:   2632] loss: 0.19473  | 0.18\n",
      "[epoch: 3, batch:   2634] loss: 0.29221  | 0.17\n",
      "[epoch: 3, batch:   2636] loss: 0.19816  | 0.18\n",
      "[epoch: 3, batch:   2638] loss: 0.08324  | 0.18\n",
      "[epoch: 3, batch:   2640] loss: 0.18252  | 0.18\n",
      "[epoch: 3, batch:   2642] loss: 0.08717  | 0.18\n",
      "[epoch: 3, batch:   2644] loss: 1.21594  | 0.18\n",
      "[epoch: 3, batch:   2646] loss: 0.54172  | 0.18\n",
      "[epoch: 3, batch:   2648] loss: 0.03650  | 0.18\n",
      "[epoch: 3, batch:   2650] loss: 0.23990  | 0.18\n",
      "[epoch: 3, batch:   2652] loss: 0.39196  | 0.18\n",
      "[epoch: 3, batch:   2654] loss: 0.20167  | 0.18\n",
      "[epoch: 3, batch:   2656] loss: 0.01688  | 0.18\n",
      "[epoch: 3, batch:   2658] loss: 0.08070  | 0.18\n",
      "[epoch: 3, batch:   2660] loss: 0.47909  | 0.18\n",
      "[epoch: 3, batch:   2662] loss: 1.04157  | 0.18\n",
      "[epoch: 3, batch:   2664] loss: 0.49730  | 0.18\n",
      "[epoch: 3, batch:   2666] loss: 0.36736  | 0.19\n",
      "[epoch: 3, batch:   2668] loss: 0.24459  | 0.18\n",
      "[epoch: 3, batch:   2670] loss: 0.13426  | 0.17\n",
      "[epoch: 3, batch:   2672] loss: 0.19193  | 0.17\n",
      "[epoch: 3, batch:   2674] loss: 0.27828  | 0.19\n",
      "[epoch: 3, batch:   2676] loss: 0.75407  | 0.18\n",
      "[epoch: 3, batch:   2678] loss: 0.15295  | 0.17\n",
      "[epoch: 3, batch:   2680] loss: 0.01724  | 0.18\n",
      "[epoch: 3, batch:   2682] loss: 0.16618  | 0.18\n",
      "[epoch: 3, batch:   2684] loss: 0.12151  | 0.18\n",
      "[epoch: 3, batch:   2686] loss: 0.53295  | 0.18\n",
      "[epoch: 3, batch:   2688] loss: 0.28292  | 0.18\n",
      "[epoch: 3, batch:   2690] loss: 0.07606  | 0.18\n",
      "[epoch: 3, batch:   2692] loss: 0.31454  | 0.43\n",
      "[epoch: 3, batch:   2694] loss: 0.13614  | 0.18\n",
      "[epoch: 3, batch:   2696] loss: 0.30626  | 0.18\n",
      "[epoch: 3, batch:   2698] loss: 0.31998  | 0.19\n",
      "[epoch: 3, batch:   2700] loss: 0.16959  | 0.17\n",
      "[epoch: 3, batch:   2702] loss: 0.40131  | 0.18\n",
      "[epoch: 3, batch:   2704] loss: 0.99266  | 0.18\n",
      "[epoch: 3, batch:   2706] loss: 0.18982  | 0.18\n",
      "[epoch: 3, batch:   2708] loss: 0.42509  | 0.18\n",
      "[epoch: 3, batch:   2710] loss: 0.54742  | 0.28\n",
      "[epoch: 3, batch:   2712] loss: 0.02770  | 0.18\n",
      "[epoch: 3, batch:   2714] loss: 0.02364  | 0.42\n",
      "[epoch: 3, batch:   2716] loss: 0.58871  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 3, batch:   2718] loss: 0.30174  | 0.18\n",
      "[epoch: 3, batch:   2720] loss: 0.50585  | 0.17\n",
      "[epoch: 3, batch:   2722] loss: 0.77034  | 0.37\n",
      "[epoch: 3, batch:   2724] loss: 0.35758  | 0.19\n",
      "[epoch: 3, batch:   2726] loss: 0.14185  | 0.18\n",
      "[epoch: 3, batch:   2728] loss: 0.23791  | 0.17\n",
      "[epoch: 3, batch:   2730] loss: 0.35944  | 0.35\n",
      "[epoch: 3, batch:   2732] loss: 0.06485  | 0.28\n",
      "[epoch: 3, batch:   2734] loss: 0.04919  | 0.17\n",
      "[epoch: 3, batch:   2736] loss: 0.14444  | 0.18\n",
      "[epoch: 3, batch:   2738] loss: 0.78432  | 0.19\n",
      "[epoch: 3, batch:   2740] loss: 0.44772  | 1.19\n",
      "[epoch: 3, batch:   2742] loss: 0.06921  | 0.17\n",
      "[epoch: 3, batch:   2744] loss: 0.61649  | 0.17\n",
      "[epoch: 3, batch:   2746] loss: 0.07020  | 0.18\n",
      "[epoch: 3, batch:   2748] loss: 0.23622  | 0.18\n",
      "[epoch: 3, batch:   2750] loss: 0.07593  | 0.19\n",
      "[epoch: 3, batch:   2752] loss: 0.40507  | 0.18\n",
      "[epoch: 3, batch:   2754] loss: 0.28248  | 0.18\n",
      "[epoch: 3, batch:   2756] loss: 0.60061  | 0.18\n",
      "[epoch: 3, batch:   2758] loss: 0.05841  | 0.42\n",
      "[epoch: 3, batch:   2760] loss: 0.07638  | 0.17\n",
      "[epoch: 3, batch:   2762] loss: 0.79854  | 0.17\n",
      "[epoch: 3, batch:   2764] loss: 0.36813  | 0.18\n",
      "[epoch: 3, batch:   2766] loss: 0.19373  | 0.18\n",
      "[epoch: 3, batch:   2768] loss: 0.16251  | 0.17\n",
      "[epoch: 3, batch:   2770] loss: 0.53479  | 0.17\n",
      "[epoch: 3, batch:   2772] loss: 0.17128  | 0.18\n",
      "[epoch: 3, batch:   2774] loss: 0.32800  | 0.77\n",
      "[epoch: 3, batch:   2776] loss: 0.33477  | 0.17\n",
      "[epoch: 3, batch:   2778] loss: 0.30479  | 0.18\n",
      "[epoch: 3, batch:   2780] loss: 0.06191  | 0.17\n",
      "[epoch: 3, batch:   2782] loss: 0.14220  | 0.18\n",
      "[epoch: 3, batch:   2784] loss: 0.94154  | 0.18\n",
      "[epoch: 3, batch:   2786] loss: 0.15244  | 0.18\n",
      "[epoch: 3, batch:   2788] loss: 0.12585  | 0.17\n",
      "[epoch: 3, batch:   2790] loss: 0.14333  | 0.18\n",
      "[epoch: 3, batch:   2792] loss: 0.05361  | 0.53\n",
      "[epoch: 3, batch:   2794] loss: 0.38660  | 0.17\n",
      "[epoch: 3, batch:   2796] loss: 0.20360  | 0.18\n",
      "[epoch: 3, batch:   2798] loss: 0.16418  | 0.18\n",
      "[epoch: 3, batch:   2800] loss: 0.11541  | 1.55\n",
      "[epoch: 3, batch:   2802] loss: 0.53034  | 0.17\n",
      "[epoch: 3, batch:   2804] loss: 1.14888  | 0.17\n",
      "[epoch: 3, batch:   2806] loss: 0.50554  | 0.18\n",
      "[epoch: 3, batch:   2808] loss: 0.64126  | 0.18\n",
      "[epoch: 3, batch:   2810] loss: 0.45011  | 0.18\n",
      "[epoch: 3, batch:   2812] loss: 0.23977  | 0.83\n",
      "[epoch: 3, batch:   2814] loss: 0.14257  | 0.17\n",
      "[epoch: 3, batch:   2816] loss: 0.05654  | 1.27\n",
      "[epoch: 3, batch:   2818] loss: 0.15756  | 0.18\n",
      "[epoch: 3, batch:   2820] loss: 0.47397  | 0.18\n",
      "[epoch: 3, batch:   2822] loss: 0.04082  | 0.17\n",
      "[epoch: 3, batch:   2824] loss: 0.05430  | 0.56\n",
      "[epoch: 3, batch:   2826] loss: 0.31908  | 0.17\n",
      "[epoch: 3, batch:   2828] loss: 0.06501  | 0.17\n",
      "[epoch: 3, batch:   2830] loss: 0.07678  | 0.17\n",
      "[epoch: 3, batch:   2832] loss: 0.13943  | 0.22\n",
      "[epoch: 3, batch:   2834] loss: 0.65525  | 0.18\n",
      "[epoch: 3, batch:   2836] loss: 0.09677  | 0.18\n",
      "[epoch: 3, batch:   2838] loss: 0.48756  | 0.17\n",
      "[epoch: 3, batch:   2840] loss: 0.24800  | 0.19\n",
      "[epoch: 3, batch:   2842] loss: 0.21125  | 0.18\n",
      "[epoch: 3, batch:   2844] loss: 0.41023  | 0.18\n",
      "[epoch: 3, batch:   2846] loss: 0.08185  | 0.17\n",
      "[epoch: 3, batch:   2848] loss: 0.20819  | 1.16\n",
      "[epoch: 3, batch:   2850] loss: 0.55046  | 0.18\n",
      "[epoch: 3, batch:   2852] loss: 0.12079  | 0.17\n",
      "[epoch: 3, batch:   2854] loss: 0.31735  | 0.17\n",
      "[epoch: 3, batch:   2856] loss: 0.66414  | 0.27\n",
      "[epoch: 3, batch:   2858] loss: 0.31891  | 0.17\n",
      "[epoch: 3, batch:   2860] loss: 0.10074  | 0.18\n",
      "[epoch: 3, batch:   2862] loss: 0.36783  | 0.18\n",
      "[epoch: 3, batch:   2864] loss: 0.14304  | 0.19\n",
      "[epoch: 3, batch:   2866] loss: 0.21738  | 0.19\n",
      "[epoch: 3, batch:   2868] loss: 0.24482  | 0.18\n",
      "[epoch: 3, batch:   2870] loss: 0.44135  | 0.18\n",
      "[epoch: 3, batch:   2872] loss: 0.06744  | 0.18\n",
      "[epoch: 3, batch:   2874] loss: 0.03821  | 0.99\n",
      "[epoch: 3, batch:   2876] loss: 0.48809  | 0.17\n",
      "[epoch: 3, batch:   2878] loss: 0.03530  | 0.18\n",
      "[epoch: 3, batch:   2880] loss: 0.03662  | 0.18\n",
      "[epoch: 3, batch:   2882] loss: 0.08103  | 0.18\n",
      "[epoch: 3, batch:   2884] loss: 0.05490  | 0.18\n",
      "[epoch: 3, batch:   2886] loss: 0.18333  | 1.03\n",
      "[epoch: 3, batch:   2888] loss: 0.97648  | 0.17\n",
      "[epoch: 3, batch:   2890] loss: 0.67336  | 0.19\n",
      "[epoch: 3, batch:   2892] loss: 0.23776  | 0.18\n",
      "[epoch: 3, batch:   2894] loss: 0.17394  | 0.19\n",
      "[epoch: 3, batch:   2896] loss: 0.05946  | 0.18\n",
      "[epoch: 3, batch:   2898] loss: 0.58506  | 0.18\n",
      "[epoch: 3, batch:   2900] loss: 0.08103  | 0.18\n",
      "[epoch: 3, batch:   2902] loss: 0.15654  | 0.18\n",
      "[epoch: 3, batch:   2904] loss: 0.36223  | 0.18\n",
      "[epoch: 3, batch:   2906] loss: 0.42853  | 0.52\n",
      "[epoch: 3, batch:   2908] loss: 0.05298  | 0.17\n",
      "[epoch: 3, batch:   2910] loss: 0.44673  | 0.18\n",
      "[epoch: 3, batch:   2912] loss: 0.37482  | 0.18\n",
      "[epoch: 3, batch:   2914] loss: 0.10918  | 0.58\n",
      "[epoch: 3, batch:   2916] loss: 0.34917  | 0.17\n",
      "[epoch: 3, batch:   2918] loss: 0.35165  | 0.18\n",
      "[epoch: 3, batch:   2920] loss: 0.27579  | 0.18\n",
      "[epoch: 3, batch:   2922] loss: 0.32781  | 0.18\n",
      "[epoch: 3, batch:   2924] loss: 0.03581  | 0.18\n",
      "[epoch: 3, batch:   2926] loss: 0.08024  | 0.18\n",
      "[epoch: 3, batch:   2928] loss: 0.41131  | 0.17\n",
      "[epoch: 3, batch:   2930] loss: 0.24667  | 0.18\n",
      "[epoch: 3, batch:   2932] loss: 1.12618  | 0.18\n",
      "[epoch: 3, batch:   2934] loss: 0.03865  | 0.55\n",
      "[epoch: 3, batch:   2936] loss: 0.13592  | 0.17\n",
      "[epoch: 3, batch:   2938] loss: 0.17387  | 0.18\n",
      "[epoch: 3, batch:   2940] loss: 0.12099  | 0.18\n",
      "[epoch: 3, batch:   2942] loss: 0.20106  | 0.46\n",
      "[epoch: 3, batch:   2944] loss: 0.16142  | 0.18\n",
      "[epoch: 3, batch:   2946] loss: 0.13813  | 0.18\n",
      "[epoch: 3, batch:   2948] loss: 0.03745  | 0.17\n",
      "[epoch: 3, batch:   2950] loss: 0.12800  | 0.18\n",
      "[epoch: 3, batch:   2952] loss: 0.46668  | 0.18\n",
      "[epoch: 3, batch:   2954] loss: 0.34176  | 0.18\n",
      "[epoch: 3, batch:   2956] loss: 0.39308  | 0.17\n",
      "[epoch: 3, batch:   2958] loss: 0.07759  | 0.18\n",
      "[epoch: 3, batch:   2960] loss: 1.03859  | 0.33\n",
      "[epoch: 3, batch:   2962] loss: 0.01695  | 0.19\n",
      "[epoch: 3, batch:   2964] loss: 0.16493  | 0.18\n",
      "[epoch: 3, batch:   2966] loss: 0.24500  | 0.18\n",
      "[epoch: 3, batch:   2968] loss: 0.15460  | 0.19\n",
      "[epoch: 3, batch:   2970] loss: 0.53091  | 0.40\n",
      "[epoch: 3, batch:   2972] loss: 0.31990  | 0.17\n",
      "[epoch: 3, batch:   2974] loss: 0.03790  | 0.18\n",
      "[epoch: 3, batch:   2976] loss: 0.24922  | 0.18\n",
      "[epoch: 3, batch:   2978] loss: 0.74494  | 0.18\n",
      "[epoch: 3, batch:   2980] loss: 0.22129  | 0.69\n",
      "[epoch: 3, batch:   2982] loss: 0.51905  | 0.17\n",
      "[epoch: 3, batch:   2984] loss: 0.05628  | 0.18\n",
      "[epoch: 3, batch:   2986] loss: 1.16121  | 0.18\n",
      "[epoch: 3, batch:   2988] loss: 0.26401  | 0.18\n",
      "[epoch: 3, batch:   2990] loss: 0.36164  | 0.17\n",
      "[epoch: 3, batch:   2992] loss: 0.34335  | 0.18\n",
      "[epoch: 3, batch:   2994] loss: 0.13999  | 0.18\n",
      "[epoch: 3, batch:   2996] loss: 0.34231  | 0.31\n",
      "[epoch: 3, batch:   2998] loss: 0.43462  | 0.36\n",
      "[epoch: 3, batch:   3000] loss: 0.05758  | 0.18\n",
      "[epoch: 3, batch:   3002] loss: 0.04416  | 0.18\n",
      "[epoch: 3, batch:   3004] loss: 0.15704  | 0.18\n",
      "[epoch: 3, batch:   3006] loss: 0.09173  | 0.43\n",
      "[epoch: 3, batch:   3008] loss: 0.04588  | 0.17\n",
      "[epoch: 3, batch:   3010] loss: 0.09757  | 0.18\n",
      "[epoch: 3, batch:   3012] loss: 0.11631  | 0.18\n",
      "[epoch: 3, batch:   3014] loss: 0.18967  | 0.58\n",
      "[epoch: 3, batch:   3016] loss: 0.15246  | 0.17\n",
      "[epoch: 3, batch:   3018] loss: 0.59660  | 0.18\n",
      "[epoch: 3, batch:   3020] loss: 0.06558  | 0.18\n",
      "[epoch: 3, batch:   3022] loss: 0.04518  | 0.18\n",
      "[epoch: 3, batch:   3024] loss: 0.55761  | 0.17\n",
      "[epoch: 3, batch:   3026] loss: 0.49195  | 0.18\n",
      "[epoch: 3, batch:   3028] loss: 0.94491  | 0.18\n",
      "[epoch: 3, batch:   3030] loss: 0.27460  | 0.18\n",
      "[epoch: 3, batch:   3032] loss: 0.35707  | 0.23\n",
      "[epoch: 3, batch:   3034] loss: 0.14608  | 0.73\n",
      "[epoch: 3, batch:   3036] loss: 0.13889  | 0.18\n",
      "[epoch: 3, batch:   3038] loss: 0.47689  | 0.18\n",
      "[epoch: 3, batch:   3040] loss: 0.12614  | 0.17\n",
      "[epoch: 3, batch:   3042] loss: 0.10568  | 0.34\n",
      "[epoch: 3, batch:   3044] loss: 0.26496  | 0.17\n",
      "[epoch: 3, batch:   3046] loss: 0.77470  | 0.18\n",
      "[epoch: 3, batch:   3048] loss: 0.41146  | 0.17\n",
      "[epoch: 3, batch:   3050] loss: 0.44379  | 0.44\n",
      "[epoch: 3, batch:   3052] loss: 0.25638  | 0.18\n",
      "[epoch: 3, batch:   3054] loss: 1.03968  | 0.18\n",
      "[epoch: 3, batch:   3056] loss: 0.05103  | 0.17\n",
      "[epoch: 3, batch:   3058] loss: 0.56060  | 0.67\n",
      "[epoch: 3, batch:   3060] loss: 0.20550  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 3, batch:   3062] loss: 0.08976  | 0.18\n",
      "[epoch: 3, batch:   3064] loss: 0.26856  | 0.17\n",
      "[epoch: 3, batch:   3066] loss: 0.10254  | 0.18\n",
      "[epoch: 3, batch:   3068] loss: 0.38738  | 0.18\n",
      "[epoch: 3, batch:   3070] loss: 0.34814  | 0.18\n",
      "[epoch: 3, batch:   3072] loss: 0.28215  | 0.19\n",
      "[epoch: 3, batch:   3074] loss: 0.34328  | 0.18\n",
      "[epoch: 3, batch:   3076] loss: 0.34782  | 0.17\n",
      "[epoch: 3, batch:   3078] loss: 0.25291  | 0.18\n",
      "[epoch: 3, batch:   3080] loss: 0.13883  | 0.48\n",
      "[epoch: 3, batch:   3082] loss: 0.08591  | 0.17\n",
      "[epoch: 3, batch:   3084] loss: 0.11685  | 0.18\n",
      "[epoch: 3, batch:   3086] loss: 0.07458  | 0.17\n",
      "[epoch: 3, batch:   3088] loss: 0.17537  | 0.18\n",
      "[epoch: 3, batch:   3090] loss: 0.24393  | 0.18\n",
      "[epoch: 3, batch:   3092] loss: 0.02879  | 0.18\n",
      "[epoch: 3, batch:   3094] loss: 0.14068  | 0.17\n",
      "[epoch: 3, batch:   3096] loss: 0.16469  | 0.19\n",
      "[epoch: 3, batch:   3098] loss: 0.13394  | 0.17\n",
      "[epoch: 3, batch:   3100] loss: 0.51720  | 0.19\n",
      "[epoch: 3, batch:   3102] loss: 0.09524  | 1.25\n",
      "[epoch: 3, batch:   3104] loss: 0.20797  | 0.18\n",
      "[epoch: 3, batch:   3106] loss: 0.46979  | 0.18\n",
      "[epoch: 3, batch:   3108] loss: 0.09921  | 0.17\n",
      "[epoch: 3, batch:   3110] loss: 1.53313  | 0.18\n",
      "[epoch: 3, batch:   3112] loss: 0.22698  | 0.18\n",
      "[epoch: 3, batch:   3114] loss: 0.81714  | 0.18\n",
      "[epoch: 3, batch:   3116] loss: 0.43679  | 0.17\n",
      "[epoch: 3, batch:   3118] loss: 0.13335  | 0.18\n",
      "[epoch: 3, batch:   3120] loss: 0.09965  | 0.18\n",
      "[epoch: 3, batch:   3122] loss: 0.06799  | 0.18\n",
      "[epoch: 3, batch:   3124] loss: 0.16287  | 0.18\n",
      "[epoch: 3, batch:   3126] loss: 0.07477  | 0.17\n",
      "[epoch: 3, batch:   3128] loss: 0.06547  | 0.60\n",
      "[epoch: 3, batch:   3130] loss: 0.08467  | 0.18\n",
      "[epoch: 3, batch:   3132] loss: 0.83899  | 0.19\n",
      "[epoch: 3, batch:   3134] loss: 0.32280  | 0.17\n",
      "[epoch: 3, batch:   3136] loss: 0.11187  | 0.18\n",
      "[epoch: 3, batch:   3138] loss: 0.81130  | 0.18\n",
      "[epoch: 3, batch:   3140] loss: 0.11898  | 0.18\n",
      "[epoch: 3, batch:   3142] loss: 0.17107  | 0.18\n",
      "[epoch: 3, batch:   3144] loss: 0.16733  | 0.18\n",
      "[epoch: 3, batch:   3146] loss: 0.33104  | 0.18\n",
      "[epoch: 3, batch:   3148] loss: 0.20393  | 0.18\n",
      "[epoch: 3, batch:   3150] loss: 0.26521  | 0.18\n",
      "[epoch: 3, batch:   3152] loss: 1.20940  | 0.19\n",
      "[epoch: 3, batch:   3154] loss: 0.07768  | 0.18\n",
      "[epoch: 3, batch:   3156] loss: 0.44665  | 0.34\n",
      "[epoch: 3, batch:   3158] loss: 0.20556  | 0.17\n",
      "[epoch: 3, batch:   3160] loss: 0.14172  | 0.18\n",
      "[epoch: 3, batch:   3162] loss: 0.11194  | 0.18\n",
      "[epoch: 3, batch:   3164] loss: 0.39187  | 1.07\n",
      "[epoch: 3, batch:   3166] loss: 1.07791  | 0.17\n",
      "[epoch: 3, batch:   3168] loss: 0.23524  | 0.18\n",
      "[epoch: 3, batch:   3170] loss: 0.24039  | 0.18\n",
      "[epoch: 3, batch:   3172] loss: 0.08897  | 0.18\n",
      "[epoch: 3, batch:   3174] loss: 0.13982  | 0.17\n",
      "[epoch: 3, batch:   3176] loss: 0.30987  | 0.18\n",
      "[epoch: 3, batch:   3178] loss: 0.08527  | 0.18\n",
      "[epoch: 3, batch:   3180] loss: 0.44309  | 0.18\n",
      "[epoch: 3, batch:   3182] loss: 0.54354  | 0.17\n",
      "[epoch: 3, batch:   3184] loss: 0.30411  | 0.18\n",
      "[epoch: 3, batch:   3186] loss: 0.04661  | 0.56\n",
      "[epoch: 3, batch:   3188] loss: 0.38378  | 0.17\n",
      "[epoch: 3, batch:   3190] loss: 0.08355  | 0.18\n",
      "[epoch: 3, batch:   3192] loss: 1.54697  | 0.18\n",
      "[epoch: 3, batch:   3194] loss: 0.34493  | 0.33\n",
      "[epoch: 3, batch:   3196] loss: 0.03789  | 0.18\n",
      "[epoch: 3, batch:   3198] loss: 0.04938  | 0.18\n",
      "[epoch: 3, batch:   3200] loss: 0.29859  | 0.17\n",
      "[epoch: 3, batch:   3202] loss: 0.31404  | 1.14\n",
      "[epoch: 3, batch:   3204] loss: 0.79835  | 0.18\n",
      "[epoch: 3, batch:   3206] loss: 0.62572  | 0.18\n",
      "[epoch: 3, batch:   3208] loss: 0.09073  | 0.17\n",
      "[epoch: 3, batch:   3210] loss: 0.07948  | 0.19\n",
      "[epoch: 3, batch:   3212] loss: 0.08837  | 0.18\n",
      "[epoch: 3, batch:   3214] loss: 0.22395  | 0.36\n",
      "[epoch: 3, batch:   3216] loss: 0.50765  | 0.17\n",
      "[epoch: 3, batch:   3218] loss: 0.04071  | 0.19\n",
      "[epoch: 3, batch:   3220] loss: 0.05194  | 0.18\n",
      "[epoch: 3, batch:   3222] loss: 0.16530  | 0.18\n",
      "[epoch: 3, batch:   3224] loss: 0.39712  | 0.18\n",
      "[epoch: 3, batch:   3226] loss: 0.02367  | 0.18\n",
      "[epoch: 3, batch:   3228] loss: 0.33235  | 0.18\n",
      "[epoch: 3, batch:   3230] loss: 0.12155  | 0.18\n",
      "[epoch: 3, batch:   3232] loss: 0.05026  | 0.18\n",
      "[epoch: 3, batch:   3234] loss: 0.34142  | 0.18\n",
      "[epoch: 3, batch:   3236] loss: 0.36409  | 0.18\n",
      "[epoch: 3, batch:   3238] loss: 0.34708  | 0.78\n",
      "[epoch: 3, batch:   3240] loss: 0.02817  | 0.17\n",
      "[epoch: 3, batch:   3242] loss: 0.53894  | 0.18\n",
      "[epoch: 3, batch:   3244] loss: 0.30626  | 0.18\n",
      "[epoch: 3, batch:   3246] loss: 0.19172  | 0.31\n",
      "[epoch: 3, batch:   3248] loss: 0.03311  | 0.18\n",
      "[epoch: 3, batch:   3250] loss: 0.24065  | 0.18\n",
      "[epoch: 3, batch:   3252] loss: 0.08959  | 0.17\n",
      "[epoch: 3, batch:   3254] loss: 0.94775  | 0.18\n",
      "[epoch: 3, batch:   3256] loss: 0.23789  | 0.18\n",
      "[epoch: 3, batch:   3258] loss: 0.03604  | 0.18\n",
      "[epoch: 3, batch:   3260] loss: 0.10414  | 0.18\n",
      "[epoch: 3, batch:   3262] loss: 0.14472  | 0.18\n",
      "[epoch: 3, batch:   3264] loss: 0.20328  | 0.18\n",
      "[epoch: 3, batch:   3266] loss: 0.21691  | 0.57\n",
      "[epoch: 3, batch:   3268] loss: 0.24092  | 0.18\n",
      "[epoch: 3, batch:   3270] loss: 0.16881  | 0.18\n",
      "[epoch: 3, batch:   3272] loss: 0.14321  | 0.18\n",
      "[epoch: 3, batch:   3274] loss: 0.05035  | 0.20\n",
      "[epoch: 3, batch:   3276] loss: 0.24727  | 0.17\n",
      "[epoch: 3, batch:   3278] loss: 0.02385  | 0.40\n",
      "[epoch: 3, batch:   3280] loss: 0.12960  | 0.17\n",
      "[epoch: 3, batch:   3282] loss: 0.08779  | 0.18\n",
      "[epoch: 3, batch:   3284] loss: 0.63947  | 0.18\n",
      "[epoch: 3, batch:   3286] loss: 0.06881  | 0.18\n",
      "[epoch: 3, batch:   3288] loss: 0.58494  | 0.18\n",
      "[epoch: 3, batch:   3290] loss: 0.63982  | 0.18\n",
      "[epoch: 3, batch:   3292] loss: 0.08344  | 0.67\n",
      "[epoch: 3, batch:   3294] loss: 0.11372  | 0.17\n",
      "[epoch: 3, batch:   3296] loss: 0.61924  | 0.18\n",
      "[epoch: 3, batch:   3298] loss: 0.51698  | 0.18\n",
      "[epoch: 3, batch:   3300] loss: 0.24789  | 0.28\n",
      "[epoch: 3, batch:   3302] loss: 0.14856  | 0.17\n",
      "[epoch: 3, batch:   3304] loss: 0.06290  | 0.18\n",
      "[epoch: 3, batch:   3306] loss: 0.09889  | 0.18\n",
      "[epoch: 3, batch:   3308] loss: 0.04420  | 0.19\n",
      "[epoch: 3, batch:   3310] loss: 0.31663  | 0.18\n",
      "[epoch: 3, batch:   3312] loss: 0.39372  | 0.18\n",
      "[epoch: 3, batch:   3314] loss: 0.26845  | 0.18\n",
      "[epoch: 3, batch:   3316] loss: 0.10535  | 0.19\n",
      "[epoch: 3, batch:   3318] loss: 0.31429  | 0.18\n",
      "[epoch: 3, batch:   3320] loss: 0.56074  | 0.18\n",
      "[epoch: 3, batch:   3322] loss: 0.17546  | 0.18\n",
      "[epoch: 3, batch:   3324] loss: 0.68463  | 0.29\n",
      "[epoch: 3, batch:   3326] loss: 0.06338  | 0.18\n",
      "[epoch: 3, batch:   3328] loss: 0.10361  | 0.18\n",
      "[epoch: 3, batch:   3330] loss: 0.47304  | 0.58\n",
      "[epoch: 3, batch:   3332] loss: 0.24927  | 0.18\n",
      "[epoch: 3, batch:   3334] loss: 0.22531  | 0.18\n",
      "[epoch: 3, batch:   3336] loss: 0.19751  | 0.20\n",
      "[epoch: 3, batch:   3338] loss: 0.37579  | 0.18\n",
      "[epoch: 3, batch:   3340] loss: 0.19085  | 0.19\n",
      "[epoch: 3, batch:   3342] loss: 0.11137  | 0.18\n",
      "[epoch: 3, batch:   3344] loss: 0.28461  | 0.18\n",
      "[epoch: 3, batch:   3346] loss: 0.11756  | 0.18\n",
      "[epoch: 3, batch:   3348] loss: 0.34732  | 0.19\n",
      "[epoch: 3, batch:   3350] loss: 0.14813  | 0.18\n",
      "[epoch: 3, batch:   3352] loss: 0.07217  | 0.17\n",
      "[epoch: 3, batch:   3354] loss: 0.38342  | 0.18\n",
      "[epoch: 3, batch:   3356] loss: 0.36042  | 0.18\n",
      "[epoch: 3, batch:   3358] loss: 0.03278  | 0.18\n",
      "[epoch: 3, batch:   3360] loss: 0.36377  | 0.40\n",
      "[epoch: 3, batch:   3362] loss: 0.06818  | 0.18\n",
      "[epoch: 3, batch:   3364] loss: 0.57425  | 0.18\n",
      "[epoch: 3, batch:   3366] loss: 0.08877  | 0.18\n",
      "[epoch: 3, batch:   3368] loss: 0.08789  | 0.81\n",
      "[epoch: 3, batch:   3370] loss: 0.43411  | 0.18\n",
      "[epoch: 3, batch:   3372] loss: 0.08289  | 0.18\n",
      "[epoch: 3, batch:   3374] loss: 0.01915  | 0.17\n",
      "[epoch: 3, batch:   3376] loss: 0.07423  | 0.67\n",
      "[epoch: 3, batch:   3378] loss: 0.13368  | 0.18\n",
      "[epoch: 3, batch:   3380] loss: 0.25265  | 0.18\n",
      "[epoch: 3, batch:   3382] loss: 0.01730  | 0.17\n",
      "[epoch: 3, batch:   3384] loss: 0.02138  | 0.18\n",
      "[epoch: 3, batch:   3386] loss: 0.28416  | 0.18\n",
      "[epoch: 3, batch:   3388] loss: 0.22790  | 0.18\n",
      "[epoch: 3, batch:   3390] loss: 0.08873  | 0.17\n",
      "[epoch: 3, batch:   3392] loss: 0.14004  | 0.19\n",
      "[epoch: 3, batch:   3394] loss: 0.13953  | 0.18\n",
      "[epoch: 3, batch:   3396] loss: 0.70193  | 0.43\n",
      "[epoch: 3, batch:   3398] loss: 0.06989  | 0.18\n",
      "[epoch: 3, batch:   3400] loss: 0.04397  | 0.18\n",
      "[epoch: 3, batch:   3402] loss: 0.06178  | 0.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 3, batch:   3404] loss: 0.48875  | 0.17\n",
      "[epoch: 3, batch:   3406] loss: 0.71085  | 0.17\n",
      "[epoch: 3, batch:   3408] loss: 0.19959  | 0.18\n",
      "[epoch: 3, batch:   3410] loss: 0.48129  | 0.19\n",
      "[epoch: 3, batch:   3412] loss: 0.29384  | 0.18\n",
      "[epoch: 3, batch:   3414] loss: 0.31213  | 0.17\n",
      "[epoch: 3, batch:   3416] loss: 0.17679  | 0.18\n",
      "[epoch: 3, batch:   3418] loss: 0.82198  | 0.18\n",
      "[epoch: 3, batch:   3420] loss: 0.60428  | 0.53\n",
      "[epoch: 3, batch:   3422] loss: 0.13364  | 0.18\n",
      "[epoch: 3, batch:   3424] loss: 0.53491  | 0.18\n",
      "[epoch: 3, batch:   3426] loss: 0.11075  | 0.18\n",
      "[epoch: 3, batch:   3428] loss: 0.04113  | 0.19\n",
      "[epoch: 3, batch:   3430] loss: 0.14104  | 0.18\n",
      "[epoch: 3, batch:   3432] loss: 0.28154  | 0.17\n",
      "[epoch: 3, batch:   3434] loss: 0.07982  | 0.18\n",
      "[epoch: 3, batch:   3436] loss: 0.11156  | 0.18\n",
      "[epoch: 3, batch:   3438] loss: 0.08222  | 0.18\n",
      "[epoch: 3, batch:   3440] loss: 0.14752  | 0.18\n",
      "[epoch: 3, batch:   3442] loss: 0.20818  | 0.18\n",
      "[epoch: 3, batch:   3444] loss: 0.26217  | 0.28\n",
      "[epoch: 3, batch:   3446] loss: 0.11215  | 0.18\n",
      "[epoch: 3, batch:   3448] loss: 0.44484  | 0.18\n",
      "[epoch: 3, batch:   3450] loss: 0.57841  | 0.18\n",
      "[epoch: 3, batch:   3452] loss: 0.06106  | 0.33\n",
      "[epoch: 3, batch:   3454] loss: 0.24524  | 0.17\n",
      "[epoch: 3, batch:   3456] loss: 0.50249  | 0.74\n",
      "[epoch: 3, batch:   3458] loss: 0.16021  | 0.17\n",
      "[epoch: 3, batch:   3460] loss: 0.06086  | 0.18\n",
      "[epoch: 3, batch:   3462] loss: 0.24372  | 0.18\n",
      "[epoch: 3, batch:   3464] loss: 0.16439  | 0.22\n",
      "[epoch: 3, batch:   3466] loss: 0.43823  | 0.25\n",
      "[epoch: 3, batch:   3468] loss: 0.39821  | 0.17\n",
      "[epoch: 3, batch:   3470] loss: 0.19406  | 0.28\n",
      "[epoch: 3, batch:   3472] loss: 0.11862  | 0.18\n",
      "[epoch: 3, batch:   3474] loss: 0.38906  | 0.19\n",
      "[epoch: 3, batch:   3476] loss: 0.27022  | 0.17\n",
      "[epoch: 3, batch:   3478] loss: 0.24630  | 0.18\n",
      "[epoch: 3, batch:   3480] loss: 0.17248  | 0.18\n",
      "[epoch: 3, batch:   3482] loss: 0.75412  | 0.27\n",
      "[epoch: 3, batch:   3484] loss: 0.07099  | 0.17\n",
      "[epoch: 3, batch:   3486] loss: 0.18253  | 0.58\n",
      "[epoch: 3, batch:   3488] loss: 0.01802  | 0.18\n",
      "[epoch: 3, batch:   3490] loss: 0.22701  | 0.18\n",
      "[epoch: 3, batch:   3492] loss: 0.45329  | 0.17\n",
      "[epoch: 3, batch:   3494] loss: 0.71364  | 0.37\n",
      "[epoch: 3, batch:   3496] loss: 1.58881  | 0.17\n",
      "[epoch: 3, batch:   3498] loss: 0.03368  | 0.18\n",
      "[epoch: 3, batch:   3500] loss: 0.98382  | 0.18\n",
      "[epoch: 3, batch:   3502] loss: 0.05507  | 0.83\n",
      "[epoch: 3, batch:   3504] loss: 0.11483  | 0.18\n",
      "[epoch: 3, batch:   3506] loss: 0.47122  | 0.18\n",
      "[epoch: 3, batch:   3508] loss: 0.42156  | 0.17\n",
      "[epoch: 3, batch:   3510] loss: 0.24007  | 0.18\n",
      "[epoch: 3, batch:   3512] loss: 0.11255  | 0.18\n",
      "[epoch: 3, batch:   3514] loss: 0.07634  | 0.18\n",
      "[epoch: 3, batch:   3516] loss: 0.22617  | 0.17\n",
      "[epoch: 3, batch:   3518] loss: 0.05350  | 0.18\n",
      "[epoch: 3, batch:   3520] loss: 0.03938  | 0.18\n",
      "[epoch: 3, batch:   3522] loss: 0.36343  | 0.20\n",
      "[epoch: 3, batch:   3524] loss: 0.10176  | 0.17\n",
      "[epoch: 3, batch:   3526] loss: 0.16429  | 0.18\n",
      "[epoch: 3, batch:   3528] loss: 0.03668  | 0.18\n",
      "[epoch: 3, batch:   3530] loss: 0.17433  | 0.40\n",
      "[epoch: 3, batch:   3532] loss: 0.38982  | 0.18\n",
      "[epoch: 3, batch:   3534] loss: 0.24570  | 0.18\n",
      "[epoch: 3, batch:   3536] loss: 0.11897  | 0.17\n",
      "[epoch: 3, batch:   3538] loss: 0.21991  | 0.32\n",
      "[epoch: 3, batch:   3540] loss: 0.16982  | 0.18\n",
      "[epoch: 3, batch:   3542] loss: 0.55749  | 0.18\n",
      "[epoch: 3, batch:   3544] loss: 0.29451  | 0.18\n",
      "[epoch: 3, batch:   3546] loss: 0.06356  | 0.24\n",
      "[epoch: 3, batch:   3548] loss: 0.34341  | 0.18\n",
      "[epoch: 3, batch:   3550] loss: 0.17929  | 0.18\n",
      "[epoch: 3, batch:   3552] loss: 0.27222  | 0.18\n",
      "[epoch: 3, batch:   3554] loss: 0.39103  | 0.31\n",
      "[epoch: 3, batch:   3556] loss: 0.14403  | 0.19\n",
      "[epoch: 3, batch:   3558] loss: 0.92031  | 0.18\n",
      "[epoch: 3, batch:   3560] loss: 0.75648  | 0.55\n",
      "[epoch: 3, batch:   3562] loss: 0.07409  | 0.18\n",
      "[epoch: 3, batch:   3564] loss: 0.22540  | 0.18\n",
      "[epoch: 3, batch:   3566] loss: 0.18107  | 0.17\n",
      "[epoch: 3, batch:   3568] loss: 0.03514  | 0.31\n",
      "[epoch: 3, batch:   3570] loss: 0.41033  | 0.17\n",
      "[epoch: 3, batch:   3572] loss: 0.59123  | 0.18\n",
      "[epoch: 3, batch:   3574] loss: 0.08279  | 0.17\n",
      "[epoch: 3, batch:   3576] loss: 0.07030  | 0.19\n",
      "[epoch: 3, batch:   3578] loss: 0.86823  | 0.18\n",
      "[epoch: 3, batch:   3580] loss: 0.38998  | 0.18\n",
      "[epoch: 3, batch:   3582] loss: 1.03118  | 0.39\n",
      "[epoch: 3, batch:   3584] loss: 0.37501  | 0.17\n",
      "[epoch: 3, batch:   3586] loss: 0.64131  | 0.19\n",
      "[epoch: 3, batch:   3588] loss: 0.38947  | 0.17\n",
      "[epoch: 3, batch:   3590] loss: 0.14257  | 0.19\n",
      "[epoch: 3, batch:   3592] loss: 0.14224  | 0.18\n",
      "[epoch: 3, batch:   3594] loss: 0.19355  | 0.18\n",
      "[epoch: 3, batch:   3596] loss: 0.37556  | 0.63\n",
      "[epoch: 3, batch:   3598] loss: 0.72160  | 0.17\n",
      "[epoch: 3, batch:   3600] loss: 0.38045  | 0.18\n",
      "[epoch: 3, batch:   3602] loss: 1.07480  | 0.18\n",
      "[epoch: 3, batch:   3604] loss: 0.02823  | 0.36\n",
      "[epoch: 3, batch:   3606] loss: 0.05685  | 0.17\n",
      "[epoch: 3, batch:   3608] loss: 0.00831  | 0.18\n",
      "[epoch: 3, batch:   3610] loss: 0.24044  | 0.17\n",
      "[epoch: 3, batch:   3612] loss: 0.10600  | 0.18\n",
      "[epoch: 3, batch:   3614] loss: 0.27540  | 0.18\n",
      "[epoch: 3, batch:   3616] loss: 0.22636  | 0.54\n",
      "[epoch: 3, batch:   3618] loss: 0.15057  | 0.17\n",
      "[epoch: 3, batch:   3620] loss: 0.44933  | 0.18\n",
      "[epoch: 3, batch:   3622] loss: 1.88476  | 0.17\n",
      "[epoch: 3, batch:   3624] loss: 0.17764  | 0.18\n",
      "[epoch: 3, batch:   3626] loss: 0.12741  | 0.18\n",
      "[epoch: 3, batch:   3628] loss: 0.18296  | 0.18\n",
      "[epoch: 3, batch:   3630] loss: 0.08996  | 0.18\n",
      "[epoch: 3, batch:   3632] loss: 0.15350  | 0.18\n",
      "[epoch: 3, batch:   3634] loss: 0.09523  | 0.18\n",
      "[epoch: 3, batch:   3636] loss: 0.06552  | 0.93\n",
      "[epoch: 3, batch:   3638] loss: 0.70116  | 0.17\n",
      "[epoch: 3, batch:   3640] loss: 0.16211  | 0.18\n",
      "[epoch: 3, batch:   3642] loss: 0.31209  | 0.18\n",
      "[epoch: 3, batch:   3644] loss: 0.07727  | 0.18\n",
      "[epoch: 3, batch:   3646] loss: 0.07692  | 0.17\n",
      "[epoch: 3, batch:   3648] loss: 0.18630  | 0.18\n",
      "[epoch: 3, batch:   3650] loss: 0.06062  | 0.17\n",
      "[epoch: 3, batch:   3652] loss: 0.05269  | 0.18\n",
      "[epoch: 3, batch:   3654] loss: 0.48957  | 0.33\n",
      "[epoch: 3, batch:   3656] loss: 0.39822  | 0.17\n",
      "[epoch: 3, batch:   3658] loss: 0.06218  | 0.18\n",
      "[epoch: 3, batch:   3660] loss: 0.08714  | 0.18\n",
      "[epoch: 3, batch:   3662] loss: 0.92971  | 0.19\n",
      "[epoch: 3, batch:   3664] loss: 0.07761  | 0.17\n",
      "[epoch: 3, batch:   3666] loss: 0.38885  | 0.18\n",
      "[epoch: 3, batch:   3668] loss: 0.02636  | 0.29\n",
      "[epoch: 3, batch:   3670] loss: 0.15971  | 0.18\n",
      "[epoch: 3, batch:   3672] loss: 0.36722  | 0.18\n",
      "[epoch: 3, batch:   3674] loss: 0.08541  | 0.18\n",
      "[epoch: 3, batch:   3676] loss: 0.17822  | 0.19\n",
      "[epoch: 3, batch:   3678] loss: 0.05171  | 0.18\n",
      "[epoch: 3, batch:   3680] loss: 0.51970  | 0.18\n",
      "[epoch: 3, batch:   3682] loss: 0.06833  | 0.17\n",
      "[epoch: 3, batch:   3684] loss: 0.27794  | 0.53\n",
      "[epoch: 3, batch:   3686] loss: 0.70982  | 0.17\n",
      "[epoch: 3, batch:   3688] loss: 0.15850  | 0.18\n",
      "[epoch: 3, batch:   3690] loss: 0.22876  | 0.18\n",
      "[epoch: 3, batch:   3692] loss: 0.02198  | 0.19\n",
      "[epoch: 3, batch:   3694] loss: 0.24153  | 0.17\n",
      "[epoch: 3, batch:   3696] loss: 0.21910  | 0.73\n",
      "[epoch: 3, batch:   3698] loss: 0.43167  | 0.17\n",
      "[epoch: 3, batch:   3700] loss: 0.05138  | 0.18\n",
      "[epoch: 3, batch:   3702] loss: 0.50844  | 0.18\n",
      "[epoch: 3, batch:   3704] loss: 0.14240  | 0.31\n",
      "[epoch: 3, batch:   3706] loss: 0.14201  | 0.17\n",
      "[epoch: 3, batch:   3708] loss: 0.36118  | 0.18\n",
      "[epoch: 3, batch:   3710] loss: 0.05825  | 0.18\n",
      "[epoch: 3, batch:   3712] loss: 0.27499  | 0.19\n",
      "[epoch: 3, batch:   3714] loss: 0.25406  | 0.33\n",
      "[epoch: 3, batch:   3716] loss: 0.18696  | 0.18\n",
      "[epoch: 3, batch:   3718] loss: 0.17484  | 1.17\n",
      "[epoch: 3, batch:   3720] loss: 0.43618  | 0.17\n",
      "[epoch: 3, batch:   3722] loss: 0.45248  | 0.18\n",
      "[epoch: 3, batch:   3724] loss: 0.10747  | 0.17\n",
      "[epoch: 3, batch:   3726] loss: 0.20129  | 0.28\n",
      "[epoch: 3, batch:   3728] loss: 0.09711  | 0.17\n",
      "[epoch: 3, batch:   3730] loss: 0.28971  | 0.18\n",
      "[epoch: 3, batch:   3732] loss: 0.30825  | 0.17\n",
      "[epoch: 3, batch:   3734] loss: 0.04426  | 0.37\n",
      "[epoch: 3, batch:   3736] loss: 0.21497  | 0.18\n",
      "[epoch: 3, batch:   3738] loss: 0.56537  | 0.18\n",
      "[epoch: 3, batch:   3740] loss: 0.09839  | 0.18\n",
      "[epoch: 3, batch:   3742] loss: 0.19910  | 0.25\n",
      "[epoch: 3, batch:   3744] loss: 0.08591  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 3, batch:   3746] loss: 0.11113  | 0.18\n",
      "[epoch: 3, batch:   3748] loss: 0.18851  | 0.17\n",
      "[epoch: 3, batch:   3750] loss: 0.09471  | 0.46\n",
      "[epoch: 3, batch:   3752] loss: 0.58808  | 0.17\n",
      "[epoch: 3, batch:   3754] loss: 0.02803  | 0.18\n",
      "[epoch: 3, batch:   3756] loss: 0.11322  | 0.18\n",
      "[epoch: 3, batch:   3758] loss: 1.20766  | 0.18\n",
      "[epoch: 3, batch:   3760] loss: 0.10897  | 0.17\n",
      "[epoch: 3, batch:   3762] loss: 0.05301  | 0.69\n",
      "[epoch: 3, batch:   3764] loss: 0.33207  | 0.18\n",
      "[epoch: 3, batch:   3766] loss: 0.31430  | 0.18\n",
      "[epoch: 3, batch:   3768] loss: 0.34918  | 0.17\n",
      "[epoch: 3, batch:   3770] loss: 0.55699  | 0.18\n",
      "[epoch: 3, batch:   3772] loss: 0.27489  | 0.18\n",
      "[epoch: 3, batch:   3774] loss: 0.12456  | 0.18\n",
      "[epoch: 3, batch:   3776] loss: 0.11825  | 0.17\n",
      "[epoch: 3, batch:   3778] loss: 0.08134  | 0.18\n",
      "[epoch: 3, batch:   3780] loss: 0.38634  | 0.18\n",
      "[epoch: 3, batch:   3782] loss: 0.09736  | 0.40\n",
      "[epoch: 3, batch:   3784] loss: 0.68836  | 0.18\n",
      "[epoch: 3, batch:   3786] loss: 0.12568  | 0.18\n",
      "[epoch: 3, batch:   3788] loss: 0.01576  | 0.17\n",
      "[epoch: 3, batch:   3790] loss: 0.02395  | 0.19\n",
      "[epoch: 3, batch:   3792] loss: 0.15733  | 0.18\n",
      "[epoch: 3, batch:   3794] loss: 0.17800  | 0.19\n",
      "[epoch: 3, batch:   3796] loss: 0.04534  | 0.17\n",
      "[epoch: 3, batch:   3798] loss: 0.01613  | 0.18\n",
      "[epoch: 3, batch:   3800] loss: 0.36355  | 0.18\n",
      "[epoch: 3, batch:   3802] loss: 0.16748  | 0.18\n",
      "[epoch: 3, batch:   3804] loss: 0.04182  | 0.18\n",
      "[epoch: 3, batch:   3806] loss: 0.57181  | 0.18\n",
      "[epoch: 3, batch:   3808] loss: 0.21943  | 0.19\n",
      "[epoch: 3, batch:   3810] loss: 0.12758  | 0.18\n",
      "[epoch: 3, batch:   3812] loss: 0.13578  | 0.18\n",
      "[epoch: 3, batch:   3814] loss: 0.05766  | 0.18\n",
      "[epoch: 3, batch:   3816] loss: 0.25253  | 0.30\n",
      "[epoch: 3, batch:   3818] loss: 0.15283  | 0.48\n",
      "[epoch: 3, batch:   3820] loss: 0.26967  | 0.17\n",
      "[epoch: 3, batch:   3822] loss: 0.30067  | 0.18\n",
      "[epoch: 3, batch:   3824] loss: 0.38322  | 0.17\n",
      "[epoch: 3, batch:   3826] loss: 0.43799  | 0.31\n",
      "[epoch: 3, batch:   3828] loss: 1.16704  | 0.18\n",
      "[epoch: 3, batch:   3830] loss: 0.30404  | 0.18\n",
      "[epoch: 3, batch:   3832] loss: 0.05771  | 0.18\n",
      "[epoch: 3, batch:   3834] loss: 0.09232  | 0.18\n",
      "[epoch: 3, batch:   3836] loss: 0.03149  | 0.18\n",
      "[epoch: 3, batch:   3838] loss: 0.05024  | 0.18\n",
      "[epoch: 3, batch:   3840] loss: 0.06343  | 0.31\n",
      "[epoch: 3, batch:   3842] loss: 0.13988  | 0.18\n",
      "[epoch: 3, batch:   3844] loss: 0.05778  | 0.18\n",
      "[epoch: 3, batch:   3846] loss: 0.04766  | 0.17\n",
      "[epoch: 3, batch:   3848] loss: 0.34776  | 0.19\n",
      "[epoch: 3, batch:   3850] loss: 0.21637  | 0.18\n",
      "[epoch: 3, batch:   3852] loss: 0.09294  | 0.18\n",
      "[epoch: 3, batch:   3854] loss: 0.21465  | 0.18\n",
      "[epoch: 3, batch:   3856] loss: 0.28831  | 0.33\n",
      "[epoch: 3, batch:   3858] loss: 0.13378  | 0.17\n",
      "[epoch: 3, batch:   3860] loss: 0.13586  | 0.18\n",
      "[epoch: 3, batch:   3862] loss: 0.15511  | 0.18\n",
      "[epoch: 3, batch:   3864] loss: 0.08956  | 0.19\n",
      "[epoch: 3, batch:   3866] loss: 0.42353  | 0.18\n",
      "[epoch: 3, batch:   3868] loss: 0.25576  | 0.63\n",
      "[epoch: 3, batch:   3870] loss: 0.27446  | 0.17\n",
      "[epoch: 3, batch:   3872] loss: 0.36627  | 0.18\n",
      "[epoch: 3, batch:   3874] loss: 0.91969  | 0.17\n",
      "[epoch: 3, batch:   3876] loss: 0.03283  | 0.18\n",
      "[epoch: 3, batch:   3878] loss: 0.11184  | 0.17\n",
      "[epoch: 3, batch:   3880] loss: 0.06542  | 0.18\n",
      "[epoch: 3, batch:   3882] loss: 0.43684  | 0.18\n",
      "[epoch: 3, batch:   3884] loss: 0.08988  | 0.24\n",
      "[epoch: 3, batch:   3886] loss: 0.05358  | 0.18\n",
      "[epoch: 3, batch:   3888] loss: 1.32106  | 0.18\n",
      "[epoch: 3, batch:   3890] loss: 0.26868  | 0.18\n",
      "[epoch: 3, batch:   3892] loss: 0.11561  | 0.34\n",
      "[epoch: 3, batch:   3894] loss: 0.11993  | 0.18\n",
      "[epoch: 3, batch:   3896] loss: 0.43586  | 0.18\n",
      "[epoch: 3, batch:   3898] loss: 0.33959  | 0.18\n",
      "[epoch: 3, batch:   3900] loss: 0.02191  | 0.58\n",
      "[epoch: 3, batch:   3902] loss: 0.15595  | 0.18\n",
      "[epoch: 3, batch:   3904] loss: 0.12659  | 0.18\n",
      "[epoch: 3, batch:   3906] loss: 0.05525  | 0.17\n",
      "[epoch: 3, batch:   3908] loss: 0.80646  | 0.18\n",
      "[epoch: 3, batch:   3910] loss: 0.13771  | 0.18\n",
      "[epoch: 3, batch:   3912] loss: 0.06702  | 0.18\n",
      "[epoch: 3, batch:   3914] loss: 0.04346  | 0.17\n",
      "[epoch: 3, batch:   3916] loss: 0.25368  | 0.18\n",
      "[epoch: 3, batch:   3918] loss: 0.22305  | 0.18\n",
      "[epoch: 3, batch:   3920] loss: 0.08039  | 0.25\n",
      "[epoch: 3, batch:   3922] loss: 0.47293  | 0.17\n",
      "[epoch: 3, batch:   3924] loss: 0.97470  | 0.18\n",
      "[epoch: 3, batch:   3926] loss: 0.26602  | 0.18\n",
      "[epoch: 3, batch:   3928] loss: 0.23034  | 0.19\n",
      "[epoch: 3, batch:   3930] loss: 0.29788  | 0.18\n",
      "[epoch: 3, batch:   3932] loss: 0.24461  | 0.18\n",
      "[epoch: 3, batch:   3934] loss: 0.83840  | 0.18\n",
      "[epoch: 3, batch:   3936] loss: 0.06719  | 0.19\n",
      "[epoch: 3, batch:   3938] loss: 0.13287  | 0.71\n",
      "[epoch: 3, batch:   3940] loss: 0.09130  | 0.18\n",
      "[epoch: 3, batch:   3942] loss: 0.02224  | 0.18\n",
      "[epoch: 3, batch:   3944] loss: 0.04055  | 0.17\n",
      "[epoch: 3, batch:   3946] loss: 0.17288  | 0.18\n",
      "[epoch: 3, batch:   3948] loss: 0.25947  | 0.18\n",
      "[epoch: 3, batch:   3950] loss: 0.25992  | 0.18\n",
      "[epoch: 3, batch:   3952] loss: 0.06108  | 0.17\n",
      "[epoch: 3, batch:   3954] loss: 0.28677  | 0.68\n",
      "[epoch: 3, batch:   3956] loss: 0.05032  | 0.18\n",
      "[epoch: 3, batch:   3958] loss: 0.29800  | 0.18\n",
      "[epoch: 3, batch:   3960] loss: 0.61677  | 0.17\n",
      "[epoch: 3, batch:   3962] loss: 0.56967  | 0.18\n",
      "[epoch: 3, batch:   3964] loss: 0.10246  | 0.18\n",
      "[epoch: 3, batch:   3966] loss: 0.05867  | 0.18\n",
      "[epoch: 3, batch:   3968] loss: 0.04346  | 0.17\n",
      "[epoch: 3, batch:   3970] loss: 0.62460  | 0.18\n",
      "[epoch: 3, batch:   3972] loss: 0.83649  | 0.17\n",
      "[epoch: 3, batch:   3974] loss: 0.24214  | 0.18\n",
      "[epoch: 3, batch:   3976] loss: 0.37926  | 0.18\n",
      "[epoch: 3, batch:   3978] loss: 0.41602  | 0.18\n",
      "[epoch: 3, batch:   3980] loss: 0.27293  | 0.18\n",
      "[epoch: 3, batch:   3982] loss: 0.14480  | 0.26\n",
      "[epoch: 3, batch:   3984] loss: 0.11629  | 0.18\n",
      "[epoch: 3, batch:   3986] loss: 0.12687  | 0.18\n",
      "[epoch: 3, batch:   3988] loss: 0.06664  | 0.18\n",
      "[epoch: 3, batch:   3990] loss: 1.26542  | 0.18\n",
      "[epoch: 3, batch:   3992] loss: 0.50868  | 0.18\n",
      "[epoch: 3, batch:   3994] loss: 0.23136  | 0.18\n",
      "[epoch: 3, batch:   3996] loss: 0.08229  | 0.18\n",
      "[epoch: 3, batch:   3998] loss: 0.83571  | 0.28\n",
      "[epoch: 3, batch:   4000] loss: 0.60429  | 0.17\n",
      "[epoch: 3, batch:   4002] loss: 0.02738  | 0.18\n",
      "[epoch: 3, batch:   4004] loss: 0.11219  | 0.18\n",
      "[epoch: 3, batch:   4006] loss: 0.22667  | 0.18\n",
      "[epoch: 3, batch:   4008] loss: 0.24655  | 0.74\n",
      "[epoch: 3, batch:   4010] loss: 0.05397  | 0.42\n",
      "[epoch: 3, batch:   4012] loss: 0.10313  | 0.18\n",
      "[epoch: 3, batch:   4014] loss: 0.73577  | 0.18\n",
      "[epoch: 3, batch:   4016] loss: 0.04905  | 0.73\n",
      "[epoch: 3, batch:   4018] loss: 0.44191  | 0.17\n",
      "[epoch: 3, batch:   4020] loss: 0.15822  | 0.96\n",
      "[epoch: 3, batch:   4022] loss: 0.03616  | 0.18\n",
      "[epoch: 3, batch:   4024] loss: 0.20557  | 0.18\n",
      "[epoch: 3, batch:   4026] loss: 0.40221  | 0.18\n",
      "[epoch: 3, batch:   4028] loss: 0.21418  | 0.18\n",
      "[epoch: 3, batch:   4030] loss: 0.07127  | 0.17\n",
      "[epoch: 3, batch:   4032] loss: 0.13198  | 0.18\n",
      "[epoch: 3, batch:   4034] loss: 0.49771  | 0.18\n",
      "[epoch: 3, batch:   4036] loss: 0.50882  | 0.18\n",
      "[epoch: 3, batch:   4038] loss: 0.27956  | 0.88\n",
      "[epoch: 3, batch:   4040] loss: 0.37597  | 0.17\n",
      "[epoch: 3, batch:   4042] loss: 0.05436  | 0.18\n",
      "[epoch: 3, batch:   4044] loss: 0.35859  | 0.18\n",
      "[epoch: 3, batch:   4046] loss: 2.08496  | 0.18\n",
      "[epoch: 3, batch:   4048] loss: 1.28619  | 0.17\n",
      "[epoch: 3, batch:   4050] loss: 0.14546  | 0.18\n",
      "[epoch: 3, batch:   4052] loss: 0.44555  | 0.18\n",
      "[epoch: 3, batch:   4054] loss: 0.10437  | 0.66\n",
      "[epoch: 3, batch:   4056] loss: 0.05033  | 0.18\n",
      "[epoch: 3, batch:   4058] loss: 1.07214  | 0.18\n",
      "[epoch: 3, batch:   4060] loss: 0.05288  | 0.17\n",
      "[epoch: 3, batch:   4062] loss: 0.09138  | 0.18\n",
      "[epoch: 3, batch:   4064] loss: 0.01899  | 0.18\n",
      "[epoch: 3, batch:   4066] loss: 0.11300  | 0.18\n",
      "[epoch: 3, batch:   4068] loss: 0.36777  | 0.17\n",
      "[epoch: 3, batch:   4070] loss: 0.24039  | 0.35\n",
      "[epoch: 3, batch:   4072] loss: 0.41021  | 0.18\n",
      "[epoch: 3, batch:   4074] loss: 0.09169  | 0.19\n",
      "[epoch: 3, batch:   4076] loss: 0.40558  | 0.34\n",
      "[epoch: 3, batch:   4078] loss: 0.11185  | 0.18\n",
      "[epoch: 3, batch:   4080] loss: 0.31534  | 0.18\n",
      "[epoch: 3, batch:   4082] loss: 0.10852  | 0.18\n",
      "[epoch: 3, batch:   4084] loss: 0.86094  | 0.40\n",
      "[epoch: 3, batch:   4086] loss: 0.16628  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 3, batch:   4088] loss: 0.02295  | 0.18\n",
      "[epoch: 3, batch:   4090] loss: 0.02761  | 0.17\n",
      "[epoch: 3, batch:   4092] loss: 0.03708  | 0.19\n",
      "[epoch: 3, batch:   4094] loss: 0.59795  | 0.18\n",
      "[epoch: 3, batch:   4096] loss: 0.15935  | 0.18\n",
      "[epoch: 3, batch:   4098] loss: 0.41702  | 0.18\n",
      "[epoch: 3, batch:   4100] loss: 0.09445  | 0.18\n",
      "[epoch: 3, batch:   4102] loss: 0.05250  | 0.60\n",
      "[epoch: 3, batch:   4104] loss: 0.25519  | 0.18\n",
      "[epoch: 3, batch:   4106] loss: 0.38557  | 0.18\n",
      "[epoch: 3, batch:   4108] loss: 0.00553  | 0.17\n",
      "[epoch: 3, batch:   4110] loss: 0.35612  | 0.18\n",
      "[epoch: 3, batch:   4112] loss: 0.27591  | 0.18\n",
      "[epoch: 3, batch:   4114] loss: 0.06873  | 0.18\n",
      "[epoch: 3, batch:   4116] loss: 0.03303  | 0.17\n",
      "[epoch: 3, batch:   4118] loss: 0.65767  | 0.19\n",
      "[epoch: 3, batch:   4120] loss: 1.87426  | 0.18\n",
      "[epoch: 3, batch:   4122] loss: 0.60478  | 0.18\n",
      "[epoch: 3, batch:   4124] loss: 0.27665  | 0.18\n",
      "[epoch: 3, batch:   4126] loss: 0.09403  | 0.18\n",
      "[epoch: 3, batch:   4128] loss: 0.20985  | 0.39\n",
      "[epoch: 3, batch:   4130] loss: 0.12704  | 0.19\n",
      "[epoch: 3, batch:   4132] loss: 0.14303  | 0.18\n",
      "[epoch: 3, batch:   4134] loss: 0.17892  | 0.18\n",
      "[epoch: 3, batch:   4136] loss: 0.13339  | 0.19\n",
      "[epoch: 3, batch:   4138] loss: 0.13178  | 0.18\n",
      "[epoch: 3, batch:   4140] loss: 0.34980  | 0.18\n",
      "[epoch: 3, batch:   4142] loss: 0.68784  | 0.17\n",
      "[epoch: 3, batch:   4144] loss: 0.17155  | 0.18\n",
      "[epoch: 3, batch:   4146] loss: 0.48827  | 0.18\n",
      "[epoch: 3, batch:   4148] loss: 0.05771  | 0.18\n",
      "[epoch: 3, batch:   4150] loss: 0.04477  | 0.18\n",
      "[epoch: 3, batch:   4152] loss: 0.16589  | 0.19\n",
      "[epoch: 3, batch:   4154] loss: 0.27780  | 0.17\n",
      "[epoch: 3, batch:   4156] loss: 0.13892  | 0.18\n",
      "[epoch: 3, batch:   4158] loss: 0.42813  | 0.18\n",
      "[epoch: 3, batch:   4160] loss: 0.74973  | 0.18\n",
      "[epoch: 3, batch:   4162] loss: 0.13021  | 0.18\n",
      "[epoch: 3, batch:   4164] loss: 0.08353  | 0.60\n",
      "[epoch: 3, batch:   4166] loss: 0.11006  | 0.18\n",
      "[epoch: 3, batch:   4168] loss: 0.17282  | 0.18\n",
      "[epoch: 3, batch:   4170] loss: 0.57956  | 0.18\n",
      "[epoch: 3, batch:   4172] loss: 0.01805  | 0.19\n",
      "[epoch: 3, batch:   4174] loss: 0.29650  | 0.18\n",
      "[epoch: 3, batch:   4176] loss: 0.20084  | 0.18\n",
      "[epoch: 3, batch:   4178] loss: 0.07631  | 0.17\n",
      "[epoch: 3, batch:   4180] loss: 0.40684  | 0.18\n",
      "[epoch: 3, batch:   4182] loss: 0.37028  | 0.18\n",
      "[epoch: 3, batch:   4184] loss: 0.28293  | 0.18\n",
      "[epoch: 3, batch:   4186] loss: 0.04923  | 0.28\n",
      "[epoch: 3, batch:   4188] loss: 0.46930  | 0.18\n",
      "[epoch: 3, batch:   4190] loss: 0.79225  | 0.18\n",
      "[epoch: 3, batch:   4192] loss: 0.05444  | 0.19\n",
      "[epoch: 3, batch:   4194] loss: 0.16217  | 0.19\n",
      "[epoch: 3, batch:   4196] loss: 0.17703  | 0.17\n",
      "[epoch: 3, batch:   4198] loss: 0.19771  | 0.18\n",
      "[epoch: 3, batch:   4200] loss: 0.70239  | 0.19\n",
      "[epoch: 3, batch:   4202] loss: 0.45254  | 0.18\n",
      "[epoch: 3, batch:   4204] loss: 0.94289  | 0.17\n",
      "[epoch: 3, batch:   4206] loss: 0.07373  | 0.18\n",
      "[epoch: 3, batch:   4208] loss: 0.73518  | 0.19\n",
      "[epoch: 3, batch:   4210] loss: 0.04099  | 0.18\n",
      "[epoch: 3, batch:   4212] loss: 1.49363  | 0.30\n",
      "[epoch: 3, batch:   4214] loss: 0.24150  | 0.18\n",
      "[epoch: 3, batch:   4216] loss: 0.30968  | 0.18\n",
      "[epoch: 3, batch:   4218] loss: 0.45722  | 0.17\n",
      "[epoch: 3, batch:   4220] loss: 0.72315  | 0.18\n",
      "[epoch: 3, batch:   4222] loss: 0.08200  | 0.18\n",
      "[epoch: 3, batch:   4224] loss: 0.12968  | 0.18\n",
      "[epoch: 3, batch:   4226] loss: 0.10673  | 0.17\n",
      "[epoch: 3, batch:   4228] loss: 0.09689  | 0.18\n",
      "[epoch: 3, batch:   4230] loss: 0.03436  | 0.18\n",
      "[epoch: 3, batch:   4232] loss: 0.19882  | 0.95\n",
      "[epoch: 3, batch:   4234] loss: 0.09622  | 0.18\n",
      "[epoch: 3, batch:   4236] loss: 0.11535  | 0.18\n",
      "[epoch: 3, batch:   4238] loss: 0.24352  | 0.19\n",
      "[epoch: 3, batch:   4240] loss: 0.14495  | 0.19\n",
      "[epoch: 3, batch:   4242] loss: 0.74270  | 0.17\n",
      "[epoch: 3, batch:   4244] loss: 0.44052  | 0.18\n",
      "[epoch: 3, batch:   4246] loss: 0.82909  | 0.18\n",
      "[epoch: 3, batch:   4248] loss: 0.69651  | 0.18\n",
      "[epoch: 3, batch:   4250] loss: 0.19905  | 0.18\n",
      "[epoch: 3, batch:   4252] loss: 0.39358  | 0.18\n",
      "[epoch: 3, batch:   4254] loss: 0.23223  | 0.50\n",
      "[epoch: 3, batch:   4256] loss: 0.17171  | 0.18\n",
      "[epoch: 3, batch:   4258] loss: 0.16719  | 0.18\n",
      "[epoch: 3, batch:   4260] loss: 0.42745  | 0.17\n",
      "[epoch: 3, batch:   4262] loss: 0.12160  | 0.20\n",
      "[epoch: 3, batch:   4264] loss: 0.72780  | 0.18\n",
      "[epoch: 3, batch:   4266] loss: 0.08194  | 0.18\n",
      "[epoch: 3, batch:   4268] loss: 0.24944  | 0.27\n",
      "[epoch: 3, batch:   4270] loss: 0.15021  | 0.17\n",
      "[epoch: 3, batch:   4272] loss: 0.18478  | 0.41\n",
      "[epoch: 3, batch:   4274] loss: 0.05370  | 0.18\n",
      "[epoch: 3, batch:   4276] loss: 0.07312  | 0.18\n",
      "[epoch: 3, batch:   4278] loss: 0.18933  | 0.18\n",
      "[epoch: 3, batch:   4280] loss: 0.11144  | 0.27\n",
      "[epoch: 3, batch:   4282] loss: 0.15032  | 0.18\n",
      "[epoch: 3, batch:   4284] loss: 0.39228  | 0.18\n",
      "[epoch: 3, batch:   4286] loss: 0.32374  | 0.18\n",
      "[epoch: 3, batch:   4288] loss: 0.20674  | 0.19\n",
      "[epoch: 3, batch:   4290] loss: 0.24751  | 0.18\n",
      "[epoch: 3, batch:   4292] loss: 0.14150  | 0.19\n",
      "[epoch: 3, batch:   4294] loss: 0.17456  | 0.18\n",
      "[epoch: 3, batch:   4296] loss: 0.18742  | 0.18\n",
      "[epoch: 3, batch:   4298] loss: 0.40102  | 0.17\n",
      "[epoch: 3, batch:   4300] loss: 0.01110  | 0.18\n",
      "[epoch: 3, batch:   4302] loss: 0.06506  | 0.18\n",
      "[epoch: 3, batch:   4304] loss: 0.05899  | 0.18\n",
      "[epoch: 3, batch:   4306] loss: 0.36739  | 0.18\n",
      "[epoch: 3, batch:   4308] loss: 0.25443  | 0.43\n",
      "[epoch: 3, batch:   4310] loss: 0.49131  | 0.19\n",
      "[epoch: 3, batch:   4312] loss: 0.24359  | 0.18\n",
      "[epoch: 3, batch:   4314] loss: 0.14090  | 0.18\n",
      "[epoch: 3, batch:   4316] loss: 0.14083  | 0.31\n",
      "[epoch: 3, batch:   4318] loss: 0.76121  | 0.18\n",
      "[epoch: 3, batch:   4320] loss: 0.06369  | 0.18\n",
      "[epoch: 3, batch:   4322] loss: 1.01092  | 0.18\n",
      "[epoch: 3, batch:   4324] loss: 0.18418  | 0.19\n",
      "[epoch: 3, batch:   4326] loss: 0.59486  | 0.18\n",
      "[epoch: 3, batch:   4328] loss: 0.12598  | 0.18\n",
      "[epoch: 3, batch:   4330] loss: 0.15495  | 0.18\n",
      "[epoch: 3, batch:   4332] loss: 0.03026  | 0.18\n",
      "[epoch: 3, batch:   4334] loss: 0.24064  | 0.19\n",
      "[epoch: 3, batch:   4336] loss: 0.12489  | 0.18\n",
      "[epoch: 3, batch:   4338] loss: 0.03706  | 0.17\n",
      "[epoch: 3, batch:   4340] loss: 0.18441  | 0.18\n",
      "[epoch: 3, batch:   4342] loss: 0.85504  | 0.93\n",
      "[epoch: 3, batch:   4344] loss: 0.12249  | 0.18\n",
      "[epoch: 3, batch:   4346] loss: 1.11310  | 0.18\n",
      "[epoch: 3, batch:   4348] loss: 0.19526  | 0.19\n",
      "[epoch: 3, batch:   4350] loss: 0.20859  | 0.18\n",
      "[epoch: 3, batch:   4352] loss: 0.21389  | 0.18\n",
      "[epoch: 3, batch:   4354] loss: 0.11894  | 0.18\n",
      "[epoch: 3, batch:   4356] loss: 1.03505  | 0.24\n",
      "[epoch: 3, batch:   4358] loss: 0.18779  | 0.18\n",
      "[epoch: 3, batch:   4360] loss: 0.45334  | 0.18\n",
      "[epoch: 3, batch:   4362] loss: 0.67475  | 0.23\n",
      "[epoch: 3, batch:   4364] loss: 1.54878  | 0.18\n",
      "[epoch: 3, batch:   4366] loss: 0.25402  | 0.18\n",
      "[epoch: 3, batch:   4368] loss: 0.12092  | 0.18\n",
      "[epoch: 3, batch:   4370] loss: 0.07503  | 1.33\n",
      "[epoch: 3, batch:   4372] loss: 0.08301  | 0.17\n",
      "[epoch: 3, batch:   4374] loss: 0.10160  | 0.18\n",
      "[epoch: 3, batch:   4376] loss: 0.16591  | 0.36\n",
      "[epoch: 3, batch:   4378] loss: 0.09270  | 0.17\n",
      "[epoch: 3, batch:   4380] loss: 0.23320  | 0.18\n",
      "[epoch: 3, batch:   4382] loss: 0.07354  | 0.18\n",
      "[epoch: 3, batch:   4384] loss: 0.08651  | 0.58\n",
      "[epoch: 3, batch:   4386] loss: 0.25794  | 0.17\n",
      "[epoch: 3, batch:   4388] loss: 0.15180  | 0.18\n",
      "[epoch: 3, batch:   4390] loss: 0.56094  | 0.18\n",
      "[epoch: 3, batch:   4392] loss: 0.13515  | 0.18\n",
      "[epoch: 3, batch:   4394] loss: 0.04719  | 0.17\n",
      "[epoch: 3, batch:   4396] loss: 0.03903  | 0.18\n",
      "[epoch: 3, batch:   4398] loss: 0.46185  | 0.18\n",
      "[epoch: 3, batch:   4400] loss: 0.19082  | 0.18\n",
      "[epoch: 3, batch:   4402] loss: 0.60252  | 0.19\n",
      "[epoch: 3, batch:   4404] loss: 0.23264  | 0.18\n",
      "[epoch: 3, batch:   4406] loss: 0.53398  | 0.24\n",
      "[epoch: 3, batch:   4408] loss: 0.03318  | 0.17\n",
      "[epoch: 3, batch:   4410] loss: 0.14994  | 0.19\n",
      "[epoch: 3, batch:   4412] loss: 0.34947  | 0.18\n",
      "[epoch: 3, batch:   4414] loss: 0.16647  | 0.18\n",
      "[epoch: 3, batch:   4416] loss: 0.09481  | 0.18\n",
      "[epoch: 3, batch:   4418] loss: 0.12562  | 0.40\n",
      "[epoch: 3, batch:   4420] loss: 0.05834  | 0.18\n",
      "[epoch: 3, batch:   4422] loss: 0.13867  | 0.18\n",
      "[epoch: 3, batch:   4424] loss: 0.12619  | 0.17\n",
      "[epoch: 3, batch:   4426] loss: 0.62651  | 0.19\n",
      "[epoch: 3, batch:   4428] loss: 0.15979  | 0.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 3, batch:   4430] loss: 0.29022  | 0.19\n",
      "[epoch: 3, batch:   4432] loss: 0.29370  | 0.80\n",
      "[epoch: 3, batch:   4434] loss: 0.46677  | 0.17\n",
      "[epoch: 3, batch:   4436] loss: 0.29303  | 0.18\n",
      "[epoch: 3, batch:   4438] loss: 0.33041  | 0.18\n",
      "[epoch: 3, batch:   4440] loss: 0.06803  | 0.18\n",
      "[epoch: 3, batch:   4442] loss: 0.15874  | 0.17\n",
      "[epoch: 3, batch:   4444] loss: 0.20614  | 0.18\n",
      "[epoch: 3, batch:   4446] loss: 0.29913  | 0.18\n",
      "[epoch: 3, batch:   4448] loss: 0.30214  | 0.18\n",
      "[epoch: 3, batch:   4450] loss: 0.04645  | 0.18\n",
      "[epoch: 3, batch:   4452] loss: 0.64925  | 0.35\n",
      "[epoch: 3, batch:   4454] loss: 0.27595  | 0.17\n",
      "[epoch: 3, batch:   4456] loss: 0.00675  | 0.18\n",
      "[epoch: 3, batch:   4458] loss: 0.02547  | 0.18\n",
      "[epoch: 3, batch:   4460] loss: 0.38684  | 0.31\n",
      "[epoch: 3, batch:   4462] loss: 0.20249  | 0.18\n",
      "[epoch: 3, batch:   4464] loss: 0.29101  | 0.18\n",
      "[epoch: 3, batch:   4466] loss: 0.01456  | 0.18\n",
      "[epoch: 3, batch:   4468] loss: 0.06936  | 0.18\n",
      "[epoch: 3, batch:   4470] loss: 0.15358  | 0.18\n",
      "[epoch: 3, batch:   4472] loss: 0.06601  | 0.35\n",
      "[epoch: 3, batch:   4474] loss: 0.04676  | 0.17\n",
      "[epoch: 3, batch:   4476] loss: 0.05761  | 0.18\n",
      "[epoch: 3, batch:   4478] loss: 0.08108  | 0.18\n",
      "[epoch: 3, batch:   4480] loss: 0.14195  | 0.18\n",
      "[epoch: 3, batch:   4482] loss: 0.54933  | 0.32\n",
      "[epoch: 3, batch:   4484] loss: 0.23946  | 0.17\n",
      "[epoch: 3, batch:   4486] loss: 0.08456  | 0.18\n",
      "[epoch: 3, batch:   4488] loss: 0.20686  | 0.18\n",
      "[epoch: 3, batch:   4490] loss: 0.59018  | 0.19\n",
      "[epoch: 3, batch:   4492] loss: 0.15484  | 0.19\n",
      "[epoch: 3, batch:   4494] loss: 0.12864  | 0.30\n",
      "[epoch: 3, batch:   4496] loss: 0.48592  | 0.18\n",
      "[epoch: 3, batch:   4498] loss: 0.04605  | 0.19\n",
      "[epoch: 3, batch:   4500] loss: 0.10483  | 0.18\n",
      "[epoch: 3, batch:   4502] loss: 0.07691  | 0.18\n",
      "[epoch: 3, batch:   4504] loss: 0.59909  | 0.18\n",
      "[epoch: 3, batch:   4506] loss: 0.09112  | 0.18\n",
      "[epoch: 3, batch:   4508] loss: 0.24736  | 0.18\n",
      "[epoch: 3, batch:   4510] loss: 0.33026  | 0.18\n",
      "[epoch: 3, batch:   4512] loss: 0.10735  | 0.18\n",
      "[epoch: 3, batch:   4514] loss: 0.14387  | 0.18\n",
      "[epoch: 3, batch:   4516] loss: 0.59003  | 0.18\n",
      "[epoch: 3, batch:   4518] loss: 0.26170  | 0.52\n",
      "[epoch: 3, batch:   4520] loss: 0.26911  | 0.18\n",
      "[epoch: 3, batch:   4522] loss: 0.12364  | 0.18\n",
      "[epoch: 3, batch:   4524] loss: 0.24452  | 0.18\n",
      "[epoch: 3, batch:   4526] loss: 0.08353  | 0.18\n",
      "[epoch: 3, batch:   4528] loss: 0.16070  | 0.19\n",
      "[epoch: 3, batch:   4530] loss: 0.15353  | 0.18\n",
      "[epoch: 3, batch:   4532] loss: 0.16375  | 0.17\n",
      "[epoch: 3, batch:   4534] loss: 0.11691  | 0.18\n",
      "[epoch: 3, batch:   4536] loss: 0.06108  | 0.18\n",
      "[epoch: 3, batch:   4538] loss: 0.03938  | 0.31\n",
      "[epoch: 3, batch:   4540] loss: 0.08004  | 0.18\n",
      "[epoch: 3, batch:   4542] loss: 0.65987  | 0.18\n",
      "[epoch: 3, batch:   4544] loss: 0.25580  | 0.18\n",
      "[epoch: 3, batch:   4546] loss: 0.01025  | 0.29\n",
      "[epoch: 3, batch:   4548] loss: 0.03944  | 0.18\n",
      "[epoch: 3, batch:   4550] loss: 0.05590  | 0.18\n",
      "[epoch: 3, batch:   4552] loss: 0.04945  | 0.18\n",
      "[epoch: 3, batch:   4554] loss: 0.12661  | 0.49\n",
      "[epoch: 3, batch:   4556] loss: 0.49092  | 0.18\n",
      "[epoch: 3, batch:   4558] loss: 0.02812  | 0.19\n",
      "[epoch: 3, batch:   4560] loss: 0.19337  | 0.18\n",
      "[epoch: 3, batch:   4562] loss: 0.31828  | 0.35\n",
      "[epoch: 3, batch:   4564] loss: 0.26127  | 0.18\n",
      "[epoch: 3, batch:   4566] loss: 0.55505  | 0.18\n",
      "[epoch: 3, batch:   4568] loss: 0.09975  | 0.17\n",
      "[epoch: 3, batch:   4570] loss: 0.10923  | 0.18\n",
      "[epoch: 3, batch:   4572] loss: 0.21695  | 0.55\n",
      "[epoch: 3, batch:   4574] loss: 0.13635  | 0.17\n",
      "[epoch: 3, batch:   4576] loss: 0.09725  | 0.18\n",
      "[epoch: 3, batch:   4578] loss: 0.12833  | 0.18\n",
      "[epoch: 3, batch:   4580] loss: 0.25528  | 0.44\n",
      "[epoch: 3, batch:   4582] loss: 0.40331  | 0.19\n",
      "[epoch: 3, batch:   4584] loss: 0.01749  | 0.18\n",
      "[epoch: 3, batch:   4586] loss: 0.44491  | 0.17\n",
      "[epoch: 3, batch:   4588] loss: 0.07869  | 0.18\n",
      "[epoch: 3, batch:   4590] loss: 0.08131  | 0.41\n",
      "[epoch: 3, batch:   4592] loss: 0.15235  | 0.18\n",
      "[epoch: 3, batch:   4594] loss: 0.18085  | 0.18\n",
      "[epoch: 3, batch:   4596] loss: 0.50476  | 0.18\n",
      "[epoch: 3, batch:   4598] loss: 0.14143  | 0.18\n",
      "[epoch: 3, batch:   4600] loss: 0.07795  | 0.19\n",
      "[epoch: 3, batch:   4602] loss: 0.27988  | 0.19\n",
      "[epoch: 3, batch:   4604] loss: 0.10037  | 0.18\n",
      "[epoch: 3, batch:   4606] loss: 0.04327  | 0.18\n",
      "[epoch: 3, batch:   4608] loss: 0.04279  | 0.17\n",
      "[epoch: 3, batch:   4610] loss: 0.29222  | 0.19\n",
      "[epoch: 3, batch:   4612] loss: 0.01473  | 0.18\n",
      "[epoch: 3, batch:   4614] loss: 0.07311  | 0.18\n",
      "[epoch: 3, batch:   4616] loss: 0.28225  | 0.17\n",
      "[epoch: 3, batch:   4618] loss: 0.03379  | 0.18\n",
      "[epoch: 3, batch:   4620] loss: 0.21591  | 0.18\n",
      "[epoch: 3, batch:   4622] loss: 0.21458  | 0.37\n",
      "[epoch: 3, batch:   4624] loss: 0.04596  | 0.19\n",
      "[epoch: 3, batch:   4626] loss: 0.29762  | 0.18\n",
      "[epoch: 3, batch:   4628] loss: 0.11042  | 0.18\n",
      "[epoch: 3, batch:   4630] loss: 0.50719  | 0.18\n",
      "[epoch: 3, batch:   4632] loss: 0.16642  | 0.19\n",
      "[epoch: 3, batch:   4634] loss: 0.10348  | 0.18\n",
      "[epoch: 3, batch:   4636] loss: 0.10090  | 0.17\n",
      "[epoch: 3, batch:   4638] loss: 0.11356  | 0.19\n",
      "[epoch: 3, batch:   4640] loss: 0.13650  | 0.18\n",
      "[epoch: 3, batch:   4642] loss: 0.45563  | 0.18\n",
      "[epoch: 3, batch:   4644] loss: 0.15075  | 0.18\n",
      "[epoch: 3, batch:   4646] loss: 0.35901  | 0.20\n",
      "[epoch: 3, batch:   4648] loss: 0.05956  | 0.18\n",
      "[epoch: 3, batch:   4650] loss: 0.38985  | 0.18\n",
      "[epoch: 3, batch:   4652] loss: 0.31300  | 0.17\n",
      "[epoch: 3, batch:   4654] loss: 0.40794  | 0.18\n",
      "[epoch: 3, batch:   4656] loss: 0.06724  | 0.18\n",
      "[epoch: 3, batch:   4658] loss: 0.04910  | 0.19\n",
      "[epoch: 3, batch:   4660] loss: 0.33711  | 0.17\n",
      "[epoch: 3, batch:   4662] loss: 0.12848  | 0.18\n",
      "[epoch: 3, batch:   4664] loss: 0.02018  | 0.18\n",
      "[epoch: 3, batch:   4666] loss: 0.71941  | 0.30\n",
      "[epoch: 3, batch:   4668] loss: 0.23043  | 0.18\n",
      "[epoch: 3, batch:   4670] loss: 0.11106  | 0.61\n",
      "[epoch: 3, batch:   4672] loss: 0.17295  | 0.17\n",
      "[epoch: 3, batch:   4674] loss: 0.28394  | 0.18\n",
      "[epoch: 3, batch:   4676] loss: 0.26617  | 0.18\n",
      "[epoch: 3, batch:   4678] loss: 0.56697  | 0.18\n",
      "[epoch: 3, batch:   4680] loss: 0.17878  | 0.17\n",
      "[epoch: 3, batch:   4682] loss: 0.33259  | 0.18\n",
      "[epoch: 3, batch:   4684] loss: 1.19461  | 0.18\n",
      "[epoch: 3, batch:   4686] loss: 0.41722  | 0.18\n",
      "[epoch: 3, batch:   4688] loss: 0.20035  | 0.18\n",
      "[epoch: 3, batch:   4690] loss: 0.07900  | 0.18\n",
      "[epoch: 3, batch:   4692] loss: 0.20377  | 0.18\n",
      "[epoch: 3, batch:   4694] loss: 0.07192  | 0.18\n",
      "[epoch: 3, batch:   4696] loss: 0.10420  | 0.18\n",
      "[epoch: 3, batch:   4698] loss: 0.15000  | 0.35\n",
      "[epoch: 3, batch:   4700] loss: 0.21891  | 0.18\n",
      "[epoch: 3, batch:   4702] loss: 0.37996  | 0.18\n",
      "[epoch: 3, batch:   4704] loss: 0.06255  | 0.18\n",
      "[epoch: 3, batch:   4706] loss: 0.39370  | 0.27\n",
      "[epoch: 3, batch:   4708] loss: 0.06717  | 0.18\n",
      "[epoch: 3, batch:   4710] loss: 0.64106  | 0.18\n",
      "[epoch: 3, batch:   4712] loss: 0.07434  | 0.17\n",
      "[epoch: 3, batch:   4714] loss: 0.04251  | 0.19\n",
      "[epoch: 3, batch:   4716] loss: 0.04354  | 0.18\n",
      "[epoch: 3, batch:   4718] loss: 0.03550  | 0.18\n",
      "[epoch: 3, batch:   4720] loss: 0.08151  | 0.18\n",
      "[epoch: 3, batch:   4722] loss: 0.08884  | 0.18\n",
      "[epoch: 3, batch:   4724] loss: 0.27217  | 0.73\n",
      "[epoch: 3, batch:   4726] loss: 0.04113  | 0.17\n",
      "[epoch: 3, batch:   4728] loss: 0.02995  | 0.18\n",
      "[epoch: 3, batch:   4730] loss: 0.09460  | 0.17\n",
      "[epoch: 3, batch:   4732] loss: 0.10255  | 0.18\n",
      "[epoch: 3, batch:   4734] loss: 0.59186  | 0.17\n",
      "[epoch: 3, batch:   4736] loss: 1.75087  | 0.18\n",
      "[epoch: 3, batch:   4738] loss: 0.13085  | 0.17\n",
      "[epoch: 3, batch:   4740] loss: 0.05842  | 0.38\n",
      "[epoch: 3, batch:   4742] loss: 0.23449  | 0.17\n",
      "[epoch: 3, batch:   4744] loss: 0.07083  | 0.18\n",
      "[epoch: 3, batch:   4746] loss: 0.78802  | 0.17\n",
      "[epoch: 3, batch:   4748] loss: 0.49498  | 0.18\n",
      "[epoch: 3, batch:   4750] loss: 0.24313  | 0.31\n",
      "[epoch: 3, batch:   4752] loss: 0.61302  | 0.38\n",
      "[epoch: 3, batch:   4754] loss: 0.07014  | 0.18\n",
      "[epoch: 3, batch:   4756] loss: 0.27223  | 0.19\n",
      "[epoch: 3, batch:   4758] loss: 0.61923  | 0.18\n",
      "[epoch: 3, batch:   4760] loss: 0.20074  | 0.19\n",
      "[epoch: 3, batch:   4762] loss: 0.19796  | 0.17\n",
      "[epoch: 3, batch:   4764] loss: 0.17469  | 1.24\n",
      "[epoch: 3, batch:   4766] loss: 0.08070  | 0.17\n",
      "[epoch: 3, batch:   4768] loss: 0.13860  | 0.18\n",
      "[epoch: 3, batch:   4770] loss: 0.17577  | 0.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 3, batch:   4772] loss: 0.26962  | 0.18\n",
      "[epoch: 3, batch:   4774] loss: 0.03986  | 0.17\n",
      "[epoch: 3, batch:   4776] loss: 0.22669  | 0.52\n",
      "[epoch: 3, batch:   4778] loss: 0.04454  | 0.18\n",
      "[epoch: 3, batch:   4780] loss: 0.07369  | 0.18\n",
      "[epoch: 3, batch:   4782] loss: 0.04139  | 0.17\n",
      "[epoch: 3, batch:   4784] loss: 0.37681  | 0.18\n",
      "[epoch: 3, batch:   4786] loss: 0.15854  | 0.80\n",
      "[epoch: 3, batch:   4788] loss: 0.13145  | 0.18\n",
      "[epoch: 3, batch:   4790] loss: 1.26421  | 0.18\n",
      "[epoch: 3, batch:   4792] loss: 0.41654  | 0.17\n",
      "[epoch: 3, batch:   4794] loss: 0.22536  | 0.18\n",
      "[epoch: 3, batch:   4796] loss: 0.01468  | 0.18\n",
      "[epoch: 3, batch:   4798] loss: 0.84818  | 0.18\n",
      "[epoch: 3, batch:   4800] loss: 0.48219  | 0.18\n",
      "[epoch: 3, batch:   4802] loss: 0.18884  | 0.18\n",
      "[epoch: 3, batch:   4804] loss: 0.59752  | 0.18\n",
      "[epoch: 3, batch:   4806] loss: 0.03968  | 0.18\n",
      "[epoch: 3, batch:   4808] loss: 0.17787  | 0.18\n",
      "[epoch: 3, batch:   4810] loss: 0.06065  | 0.18\n",
      "[epoch: 3, batch:   4812] loss: 0.68961  | 0.19\n",
      "[epoch: 3, batch:   4814] loss: 0.27927  | 0.18\n",
      "[epoch: 3, batch:   4816] loss: 0.01451  | 0.18\n",
      "[epoch: 3, batch:   4818] loss: 0.12318  | 0.18\n",
      "[epoch: 3, batch:   4820] loss: 0.24907  | 2.37\n",
      "[epoch: 3, batch:   4822] loss: 0.07373  | 0.18\n",
      "[epoch: 3, batch:   4824] loss: 0.07214  | 0.18\n",
      "[epoch: 3, batch:   4826] loss: 0.20584  | 0.17\n",
      "[epoch: 3, batch:   4828] loss: 0.12989  | 0.18\n",
      "[epoch: 3, batch:   4830] loss: 0.34752  | 0.18\n",
      "[epoch: 3, batch:   4832] loss: 0.04395  | 0.18\n",
      "[epoch: 3, batch:   4834] loss: 0.05976  | 0.17\n",
      "[epoch: 3, batch:   4836] loss: 0.07213  | 0.18\n",
      "[epoch: 3, batch:   4838] loss: 0.27831  | 0.18\n",
      "[epoch: 3, batch:   4840] loss: 0.51738  | 0.20\n",
      "[epoch: 3, batch:   4842] loss: 0.02183  | 0.18\n",
      "[epoch: 3, batch:   4844] loss: 0.16227  | 0.18\n",
      "[epoch: 3, batch:   4846] loss: 0.68760  | 0.17\n",
      "[epoch: 3, batch:   4848] loss: 0.29963  | 0.19\n",
      "[epoch: 3, batch:   4850] loss: 0.32535  | 0.17\n",
      "[epoch: 3, batch:   4852] loss: 0.09476  | 0.18\n",
      "[epoch: 3, batch:   4854] loss: 0.17803  | 0.18\n",
      "[epoch: 3, batch:   4856] loss: 0.14972  | 0.18\n",
      "[epoch: 3, batch:   4858] loss: 0.53675  | 0.18\n",
      "[epoch: 3, batch:   4860] loss: 0.26455  | 0.18\n",
      "[epoch: 3, batch:   4862] loss: 0.14570  | 0.18\n",
      "[epoch: 3, batch:   4864] loss: 0.04684  | 0.46\n",
      "[epoch: 3, batch:   4866] loss: 0.08742  | 0.18\n",
      "[epoch: 3, batch:   4868] loss: 0.03346  | 0.18\n",
      "[epoch: 3, batch:   4870] loss: 0.58201  | 0.18\n",
      "[epoch: 3, batch:   4872] loss: 0.46643  | 0.18\n",
      "[epoch: 3, batch:   4874] loss: 0.21101  | 0.18\n",
      "[epoch: 3, batch:   4876] loss: 0.10377  | 0.18\n",
      "[epoch: 3, batch:   4878] loss: 0.18247  | 0.54\n",
      "[epoch: 3, batch:   4880] loss: 0.39604  | 0.18\n",
      "[epoch: 3, batch:   4882] loss: 0.16461  | 0.18\n",
      "[epoch: 3, batch:   4884] loss: 0.25649  | 0.19\n",
      "[epoch: 3, batch:   4886] loss: 0.16950  | 0.35\n",
      "[epoch: 3, batch:   4888] loss: 0.25499  | 0.18\n",
      "[epoch: 3, batch:   4890] loss: 0.18353  | 0.17\n",
      "[epoch: 3, batch:   4892] loss: 0.10123  | 0.17\n",
      "[epoch: 3, batch:   4894] loss: 0.02903  | 0.25\n",
      "[epoch: 3, batch:   4896] loss: 0.08440  | 0.17\n",
      "[epoch: 3, batch:   4898] loss: 0.03207  | 0.18\n",
      "[epoch: 3, batch:   4900] loss: 0.12502  | 0.18\n",
      "[epoch: 3, batch:   4902] loss: 0.63280  | 0.38\n",
      "[epoch: 3, batch:   4904] loss: 0.43645  | 0.18\n",
      "[epoch: 3, batch:   4906] loss: 0.02591  | 0.18\n",
      "[epoch: 3, batch:   4908] loss: 0.06578  | 0.18\n",
      "[epoch: 3, batch:   4910] loss: 0.74349  | 0.18\n",
      "[epoch: 3, batch:   4912] loss: 0.30631  | 0.18\n",
      "[epoch: 3, batch:   4914] loss: 0.14722  | 0.19\n",
      "[epoch: 3, batch:   4916] loss: 0.13554  | 0.18\n",
      "[epoch: 3, batch:   4918] loss: 0.65705  | 0.18\n",
      "[epoch: 3, batch:   4920] loss: 0.04160  | 0.17\n",
      "[epoch: 3, batch:   4922] loss: 0.32306  | 0.19\n",
      "[epoch: 3, batch:   4924] loss: 0.01601  | 0.18\n",
      "[epoch: 3, batch:   4926] loss: 1.19391  | 0.28\n",
      "[epoch: 3, batch:   4928] loss: 0.09857  | 0.51\n",
      "[epoch: 3, batch:   4930] loss: 0.10822  | 0.69\n",
      "[epoch: 3, batch:   4932] loss: 0.55277  | 0.17\n",
      "[epoch: 3, batch:   4934] loss: 0.10384  | 0.18\n",
      "[epoch: 3, batch:   4936] loss: 0.05394  | 0.18\n",
      "[epoch: 3, batch:   4938] loss: 0.19399  | 0.18\n",
      "[epoch: 3, batch:   4940] loss: 1.96667  | 0.17\n",
      "[epoch: 3, batch:   4942] loss: 0.07272  | 0.18\n",
      "[epoch: 3, batch:   4944] loss: 0.57339  | 0.18\n",
      "[epoch: 3, batch:   4946] loss: 0.69309  | 0.19\n",
      "[epoch: 3, batch:   4948] loss: 0.02099  | 0.18\n",
      "[epoch: 3, batch:   4950] loss: 0.09550  | 0.18\n",
      "[epoch: 3, batch:   4952] loss: 0.22739  | 0.18\n",
      "[epoch: 3, batch:   4954] loss: 0.09403  | 0.66\n",
      "[epoch: 3, batch:   4956] loss: 0.21466  | 0.17\n",
      "[epoch: 3, batch:   4958] loss: 0.34130  | 0.18\n",
      "[epoch: 3, batch:   4960] loss: 0.06815  | 0.18\n",
      "[epoch: 3, batch:   4962] loss: 0.12285  | 0.26\n",
      "[epoch: 3, batch:   4964] loss: 0.19679  | 0.18\n",
      "[epoch: 3, batch:   4966] loss: 0.31269  | 0.18\n",
      "[epoch: 3, batch:   4968] loss: 0.07751  | 0.18\n",
      "[epoch: 3, batch:   4970] loss: 0.34035  | 0.18\n",
      "[epoch: 3, batch:   4972] loss: 0.43155  | 0.18\n",
      "[epoch: 3, batch:   4974] loss: 0.38799  | 0.19\n",
      "[epoch: 3, batch:   4976] loss: 0.27869  | 0.17\n",
      "[epoch: 3, batch:   4978] loss: 0.14246  | 0.18\n",
      "[epoch: 3, batch:   4980] loss: 0.34067  | 0.18\n",
      "[epoch: 3, batch:   4982] loss: 0.08818  | 0.20\n",
      "[epoch: 3, batch:   4984] loss: 0.65484  | 0.17\n",
      "[epoch: 3, batch:   4986] loss: 0.64220  | 0.18\n",
      "[epoch: 3, batch:   4988] loss: 0.08315  | 0.18\n",
      "[epoch: 3, batch:   4990] loss: 0.25555  | 1.42\n",
      "[epoch: 3, batch:   4992] loss: 0.13451  | 0.17\n",
      "[epoch: 3, batch:   4994] loss: 0.21385  | 0.18\n",
      "[epoch: 3, batch:   4996] loss: 0.04695  | 0.18\n",
      "[epoch: 3, batch:   4998] loss: 0.07581  | 0.18\n",
      "[epoch: 3, batch:   5000] loss: 0.16808  | 0.17\n",
      "[epoch: 4, batch:      2] loss: 0.47210  | 4.16\n",
      "[epoch: 4, batch:      4] loss: 0.04769  | 0.18\n",
      "[epoch: 4, batch:      6] loss: 0.25997  | 0.18\n",
      "[epoch: 4, batch:      8] loss: 0.24537  | 0.18\n",
      "[epoch: 4, batch:     10] loss: 0.23257  | 0.62\n",
      "[epoch: 4, batch:     12] loss: 0.43829  | 0.17\n",
      "[epoch: 4, batch:     14] loss: 0.16496  | 0.17\n",
      "[epoch: 4, batch:     16] loss: 1.62141  | 0.17\n",
      "[epoch: 4, batch:     18] loss: 0.59375  | 0.35\n",
      "[epoch: 4, batch:     20] loss: 0.09724  | 0.17\n",
      "[epoch: 4, batch:     22] loss: 1.12818  | 0.18\n",
      "[epoch: 4, batch:     24] loss: 0.79223  | 0.18\n",
      "[epoch: 4, batch:     26] loss: 0.03622  | 0.48\n",
      "[epoch: 4, batch:     28] loss: 0.18840  | 0.18\n",
      "[epoch: 4, batch:     30] loss: 0.34004  | 0.18\n",
      "[epoch: 4, batch:     32] loss: 0.13778  | 0.18\n",
      "[epoch: 4, batch:     34] loss: 0.08568  | 0.18\n",
      "[epoch: 4, batch:     36] loss: 1.92361  | 0.18\n",
      "[epoch: 4, batch:     38] loss: 0.12360  | 0.18\n",
      "[epoch: 4, batch:     40] loss: 0.45980  | 0.18\n",
      "[epoch: 4, batch:     42] loss: 0.93390  | 0.18\n",
      "[epoch: 4, batch:     44] loss: 0.19550  | 0.18\n",
      "[epoch: 4, batch:     46] loss: 0.10138  | 0.18\n",
      "[epoch: 4, batch:     48] loss: 0.13345  | 0.18\n",
      "[epoch: 4, batch:     50] loss: 0.10441  | 0.19\n",
      "[epoch: 4, batch:     52] loss: 0.13419  | 0.17\n",
      "[epoch: 4, batch:     54] loss: 0.47652  | 0.18\n",
      "[epoch: 4, batch:     56] loss: 0.23221  | 0.18\n",
      "[epoch: 4, batch:     58] loss: 1.18299  | 0.25\n",
      "[epoch: 4, batch:     60] loss: 0.11762  | 0.17\n",
      "[epoch: 4, batch:     62] loss: 0.15063  | 0.18\n",
      "[epoch: 4, batch:     64] loss: 0.33464  | 0.18\n",
      "[epoch: 4, batch:     66] loss: 0.30982  | 0.58\n",
      "[epoch: 4, batch:     68] loss: 0.13063  | 0.18\n",
      "[epoch: 4, batch:     70] loss: 0.02961  | 0.18\n",
      "[epoch: 4, batch:     72] loss: 0.44964  | 0.18\n",
      "[epoch: 4, batch:     74] loss: 0.10283  | 0.68\n",
      "[epoch: 4, batch:     76] loss: 0.45831  | 0.17\n",
      "[epoch: 4, batch:     78] loss: 0.38412  | 0.18\n",
      "[epoch: 4, batch:     80] loss: 0.05250  | 0.18\n",
      "[epoch: 4, batch:     82] loss: 0.01187  | 0.19\n",
      "[epoch: 4, batch:     84] loss: 0.03948  | 0.17\n",
      "[epoch: 4, batch:     86] loss: 1.26875  | 0.18\n",
      "[epoch: 4, batch:     88] loss: 0.43776  | 0.17\n",
      "[epoch: 4, batch:     90] loss: 0.17712  | 0.19\n",
      "[epoch: 4, batch:     92] loss: 0.33114  | 0.17\n",
      "[epoch: 4, batch:     94] loss: 0.53308  | 0.19\n",
      "[epoch: 4, batch:     96] loss: 0.26995  | 0.17\n",
      "[epoch: 4, batch:     98] loss: 0.03963  | 0.18\n",
      "[epoch: 4, batch:    100] loss: 0.90178  | 0.18\n",
      "[epoch: 4, batch:    102] loss: 0.18523  | 0.18\n",
      "[epoch: 4, batch:    104] loss: 0.09024  | 0.17\n",
      "[epoch: 4, batch:    106] loss: 0.17751  | 0.19\n",
      "[epoch: 4, batch:    108] loss: 0.33795  | 0.17\n",
      "[epoch: 4, batch:    110] loss: 0.11866  | 0.18\n",
      "[epoch: 4, batch:    112] loss: 0.52107  | 0.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4, batch:    114] loss: 0.36770  | 0.29\n",
      "[epoch: 4, batch:    116] loss: 0.12734  | 0.18\n",
      "[epoch: 4, batch:    118] loss: 0.45724  | 0.19\n",
      "[epoch: 4, batch:    120] loss: 0.12713  | 0.19\n",
      "[epoch: 4, batch:    122] loss: 0.17704  | 0.18\n",
      "[epoch: 4, batch:    124] loss: 0.25577  | 0.18\n",
      "[epoch: 4, batch:    126] loss: 0.01506  | 0.18\n",
      "[epoch: 4, batch:    128] loss: 0.05223  | 0.18\n",
      "[epoch: 4, batch:    130] loss: 0.11022  | 0.18\n",
      "[epoch: 4, batch:    132] loss: 0.03119  | 0.18\n",
      "[epoch: 4, batch:    134] loss: 0.13035  | 0.19\n",
      "[epoch: 4, batch:    136] loss: 0.05238  | 0.17\n",
      "[epoch: 4, batch:    138] loss: 0.58221  | 0.18\n",
      "[epoch: 4, batch:    140] loss: 0.14541  | 0.30\n",
      "[epoch: 4, batch:    142] loss: 0.33898  | 0.17\n",
      "[epoch: 4, batch:    144] loss: 0.18863  | 0.18\n",
      "[epoch: 4, batch:    146] loss: 0.13056  | 0.18\n",
      "[epoch: 4, batch:    148] loss: 0.55754  | 0.19\n",
      "[epoch: 4, batch:    150] loss: 0.42027  | 0.28\n",
      "[epoch: 4, batch:    152] loss: 0.20781  | 0.17\n",
      "[epoch: 4, batch:    154] loss: 0.06601  | 0.18\n",
      "[epoch: 4, batch:    156] loss: 0.24771  | 0.17\n",
      "[epoch: 4, batch:    158] loss: 0.33337  | 0.29\n",
      "[epoch: 4, batch:    160] loss: 0.39516  | 0.17\n",
      "[epoch: 4, batch:    162] loss: 0.10349  | 0.18\n",
      "[epoch: 4, batch:    164] loss: 0.22345  | 0.17\n",
      "[epoch: 4, batch:    166] loss: 0.36647  | 0.18\n",
      "[epoch: 4, batch:    168] loss: 0.21456  | 0.68\n",
      "[epoch: 4, batch:    170] loss: 0.07429  | 0.17\n",
      "[epoch: 4, batch:    172] loss: 0.05077  | 0.18\n",
      "[epoch: 4, batch:    174] loss: 0.22307  | 0.17\n",
      "[epoch: 4, batch:    176] loss: 0.59347  | 0.34\n",
      "[epoch: 4, batch:    178] loss: 0.16812  | 0.17\n",
      "[epoch: 4, batch:    180] loss: 0.06813  | 0.18\n",
      "[epoch: 4, batch:    182] loss: 0.25318  | 0.17\n",
      "[epoch: 4, batch:    184] loss: 0.47042  | 0.18\n",
      "[epoch: 4, batch:    186] loss: 0.28949  | 0.27\n",
      "[epoch: 4, batch:    188] loss: 0.58003  | 0.18\n",
      "[epoch: 4, batch:    190] loss: 0.11798  | 0.18\n",
      "[epoch: 4, batch:    192] loss: 0.29835  | 0.18\n",
      "[epoch: 4, batch:    194] loss: 0.33328  | 0.19\n",
      "[epoch: 4, batch:    196] loss: 0.22974  | 0.17\n",
      "[epoch: 4, batch:    198] loss: 0.05258  | 0.18\n",
      "[epoch: 4, batch:    200] loss: 0.14969  | 0.17\n",
      "[epoch: 4, batch:    202] loss: 0.23101  | 0.27\n",
      "[epoch: 4, batch:    204] loss: 0.09021  | 0.17\n",
      "[epoch: 4, batch:    206] loss: 0.08387  | 0.18\n",
      "[epoch: 4, batch:    208] loss: 0.14078  | 0.18\n",
      "[epoch: 4, batch:    210] loss: 0.03108  | 0.31\n",
      "[epoch: 4, batch:    212] loss: 0.24327  | 0.17\n",
      "[epoch: 4, batch:    214] loss: 0.26412  | 0.18\n",
      "[epoch: 4, batch:    216] loss: 0.49982  | 0.18\n",
      "[epoch: 4, batch:    218] loss: 0.07720  | 0.18\n",
      "[epoch: 4, batch:    220] loss: 0.13845  | 0.19\n",
      "[epoch: 4, batch:    222] loss: 0.47857  | 0.18\n",
      "[epoch: 4, batch:    224] loss: 0.02528  | 0.17\n",
      "[epoch: 4, batch:    226] loss: 0.48339  | 0.18\n",
      "[epoch: 4, batch:    228] loss: 0.07432  | 0.28\n",
      "[epoch: 4, batch:    230] loss: 0.15663  | 0.17\n",
      "[epoch: 4, batch:    232] loss: 0.12116  | 0.18\n",
      "[epoch: 4, batch:    234] loss: 0.35797  | 0.18\n",
      "[epoch: 4, batch:    236] loss: 0.09027  | 0.19\n",
      "[epoch: 4, batch:    238] loss: 0.00597  | 0.17\n",
      "[epoch: 4, batch:    240] loss: 0.14311  | 0.18\n",
      "[epoch: 4, batch:    242] loss: 0.29691  | 0.18\n",
      "[epoch: 4, batch:    244] loss: 0.18034  | 0.19\n",
      "[epoch: 4, batch:    246] loss: 0.23090  | 0.17\n",
      "[epoch: 4, batch:    248] loss: 0.25276  | 0.18\n",
      "[epoch: 4, batch:    250] loss: 0.06788  | 0.36\n",
      "[epoch: 4, batch:    252] loss: 1.23567  | 0.17\n",
      "[epoch: 4, batch:    254] loss: 0.26950  | 0.18\n",
      "[epoch: 4, batch:    256] loss: 0.05627  | 0.18\n",
      "[epoch: 4, batch:    258] loss: 0.16653  | 0.40\n",
      "[epoch: 4, batch:    260] loss: 0.31663  | 0.17\n",
      "[epoch: 4, batch:    262] loss: 0.20429  | 0.18\n",
      "[epoch: 4, batch:    264] loss: 0.01651  | 0.17\n",
      "[epoch: 4, batch:    266] loss: 0.05269  | 0.18\n",
      "[epoch: 4, batch:    268] loss: 0.04875  | 0.17\n",
      "[epoch: 4, batch:    270] loss: 0.11919  | 0.18\n",
      "[epoch: 4, batch:    272] loss: 0.18284  | 0.17\n",
      "[epoch: 4, batch:    274] loss: 0.19320  | 0.41\n",
      "[epoch: 4, batch:    276] loss: 0.17980  | 0.17\n",
      "[epoch: 4, batch:    278] loss: 0.32311  | 0.18\n",
      "[epoch: 4, batch:    280] loss: 0.12837  | 0.18\n",
      "[epoch: 4, batch:    282] loss: 0.60980  | 0.18\n",
      "[epoch: 4, batch:    284] loss: 0.60852  | 0.18\n",
      "[epoch: 4, batch:    286] loss: 0.32076  | 0.18\n",
      "[epoch: 4, batch:    288] loss: 0.41273  | 0.17\n",
      "[epoch: 4, batch:    290] loss: 0.02570  | 0.18\n",
      "[epoch: 4, batch:    292] loss: 0.03654  | 0.18\n",
      "[epoch: 4, batch:    294] loss: 1.17339  | 0.18\n",
      "[epoch: 4, batch:    296] loss: 0.09058  | 0.18\n",
      "[epoch: 4, batch:    298] loss: 0.29738  | 0.18\n",
      "[epoch: 4, batch:    300] loss: 0.31966  | 0.38\n",
      "[epoch: 4, batch:    302] loss: 0.49276  | 0.19\n",
      "[epoch: 4, batch:    304] loss: 0.92256  | 0.17\n",
      "[epoch: 4, batch:    306] loss: 0.10941  | 0.17\n",
      "[epoch: 4, batch:    308] loss: 0.33108  | 0.18\n",
      "[epoch: 4, batch:    310] loss: 0.23886  | 0.18\n",
      "[epoch: 4, batch:    312] loss: 0.28553  | 0.18\n",
      "[epoch: 4, batch:    314] loss: 0.19031  | 0.18\n",
      "[epoch: 4, batch:    316] loss: 0.13905  | 0.18\n",
      "[epoch: 4, batch:    318] loss: 0.36108  | 0.18\n",
      "[epoch: 4, batch:    320] loss: 0.14099  | 0.28\n",
      "[epoch: 4, batch:    322] loss: 0.05442  | 0.17\n",
      "[epoch: 4, batch:    324] loss: 0.13902  | 0.18\n",
      "[epoch: 4, batch:    326] loss: 0.26968  | 0.77\n",
      "[epoch: 4, batch:    328] loss: 0.22593  | 0.17\n",
      "[epoch: 4, batch:    330] loss: 0.45358  | 0.18\n",
      "[epoch: 4, batch:    332] loss: 0.10273  | 0.18\n",
      "[epoch: 4, batch:    334] loss: 0.15863  | 0.18\n",
      "[epoch: 4, batch:    336] loss: 0.04371  | 0.17\n",
      "[epoch: 4, batch:    338] loss: 0.04962  | 0.18\n",
      "[epoch: 4, batch:    340] loss: 0.12725  | 0.18\n",
      "[epoch: 4, batch:    342] loss: 0.26108  | 0.18\n",
      "[epoch: 4, batch:    344] loss: 0.12287  | 0.17\n",
      "[epoch: 4, batch:    346] loss: 0.03776  | 0.33\n",
      "[epoch: 4, batch:    348] loss: 0.90152  | 0.18\n",
      "[epoch: 4, batch:    350] loss: 0.08862  | 0.18\n",
      "[epoch: 4, batch:    352] loss: 0.29499  | 0.18\n",
      "[epoch: 4, batch:    354] loss: 0.59125  | 0.18\n",
      "[epoch: 4, batch:    356] loss: 0.42444  | 0.19\n",
      "[epoch: 4, batch:    358] loss: 0.13058  | 0.52\n",
      "[epoch: 4, batch:    360] loss: 0.11718  | 0.17\n",
      "[epoch: 4, batch:    362] loss: 0.09430  | 0.18\n",
      "[epoch: 4, batch:    364] loss: 0.06800  | 0.17\n",
      "[epoch: 4, batch:    366] loss: 0.14223  | 0.78\n",
      "[epoch: 4, batch:    368] loss: 0.03471  | 0.17\n",
      "[epoch: 4, batch:    370] loss: 0.21273  | 0.18\n",
      "[epoch: 4, batch:    372] loss: 0.14037  | 0.17\n",
      "[epoch: 4, batch:    374] loss: 0.04374  | 0.18\n",
      "[epoch: 4, batch:    376] loss: 0.16983  | 0.17\n",
      "[epoch: 4, batch:    378] loss: 0.21512  | 0.18\n",
      "[epoch: 4, batch:    380] loss: 0.56160  | 0.17\n",
      "[epoch: 4, batch:    382] loss: 0.18019  | 0.18\n",
      "[epoch: 4, batch:    384] loss: 0.04212  | 0.17\n",
      "[epoch: 4, batch:    386] loss: 0.06811  | 0.18\n",
      "[epoch: 4, batch:    388] loss: 0.05808  | 0.62\n",
      "[epoch: 4, batch:    390] loss: 0.20716  | 0.18\n",
      "[epoch: 4, batch:    392] loss: 0.03840  | 0.33\n",
      "[epoch: 4, batch:    394] loss: 0.25693  | 0.17\n",
      "[epoch: 4, batch:    396] loss: 0.10318  | 0.18\n",
      "[epoch: 4, batch:    398] loss: 0.12111  | 0.18\n",
      "[epoch: 4, batch:    400] loss: 0.09265  | 0.29\n",
      "[epoch: 4, batch:    402] loss: 0.04419  | 0.17\n",
      "[epoch: 4, batch:    404] loss: 0.11652  | 0.18\n",
      "[epoch: 4, batch:    406] loss: 0.27349  | 0.18\n",
      "[epoch: 4, batch:    408] loss: 0.10057  | 0.19\n",
      "[epoch: 4, batch:    410] loss: 0.42484  | 0.50\n",
      "[epoch: 4, batch:    412] loss: 0.12096  | 0.17\n",
      "[epoch: 4, batch:    414] loss: 0.35606  | 0.18\n",
      "[epoch: 4, batch:    416] loss: 0.11302  | 0.18\n",
      "[epoch: 4, batch:    418] loss: 0.05371  | 0.18\n",
      "[epoch: 4, batch:    420] loss: 0.16543  | 0.17\n",
      "[epoch: 4, batch:    422] loss: 0.54284  | 0.18\n",
      "[epoch: 4, batch:    424] loss: 0.38295  | 0.18\n",
      "[epoch: 4, batch:    426] loss: 0.35345  | 0.18\n",
      "[epoch: 4, batch:    428] loss: 0.28417  | 0.18\n",
      "[epoch: 4, batch:    430] loss: 0.62361  | 0.18\n",
      "[epoch: 4, batch:    432] loss: 0.00520  | 0.18\n",
      "[epoch: 4, batch:    434] loss: 0.13588  | 0.18\n",
      "[epoch: 4, batch:    436] loss: 0.12687  | 0.51\n",
      "[epoch: 4, batch:    438] loss: 0.08147  | 0.17\n",
      "[epoch: 4, batch:    440] loss: 0.17771  | 0.18\n",
      "[epoch: 4, batch:    442] loss: 0.18031  | 0.17\n",
      "[epoch: 4, batch:    444] loss: 0.11108  | 0.33\n",
      "[epoch: 4, batch:    446] loss: 0.61670  | 0.19\n",
      "[epoch: 4, batch:    448] loss: 0.18103  | 0.18\n",
      "[epoch: 4, batch:    450] loss: 0.13007  | 0.18\n",
      "[epoch: 4, batch:    452] loss: 0.07307  | 1.05\n",
      "[epoch: 4, batch:    454] loss: 0.05507  | 0.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4, batch:    456] loss: 0.12299  | 0.18\n",
      "[epoch: 4, batch:    458] loss: 0.10157  | 0.17\n",
      "[epoch: 4, batch:    460] loss: 0.19904  | 0.18\n",
      "[epoch: 4, batch:    462] loss: 0.07224  | 0.18\n",
      "[epoch: 4, batch:    464] loss: 0.02695  | 0.18\n",
      "[epoch: 4, batch:    466] loss: 0.47898  | 0.17\n",
      "[epoch: 4, batch:    468] loss: 0.10312  | 0.18\n",
      "[epoch: 4, batch:    470] loss: 0.16917  | 0.17\n",
      "[epoch: 4, batch:    472] loss: 0.16491  | 0.18\n",
      "[epoch: 4, batch:    474] loss: 0.24114  | 0.19\n",
      "[epoch: 4, batch:    476] loss: 0.09812  | 0.18\n",
      "[epoch: 4, batch:    478] loss: 0.06926  | 0.18\n",
      "[epoch: 4, batch:    480] loss: 0.06849  | 0.18\n",
      "[epoch: 4, batch:    482] loss: 1.25778  | 0.18\n",
      "[epoch: 4, batch:    484] loss: 0.11547  | 0.20\n",
      "[epoch: 4, batch:    486] loss: 1.34540  | 0.17\n",
      "[epoch: 4, batch:    488] loss: 0.37415  | 0.18\n",
      "[epoch: 4, batch:    490] loss: 0.43849  | 0.18\n",
      "[epoch: 4, batch:    492] loss: 0.30541  | 0.18\n",
      "[epoch: 4, batch:    494] loss: 0.08767  | 0.24\n",
      "[epoch: 4, batch:    496] loss: 0.15690  | 0.18\n",
      "[epoch: 4, batch:    498] loss: 0.32871  | 0.18\n",
      "[epoch: 4, batch:    500] loss: 0.97569  | 0.29\n",
      "[epoch: 4, batch:    502] loss: 0.10017  | 0.18\n",
      "[epoch: 4, batch:    504] loss: 0.21162  | 0.18\n",
      "[epoch: 4, batch:    506] loss: 0.56168  | 0.18\n",
      "[epoch: 4, batch:    508] loss: 0.11054  | 0.20\n",
      "[epoch: 4, batch:    510] loss: 0.98148  | 0.17\n",
      "[epoch: 4, batch:    512] loss: 0.08243  | 0.18\n",
      "[epoch: 4, batch:    514] loss: 0.06679  | 0.18\n",
      "[epoch: 4, batch:    516] loss: 0.12854  | 0.19\n",
      "[epoch: 4, batch:    518] loss: 0.05860  | 0.18\n",
      "[epoch: 4, batch:    520] loss: 0.13830  | 0.18\n",
      "[epoch: 4, batch:    522] loss: 0.11729  | 0.18\n",
      "[epoch: 4, batch:    524] loss: 0.06200  | 0.19\n",
      "[epoch: 4, batch:    526] loss: 0.10477  | 0.27\n",
      "[epoch: 4, batch:    528] loss: 0.26199  | 0.18\n",
      "[epoch: 4, batch:    530] loss: 0.05964  | 0.18\n",
      "[epoch: 4, batch:    532] loss: 0.27753  | 0.18\n",
      "[epoch: 4, batch:    534] loss: 0.46760  | 0.31\n",
      "[epoch: 4, batch:    536] loss: 0.20039  | 0.18\n",
      "[epoch: 4, batch:    538] loss: 0.20354  | 0.18\n",
      "[epoch: 4, batch:    540] loss: 0.21335  | 0.17\n",
      "[epoch: 4, batch:    542] loss: 0.06157  | 0.18\n",
      "[epoch: 4, batch:    544] loss: 0.12290  | 0.30\n",
      "[epoch: 4, batch:    546] loss: 0.12592  | 0.18\n",
      "[epoch: 4, batch:    548] loss: 0.19081  | 0.17\n",
      "[epoch: 4, batch:    550] loss: 0.02737  | 0.18\n",
      "[epoch: 4, batch:    552] loss: 0.03813  | 0.19\n",
      "[epoch: 4, batch:    554] loss: 0.15654  | 0.17\n",
      "[epoch: 4, batch:    556] loss: 0.33599  | 0.18\n",
      "[epoch: 4, batch:    558] loss: 0.14943  | 0.17\n",
      "[epoch: 4, batch:    560] loss: 0.10142  | 0.18\n",
      "[epoch: 4, batch:    562] loss: 0.31312  | 0.47\n",
      "[epoch: 4, batch:    564] loss: 0.17344  | 0.18\n",
      "[epoch: 4, batch:    566] loss: 0.28975  | 0.18\n",
      "[epoch: 4, batch:    568] loss: 0.11676  | 0.18\n",
      "[epoch: 4, batch:    570] loss: 0.24851  | 0.19\n",
      "[epoch: 4, batch:    572] loss: 0.05627  | 0.18\n",
      "[epoch: 4, batch:    574] loss: 0.68941  | 0.18\n",
      "[epoch: 4, batch:    576] loss: 0.16072  | 0.17\n",
      "[epoch: 4, batch:    578] loss: 0.42347  | 0.18\n",
      "[epoch: 4, batch:    580] loss: 0.11181  | 0.17\n",
      "[epoch: 4, batch:    582] loss: 0.76330  | 0.18\n",
      "[epoch: 4, batch:    584] loss: 0.05146  | 0.18\n",
      "[epoch: 4, batch:    586] loss: 0.07756  | 0.18\n",
      "[epoch: 4, batch:    588] loss: 0.11775  | 0.18\n",
      "[epoch: 4, batch:    590] loss: 0.58367  | 0.18\n",
      "[epoch: 4, batch:    592] loss: 0.15877  | 0.34\n",
      "[epoch: 4, batch:    594] loss: 0.09334  | 0.18\n",
      "[epoch: 4, batch:    596] loss: 0.17241  | 0.18\n",
      "[epoch: 4, batch:    598] loss: 0.33691  | 0.19\n",
      "[epoch: 4, batch:    600] loss: 0.64251  | 0.18\n",
      "[epoch: 4, batch:    602] loss: 0.20462  | 0.17\n",
      "[epoch: 4, batch:    604] loss: 0.42362  | 0.18\n",
      "[epoch: 4, batch:    606] loss: 0.22626  | 0.18\n",
      "[epoch: 4, batch:    608] loss: 0.06281  | 0.18\n",
      "[epoch: 4, batch:    610] loss: 1.26499  | 0.18\n",
      "[epoch: 4, batch:    612] loss: 0.20198  | 0.18\n",
      "[epoch: 4, batch:    614] loss: 0.22603  | 0.19\n",
      "[epoch: 4, batch:    616] loss: 0.12801  | 0.41\n",
      "[epoch: 4, batch:    618] loss: 0.15021  | 0.17\n",
      "[epoch: 4, batch:    620] loss: 0.44973  | 0.18\n",
      "[epoch: 4, batch:    622] loss: 0.12089  | 0.17\n",
      "[epoch: 4, batch:    624] loss: 0.10336  | 0.34\n",
      "[epoch: 4, batch:    626] loss: 0.31732  | 0.17\n",
      "[epoch: 4, batch:    628] loss: 0.12823  | 0.18\n",
      "[epoch: 4, batch:    630] loss: 0.11273  | 0.17\n",
      "[epoch: 4, batch:    632] loss: 0.10897  | 0.19\n",
      "[epoch: 4, batch:    634] loss: 0.44817  | 0.17\n",
      "[epoch: 4, batch:    636] loss: 0.53023  | 0.34\n",
      "[epoch: 4, batch:    638] loss: 0.07992  | 0.17\n",
      "[epoch: 4, batch:    640] loss: 0.10018  | 0.18\n",
      "[epoch: 4, batch:    642] loss: 0.17615  | 0.17\n",
      "[epoch: 4, batch:    644] loss: 0.12684  | 0.28\n",
      "[epoch: 4, batch:    646] loss: 0.61520  | 0.17\n",
      "[epoch: 4, batch:    648] loss: 0.00543  | 0.18\n",
      "[epoch: 4, batch:    650] loss: 0.17853  | 0.17\n",
      "[epoch: 4, batch:    652] loss: 0.24229  | 0.20\n",
      "[epoch: 4, batch:    654] loss: 0.10297  | 0.18\n",
      "[epoch: 4, batch:    656] loss: 0.06249  | 0.18\n",
      "[epoch: 4, batch:    658] loss: 1.17512  | 0.17\n",
      "[epoch: 4, batch:    660] loss: 0.18148  | 0.23\n",
      "[epoch: 4, batch:    662] loss: 0.02739  | 0.17\n",
      "[epoch: 4, batch:    664] loss: 0.19589  | 0.18\n",
      "[epoch: 4, batch:    666] loss: 0.56465  | 0.18\n",
      "[epoch: 4, batch:    668] loss: 0.04489  | 0.19\n",
      "[epoch: 4, batch:    670] loss: 0.85734  | 0.17\n",
      "[epoch: 4, batch:    672] loss: 0.03503  | 0.18\n",
      "[epoch: 4, batch:    674] loss: 0.08847  | 0.18\n",
      "[epoch: 4, batch:    676] loss: 0.05897  | 0.18\n",
      "[epoch: 4, batch:    678] loss: 0.87679  | 0.18\n",
      "[epoch: 4, batch:    680] loss: 0.35976  | 0.19\n",
      "[epoch: 4, batch:    682] loss: 0.34616  | 0.17\n",
      "[epoch: 4, batch:    684] loss: 0.03382  | 0.18\n",
      "[epoch: 4, batch:    686] loss: 0.11987  | 0.18\n",
      "[epoch: 4, batch:    688] loss: 0.33620  | 0.31\n",
      "[epoch: 4, batch:    690] loss: 0.18503  | 0.17\n",
      "[epoch: 4, batch:    692] loss: 0.46575  | 0.18\n",
      "[epoch: 4, batch:    694] loss: 0.86343  | 0.18\n",
      "[epoch: 4, batch:    696] loss: 0.08514  | 0.78\n",
      "[epoch: 4, batch:    698] loss: 0.15015  | 0.17\n",
      "[epoch: 4, batch:    700] loss: 0.39983  | 0.18\n",
      "[epoch: 4, batch:    702] loss: 0.06563  | 0.18\n",
      "[epoch: 4, batch:    704] loss: 0.04654  | 0.18\n",
      "[epoch: 4, batch:    706] loss: 0.07332  | 0.17\n",
      "[epoch: 4, batch:    708] loss: 0.54832  | 0.18\n",
      "[epoch: 4, batch:    710] loss: 0.48291  | 0.17\n",
      "[epoch: 4, batch:    712] loss: 0.41345  | 0.18\n",
      "[epoch: 4, batch:    714] loss: 1.34016  | 0.18\n",
      "[epoch: 4, batch:    716] loss: 0.20085  | 0.17\n",
      "[epoch: 4, batch:    718] loss: 0.30292  | 0.20\n",
      "[epoch: 4, batch:    720] loss: 0.23228  | 0.18\n",
      "[epoch: 4, batch:    722] loss: 0.13946  | 0.17\n",
      "[epoch: 4, batch:    724] loss: 0.11516  | 0.18\n",
      "[epoch: 4, batch:    726] loss: 0.38344  | 0.18\n",
      "[epoch: 4, batch:    728] loss: 1.21374  | 0.18\n",
      "[epoch: 4, batch:    730] loss: 1.04525  | 0.18\n",
      "[epoch: 4, batch:    732] loss: 0.37111  | 0.18\n",
      "[epoch: 4, batch:    734] loss: 0.51629  | 0.42\n",
      "[epoch: 4, batch:    736] loss: 0.38822  | 0.17\n",
      "[epoch: 4, batch:    738] loss: 0.43103  | 0.31\n",
      "[epoch: 4, batch:    740] loss: 0.04224  | 0.17\n",
      "[epoch: 4, batch:    742] loss: 0.11971  | 0.18\n",
      "[epoch: 4, batch:    744] loss: 0.04810  | 0.17\n",
      "[epoch: 4, batch:    746] loss: 0.08921  | 0.19\n",
      "[epoch: 4, batch:    748] loss: 1.28841  | 0.17\n",
      "[epoch: 4, batch:    750] loss: 0.04970  | 0.18\n",
      "[epoch: 4, batch:    752] loss: 0.30659  | 0.18\n",
      "[epoch: 4, batch:    754] loss: 0.35686  | 0.19\n",
      "[epoch: 4, batch:    756] loss: 0.54582  | 0.17\n",
      "[epoch: 4, batch:    758] loss: 0.09027  | 0.19\n",
      "[epoch: 4, batch:    760] loss: 0.06253  | 0.18\n",
      "[epoch: 4, batch:    762] loss: 0.16628  | 0.18\n",
      "[epoch: 4, batch:    764] loss: 0.06284  | 0.18\n",
      "[epoch: 4, batch:    766] loss: 0.46847  | 0.41\n",
      "[epoch: 4, batch:    768] loss: 0.17879  | 0.17\n",
      "[epoch: 4, batch:    770] loss: 0.22187  | 0.18\n",
      "[epoch: 4, batch:    772] loss: 0.09576  | 0.18\n",
      "[epoch: 4, batch:    774] loss: 0.01569  | 0.72\n",
      "[epoch: 4, batch:    776] loss: 0.76061  | 0.17\n",
      "[epoch: 4, batch:    778] loss: 0.08025  | 0.17\n",
      "[epoch: 4, batch:    780] loss: 0.11926  | 0.17\n",
      "[epoch: 4, batch:    782] loss: 0.37575  | 0.22\n",
      "[epoch: 4, batch:    784] loss: 0.84851  | 0.17\n",
      "[epoch: 4, batch:    786] loss: 0.07532  | 0.17\n",
      "[epoch: 4, batch:    788] loss: 0.61983  | 0.18\n",
      "[epoch: 4, batch:    790] loss: 0.05961  | 1.11\n",
      "[epoch: 4, batch:    792] loss: 0.25757  | 0.17\n",
      "[epoch: 4, batch:    794] loss: 0.08407  | 0.17\n",
      "[epoch: 4, batch:    796] loss: 0.28134  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4, batch:    798] loss: 0.19769  | 0.63\n",
      "[epoch: 4, batch:    800] loss: 0.18326  | 0.17\n",
      "[epoch: 4, batch:    802] loss: 0.47691  | 0.17\n",
      "[epoch: 4, batch:    804] loss: 0.11531  | 0.17\n",
      "[epoch: 4, batch:    806] loss: 0.57446  | 0.19\n",
      "[epoch: 4, batch:    808] loss: 0.01290  | 0.17\n",
      "[epoch: 4, batch:    810] loss: 0.15402  | 0.17\n",
      "[epoch: 4, batch:    812] loss: 0.19411  | 0.18\n",
      "[epoch: 4, batch:    814] loss: 0.19026  | 0.18\n",
      "[epoch: 4, batch:    816] loss: 0.09856  | 0.18\n",
      "[epoch: 4, batch:    818] loss: 0.04907  | 1.34\n",
      "[epoch: 4, batch:    820] loss: 0.40503  | 0.17\n",
      "[epoch: 4, batch:    822] loss: 0.38607  | 0.18\n",
      "[epoch: 4, batch:    824] loss: 0.16356  | 0.17\n",
      "[epoch: 4, batch:    826] loss: 0.53020  | 0.18\n",
      "[epoch: 4, batch:    828] loss: 0.03487  | 0.17\n",
      "[epoch: 4, batch:    830] loss: 0.27585  | 0.17\n",
      "[epoch: 4, batch:    832] loss: 0.19057  | 0.17\n",
      "[epoch: 4, batch:    834] loss: 0.11841  | 0.19\n",
      "[epoch: 4, batch:    836] loss: 0.14697  | 0.18\n",
      "[epoch: 4, batch:    838] loss: 0.07188  | 0.18\n",
      "[epoch: 4, batch:    840] loss: 0.98810  | 0.18\n",
      "[epoch: 4, batch:    842] loss: 0.04420  | 0.18\n",
      "[epoch: 4, batch:    844] loss: 0.15689  | 0.18\n",
      "[epoch: 4, batch:    846] loss: 0.07852  | 0.18\n",
      "[epoch: 4, batch:    848] loss: 0.16248  | 0.18\n",
      "[epoch: 4, batch:    850] loss: 0.09835  | 0.18\n",
      "[epoch: 4, batch:    852] loss: 0.35662  | 0.18\n",
      "[epoch: 4, batch:    854] loss: 0.14484  | 0.18\n",
      "[epoch: 4, batch:    856] loss: 0.05994  | 0.19\n",
      "[epoch: 4, batch:    858] loss: 0.51346  | 0.18\n",
      "[epoch: 4, batch:    860] loss: 0.14497  | 0.17\n",
      "[epoch: 4, batch:    862] loss: 0.00718  | 0.17\n",
      "[epoch: 4, batch:    864] loss: 0.27245  | 0.18\n",
      "[epoch: 4, batch:    866] loss: 0.03191  | 0.18\n",
      "[epoch: 4, batch:    868] loss: 1.16181  | 0.17\n",
      "[epoch: 4, batch:    870] loss: 0.06036  | 0.18\n",
      "[epoch: 4, batch:    872] loss: 0.25924  | 0.45\n",
      "[epoch: 4, batch:    874] loss: 0.03858  | 0.18\n",
      "[epoch: 4, batch:    876] loss: 0.10638  | 0.18\n",
      "[epoch: 4, batch:    878] loss: 1.23051  | 0.18\n",
      "[epoch: 4, batch:    880] loss: 0.14961  | 0.37\n",
      "[epoch: 4, batch:    882] loss: 0.08895  | 0.17\n",
      "[epoch: 4, batch:    884] loss: 0.55873  | 0.17\n",
      "[epoch: 4, batch:    886] loss: 0.00647  | 0.17\n",
      "[epoch: 4, batch:    888] loss: 0.21430  | 0.29\n",
      "[epoch: 4, batch:    890] loss: 0.09894  | 0.36\n",
      "[epoch: 4, batch:    892] loss: 0.05461  | 0.18\n",
      "[epoch: 4, batch:    894] loss: 0.15754  | 0.18\n",
      "[epoch: 4, batch:    896] loss: 0.18973  | 0.17\n",
      "[epoch: 4, batch:    898] loss: 0.01160  | 0.18\n",
      "[epoch: 4, batch:    900] loss: 0.06378  | 0.17\n",
      "[epoch: 4, batch:    902] loss: 0.13642  | 0.18\n",
      "[epoch: 4, batch:    904] loss: 0.02524  | 0.18\n",
      "[epoch: 4, batch:    906] loss: 0.20279  | 0.19\n",
      "[epoch: 4, batch:    908] loss: 0.46023  | 0.35\n",
      "[epoch: 4, batch:    910] loss: 0.16425  | 0.17\n",
      "[epoch: 4, batch:    912] loss: 0.20528  | 0.18\n",
      "[epoch: 4, batch:    914] loss: 0.38572  | 0.17\n",
      "[epoch: 4, batch:    916] loss: 0.24578  | 0.18\n",
      "[epoch: 4, batch:    918] loss: 0.22295  | 0.17\n",
      "[epoch: 4, batch:    920] loss: 0.12906  | 0.18\n",
      "[epoch: 4, batch:    922] loss: 0.31600  | 0.17\n",
      "[epoch: 4, batch:    924] loss: 0.15191  | 0.18\n",
      "[epoch: 4, batch:    926] loss: 0.26290  | 0.18\n",
      "[epoch: 4, batch:    928] loss: 0.45988  | 0.18\n",
      "[epoch: 4, batch:    930] loss: 0.04687  | 0.36\n",
      "[epoch: 4, batch:    932] loss: 0.49972  | 0.17\n",
      "[epoch: 4, batch:    934] loss: 0.13981  | 0.17\n",
      "[epoch: 4, batch:    936] loss: 0.14067  | 0.17\n",
      "[epoch: 4, batch:    938] loss: 0.08209  | 0.18\n",
      "[epoch: 4, batch:    940] loss: 0.97298  | 0.18\n",
      "[epoch: 4, batch:    942] loss: 0.27724  | 0.18\n",
      "[epoch: 4, batch:    944] loss: 0.38560  | 0.18\n",
      "[epoch: 4, batch:    946] loss: 0.18625  | 0.18\n",
      "[epoch: 4, batch:    948] loss: 0.12272  | 0.18\n",
      "[epoch: 4, batch:    950] loss: 0.53177  | 0.18\n",
      "[epoch: 4, batch:    952] loss: 0.48298  | 0.18\n",
      "[epoch: 4, batch:    954] loss: 0.07853  | 0.19\n",
      "[epoch: 4, batch:    956] loss: 0.20031  | 0.17\n",
      "[epoch: 4, batch:    958] loss: 0.57102  | 0.32\n",
      "[epoch: 4, batch:    960] loss: 0.18013  | 0.17\n",
      "[epoch: 4, batch:    962] loss: 0.27830  | 0.18\n",
      "[epoch: 4, batch:    964] loss: 0.34870  | 0.18\n",
      "[epoch: 4, batch:    966] loss: 0.22871  | 0.18\n",
      "[epoch: 4, batch:    968] loss: 0.16555  | 0.18\n",
      "[epoch: 4, batch:    970] loss: 0.09068  | 0.18\n",
      "[epoch: 4, batch:    972] loss: 0.37087  | 1.10\n",
      "[epoch: 4, batch:    974] loss: 0.31238  | 0.18\n",
      "[epoch: 4, batch:    976] loss: 0.07235  | 0.18\n",
      "[epoch: 4, batch:    978] loss: 0.16040  | 0.18\n",
      "[epoch: 4, batch:    980] loss: 0.27803  | 0.18\n",
      "[epoch: 4, batch:    982] loss: 0.19346  | 0.26\n",
      "[epoch: 4, batch:    984] loss: 0.33063  | 0.17\n",
      "[epoch: 4, batch:    986] loss: 0.12671  | 0.18\n",
      "[epoch: 4, batch:    988] loss: 0.18823  | 0.19\n",
      "[epoch: 4, batch:    990] loss: 0.03942  | 0.18\n",
      "[epoch: 4, batch:    992] loss: 0.48762  | 0.17\n",
      "[epoch: 4, batch:    994] loss: 0.90721  | 0.40\n",
      "[epoch: 4, batch:    996] loss: 0.09451  | 0.18\n",
      "[epoch: 4, batch:    998] loss: 0.25830  | 0.18\n",
      "[epoch: 4, batch:   1000] loss: 0.22951  | 0.17\n",
      "[epoch: 4, batch:   1002] loss: 0.17032  | 0.19\n",
      "[epoch: 4, batch:   1004] loss: 0.16503  | 0.18\n",
      "[epoch: 4, batch:   1006] loss: 0.07393  | 0.18\n",
      "[epoch: 4, batch:   1008] loss: 0.33595  | 0.41\n",
      "[epoch: 4, batch:   1010] loss: 0.10751  | 0.17\n",
      "[epoch: 4, batch:   1012] loss: 0.30731  | 0.18\n",
      "[epoch: 4, batch:   1014] loss: 0.05529  | 0.18\n",
      "[epoch: 4, batch:   1016] loss: 0.20339  | 0.18\n",
      "[epoch: 4, batch:   1018] loss: 0.03596  | 0.17\n",
      "[epoch: 4, batch:   1020] loss: 0.11914  | 0.17\n",
      "[epoch: 4, batch:   1022] loss: 0.10853  | 0.17\n",
      "[epoch: 4, batch:   1024] loss: 0.15253  | 0.18\n",
      "[epoch: 4, batch:   1026] loss: 0.04099  | 0.20\n",
      "[epoch: 4, batch:   1028] loss: 0.43780  | 0.18\n",
      "[epoch: 4, batch:   1030] loss: 0.11325  | 0.17\n",
      "[epoch: 4, batch:   1032] loss: 0.23030  | 0.18\n",
      "[epoch: 4, batch:   1034] loss: 0.46922  | 0.41\n",
      "[epoch: 4, batch:   1036] loss: 0.09053  | 0.17\n",
      "[epoch: 4, batch:   1038] loss: 0.13256  | 0.18\n",
      "[epoch: 4, batch:   1040] loss: 0.18665  | 0.17\n",
      "[epoch: 4, batch:   1042] loss: 0.15484  | 0.18\n",
      "[epoch: 4, batch:   1044] loss: 0.20055  | 0.18\n",
      "[epoch: 4, batch:   1046] loss: 0.37046  | 0.18\n",
      "[epoch: 4, batch:   1048] loss: 0.46352  | 0.17\n",
      "[epoch: 4, batch:   1050] loss: 0.74169  | 0.18\n",
      "[epoch: 4, batch:   1052] loss: 0.79132  | 0.18\n",
      "[epoch: 4, batch:   1054] loss: 0.20736  | 0.18\n",
      "[epoch: 4, batch:   1056] loss: 0.22628  | 0.41\n",
      "[epoch: 4, batch:   1058] loss: 0.10402  | 0.17\n",
      "[epoch: 4, batch:   1060] loss: 0.69286  | 0.18\n",
      "[epoch: 4, batch:   1062] loss: 0.36788  | 0.17\n",
      "[epoch: 4, batch:   1064] loss: 0.07798  | 0.19\n",
      "[epoch: 4, batch:   1066] loss: 0.25615  | 0.17\n",
      "[epoch: 4, batch:   1068] loss: 0.01897  | 0.17\n",
      "[epoch: 4, batch:   1070] loss: 0.05169  | 0.17\n",
      "[epoch: 4, batch:   1072] loss: 1.11392  | 0.19\n",
      "[epoch: 4, batch:   1074] loss: 0.12580  | 0.18\n",
      "[epoch: 4, batch:   1076] loss: 0.09024  | 0.41\n",
      "[epoch: 4, batch:   1078] loss: 0.26977  | 0.17\n",
      "[epoch: 4, batch:   1080] loss: 0.05332  | 0.18\n",
      "[epoch: 4, batch:   1082] loss: 0.68088  | 0.18\n",
      "[epoch: 4, batch:   1084] loss: 0.06252  | 0.19\n",
      "[epoch: 4, batch:   1086] loss: 0.05134  | 0.17\n",
      "[epoch: 4, batch:   1088] loss: 0.42141  | 0.18\n",
      "[epoch: 4, batch:   1090] loss: 0.48119  | 0.17\n",
      "[epoch: 4, batch:   1092] loss: 0.15835  | 0.19\n",
      "[epoch: 4, batch:   1094] loss: 0.35917  | 0.18\n",
      "[epoch: 4, batch:   1096] loss: 0.04257  | 0.18\n",
      "[epoch: 4, batch:   1098] loss: 0.57409  | 0.18\n",
      "[epoch: 4, batch:   1100] loss: 0.50312  | 0.18\n",
      "[epoch: 4, batch:   1102] loss: 0.08502  | 0.18\n",
      "[epoch: 4, batch:   1104] loss: 1.06270  | 0.20\n",
      "[epoch: 4, batch:   1106] loss: 0.21860  | 0.18\n",
      "[epoch: 4, batch:   1108] loss: 0.14766  | 0.18\n",
      "[epoch: 4, batch:   1110] loss: 0.10051  | 0.17\n",
      "[epoch: 4, batch:   1112] loss: 0.27478  | 0.18\n",
      "[epoch: 4, batch:   1114] loss: 0.28958  | 0.18\n",
      "[epoch: 4, batch:   1116] loss: 0.43968  | 0.18\n",
      "[epoch: 4, batch:   1118] loss: 0.36615  | 0.41\n",
      "[epoch: 4, batch:   1120] loss: 0.13080  | 0.17\n",
      "[epoch: 4, batch:   1122] loss: 0.05876  | 0.18\n",
      "[epoch: 4, batch:   1124] loss: 0.08666  | 0.18\n",
      "[epoch: 4, batch:   1126] loss: 0.35903  | 0.18\n",
      "[epoch: 4, batch:   1128] loss: 0.10287  | 0.17\n",
      "[epoch: 4, batch:   1130] loss: 0.14198  | 0.18\n",
      "[epoch: 4, batch:   1132] loss: 0.08088  | 0.18\n",
      "[epoch: 4, batch:   1134] loss: 0.27104  | 0.18\n",
      "[epoch: 4, batch:   1136] loss: 0.54313  | 0.18\n",
      "[epoch: 4, batch:   1138] loss: 0.16972  | 0.18\n",
      "[epoch: 4, batch:   1140] loss: 1.02251  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4, batch:   1142] loss: 0.09853  | 0.18\n",
      "[epoch: 4, batch:   1144] loss: 1.03578  | 0.18\n",
      "[epoch: 4, batch:   1146] loss: 0.25118  | 0.18\n",
      "[epoch: 4, batch:   1148] loss: 0.08673  | 0.18\n",
      "[epoch: 4, batch:   1150] loss: 0.07972  | 0.18\n",
      "[epoch: 4, batch:   1152] loss: 0.18293  | 0.18\n",
      "[epoch: 4, batch:   1154] loss: 0.23655  | 0.18\n",
      "[epoch: 4, batch:   1156] loss: 0.13682  | 1.54\n",
      "[epoch: 4, batch:   1158] loss: 0.42494  | 0.18\n",
      "[epoch: 4, batch:   1160] loss: 0.02209  | 0.18\n",
      "[epoch: 4, batch:   1162] loss: 0.04584  | 0.17\n",
      "[epoch: 4, batch:   1164] loss: 0.02886  | 0.18\n",
      "[epoch: 4, batch:   1166] loss: 0.08273  | 0.18\n",
      "[epoch: 4, batch:   1168] loss: 0.08708  | 0.18\n",
      "[epoch: 4, batch:   1170] loss: 0.42247  | 0.17\n",
      "[epoch: 4, batch:   1172] loss: 0.29624  | 0.55\n",
      "[epoch: 4, batch:   1174] loss: 0.33685  | 0.18\n",
      "[epoch: 4, batch:   1176] loss: 0.03501  | 0.18\n",
      "[epoch: 4, batch:   1178] loss: 1.06954  | 0.18\n",
      "[epoch: 4, batch:   1180] loss: 0.09908  | 0.18\n",
      "[epoch: 4, batch:   1182] loss: 0.19049  | 0.18\n",
      "[epoch: 4, batch:   1184] loss: 0.10052  | 0.18\n",
      "[epoch: 4, batch:   1186] loss: 1.20874  | 0.18\n",
      "[epoch: 4, batch:   1188] loss: 0.30731  | 0.18\n",
      "[epoch: 4, batch:   1190] loss: 0.42546  | 0.69\n",
      "[epoch: 4, batch:   1192] loss: 0.19368  | 0.17\n",
      "[epoch: 4, batch:   1194] loss: 0.07780  | 0.18\n",
      "[epoch: 4, batch:   1196] loss: 0.19619  | 0.17\n",
      "[epoch: 4, batch:   1198] loss: 0.14162  | 0.18\n",
      "[epoch: 4, batch:   1200] loss: 0.01725  | 0.17\n",
      "[epoch: 4, batch:   1202] loss: 0.40520  | 0.18\n",
      "[epoch: 4, batch:   1204] loss: 0.09186  | 0.17\n",
      "[epoch: 4, batch:   1206] loss: 0.10776  | 0.18\n",
      "[epoch: 4, batch:   1208] loss: 0.08849  | 0.18\n",
      "[epoch: 4, batch:   1210] loss: 0.08268  | 0.18\n",
      "[epoch: 4, batch:   1212] loss: 0.11515  | 0.18\n",
      "[epoch: 4, batch:   1214] loss: 0.33936  | 0.19\n",
      "[epoch: 4, batch:   1216] loss: 0.13700  | 0.20\n",
      "[epoch: 4, batch:   1218] loss: 0.12074  | 0.18\n",
      "[epoch: 4, batch:   1220] loss: 1.02776  | 0.17\n",
      "[epoch: 4, batch:   1222] loss: 0.07403  | 0.18\n",
      "[epoch: 4, batch:   1224] loss: 0.12983  | 0.18\n",
      "[epoch: 4, batch:   1226] loss: 0.17598  | 0.18\n",
      "[epoch: 4, batch:   1228] loss: 0.19462  | 0.18\n",
      "[epoch: 4, batch:   1230] loss: 0.11930  | 0.48\n",
      "[epoch: 4, batch:   1232] loss: 0.30256  | 0.18\n",
      "[epoch: 4, batch:   1234] loss: 0.14383  | 0.18\n",
      "[epoch: 4, batch:   1236] loss: 0.13719  | 0.17\n",
      "[epoch: 4, batch:   1238] loss: 0.19887  | 0.18\n",
      "[epoch: 4, batch:   1240] loss: 0.11087  | 0.18\n",
      "[epoch: 4, batch:   1242] loss: 0.05877  | 0.18\n",
      "[epoch: 4, batch:   1244] loss: 0.24068  | 0.17\n",
      "[epoch: 4, batch:   1246] loss: 0.70106  | 0.18\n",
      "[epoch: 4, batch:   1248] loss: 0.07437  | 0.18\n",
      "[epoch: 4, batch:   1250] loss: 0.08674  | 0.18\n",
      "[epoch: 4, batch:   1252] loss: 0.02780  | 0.18\n",
      "[epoch: 4, batch:   1254] loss: 0.38293  | 0.18\n",
      "[epoch: 4, batch:   1256] loss: 0.24630  | 0.18\n",
      "[epoch: 4, batch:   1258] loss: 0.21540  | 0.18\n",
      "[epoch: 4, batch:   1260] loss: 0.11117  | 0.19\n",
      "[epoch: 4, batch:   1262] loss: 0.50300  | 0.18\n",
      "[epoch: 4, batch:   1264] loss: 0.12471  | 0.18\n",
      "[epoch: 4, batch:   1266] loss: 0.10414  | 0.18\n",
      "[epoch: 4, batch:   1268] loss: 0.27682  | 0.18\n",
      "[epoch: 4, batch:   1270] loss: 0.28426  | 0.18\n",
      "[epoch: 4, batch:   1272] loss: 0.12803  | 0.18\n",
      "[epoch: 4, batch:   1274] loss: 0.38118  | 0.18\n",
      "[epoch: 4, batch:   1276] loss: 0.07716  | 0.18\n",
      "[epoch: 4, batch:   1278] loss: 0.14876  | 0.18\n",
      "[epoch: 4, batch:   1280] loss: 0.07620  | 0.18\n",
      "[epoch: 4, batch:   1282] loss: 0.02666  | 0.18\n",
      "[epoch: 4, batch:   1284] loss: 0.29405  | 0.18\n",
      "[epoch: 4, batch:   1286] loss: 0.62236  | 0.18\n",
      "[epoch: 4, batch:   1288] loss: 0.10813  | 0.18\n",
      "[epoch: 4, batch:   1290] loss: 0.18347  | 0.18\n",
      "[epoch: 4, batch:   1292] loss: 0.19633  | 0.18\n",
      "[epoch: 4, batch:   1294] loss: 0.05438  | 0.18\n",
      "[epoch: 4, batch:   1296] loss: 0.22933  | 0.18\n",
      "[epoch: 4, batch:   1298] loss: 0.08327  | 0.18\n",
      "[epoch: 4, batch:   1300] loss: 0.15521  | 0.18\n",
      "[epoch: 4, batch:   1302] loss: 0.17718  | 0.18\n",
      "[epoch: 4, batch:   1304] loss: 0.09695  | 0.18\n",
      "[epoch: 4, batch:   1306] loss: 0.17290  | 0.18\n",
      "[epoch: 4, batch:   1308] loss: 0.31138  | 0.18\n",
      "[epoch: 4, batch:   1310] loss: 0.06076  | 0.19\n",
      "[epoch: 4, batch:   1312] loss: 0.14108  | 0.18\n",
      "[epoch: 4, batch:   1314] loss: 0.36584  | 0.18\n",
      "[epoch: 4, batch:   1316] loss: 0.01955  | 0.18\n",
      "[epoch: 4, batch:   1318] loss: 0.14843  | 0.18\n",
      "[epoch: 4, batch:   1320] loss: 0.03732  | 0.17\n",
      "[epoch: 4, batch:   1322] loss: 0.12360  | 0.19\n",
      "[epoch: 4, batch:   1324] loss: 0.06812  | 0.18\n",
      "[epoch: 4, batch:   1326] loss: 0.30874  | 0.18\n",
      "[epoch: 4, batch:   1328] loss: 0.27090  | 0.18\n",
      "[epoch: 4, batch:   1330] loss: 0.24403  | 0.18\n",
      "[epoch: 4, batch:   1332] loss: 0.31204  | 0.18\n",
      "[epoch: 4, batch:   1334] loss: 0.79471  | 0.18\n",
      "[epoch: 4, batch:   1336] loss: 0.05556  | 0.18\n",
      "[epoch: 4, batch:   1338] loss: 0.66602  | 0.18\n",
      "[epoch: 4, batch:   1340] loss: 0.16080  | 0.18\n",
      "[epoch: 4, batch:   1342] loss: 0.03787  | 0.18\n",
      "[epoch: 4, batch:   1344] loss: 0.08398  | 0.18\n",
      "[epoch: 4, batch:   1346] loss: 0.25716  | 0.18\n",
      "[epoch: 4, batch:   1348] loss: 0.05823  | 0.18\n",
      "[epoch: 4, batch:   1350] loss: 0.16824  | 0.18\n",
      "[epoch: 4, batch:   1352] loss: 0.03290  | 0.18\n",
      "[epoch: 4, batch:   1354] loss: 0.05011  | 0.18\n",
      "[epoch: 4, batch:   1356] loss: 0.14292  | 0.18\n",
      "[epoch: 4, batch:   1358] loss: 0.11091  | 0.18\n",
      "[epoch: 4, batch:   1360] loss: 0.11214  | 0.18\n",
      "[epoch: 4, batch:   1362] loss: 0.16125  | 0.18\n",
      "[epoch: 4, batch:   1364] loss: 0.17298  | 0.18\n",
      "[epoch: 4, batch:   1366] loss: 0.05831  | 0.18\n",
      "[epoch: 4, batch:   1368] loss: 0.05162  | 0.18\n",
      "[epoch: 4, batch:   1370] loss: 0.04818  | 0.18\n",
      "[epoch: 4, batch:   1372] loss: 0.11202  | 0.18\n",
      "[epoch: 4, batch:   1374] loss: 0.16335  | 0.18\n",
      "[epoch: 4, batch:   1376] loss: 1.02336  | 0.18\n",
      "[epoch: 4, batch:   1378] loss: 0.31422  | 0.18\n",
      "[epoch: 4, batch:   1380] loss: 0.07111  | 0.18\n",
      "[epoch: 4, batch:   1382] loss: 0.06157  | 0.18\n",
      "[epoch: 4, batch:   1384] loss: 0.14298  | 0.18\n",
      "[epoch: 4, batch:   1386] loss: 0.04161  | 0.18\n",
      "[epoch: 4, batch:   1388] loss: 0.07605  | 0.18\n",
      "[epoch: 4, batch:   1390] loss: 0.01823  | 0.19\n",
      "[epoch: 4, batch:   1392] loss: 0.15522  | 0.18\n",
      "[epoch: 4, batch:   1394] loss: 0.02045  | 0.18\n",
      "[epoch: 4, batch:   1396] loss: 0.08672  | 0.18\n",
      "[epoch: 4, batch:   1398] loss: 0.05543  | 0.19\n",
      "[epoch: 4, batch:   1400] loss: 0.13685  | 0.17\n",
      "[epoch: 4, batch:   1402] loss: 0.25024  | 0.19\n",
      "[epoch: 4, batch:   1404] loss: 0.31011  | 0.18\n",
      "[epoch: 4, batch:   1406] loss: 0.28400  | 0.18\n",
      "[epoch: 4, batch:   1408] loss: 0.32100  | 0.18\n",
      "[epoch: 4, batch:   1410] loss: 0.12693  | 0.18\n",
      "[epoch: 4, batch:   1412] loss: 0.29024  | 0.18\n",
      "[epoch: 4, batch:   1414] loss: 0.07732  | 0.18\n",
      "[epoch: 4, batch:   1416] loss: 0.03200  | 0.18\n",
      "[epoch: 4, batch:   1418] loss: 0.18634  | 0.18\n",
      "[epoch: 4, batch:   1420] loss: 0.04187  | 0.18\n",
      "[epoch: 4, batch:   1422] loss: 0.21524  | 0.18\n",
      "[epoch: 4, batch:   1424] loss: 0.17235  | 0.18\n",
      "[epoch: 4, batch:   1426] loss: 0.24767  | 0.19\n",
      "[epoch: 4, batch:   1428] loss: 0.03819  | 0.18\n",
      "[epoch: 4, batch:   1430] loss: 0.63763  | 0.18\n",
      "[epoch: 4, batch:   1432] loss: 0.32850  | 0.18\n",
      "[epoch: 4, batch:   1434] loss: 0.00190  | 0.18\n",
      "[epoch: 4, batch:   1436] loss: 0.06751  | 0.18\n",
      "[epoch: 4, batch:   1438] loss: 0.17724  | 0.18\n",
      "[epoch: 4, batch:   1440] loss: 0.07088  | 0.18\n",
      "[epoch: 4, batch:   1442] loss: 0.97797  | 0.18\n",
      "[epoch: 4, batch:   1444] loss: 0.07036  | 0.18\n",
      "[epoch: 4, batch:   1446] loss: 0.20097  | 0.18\n",
      "[epoch: 4, batch:   1448] loss: 0.38190  | 0.18\n",
      "[epoch: 4, batch:   1450] loss: 0.17167  | 0.18\n",
      "[epoch: 4, batch:   1452] loss: 0.03889  | 0.20\n",
      "[epoch: 4, batch:   1454] loss: 0.00935  | 0.18\n",
      "[epoch: 4, batch:   1456] loss: 0.25953  | 0.18\n",
      "[epoch: 4, batch:   1458] loss: 1.37367  | 0.18\n",
      "[epoch: 4, batch:   1460] loss: 0.18314  | 0.18\n",
      "[epoch: 4, batch:   1462] loss: 0.11401  | 0.18\n",
      "[epoch: 4, batch:   1464] loss: 0.10495  | 0.18\n",
      "[epoch: 4, batch:   1466] loss: 0.15217  | 0.18\n",
      "[epoch: 4, batch:   1468] loss: 0.14718  | 0.20\n",
      "[epoch: 4, batch:   1470] loss: 0.09429  | 0.18\n",
      "[epoch: 4, batch:   1472] loss: 0.48037  | 0.18\n",
      "[epoch: 4, batch:   1474] loss: 0.71910  | 0.18\n",
      "[epoch: 4, batch:   1476] loss: 0.42408  | 0.57\n",
      "[epoch: 4, batch:   1478] loss: 0.24930  | 0.18\n",
      "[epoch: 4, batch:   1480] loss: 0.28107  | 0.18\n",
      "[epoch: 4, batch:   1482] loss: 0.17844  | 0.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4, batch:   1484] loss: 0.19528  | 0.18\n",
      "[epoch: 4, batch:   1486] loss: 0.22322  | 0.18\n",
      "[epoch: 4, batch:   1488] loss: 0.25069  | 0.18\n",
      "[epoch: 4, batch:   1490] loss: 0.04365  | 0.17\n",
      "[epoch: 4, batch:   1492] loss: 0.02986  | 0.18\n",
      "[epoch: 4, batch:   1494] loss: 0.14027  | 0.18\n",
      "[epoch: 4, batch:   1496] loss: 1.02654  | 0.18\n",
      "[epoch: 4, batch:   1498] loss: 0.38377  | 0.18\n",
      "[epoch: 4, batch:   1500] loss: 0.25147  | 0.19\n",
      "[epoch: 4, batch:   1502] loss: 0.23806  | 0.17\n",
      "[epoch: 4, batch:   1504] loss: 0.10408  | 0.18\n",
      "[epoch: 4, batch:   1506] loss: 0.30457  | 0.18\n",
      "[epoch: 4, batch:   1508] loss: 0.09520  | 0.18\n",
      "[epoch: 4, batch:   1510] loss: 0.09995  | 0.18\n",
      "[epoch: 4, batch:   1512] loss: 0.37191  | 0.18\n",
      "[epoch: 4, batch:   1514] loss: 0.21761  | 0.18\n",
      "[epoch: 4, batch:   1516] loss: 0.30809  | 0.18\n",
      "[epoch: 4, batch:   1518] loss: 0.15630  | 0.27\n",
      "[epoch: 4, batch:   1520] loss: 0.10998  | 0.17\n",
      "[epoch: 4, batch:   1522] loss: 0.26653  | 0.19\n",
      "[epoch: 4, batch:   1524] loss: 0.06445  | 0.18\n",
      "[epoch: 4, batch:   1526] loss: 2.04563  | 0.18\n",
      "[epoch: 4, batch:   1528] loss: 0.12033  | 0.18\n",
      "[epoch: 4, batch:   1530] loss: 0.25666  | 0.19\n",
      "[epoch: 4, batch:   1532] loss: 0.91882  | 0.18\n",
      "[epoch: 4, batch:   1534] loss: 0.03120  | 0.18\n",
      "[epoch: 4, batch:   1536] loss: 0.05379  | 0.19\n",
      "[epoch: 4, batch:   1538] loss: 0.05412  | 0.18\n",
      "[epoch: 4, batch:   1540] loss: 0.12175  | 0.18\n",
      "[epoch: 4, batch:   1542] loss: 0.50844  | 0.18\n",
      "[epoch: 4, batch:   1544] loss: 0.10722  | 0.32\n",
      "[epoch: 4, batch:   1546] loss: 0.29048  | 0.18\n",
      "[epoch: 4, batch:   1548] loss: 0.05061  | 0.18\n",
      "[epoch: 4, batch:   1550] loss: 0.09316  | 0.18\n",
      "[epoch: 4, batch:   1552] loss: 0.35630  | 0.19\n",
      "[epoch: 4, batch:   1554] loss: 0.39503  | 0.63\n",
      "[epoch: 4, batch:   1556] loss: 0.02526  | 0.17\n",
      "[epoch: 4, batch:   1558] loss: 0.09419  | 0.18\n",
      "[epoch: 4, batch:   1560] loss: 0.34010  | 0.18\n",
      "[epoch: 4, batch:   1562] loss: 0.19951  | 0.19\n",
      "[epoch: 4, batch:   1564] loss: 0.34894  | 0.17\n",
      "[epoch: 4, batch:   1566] loss: 0.31177  | 0.18\n",
      "[epoch: 4, batch:   1568] loss: 0.26425  | 0.18\n",
      "[epoch: 4, batch:   1570] loss: 0.15038  | 0.19\n",
      "[epoch: 4, batch:   1572] loss: 0.14617  | 0.19\n",
      "[epoch: 4, batch:   1574] loss: 0.38374  | 0.18\n",
      "[epoch: 4, batch:   1576] loss: 0.46274  | 0.17\n",
      "[epoch: 4, batch:   1578] loss: 0.08820  | 0.18\n",
      "[epoch: 4, batch:   1580] loss: 0.72749  | 0.19\n",
      "[epoch: 4, batch:   1582] loss: 0.24398  | 0.18\n",
      "[epoch: 4, batch:   1584] loss: 0.24260  | 0.17\n",
      "[epoch: 4, batch:   1586] loss: 0.32377  | 0.18\n",
      "[epoch: 4, batch:   1588] loss: 0.41484  | 0.19\n",
      "[epoch: 4, batch:   1590] loss: 0.21959  | 0.18\n",
      "[epoch: 4, batch:   1592] loss: 0.42709  | 0.17\n",
      "[epoch: 4, batch:   1594] loss: 0.10691  | 0.18\n",
      "[epoch: 4, batch:   1596] loss: 0.09714  | 0.18\n",
      "[epoch: 4, batch:   1598] loss: 0.39395  | 0.18\n",
      "[epoch: 4, batch:   1600] loss: 0.08284  | 0.18\n",
      "[epoch: 4, batch:   1602] loss: 0.02134  | 0.19\n",
      "[epoch: 4, batch:   1604] loss: 0.03132  | 0.17\n",
      "[epoch: 4, batch:   1606] loss: 0.02278  | 0.18\n",
      "[epoch: 4, batch:   1608] loss: 0.15051  | 0.18\n",
      "[epoch: 4, batch:   1610] loss: 0.08441  | 0.19\n",
      "[epoch: 4, batch:   1612] loss: 0.03981  | 0.17\n",
      "[epoch: 4, batch:   1614] loss: 0.32545  | 0.18\n",
      "[epoch: 4, batch:   1616] loss: 0.22248  | 0.18\n",
      "[epoch: 4, batch:   1618] loss: 0.54484  | 0.18\n",
      "[epoch: 4, batch:   1620] loss: 0.69821  | 0.19\n",
      "[epoch: 4, batch:   1622] loss: 1.39792  | 0.18\n",
      "[epoch: 4, batch:   1624] loss: 0.08339  | 0.18\n",
      "[epoch: 4, batch:   1626] loss: 0.17182  | 0.18\n",
      "[epoch: 4, batch:   1628] loss: 0.25259  | 0.18\n",
      "[epoch: 4, batch:   1630] loss: 0.33833  | 0.18\n",
      "[epoch: 4, batch:   1632] loss: 0.10227  | 0.17\n",
      "[epoch: 4, batch:   1634] loss: 0.00293  | 0.18\n",
      "[epoch: 4, batch:   1636] loss: 0.13306  | 0.18\n",
      "[epoch: 4, batch:   1638] loss: 0.08610  | 0.18\n",
      "[epoch: 4, batch:   1640] loss: 0.03188  | 0.18\n",
      "[epoch: 4, batch:   1642] loss: 0.04435  | 0.99\n",
      "[epoch: 4, batch:   1644] loss: 1.43189  | 0.17\n",
      "[epoch: 4, batch:   1646] loss: 0.39621  | 0.18\n",
      "[epoch: 4, batch:   1648] loss: 0.27604  | 0.18\n",
      "[epoch: 4, batch:   1650] loss: 0.23234  | 0.18\n",
      "[epoch: 4, batch:   1652] loss: 0.05112  | 0.17\n",
      "[epoch: 4, batch:   1654] loss: 0.13305  | 0.18\n",
      "[epoch: 4, batch:   1656] loss: 0.45361  | 0.18\n",
      "[epoch: 4, batch:   1658] loss: 1.46873  | 0.18\n",
      "[epoch: 4, batch:   1660] loss: 0.26131  | 0.19\n",
      "[epoch: 4, batch:   1662] loss: 0.20355  | 0.18\n",
      "[epoch: 4, batch:   1664] loss: 0.16824  | 0.18\n",
      "[epoch: 4, batch:   1666] loss: 0.02184  | 0.18\n",
      "[epoch: 4, batch:   1668] loss: 0.11611  | 0.18\n",
      "[epoch: 4, batch:   1670] loss: 0.08294  | 0.18\n",
      "[epoch: 4, batch:   1672] loss: 0.14955  | 0.18\n",
      "[epoch: 4, batch:   1674] loss: 0.16380  | 0.18\n",
      "[epoch: 4, batch:   1676] loss: 0.12335  | 0.18\n",
      "[epoch: 4, batch:   1678] loss: 0.15204  | 0.18\n",
      "[epoch: 4, batch:   1680] loss: 0.13000  | 0.18\n",
      "[epoch: 4, batch:   1682] loss: 0.10677  | 0.18\n",
      "[epoch: 4, batch:   1684] loss: 0.03917  | 0.18\n",
      "[epoch: 4, batch:   1686] loss: 0.10456  | 0.19\n",
      "[epoch: 4, batch:   1688] loss: 0.03595  | 0.17\n",
      "[epoch: 4, batch:   1690] loss: 0.21903  | 0.18\n",
      "[epoch: 4, batch:   1692] loss: 0.07514  | 0.17\n",
      "[epoch: 4, batch:   1694] loss: 0.07645  | 0.18\n",
      "[epoch: 4, batch:   1696] loss: 0.02933  | 0.18\n",
      "[epoch: 4, batch:   1698] loss: 0.67187  | 0.19\n",
      "[epoch: 4, batch:   1700] loss: 0.07198  | 0.18\n",
      "[epoch: 4, batch:   1702] loss: 0.22763  | 0.18\n",
      "[epoch: 4, batch:   1704] loss: 0.25974  | 0.17\n",
      "[epoch: 4, batch:   1706] loss: 0.48827  | 0.18\n",
      "[epoch: 4, batch:   1708] loss: 0.12458  | 0.18\n",
      "[epoch: 4, batch:   1710] loss: 0.59524  | 0.19\n",
      "[epoch: 4, batch:   1712] loss: 0.02652  | 0.18\n",
      "[epoch: 4, batch:   1714] loss: 0.58218  | 0.18\n",
      "[epoch: 4, batch:   1716] loss: 0.23949  | 0.19\n",
      "[epoch: 4, batch:   1718] loss: 0.18736  | 0.18\n",
      "[epoch: 4, batch:   1720] loss: 0.21408  | 0.17\n",
      "[epoch: 4, batch:   1722] loss: 1.36930  | 0.18\n",
      "[epoch: 4, batch:   1724] loss: 0.23705  | 0.20\n",
      "[epoch: 4, batch:   1726] loss: 0.11584  | 0.18\n",
      "[epoch: 4, batch:   1728] loss: 0.24439  | 0.18\n",
      "[epoch: 4, batch:   1730] loss: 0.08925  | 0.18\n",
      "[epoch: 4, batch:   1732] loss: 0.46730  | 0.18\n",
      "[epoch: 4, batch:   1734] loss: 0.17487  | 0.18\n",
      "[epoch: 4, batch:   1736] loss: 0.18026  | 0.18\n",
      "[epoch: 4, batch:   1738] loss: 0.30251  | 0.18\n",
      "[epoch: 4, batch:   1740] loss: 0.21086  | 0.18\n",
      "[epoch: 4, batch:   1742] loss: 0.16498  | 0.19\n",
      "[epoch: 4, batch:   1744] loss: 1.00382  | 0.18\n",
      "[epoch: 4, batch:   1746] loss: 0.14232  | 0.18\n",
      "[epoch: 4, batch:   1748] loss: 0.13361  | 0.17\n",
      "[epoch: 4, batch:   1750] loss: 0.04425  | 0.18\n",
      "[epoch: 4, batch:   1752] loss: 0.11872  | 0.18\n",
      "[epoch: 4, batch:   1754] loss: 0.12475  | 0.18\n",
      "[epoch: 4, batch:   1756] loss: 0.30927  | 0.19\n",
      "[epoch: 4, batch:   1758] loss: 0.11938  | 0.17\n",
      "[epoch: 4, batch:   1760] loss: 0.18379  | 0.18\n",
      "[epoch: 4, batch:   1762] loss: 0.04031  | 0.18\n",
      "[epoch: 4, batch:   1764] loss: 0.16395  | 0.19\n",
      "[epoch: 4, batch:   1766] loss: 0.40415  | 0.18\n",
      "[epoch: 4, batch:   1768] loss: 0.06791  | 0.18\n",
      "[epoch: 4, batch:   1770] loss: 0.22194  | 0.18\n",
      "[epoch: 4, batch:   1772] loss: 0.19470  | 0.19\n",
      "[epoch: 4, batch:   1774] loss: 0.37643  | 0.26\n",
      "[epoch: 4, batch:   1776] loss: 0.33213  | 0.17\n",
      "[epoch: 4, batch:   1778] loss: 0.02840  | 0.18\n",
      "[epoch: 4, batch:   1780] loss: 0.03456  | 0.17\n",
      "[epoch: 4, batch:   1782] loss: 0.06832  | 0.19\n",
      "[epoch: 4, batch:   1784] loss: 0.09135  | 0.17\n",
      "[epoch: 4, batch:   1786] loss: 0.08999  | 0.18\n",
      "[epoch: 4, batch:   1788] loss: 0.04261  | 0.18\n",
      "[epoch: 4, batch:   1790] loss: 0.10645  | 0.19\n",
      "[epoch: 4, batch:   1792] loss: 0.80953  | 0.17\n",
      "[epoch: 4, batch:   1794] loss: 0.32253  | 0.18\n",
      "[epoch: 4, batch:   1796] loss: 0.04504  | 0.18\n",
      "[epoch: 4, batch:   1798] loss: 0.54459  | 0.19\n",
      "[epoch: 4, batch:   1800] loss: 0.03760  | 0.17\n",
      "[epoch: 4, batch:   1802] loss: 0.10685  | 0.18\n",
      "[epoch: 4, batch:   1804] loss: 0.23131  | 0.18\n",
      "[epoch: 4, batch:   1806] loss: 0.30818  | 0.18\n",
      "[epoch: 4, batch:   1808] loss: 0.16514  | 0.17\n",
      "[epoch: 4, batch:   1810] loss: 0.17316  | 0.18\n",
      "[epoch: 4, batch:   1812] loss: 0.06342  | 0.18\n",
      "[epoch: 4, batch:   1814] loss: 0.04041  | 0.19\n",
      "[epoch: 4, batch:   1816] loss: 0.01934  | 0.17\n",
      "[epoch: 4, batch:   1818] loss: 0.47882  | 0.18\n",
      "[epoch: 4, batch:   1820] loss: 0.51292  | 0.19\n",
      "[epoch: 4, batch:   1822] loss: 0.50301  | 0.32\n",
      "[epoch: 4, batch:   1824] loss: 0.05178  | 0.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4, batch:   1826] loss: 0.18009  | 0.18\n",
      "[epoch: 4, batch:   1828] loss: 0.00919  | 0.17\n",
      "[epoch: 4, batch:   1830] loss: 0.20219  | 0.18\n",
      "[epoch: 4, batch:   1832] loss: 0.03869  | 0.18\n",
      "[epoch: 4, batch:   1834] loss: 0.36769  | 0.17\n",
      "[epoch: 4, batch:   1836] loss: 0.73476  | 0.18\n",
      "[epoch: 4, batch:   1838] loss: 0.28311  | 0.18\n",
      "[epoch: 4, batch:   1840] loss: 0.03624  | 0.19\n",
      "[epoch: 4, batch:   1842] loss: 0.07571  | 0.18\n",
      "[epoch: 4, batch:   1844] loss: 0.24800  | 0.35\n",
      "[epoch: 4, batch:   1846] loss: 0.21201  | 0.18\n",
      "[epoch: 4, batch:   1848] loss: 0.04777  | 0.18\n",
      "[epoch: 4, batch:   1850] loss: 1.11376  | 0.17\n",
      "[epoch: 4, batch:   1852] loss: 0.12009  | 0.18\n",
      "[epoch: 4, batch:   1854] loss: 0.08549  | 0.18\n",
      "[epoch: 4, batch:   1856] loss: 0.09553  | 0.18\n",
      "[epoch: 4, batch:   1858] loss: 0.23212  | 0.17\n",
      "[epoch: 4, batch:   1860] loss: 0.16037  | 0.18\n",
      "[epoch: 4, batch:   1862] loss: 0.76197  | 0.18\n",
      "[epoch: 4, batch:   1864] loss: 0.48073  | 0.18\n",
      "[epoch: 4, batch:   1866] loss: 0.29067  | 0.18\n",
      "[epoch: 4, batch:   1868] loss: 0.10930  | 0.18\n",
      "[epoch: 4, batch:   1870] loss: 0.06455  | 0.20\n",
      "[epoch: 4, batch:   1872] loss: 0.12693  | 0.18\n",
      "[epoch: 4, batch:   1874] loss: 0.86786  | 0.17\n",
      "[epoch: 4, batch:   1876] loss: 0.16477  | 0.18\n",
      "[epoch: 4, batch:   1878] loss: 0.04081  | 0.18\n",
      "[epoch: 4, batch:   1880] loss: 0.13343  | 0.18\n",
      "[epoch: 4, batch:   1882] loss: 0.30167  | 0.18\n",
      "[epoch: 4, batch:   1884] loss: 0.05109  | 0.18\n",
      "[epoch: 4, batch:   1886] loss: 0.15787  | 0.18\n",
      "[epoch: 4, batch:   1888] loss: 0.08909  | 0.18\n",
      "[epoch: 4, batch:   1890] loss: 0.05450  | 0.18\n",
      "[epoch: 4, batch:   1892] loss: 0.06298  | 0.18\n",
      "[epoch: 4, batch:   1894] loss: 0.37025  | 0.47\n",
      "[epoch: 4, batch:   1896] loss: 0.33863  | 0.18\n",
      "[epoch: 4, batch:   1898] loss: 0.73775  | 0.18\n",
      "[epoch: 4, batch:   1900] loss: 0.31772  | 0.18\n",
      "[epoch: 4, batch:   1902] loss: 0.07479  | 0.18\n",
      "[epoch: 4, batch:   1904] loss: 0.23033  | 0.18\n",
      "[epoch: 4, batch:   1906] loss: 0.19739  | 0.18\n",
      "[epoch: 4, batch:   1908] loss: 0.10585  | 0.19\n",
      "[epoch: 4, batch:   1910] loss: 0.12306  | 0.18\n",
      "[epoch: 4, batch:   1912] loss: 0.06476  | 0.18\n",
      "[epoch: 4, batch:   1914] loss: 0.06899  | 0.18\n",
      "[epoch: 4, batch:   1916] loss: 0.19441  | 0.18\n",
      "[epoch: 4, batch:   1918] loss: 0.03141  | 0.20\n",
      "[epoch: 4, batch:   1920] loss: 0.06710  | 0.17\n",
      "[epoch: 4, batch:   1922] loss: 0.23409  | 0.18\n",
      "[epoch: 4, batch:   1924] loss: 0.43768  | 0.18\n",
      "[epoch: 4, batch:   1926] loss: 0.12295  | 0.18\n",
      "[epoch: 4, batch:   1928] loss: 0.41641  | 0.17\n",
      "[epoch: 4, batch:   1930] loss: 0.01713  | 0.18\n",
      "[epoch: 4, batch:   1932] loss: 0.44675  | 0.18\n",
      "[epoch: 4, batch:   1934] loss: 0.14592  | 0.18\n",
      "[epoch: 4, batch:   1936] loss: 0.02189  | 0.18\n",
      "[epoch: 4, batch:   1938] loss: 0.32136  | 0.18\n",
      "[epoch: 4, batch:   1940] loss: 0.64077  | 0.18\n",
      "[epoch: 4, batch:   1942] loss: 0.58898  | 0.18\n",
      "[epoch: 4, batch:   1944] loss: 0.16536  | 0.18\n",
      "[epoch: 4, batch:   1946] loss: 0.04604  | 0.19\n",
      "[epoch: 4, batch:   1948] loss: 0.40769  | 0.17\n",
      "[epoch: 4, batch:   1950] loss: 0.10646  | 0.18\n",
      "[epoch: 4, batch:   1952] loss: 0.03731  | 0.17\n",
      "[epoch: 4, batch:   1954] loss: 0.07205  | 0.19\n",
      "[epoch: 4, batch:   1956] loss: 0.34868  | 0.17\n",
      "[epoch: 4, batch:   1958] loss: 0.08172  | 0.18\n",
      "[epoch: 4, batch:   1960] loss: 0.32530  | 0.18\n",
      "[epoch: 4, batch:   1962] loss: 0.09229  | 0.18\n",
      "[epoch: 4, batch:   1964] loss: 0.09200  | 0.18\n",
      "[epoch: 4, batch:   1966] loss: 0.01410  | 0.18\n",
      "[epoch: 4, batch:   1968] loss: 0.11551  | 0.18\n",
      "[epoch: 4, batch:   1970] loss: 0.39436  | 0.19\n",
      "[epoch: 4, batch:   1972] loss: 1.04371  | 0.18\n",
      "[epoch: 4, batch:   1974] loss: 0.22015  | 0.18\n",
      "[epoch: 4, batch:   1976] loss: 0.07076  | 0.18\n",
      "[epoch: 4, batch:   1978] loss: 0.08017  | 0.18\n",
      "[epoch: 4, batch:   1980] loss: 0.06012  | 0.18\n",
      "[epoch: 4, batch:   1982] loss: 0.12302  | 0.18\n",
      "[epoch: 4, batch:   1984] loss: 0.48211  | 0.17\n",
      "[epoch: 4, batch:   1986] loss: 0.16663  | 0.18\n",
      "[epoch: 4, batch:   1988] loss: 0.04172  | 0.18\n",
      "[epoch: 4, batch:   1990] loss: 0.08576  | 0.19\n",
      "[epoch: 4, batch:   1992] loss: 0.16672  | 0.17\n",
      "[epoch: 4, batch:   1994] loss: 0.14692  | 0.18\n",
      "[epoch: 4, batch:   1996] loss: 0.04350  | 0.19\n",
      "[epoch: 4, batch:   1998] loss: 0.04316  | 0.17\n",
      "[epoch: 4, batch:   2000] loss: 0.10516  | 0.17\n",
      "[epoch: 4, batch:   2002] loss: 0.31624  | 0.18\n",
      "[epoch: 4, batch:   2004] loss: 0.26099  | 0.19\n",
      "[epoch: 4, batch:   2006] loss: 1.45246  | 0.53\n",
      "[epoch: 4, batch:   2008] loss: 0.18756  | 0.18\n",
      "[epoch: 4, batch:   2010] loss: 0.32966  | 0.18\n",
      "[epoch: 4, batch:   2012] loss: 0.07743  | 0.17\n",
      "[epoch: 4, batch:   2014] loss: 0.57836  | 0.18\n",
      "[epoch: 4, batch:   2016] loss: 0.06758  | 0.18\n",
      "[epoch: 4, batch:   2018] loss: 0.06563  | 0.18\n",
      "[epoch: 4, batch:   2020] loss: 0.18401  | 0.17\n",
      "[epoch: 4, batch:   2022] loss: 0.04926  | 0.18\n",
      "[epoch: 4, batch:   2024] loss: 0.49757  | 0.18\n",
      "[epoch: 4, batch:   2026] loss: 0.05703  | 0.18\n",
      "[epoch: 4, batch:   2028] loss: 0.37635  | 0.18\n",
      "[epoch: 4, batch:   2030] loss: 0.30041  | 0.18\n",
      "[epoch: 4, batch:   2032] loss: 0.12648  | 0.18\n",
      "[epoch: 4, batch:   2034] loss: 0.11399  | 0.18\n",
      "[epoch: 4, batch:   2036] loss: 0.02764  | 0.18\n",
      "[epoch: 4, batch:   2038] loss: 0.59188  | 0.18\n",
      "[epoch: 4, batch:   2040] loss: 0.47884  | 0.18\n",
      "[epoch: 4, batch:   2042] loss: 0.84005  | 0.18\n",
      "[epoch: 4, batch:   2044] loss: 0.20643  | 0.18\n",
      "[epoch: 4, batch:   2046] loss: 0.10530  | 0.18\n",
      "[epoch: 4, batch:   2048] loss: 0.06660  | 0.18\n",
      "[epoch: 4, batch:   2050] loss: 0.09125  | 0.18\n",
      "[epoch: 4, batch:   2052] loss: 0.05223  | 0.18\n",
      "[epoch: 4, batch:   2054] loss: 0.02137  | 0.18\n",
      "[epoch: 4, batch:   2056] loss: 0.26842  | 0.56\n",
      "[epoch: 4, batch:   2058] loss: 0.09650  | 0.17\n",
      "[epoch: 4, batch:   2060] loss: 0.09142  | 0.18\n",
      "[epoch: 4, batch:   2062] loss: 0.08862  | 1.69\n",
      "[epoch: 4, batch:   2064] loss: 0.12031  | 0.17\n",
      "[epoch: 4, batch:   2066] loss: 0.06378  | 0.18\n",
      "[epoch: 4, batch:   2068] loss: 0.42462  | 0.17\n",
      "[epoch: 4, batch:   2070] loss: 1.01690  | 0.18\n",
      "[epoch: 4, batch:   2072] loss: 0.11127  | 0.17\n",
      "[epoch: 4, batch:   2074] loss: 0.07014  | 0.18\n",
      "[epoch: 4, batch:   2076] loss: 0.10215  | 0.18\n",
      "[epoch: 4, batch:   2078] loss: 0.32405  | 0.19\n",
      "[epoch: 4, batch:   2080] loss: 0.39920  | 0.17\n",
      "[epoch: 4, batch:   2082] loss: 0.03957  | 0.18\n",
      "[epoch: 4, batch:   2084] loss: 0.19596  | 0.18\n",
      "[epoch: 4, batch:   2086] loss: 0.33476  | 0.18\n",
      "[epoch: 4, batch:   2088] loss: 0.05550  | 0.18\n",
      "[epoch: 4, batch:   2090] loss: 0.11104  | 0.18\n",
      "[epoch: 4, batch:   2092] loss: 0.09395  | 0.18\n",
      "[epoch: 4, batch:   2094] loss: 0.10981  | 0.18\n",
      "[epoch: 4, batch:   2096] loss: 0.05176  | 0.30\n",
      "[epoch: 4, batch:   2098] loss: 0.04237  | 0.17\n",
      "[epoch: 4, batch:   2100] loss: 0.06897  | 0.18\n",
      "[epoch: 4, batch:   2102] loss: 0.28320  | 0.18\n",
      "[epoch: 4, batch:   2104] loss: 0.22108  | 0.19\n",
      "[epoch: 4, batch:   2106] loss: 0.06700  | 0.17\n",
      "[epoch: 4, batch:   2108] loss: 0.03940  | 0.18\n",
      "[epoch: 4, batch:   2110] loss: 0.42973  | 0.60\n",
      "[epoch: 4, batch:   2112] loss: 0.02823  | 0.18\n",
      "[epoch: 4, batch:   2114] loss: 0.06316  | 0.18\n",
      "[epoch: 4, batch:   2116] loss: 0.10414  | 0.17\n",
      "[epoch: 4, batch:   2118] loss: 0.03079  | 0.18\n",
      "[epoch: 4, batch:   2120] loss: 0.24593  | 0.18\n",
      "[epoch: 4, batch:   2122] loss: 0.03119  | 0.18\n",
      "[epoch: 4, batch:   2124] loss: 0.06540  | 0.17\n",
      "[epoch: 4, batch:   2126] loss: 0.10198  | 0.21\n",
      "[epoch: 4, batch:   2128] loss: 0.15446  | 0.17\n",
      "[epoch: 4, batch:   2130] loss: 0.29200  | 0.18\n",
      "[epoch: 4, batch:   2132] loss: 0.01055  | 0.17\n",
      "[epoch: 4, batch:   2134] loss: 0.30646  | 0.18\n",
      "[epoch: 4, batch:   2136] loss: 0.06436  | 0.17\n",
      "[epoch: 4, batch:   2138] loss: 0.07842  | 0.18\n",
      "[epoch: 4, batch:   2140] loss: 0.30431  | 0.17\n",
      "[epoch: 4, batch:   2142] loss: 0.07293  | 0.18\n",
      "[epoch: 4, batch:   2144] loss: 0.25813  | 1.21\n",
      "[epoch: 4, batch:   2146] loss: 0.28653  | 0.18\n",
      "[epoch: 4, batch:   2148] loss: 0.03844  | 0.18\n",
      "[epoch: 4, batch:   2150] loss: 0.23668  | 0.17\n",
      "[epoch: 4, batch:   2152] loss: 0.17867  | 0.18\n",
      "[epoch: 4, batch:   2154] loss: 0.22232  | 0.17\n",
      "[epoch: 4, batch:   2156] loss: 0.20094  | 0.18\n",
      "[epoch: 4, batch:   2158] loss: 1.41534  | 0.17\n",
      "[epoch: 4, batch:   2160] loss: 0.50303  | 0.19\n",
      "[epoch: 4, batch:   2162] loss: 0.19570  | 0.18\n",
      "[epoch: 4, batch:   2164] loss: 0.19356  | 0.18\n",
      "[epoch: 4, batch:   2166] loss: 0.03740  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4, batch:   2168] loss: 0.05627  | 0.20\n",
      "[epoch: 4, batch:   2170] loss: 0.06020  | 0.17\n",
      "[epoch: 4, batch:   2172] loss: 0.08452  | 0.18\n",
      "[epoch: 4, batch:   2174] loss: 0.03835  | 0.18\n",
      "[epoch: 4, batch:   2176] loss: 0.09162  | 0.18\n",
      "[epoch: 4, batch:   2178] loss: 0.28015  | 0.17\n",
      "[epoch: 4, batch:   2180] loss: 0.17380  | 0.18\n",
      "[epoch: 4, batch:   2182] loss: 0.04812  | 0.18\n",
      "[epoch: 4, batch:   2184] loss: 0.53678  | 0.32\n",
      "[epoch: 4, batch:   2186] loss: 0.22561  | 0.18\n",
      "[epoch: 4, batch:   2188] loss: 0.06675  | 0.18\n",
      "[epoch: 4, batch:   2190] loss: 0.31327  | 0.17\n",
      "[epoch: 4, batch:   2192] loss: 0.39546  | 0.18\n",
      "[epoch: 4, batch:   2194] loss: 0.20038  | 0.17\n",
      "[epoch: 4, batch:   2196] loss: 0.42666  | 0.18\n",
      "[epoch: 4, batch:   2198] loss: 0.46167  | 0.18\n",
      "[epoch: 4, batch:   2200] loss: 0.08382  | 0.18\n",
      "[epoch: 4, batch:   2202] loss: 0.06556  | 0.18\n",
      "[epoch: 4, batch:   2204] loss: 0.16277  | 0.18\n",
      "[epoch: 4, batch:   2206] loss: 0.09346  | 0.18\n",
      "[epoch: 4, batch:   2208] loss: 0.03335  | 0.18\n",
      "[epoch: 4, batch:   2210] loss: 0.04745  | 0.18\n",
      "[epoch: 4, batch:   2212] loss: 0.04523  | 0.18\n",
      "[epoch: 4, batch:   2214] loss: 0.11029  | 0.18\n",
      "[epoch: 4, batch:   2216] loss: 0.06819  | 0.37\n",
      "[epoch: 4, batch:   2218] loss: 0.08820  | 0.17\n",
      "[epoch: 4, batch:   2220] loss: 0.15581  | 0.18\n",
      "[epoch: 4, batch:   2222] loss: 0.16811  | 0.18\n",
      "[epoch: 4, batch:   2224] loss: 0.13089  | 0.19\n",
      "[epoch: 4, batch:   2226] loss: 0.04526  | 0.17\n",
      "[epoch: 4, batch:   2228] loss: 0.05944  | 0.17\n",
      "[epoch: 4, batch:   2230] loss: 0.51266  | 0.18\n",
      "[epoch: 4, batch:   2232] loss: 0.44140  | 0.18\n",
      "[epoch: 4, batch:   2234] loss: 0.07732  | 0.18\n",
      "[epoch: 4, batch:   2236] loss: 0.03056  | 0.18\n",
      "[epoch: 4, batch:   2238] loss: 0.72008  | 0.18\n",
      "[epoch: 4, batch:   2240] loss: 0.91132  | 0.19\n",
      "[epoch: 4, batch:   2242] loss: 0.37301  | 0.17\n",
      "[epoch: 4, batch:   2244] loss: 0.07740  | 0.19\n",
      "[epoch: 4, batch:   2246] loss: 0.01997  | 0.17\n",
      "[epoch: 4, batch:   2248] loss: 0.36073  | 0.18\n",
      "[epoch: 4, batch:   2250] loss: 0.04226  | 0.18\n",
      "[epoch: 4, batch:   2252] loss: 0.61160  | 0.18\n",
      "[epoch: 4, batch:   2254] loss: 0.59919  | 0.19\n",
      "[epoch: 4, batch:   2256] loss: 0.02347  | 0.18\n",
      "[epoch: 4, batch:   2258] loss: 0.03663  | 0.18\n",
      "[epoch: 4, batch:   2260] loss: 0.72489  | 0.19\n",
      "[epoch: 4, batch:   2262] loss: 0.10309  | 0.18\n",
      "[epoch: 4, batch:   2264] loss: 0.10466  | 0.18\n",
      "[epoch: 4, batch:   2266] loss: 0.07957  | 0.19\n",
      "[epoch: 4, batch:   2268] loss: 0.07497  | 0.18\n",
      "[epoch: 4, batch:   2270] loss: 0.17358  | 0.18\n",
      "[epoch: 4, batch:   2272] loss: 0.22542  | 0.18\n",
      "[epoch: 4, batch:   2274] loss: 0.23693  | 0.18\n",
      "[epoch: 4, batch:   2276] loss: 0.13944  | 0.18\n",
      "[epoch: 4, batch:   2278] loss: 0.19372  | 0.18\n",
      "[epoch: 4, batch:   2280] loss: 0.09234  | 0.18\n",
      "[epoch: 4, batch:   2282] loss: 0.26784  | 0.19\n",
      "[epoch: 4, batch:   2284] loss: 0.63237  | 0.18\n",
      "[epoch: 4, batch:   2286] loss: 0.02108  | 0.18\n",
      "[epoch: 4, batch:   2288] loss: 0.18235  | 0.18\n",
      "[epoch: 4, batch:   2290] loss: 0.12009  | 0.18\n",
      "[epoch: 4, batch:   2292] loss: 0.45179  | 0.18\n",
      "[epoch: 4, batch:   2294] loss: 0.08904  | 0.18\n",
      "[epoch: 4, batch:   2296] loss: 0.08709  | 0.18\n",
      "[epoch: 4, batch:   2298] loss: 0.42784  | 0.19\n",
      "[epoch: 4, batch:   2300] loss: 0.40547  | 0.18\n",
      "[epoch: 4, batch:   2302] loss: 0.11543  | 0.17\n",
      "[epoch: 4, batch:   2304] loss: 0.07317  | 0.19\n",
      "[epoch: 4, batch:   2306] loss: 0.00871  | 0.18\n",
      "[epoch: 4, batch:   2308] loss: 0.58030  | 0.18\n",
      "[epoch: 4, batch:   2310] loss: 0.14424  | 0.18\n",
      "[epoch: 4, batch:   2312] loss: 0.24031  | 0.18\n",
      "[epoch: 4, batch:   2314] loss: 0.48050  | 0.18\n",
      "[epoch: 4, batch:   2316] loss: 0.72690  | 0.18\n",
      "[epoch: 4, batch:   2318] loss: 0.01576  | 0.18\n",
      "[epoch: 4, batch:   2320] loss: 0.14869  | 0.18\n",
      "[epoch: 4, batch:   2322] loss: 0.38987  | 0.18\n",
      "[epoch: 4, batch:   2324] loss: 0.46227  | 0.18\n",
      "[epoch: 4, batch:   2326] loss: 0.03129  | 0.18\n",
      "[epoch: 4, batch:   2328] loss: 0.60924  | 0.18\n",
      "[epoch: 4, batch:   2330] loss: 0.27816  | 0.18\n",
      "[epoch: 4, batch:   2332] loss: 0.04982  | 0.18\n",
      "[epoch: 4, batch:   2334] loss: 0.07343  | 0.18\n",
      "[epoch: 4, batch:   2336] loss: 0.06141  | 0.18\n",
      "[epoch: 4, batch:   2338] loss: 0.28105  | 0.18\n",
      "[epoch: 4, batch:   2340] loss: 0.99842  | 0.18\n",
      "[epoch: 4, batch:   2342] loss: 0.67004  | 0.18\n",
      "[epoch: 4, batch:   2344] loss: 0.05730  | 0.18\n",
      "[epoch: 4, batch:   2346] loss: 0.16659  | 1.01\n",
      "[epoch: 4, batch:   2348] loss: 0.04390  | 0.17\n",
      "[epoch: 4, batch:   2350] loss: 0.18180  | 0.17\n",
      "[epoch: 4, batch:   2352] loss: 0.56047  | 0.18\n",
      "[epoch: 4, batch:   2354] loss: 0.09904  | 0.18\n",
      "[epoch: 4, batch:   2356] loss: 0.06719  | 0.17\n",
      "[epoch: 4, batch:   2358] loss: 0.08086  | 0.18\n",
      "[epoch: 4, batch:   2360] loss: 0.17691  | 0.95\n",
      "[epoch: 4, batch:   2362] loss: 0.17960  | 0.18\n",
      "[epoch: 4, batch:   2364] loss: 0.07917  | 0.18\n",
      "[epoch: 4, batch:   2366] loss: 0.14711  | 0.17\n",
      "[epoch: 4, batch:   2368] loss: 0.04037  | 0.18\n",
      "[epoch: 4, batch:   2370] loss: 0.09606  | 0.18\n",
      "[epoch: 4, batch:   2372] loss: 0.29946  | 0.18\n",
      "[epoch: 4, batch:   2374] loss: 0.02984  | 0.17\n",
      "[epoch: 4, batch:   2376] loss: 0.07268  | 0.18\n",
      "[epoch: 4, batch:   2378] loss: 0.27000  | 0.18\n",
      "[epoch: 4, batch:   2380] loss: 0.23718  | 0.18\n",
      "[epoch: 4, batch:   2382] loss: 0.11181  | 0.18\n",
      "[epoch: 4, batch:   2384] loss: 0.02934  | 0.18\n",
      "[epoch: 4, batch:   2386] loss: 0.20756  | 0.18\n",
      "[epoch: 4, batch:   2388] loss: 0.12354  | 0.19\n",
      "[epoch: 4, batch:   2390] loss: 0.02045  | 0.18\n",
      "[epoch: 4, batch:   2392] loss: 0.10685  | 0.19\n",
      "[epoch: 4, batch:   2394] loss: 0.25091  | 0.18\n",
      "[epoch: 4, batch:   2396] loss: 0.21607  | 0.18\n",
      "[epoch: 4, batch:   2398] loss: 0.04910  | 0.18\n",
      "[epoch: 4, batch:   2400] loss: 0.13223  | 0.18\n",
      "[epoch: 4, batch:   2402] loss: 0.04499  | 0.18\n",
      "[epoch: 4, batch:   2404] loss: 0.09452  | 0.77\n",
      "[epoch: 4, batch:   2406] loss: 0.08163  | 0.18\n",
      "[epoch: 4, batch:   2408] loss: 0.13620  | 0.18\n",
      "[epoch: 4, batch:   2410] loss: 0.10105  | 0.19\n",
      "[epoch: 4, batch:   2412] loss: 0.06651  | 0.18\n",
      "[epoch: 4, batch:   2414] loss: 0.06186  | 0.18\n",
      "[epoch: 4, batch:   2416] loss: 0.04229  | 0.18\n",
      "[epoch: 4, batch:   2418] loss: 0.12363  | 0.18\n",
      "[epoch: 4, batch:   2420] loss: 0.01778  | 0.18\n",
      "[epoch: 4, batch:   2422] loss: 0.47440  | 0.18\n",
      "[epoch: 4, batch:   2424] loss: 0.04290  | 0.18\n",
      "[epoch: 4, batch:   2426] loss: 0.07042  | 0.18\n",
      "[epoch: 4, batch:   2428] loss: 0.15558  | 0.28\n",
      "[epoch: 4, batch:   2430] loss: 0.40150  | 0.18\n",
      "[epoch: 4, batch:   2432] loss: 0.27209  | 0.18\n",
      "[epoch: 4, batch:   2434] loss: 0.14025  | 0.17\n",
      "[epoch: 4, batch:   2436] loss: 0.08767  | 0.18\n",
      "[epoch: 4, batch:   2438] loss: 0.03125  | 0.18\n",
      "[epoch: 4, batch:   2440] loss: 0.10481  | 0.18\n",
      "[epoch: 4, batch:   2442] loss: 0.40345  | 0.17\n",
      "[epoch: 4, batch:   2444] loss: 0.10576  | 0.18\n",
      "[epoch: 4, batch:   2446] loss: 0.22523  | 0.18\n",
      "[epoch: 4, batch:   2448] loss: 0.01617  | 0.18\n",
      "[epoch: 4, batch:   2450] loss: 0.05119  | 0.18\n",
      "[epoch: 4, batch:   2452] loss: 0.10571  | 0.18\n",
      "[epoch: 4, batch:   2454] loss: 0.36410  | 0.18\n",
      "[epoch: 4, batch:   2456] loss: 0.72237  | 0.18\n",
      "[epoch: 4, batch:   2458] loss: 0.03322  | 0.18\n",
      "[epoch: 4, batch:   2460] loss: 0.09310  | 0.18\n",
      "[epoch: 4, batch:   2462] loss: 0.01416  | 0.20\n",
      "[epoch: 4, batch:   2464] loss: 0.02312  | 0.18\n",
      "[epoch: 4, batch:   2466] loss: 0.06126  | 0.18\n",
      "[epoch: 4, batch:   2468] loss: 0.20708  | 0.18\n",
      "[epoch: 4, batch:   2470] loss: 0.01764  | 0.18\n",
      "[epoch: 4, batch:   2472] loss: 0.07190  | 0.18\n",
      "[epoch: 4, batch:   2474] loss: 0.07950  | 0.18\n",
      "[epoch: 4, batch:   2476] loss: 0.35280  | 0.18\n",
      "[epoch: 4, batch:   2478] loss: 1.21086  | 0.18\n",
      "[epoch: 4, batch:   2480] loss: 0.20365  | 0.18\n",
      "[epoch: 4, batch:   2482] loss: 0.08735  | 0.18\n",
      "[epoch: 4, batch:   2484] loss: 0.12802  | 0.18\n",
      "[epoch: 4, batch:   2486] loss: 0.30302  | 0.18\n",
      "[epoch: 4, batch:   2488] loss: 0.63192  | 0.19\n",
      "[epoch: 4, batch:   2490] loss: 0.02889  | 0.18\n",
      "[epoch: 4, batch:   2492] loss: 0.31509  | 0.18\n",
      "[epoch: 4, batch:   2494] loss: 0.07265  | 0.18\n",
      "[epoch: 4, batch:   2496] loss: 0.05104  | 0.18\n",
      "[epoch: 4, batch:   2498] loss: 0.08119  | 0.18\n",
      "[epoch: 4, batch:   2500] loss: 0.12364  | 0.18\n",
      "[epoch: 4, batch:   2502] loss: 0.28276  | 0.18\n",
      "[epoch: 4, batch:   2504] loss: 0.36293  | 0.18\n",
      "[epoch: 4, batch:   2506] loss: 0.25735  | 0.18\n",
      "[epoch: 4, batch:   2508] loss: 0.06749  | 0.19\n",
      "[epoch: 4, batch:   2510] loss: 0.16832  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4, batch:   2512] loss: 0.36754  | 0.18\n",
      "[epoch: 4, batch:   2514] loss: 0.02393  | 0.18\n",
      "[epoch: 4, batch:   2516] loss: 0.15752  | 0.20\n",
      "[epoch: 4, batch:   2518] loss: 0.27925  | 0.18\n",
      "[epoch: 4, batch:   2520] loss: 0.03431  | 0.18\n",
      "[epoch: 4, batch:   2522] loss: 0.38777  | 0.17\n",
      "[epoch: 4, batch:   2524] loss: 0.12414  | 0.18\n",
      "[epoch: 4, batch:   2526] loss: 0.39276  | 0.18\n",
      "[epoch: 4, batch:   2528] loss: 0.68264  | 0.18\n",
      "[epoch: 4, batch:   2530] loss: 0.02047  | 0.18\n",
      "[epoch: 4, batch:   2532] loss: 1.27957  | 0.18\n",
      "[epoch: 4, batch:   2534] loss: 0.12858  | 0.18\n",
      "[epoch: 4, batch:   2536] loss: 0.22742  | 0.18\n",
      "[epoch: 4, batch:   2538] loss: 0.08135  | 0.18\n",
      "[epoch: 4, batch:   2540] loss: 0.05322  | 0.18\n",
      "[epoch: 4, batch:   2542] loss: 0.04457  | 0.18\n",
      "[epoch: 4, batch:   2544] loss: 0.08998  | 0.18\n",
      "[epoch: 4, batch:   2546] loss: 0.08596  | 0.18\n",
      "[epoch: 4, batch:   2548] loss: 0.06577  | 0.18\n",
      "[epoch: 4, batch:   2550] loss: 0.07440  | 0.18\n",
      "[epoch: 4, batch:   2552] loss: 0.98147  | 0.57\n",
      "[epoch: 4, batch:   2554] loss: 0.24850  | 0.18\n",
      "[epoch: 4, batch:   2556] loss: 1.22199  | 0.18\n",
      "[epoch: 4, batch:   2558] loss: 0.11127  | 0.18\n",
      "[epoch: 4, batch:   2560] loss: 0.03441  | 0.18\n",
      "[epoch: 4, batch:   2562] loss: 0.04980  | 0.18\n",
      "[epoch: 4, batch:   2564] loss: 0.20377  | 0.18\n",
      "[epoch: 4, batch:   2566] loss: 0.28830  | 0.18\n",
      "[epoch: 4, batch:   2568] loss: 0.28518  | 1.15\n",
      "[epoch: 4, batch:   2570] loss: 0.71524  | 0.17\n",
      "[epoch: 4, batch:   2572] loss: 0.01178  | 0.18\n",
      "[epoch: 4, batch:   2574] loss: 0.01581  | 0.18\n",
      "[epoch: 4, batch:   2576] loss: 0.41795  | 0.18\n",
      "[epoch: 4, batch:   2578] loss: 0.06327  | 0.19\n",
      "[epoch: 4, batch:   2580] loss: 0.07917  | 0.18\n",
      "[epoch: 4, batch:   2582] loss: 0.21127  | 0.18\n",
      "[epoch: 4, batch:   2584] loss: 0.34544  | 0.18\n",
      "[epoch: 4, batch:   2586] loss: 0.93604  | 0.18\n",
      "[epoch: 4, batch:   2588] loss: 0.18399  | 0.18\n",
      "[epoch: 4, batch:   2590] loss: 0.14081  | 0.18\n",
      "[epoch: 4, batch:   2592] loss: 0.29389  | 0.18\n",
      "[epoch: 4, batch:   2594] loss: 0.13613  | 0.18\n",
      "[epoch: 4, batch:   2596] loss: 0.26111  | 0.18\n",
      "[epoch: 4, batch:   2598] loss: 0.26689  | 0.18\n",
      "[epoch: 4, batch:   2600] loss: 0.05168  | 0.19\n",
      "[epoch: 4, batch:   2602] loss: 0.11693  | 0.18\n",
      "[epoch: 4, batch:   2604] loss: 0.10457  | 0.18\n",
      "[epoch: 4, batch:   2606] loss: 0.09978  | 0.17\n",
      "[epoch: 4, batch:   2608] loss: 0.03144  | 0.18\n",
      "[epoch: 4, batch:   2610] loss: 0.07810  | 0.18\n",
      "[epoch: 4, batch:   2612] loss: 0.29514  | 0.18\n",
      "[epoch: 4, batch:   2614] loss: 0.07955  | 0.18\n",
      "[epoch: 4, batch:   2616] loss: 0.40537  | 0.18\n",
      "[epoch: 4, batch:   2618] loss: 0.15713  | 0.18\n",
      "[epoch: 4, batch:   2620] loss: 0.09624  | 0.18\n",
      "[epoch: 4, batch:   2622] loss: 0.23311  | 0.18\n",
      "[epoch: 4, batch:   2624] loss: 0.21073  | 0.48\n",
      "[epoch: 4, batch:   2626] loss: 0.30438  | 0.18\n",
      "[epoch: 4, batch:   2628] loss: 0.04137  | 0.18\n",
      "[epoch: 4, batch:   2630] loss: 0.12657  | 0.17\n",
      "[epoch: 4, batch:   2632] loss: 0.04435  | 0.18\n",
      "[epoch: 4, batch:   2634] loss: 0.19538  | 0.18\n",
      "[epoch: 4, batch:   2636] loss: 0.06735  | 0.18\n",
      "[epoch: 4, batch:   2638] loss: 0.02960  | 0.17\n",
      "[epoch: 4, batch:   2640] loss: 0.15187  | 0.18\n",
      "[epoch: 4, batch:   2642] loss: 0.10813  | 0.18\n",
      "[epoch: 4, batch:   2644] loss: 0.95606  | 0.18\n",
      "[epoch: 4, batch:   2646] loss: 0.43971  | 0.19\n",
      "[epoch: 4, batch:   2648] loss: 0.05282  | 0.18\n",
      "[epoch: 4, batch:   2650] loss: 0.12658  | 0.18\n",
      "[epoch: 4, batch:   2652] loss: 0.15472  | 0.18\n",
      "[epoch: 4, batch:   2654] loss: 0.05618  | 0.18\n",
      "[epoch: 4, batch:   2656] loss: 0.01573  | 0.18\n",
      "[epoch: 4, batch:   2658] loss: 0.08834  | 0.18\n",
      "[epoch: 4, batch:   2660] loss: 0.26210  | 0.18\n",
      "[epoch: 4, batch:   2662] loss: 0.99390  | 0.19\n",
      "[epoch: 4, batch:   2664] loss: 0.48904  | 0.18\n",
      "[epoch: 4, batch:   2666] loss: 0.26106  | 0.18\n",
      "[epoch: 4, batch:   2668] loss: 0.30304  | 0.18\n",
      "[epoch: 4, batch:   2670] loss: 0.11688  | 0.18\n",
      "[epoch: 4, batch:   2672] loss: 0.18237  | 0.18\n",
      "[epoch: 4, batch:   2674] loss: 0.25976  | 0.18\n",
      "[epoch: 4, batch:   2676] loss: 0.64986  | 0.18\n",
      "[epoch: 4, batch:   2678] loss: 0.06406  | 0.18\n",
      "[epoch: 4, batch:   2680] loss: 0.05757  | 0.18\n",
      "[epoch: 4, batch:   2682] loss: 0.14806  | 0.18\n",
      "[epoch: 4, batch:   2684] loss: 0.16329  | 0.18\n",
      "[epoch: 4, batch:   2686] loss: 0.46375  | 0.18\n",
      "[epoch: 4, batch:   2688] loss: 0.21828  | 0.18\n",
      "[epoch: 4, batch:   2690] loss: 0.03891  | 0.18\n",
      "[epoch: 4, batch:   2692] loss: 0.11159  | 0.18\n",
      "[epoch: 4, batch:   2694] loss: 0.18972  | 0.18\n",
      "[epoch: 4, batch:   2696] loss: 0.25841  | 0.20\n",
      "[epoch: 4, batch:   2698] loss: 0.17039  | 0.18\n",
      "[epoch: 4, batch:   2700] loss: 0.07851  | 0.18\n",
      "[epoch: 4, batch:   2702] loss: 0.40463  | 0.17\n",
      "[epoch: 4, batch:   2704] loss: 0.79648  | 0.18\n",
      "[epoch: 4, batch:   2706] loss: 0.16322  | 0.17\n",
      "[epoch: 4, batch:   2708] loss: 0.31715  | 0.19\n",
      "[epoch: 4, batch:   2710] loss: 0.49782  | 0.18\n",
      "[epoch: 4, batch:   2712] loss: 0.03413  | 0.18\n",
      "[epoch: 4, batch:   2714] loss: 0.02648  | 0.18\n",
      "[epoch: 4, batch:   2716] loss: 0.56982  | 0.18\n",
      "[epoch: 4, batch:   2718] loss: 0.20979  | 0.18\n",
      "[epoch: 4, batch:   2720] loss: 0.43768  | 0.18\n",
      "[epoch: 4, batch:   2722] loss: 0.62280  | 0.18\n",
      "[epoch: 4, batch:   2724] loss: 0.21606  | 0.19\n",
      "[epoch: 4, batch:   2726] loss: 0.10957  | 0.18\n",
      "[epoch: 4, batch:   2728] loss: 0.10093  | 0.18\n",
      "[epoch: 4, batch:   2730] loss: 0.14512  | 0.19\n",
      "[epoch: 4, batch:   2732] loss: 0.03675  | 0.19\n",
      "[epoch: 4, batch:   2734] loss: 0.03371  | 0.17\n",
      "[epoch: 4, batch:   2736] loss: 0.11807  | 0.18\n",
      "[epoch: 4, batch:   2738] loss: 0.47426  | 0.18\n",
      "[epoch: 4, batch:   2740] loss: 0.13957  | 0.18\n",
      "[epoch: 4, batch:   2742] loss: 0.05953  | 0.17\n",
      "[epoch: 4, batch:   2744] loss: 0.48052  | 0.18\n",
      "[epoch: 4, batch:   2746] loss: 0.02384  | 0.18\n",
      "[epoch: 4, batch:   2748] loss: 0.03198  | 0.18\n",
      "[epoch: 4, batch:   2750] loss: 0.10083  | 0.18\n",
      "[epoch: 4, batch:   2752] loss: 0.31130  | 0.18\n",
      "[epoch: 4, batch:   2754] loss: 0.17769  | 0.19\n",
      "[epoch: 4, batch:   2756] loss: 0.56725  | 0.18\n",
      "[epoch: 4, batch:   2758] loss: 0.09663  | 0.17\n",
      "[epoch: 4, batch:   2760] loss: 0.07128  | 0.18\n",
      "[epoch: 4, batch:   2762] loss: 0.49535  | 0.18\n",
      "[epoch: 4, batch:   2764] loss: 0.13290  | 0.19\n",
      "[epoch: 4, batch:   2766] loss: 0.14970  | 0.18\n",
      "[epoch: 4, batch:   2768] loss: 0.15042  | 0.18\n",
      "[epoch: 4, batch:   2770] loss: 0.43130  | 0.18\n",
      "[epoch: 4, batch:   2772] loss: 0.12872  | 0.18\n",
      "[epoch: 4, batch:   2774] loss: 0.25851  | 0.18\n",
      "[epoch: 4, batch:   2776] loss: 0.26803  | 0.18\n",
      "[epoch: 4, batch:   2778] loss: 0.13684  | 0.18\n",
      "[epoch: 4, batch:   2780] loss: 0.05023  | 0.18\n",
      "[epoch: 4, batch:   2782] loss: 0.10454  | 0.18\n",
      "[epoch: 4, batch:   2784] loss: 0.92259  | 0.20\n",
      "[epoch: 4, batch:   2786] loss: 0.09800  | 0.18\n",
      "[epoch: 4, batch:   2788] loss: 0.10975  | 0.18\n",
      "[epoch: 4, batch:   2790] loss: 0.14865  | 0.18\n",
      "[epoch: 4, batch:   2792] loss: 0.04904  | 0.18\n",
      "[epoch: 4, batch:   2794] loss: 0.29514  | 0.18\n",
      "[epoch: 4, batch:   2796] loss: 0.12836  | 0.18\n",
      "[epoch: 4, batch:   2798] loss: 0.09899  | 0.18\n",
      "[epoch: 4, batch:   2800] loss: 0.06617  | 0.18\n",
      "[epoch: 4, batch:   2802] loss: 0.33552  | 0.18\n",
      "[epoch: 4, batch:   2804] loss: 1.09183  | 0.18\n",
      "[epoch: 4, batch:   2806] loss: 0.38610  | 0.18\n",
      "[epoch: 4, batch:   2808] loss: 0.60091  | 0.18\n",
      "[epoch: 4, batch:   2810] loss: 0.46657  | 0.19\n",
      "[epoch: 4, batch:   2812] loss: 0.18256  | 0.18\n",
      "[epoch: 4, batch:   2814] loss: 0.03076  | 0.18\n",
      "[epoch: 4, batch:   2816] loss: 0.06256  | 0.18\n",
      "[epoch: 4, batch:   2818] loss: 0.11008  | 0.18\n",
      "[epoch: 4, batch:   2820] loss: 0.38823  | 0.18\n",
      "[epoch: 4, batch:   2822] loss: 0.04475  | 0.18\n",
      "[epoch: 4, batch:   2824] loss: 0.07111  | 0.18\n",
      "[epoch: 4, batch:   2826] loss: 0.24595  | 0.18\n",
      "[epoch: 4, batch:   2828] loss: 0.04997  | 0.19\n",
      "[epoch: 4, batch:   2830] loss: 0.05805  | 0.17\n",
      "[epoch: 4, batch:   2832] loss: 0.10543  | 0.18\n",
      "[epoch: 4, batch:   2834] loss: 0.48616  | 0.18\n",
      "[epoch: 4, batch:   2836] loss: 0.11234  | 0.18\n",
      "[epoch: 4, batch:   2838] loss: 0.37723  | 0.18\n",
      "[epoch: 4, batch:   2840] loss: 0.13176  | 0.18\n",
      "[epoch: 4, batch:   2842] loss: 0.21017  | 0.18\n",
      "[epoch: 4, batch:   2844] loss: 0.33411  | 0.18\n",
      "[epoch: 4, batch:   2846] loss: 0.04566  | 0.25\n",
      "[epoch: 4, batch:   2848] loss: 0.12081  | 0.37\n",
      "[epoch: 4, batch:   2850] loss: 0.46702  | 0.18\n",
      "[epoch: 4, batch:   2852] loss: 0.12902  | 0.18\n",
      "[epoch: 4, batch:   2854] loss: 0.25205  | 0.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4, batch:   2856] loss: 0.37501  | 0.19\n",
      "[epoch: 4, batch:   2858] loss: 0.24279  | 0.18\n",
      "[epoch: 4, batch:   2860] loss: 0.08190  | 0.18\n",
      "[epoch: 4, batch:   2862] loss: 0.38108  | 0.17\n",
      "[epoch: 4, batch:   2864] loss: 0.06211  | 0.18\n",
      "[epoch: 4, batch:   2866] loss: 0.15888  | 0.18\n",
      "[epoch: 4, batch:   2868] loss: 0.22492  | 0.19\n",
      "[epoch: 4, batch:   2870] loss: 0.30587  | 0.17\n",
      "[epoch: 4, batch:   2872] loss: 0.03420  | 0.18\n",
      "[epoch: 4, batch:   2874] loss: 0.05145  | 0.20\n",
      "[epoch: 4, batch:   2876] loss: 0.24335  | 0.18\n",
      "[epoch: 4, batch:   2878] loss: 0.03900  | 0.18\n",
      "[epoch: 4, batch:   2880] loss: 0.01788  | 0.18\n",
      "[epoch: 4, batch:   2882] loss: 0.03123  | 0.18\n",
      "[epoch: 4, batch:   2884] loss: 0.06432  | 0.18\n",
      "[epoch: 4, batch:   2886] loss: 0.11758  | 0.18\n",
      "[epoch: 4, batch:   2888] loss: 0.94106  | 0.19\n",
      "[epoch: 4, batch:   2890] loss: 0.45262  | 0.18\n",
      "[epoch: 4, batch:   2892] loss: 0.23062  | 0.18\n",
      "[epoch: 4, batch:   2894] loss: 0.06260  | 0.18\n",
      "[epoch: 4, batch:   2896] loss: 0.02704  | 0.20\n",
      "[epoch: 4, batch:   2898] loss: 0.55793  | 0.18\n",
      "[epoch: 4, batch:   2900] loss: 0.11038  | 0.18\n",
      "[epoch: 4, batch:   2902] loss: 0.07054  | 0.17\n",
      "[epoch: 4, batch:   2904] loss: 0.11466  | 0.19\n",
      "[epoch: 4, batch:   2906] loss: 0.40276  | 0.18\n",
      "[epoch: 4, batch:   2908] loss: 0.01805  | 0.18\n",
      "[epoch: 4, batch:   2910] loss: 0.30351  | 0.18\n",
      "[epoch: 4, batch:   2912] loss: 0.18522  | 0.18\n",
      "[epoch: 4, batch:   2914] loss: 0.02932  | 0.19\n",
      "[epoch: 4, batch:   2916] loss: 0.28959  | 0.18\n",
      "[epoch: 4, batch:   2918] loss: 0.16104  | 0.17\n",
      "[epoch: 4, batch:   2920] loss: 0.28909  | 0.18\n",
      "[epoch: 4, batch:   2922] loss: 0.07401  | 0.19\n",
      "[epoch: 4, batch:   2924] loss: 0.06398  | 0.18\n",
      "[epoch: 4, batch:   2926] loss: 0.10293  | 0.18\n",
      "[epoch: 4, batch:   2928] loss: 0.20409  | 0.18\n",
      "[epoch: 4, batch:   2930] loss: 0.12701  | 0.19\n",
      "[epoch: 4, batch:   2932] loss: 1.12025  | 0.18\n",
      "[epoch: 4, batch:   2934] loss: 0.10996  | 0.18\n",
      "[epoch: 4, batch:   2936] loss: 0.08222  | 0.18\n",
      "[epoch: 4, batch:   2938] loss: 0.13585  | 0.19\n",
      "[epoch: 4, batch:   2940] loss: 0.09344  | 0.18\n",
      "[epoch: 4, batch:   2942] loss: 0.18064  | 0.17\n",
      "[epoch: 4, batch:   2944] loss: 0.09177  | 0.18\n",
      "[epoch: 4, batch:   2946] loss: 0.10701  | 0.19\n",
      "[epoch: 4, batch:   2948] loss: 0.03316  | 0.18\n",
      "[epoch: 4, batch:   2950] loss: 0.05900  | 0.18\n",
      "[epoch: 4, batch:   2952] loss: 0.34973  | 0.18\n",
      "[epoch: 4, batch:   2954] loss: 0.21008  | 0.18\n",
      "[epoch: 4, batch:   2956] loss: 0.33645  | 0.18\n",
      "[epoch: 4, batch:   2958] loss: 0.03201  | 0.19\n",
      "[epoch: 4, batch:   2960] loss: 0.98159  | 0.18\n",
      "[epoch: 4, batch:   2962] loss: 0.02689  | 0.18\n",
      "[epoch: 4, batch:   2964] loss: 0.15534  | 0.18\n",
      "[epoch: 4, batch:   2966] loss: 0.04754  | 0.19\n",
      "[epoch: 4, batch:   2968] loss: 0.08549  | 0.18\n",
      "[epoch: 4, batch:   2970] loss: 0.46181  | 0.17\n",
      "[epoch: 4, batch:   2972] loss: 0.20494  | 0.18\n",
      "[epoch: 4, batch:   2974] loss: 0.07526  | 0.18\n",
      "[epoch: 4, batch:   2976] loss: 0.11602  | 0.19\n",
      "[epoch: 4, batch:   2978] loss: 0.67543  | 0.17\n",
      "[epoch: 4, batch:   2980] loss: 0.12952  | 0.18\n",
      "[epoch: 4, batch:   2982] loss: 0.62325  | 0.18\n",
      "[epoch: 4, batch:   2984] loss: 0.01232  | 0.19\n",
      "[epoch: 4, batch:   2986] loss: 1.11892  | 0.51\n",
      "[epoch: 4, batch:   2988] loss: 0.14275  | 0.17\n",
      "[epoch: 4, batch:   2990] loss: 0.10257  | 0.18\n",
      "[epoch: 4, batch:   2992] loss: 0.17273  | 0.18\n",
      "[epoch: 4, batch:   2994] loss: 0.07201  | 0.18\n",
      "[epoch: 4, batch:   2996] loss: 0.31358  | 0.17\n",
      "[epoch: 4, batch:   2998] loss: 0.41345  | 0.17\n",
      "[epoch: 4, batch:   3000] loss: 0.06915  | 0.18\n",
      "[epoch: 4, batch:   3002] loss: 0.04594  | 0.19\n",
      "[epoch: 4, batch:   3004] loss: 0.17765  | 0.18\n",
      "[epoch: 4, batch:   3006] loss: 0.03997  | 0.17\n",
      "[epoch: 4, batch:   3008] loss: 0.05861  | 0.17\n",
      "[epoch: 4, batch:   3010] loss: 0.11447  | 0.20\n",
      "[epoch: 4, batch:   3012] loss: 0.10312  | 0.18\n",
      "[epoch: 4, batch:   3014] loss: 0.09889  | 0.18\n",
      "[epoch: 4, batch:   3016] loss: 0.12076  | 0.17\n",
      "[epoch: 4, batch:   3018] loss: 0.59038  | 0.18\n",
      "[epoch: 4, batch:   3020] loss: 0.05238  | 0.18\n",
      "[epoch: 4, batch:   3022] loss: 0.06289  | 0.18\n",
      "[epoch: 4, batch:   3024] loss: 0.35788  | 0.18\n",
      "[epoch: 4, batch:   3026] loss: 0.42222  | 1.05\n",
      "[epoch: 4, batch:   3028] loss: 0.77102  | 0.17\n",
      "[epoch: 4, batch:   3030] loss: 0.18059  | 0.17\n",
      "[epoch: 4, batch:   3032] loss: 0.21281  | 0.18\n",
      "[epoch: 4, batch:   3034] loss: 0.03318  | 0.18\n",
      "[epoch: 4, batch:   3036] loss: 0.10855  | 0.17\n",
      "[epoch: 4, batch:   3038] loss: 0.40059  | 0.17\n",
      "[epoch: 4, batch:   3040] loss: 0.15564  | 0.18\n",
      "[epoch: 4, batch:   3042] loss: 0.05925  | 0.18\n",
      "[epoch: 4, batch:   3044] loss: 0.23108  | 0.18\n",
      "[epoch: 4, batch:   3046] loss: 0.74777  | 0.18\n",
      "[epoch: 4, batch:   3048] loss: 0.42951  | 0.18\n",
      "[epoch: 4, batch:   3050] loss: 0.26450  | 0.19\n",
      "[epoch: 4, batch:   3052] loss: 0.23688  | 0.17\n",
      "[epoch: 4, batch:   3054] loss: 0.90498  | 0.18\n",
      "[epoch: 4, batch:   3056] loss: 0.05803  | 0.18\n",
      "[epoch: 4, batch:   3058] loss: 0.46958  | 0.18\n",
      "[epoch: 4, batch:   3060] loss: 0.15754  | 0.18\n",
      "[epoch: 4, batch:   3062] loss: 0.19660  | 0.18\n",
      "[epoch: 4, batch:   3064] loss: 0.21610  | 0.18\n",
      "[epoch: 4, batch:   3066] loss: 0.10366  | 0.18\n",
      "[epoch: 4, batch:   3068] loss: 0.29450  | 0.18\n",
      "[epoch: 4, batch:   3070] loss: 0.10965  | 0.19\n",
      "[epoch: 4, batch:   3072] loss: 0.20155  | 0.17\n",
      "[epoch: 4, batch:   3074] loss: 0.28037  | 0.52\n",
      "[epoch: 4, batch:   3076] loss: 0.29121  | 0.18\n",
      "[epoch: 4, batch:   3078] loss: 0.25644  | 0.18\n",
      "[epoch: 4, batch:   3080] loss: 0.10174  | 0.17\n",
      "[epoch: 4, batch:   3082] loss: 0.05493  | 0.18\n",
      "[epoch: 4, batch:   3084] loss: 0.11512  | 0.18\n",
      "[epoch: 4, batch:   3086] loss: 0.08226  | 0.17\n",
      "[epoch: 4, batch:   3088] loss: 0.02343  | 0.17\n",
      "[epoch: 4, batch:   3090] loss: 0.20760  | 0.18\n",
      "[epoch: 4, batch:   3092] loss: 0.03294  | 0.18\n",
      "[epoch: 4, batch:   3094] loss: 0.09708  | 0.17\n",
      "[epoch: 4, batch:   3096] loss: 0.12728  | 0.18\n",
      "[epoch: 4, batch:   3098] loss: 0.10613  | 0.33\n",
      "[epoch: 4, batch:   3100] loss: 0.44502  | 0.17\n",
      "[epoch: 4, batch:   3102] loss: 0.07571  | 0.18\n",
      "[epoch: 4, batch:   3104] loss: 0.16739  | 0.18\n",
      "[epoch: 4, batch:   3106] loss: 0.40914  | 0.18\n",
      "[epoch: 4, batch:   3108] loss: 0.10429  | 0.17\n",
      "[epoch: 4, batch:   3110] loss: 1.24542  | 0.18\n",
      "[epoch: 4, batch:   3112] loss: 0.17347  | 0.18\n",
      "[epoch: 4, batch:   3114] loss: 0.64930  | 0.18\n",
      "[epoch: 4, batch:   3116] loss: 0.40833  | 0.20\n",
      "[epoch: 4, batch:   3118] loss: 0.11597  | 0.18\n",
      "[epoch: 4, batch:   3120] loss: 0.08618  | 0.18\n",
      "[epoch: 4, batch:   3122] loss: 0.08081  | 0.17\n",
      "[epoch: 4, batch:   3124] loss: 0.11403  | 0.18\n",
      "[epoch: 4, batch:   3126] loss: 0.05067  | 0.17\n",
      "[epoch: 4, batch:   3128] loss: 0.05793  | 0.17\n",
      "[epoch: 4, batch:   3130] loss: 0.06792  | 0.18\n",
      "[epoch: 4, batch:   3132] loss: 0.70280  | 0.18\n",
      "[epoch: 4, batch:   3134] loss: 0.25086  | 0.17\n",
      "[epoch: 4, batch:   3136] loss: 0.03877  | 0.37\n",
      "[epoch: 4, batch:   3138] loss: 0.75022  | 0.18\n",
      "[epoch: 4, batch:   3140] loss: 0.05214  | 0.17\n",
      "[epoch: 4, batch:   3142] loss: 0.15473  | 0.18\n",
      "[epoch: 4, batch:   3144] loss: 0.14150  | 0.18\n",
      "[epoch: 4, batch:   3146] loss: 0.15619  | 0.18\n",
      "[epoch: 4, batch:   3148] loss: 0.21422  | 0.60\n",
      "[epoch: 4, batch:   3150] loss: 0.33655  | 0.17\n",
      "[epoch: 4, batch:   3152] loss: 1.13551  | 0.18\n",
      "[epoch: 4, batch:   3154] loss: 0.06384  | 0.18\n",
      "[epoch: 4, batch:   3156] loss: 0.33716  | 0.18\n",
      "[epoch: 4, batch:   3158] loss: 0.12857  | 0.17\n",
      "[epoch: 4, batch:   3160] loss: 0.06240  | 0.18\n",
      "[epoch: 4, batch:   3162] loss: 0.03771  | 0.18\n",
      "[epoch: 4, batch:   3164] loss: 0.19338  | 0.18\n",
      "[epoch: 4, batch:   3166] loss: 0.76527  | 0.18\n",
      "[epoch: 4, batch:   3168] loss: 0.17168  | 0.18\n",
      "[epoch: 4, batch:   3170] loss: 0.15836  | 0.18\n",
      "[epoch: 4, batch:   3172] loss: 0.08144  | 0.18\n",
      "[epoch: 4, batch:   3174] loss: 0.07749  | 0.17\n",
      "[epoch: 4, batch:   3176] loss: 0.15290  | 0.19\n",
      "[epoch: 4, batch:   3178] loss: 0.07031  | 0.18\n",
      "[epoch: 4, batch:   3180] loss: 0.41697  | 0.18\n",
      "[epoch: 4, batch:   3182] loss: 0.48401  | 0.59\n",
      "[epoch: 4, batch:   3184] loss: 0.20504  | 0.20\n",
      "[epoch: 4, batch:   3186] loss: 0.02016  | 0.18\n",
      "[epoch: 4, batch:   3188] loss: 0.15944  | 0.18\n",
      "[epoch: 4, batch:   3190] loss: 0.04174  | 0.17\n",
      "[epoch: 4, batch:   3192] loss: 1.36880  | 0.18\n",
      "[epoch: 4, batch:   3194] loss: 0.40548  | 0.18\n",
      "[epoch: 4, batch:   3196] loss: 0.03644  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4, batch:   3198] loss: 0.04461  | 0.18\n",
      "[epoch: 4, batch:   3200] loss: 0.05765  | 0.18\n",
      "[epoch: 4, batch:   3202] loss: 0.28261  | 0.18\n",
      "[epoch: 4, batch:   3204] loss: 0.78544  | 0.18\n",
      "[epoch: 4, batch:   3206] loss: 0.36025  | 0.18\n",
      "[epoch: 4, batch:   3208] loss: 0.02701  | 0.18\n",
      "[epoch: 4, batch:   3210] loss: 0.10982  | 0.20\n",
      "[epoch: 4, batch:   3212] loss: 0.07998  | 0.17\n",
      "[epoch: 4, batch:   3214] loss: 0.20838  | 0.18\n",
      "[epoch: 4, batch:   3216] loss: 0.44833  | 0.18\n",
      "[epoch: 4, batch:   3218] loss: 0.09583  | 0.18\n",
      "[epoch: 4, batch:   3220] loss: 0.04435  | 0.17\n",
      "[epoch: 4, batch:   3222] loss: 0.13427  | 0.18\n",
      "[epoch: 4, batch:   3224] loss: 0.26770  | 0.18\n",
      "[epoch: 4, batch:   3226] loss: 0.03890  | 0.18\n",
      "[epoch: 4, batch:   3228] loss: 0.27232  | 0.18\n",
      "[epoch: 4, batch:   3230] loss: 0.09846  | 0.18\n",
      "[epoch: 4, batch:   3232] loss: 0.05221  | 0.18\n",
      "[epoch: 4, batch:   3234] loss: 0.24281  | 0.18\n",
      "[epoch: 4, batch:   3236] loss: 0.29174  | 0.18\n",
      "[epoch: 4, batch:   3238] loss: 0.22418  | 0.18\n",
      "[epoch: 4, batch:   3240] loss: 0.01698  | 0.18\n",
      "[epoch: 4, batch:   3242] loss: 0.25031  | 0.18\n",
      "[epoch: 4, batch:   3244] loss: 0.20047  | 0.19\n",
      "[epoch: 4, batch:   3246] loss: 0.17696  | 0.18\n",
      "[epoch: 4, batch:   3248] loss: 0.03019  | 0.49\n",
      "[epoch: 4, batch:   3250] loss: 0.19597  | 0.18\n",
      "[epoch: 4, batch:   3252] loss: 0.06514  | 0.18\n",
      "[epoch: 4, batch:   3254] loss: 0.68097  | 0.18\n",
      "[epoch: 4, batch:   3256] loss: 0.19698  | 0.19\n",
      "[epoch: 4, batch:   3258] loss: 0.03358  | 0.17\n",
      "[epoch: 4, batch:   3260] loss: 0.04538  | 0.18\n",
      "[epoch: 4, batch:   3262] loss: 0.08841  | 0.18\n",
      "[epoch: 4, batch:   3264] loss: 0.16138  | 0.19\n",
      "[epoch: 4, batch:   3266] loss: 0.17604  | 0.18\n",
      "[epoch: 4, batch:   3268] loss: 0.05686  | 0.18\n",
      "[epoch: 4, batch:   3270] loss: 0.20728  | 0.19\n",
      "[epoch: 4, batch:   3272] loss: 0.13012  | 0.18\n",
      "[epoch: 4, batch:   3274] loss: 0.03965  | 0.18\n",
      "[epoch: 4, batch:   3276] loss: 0.09546  | 0.18\n",
      "[epoch: 4, batch:   3278] loss: 0.01950  | 0.19\n",
      "[epoch: 4, batch:   3280] loss: 0.14040  | 0.18\n",
      "[epoch: 4, batch:   3282] loss: 0.01654  | 0.18\n",
      "[epoch: 4, batch:   3284] loss: 0.54138  | 0.18\n",
      "[epoch: 4, batch:   3286] loss: 0.09674  | 0.18\n",
      "[epoch: 4, batch:   3288] loss: 0.43433  | 0.19\n",
      "[epoch: 4, batch:   3290] loss: 0.57055  | 0.22\n",
      "[epoch: 4, batch:   3292] loss: 0.10951  | 0.17\n",
      "[epoch: 4, batch:   3294] loss: 0.19598  | 0.18\n",
      "[epoch: 4, batch:   3296] loss: 0.61233  | 0.19\n",
      "[epoch: 4, batch:   3298] loss: 0.29913  | 0.18\n",
      "[epoch: 4, batch:   3300] loss: 0.15336  | 0.17\n",
      "[epoch: 4, batch:   3302] loss: 0.14505  | 0.18\n",
      "[epoch: 4, batch:   3304] loss: 0.01428  | 0.18\n",
      "[epoch: 4, batch:   3306] loss: 0.02493  | 0.18\n",
      "[epoch: 4, batch:   3308] loss: 0.10262  | 0.19\n",
      "[epoch: 4, batch:   3310] loss: 0.27469  | 0.18\n",
      "[epoch: 4, batch:   3312] loss: 0.29320  | 0.17\n",
      "[epoch: 4, batch:   3314] loss: 0.09809  | 0.18\n",
      "[epoch: 4, batch:   3316] loss: 0.13930  | 0.19\n",
      "[epoch: 4, batch:   3318] loss: 0.04721  | 0.18\n",
      "[epoch: 4, batch:   3320] loss: 0.54946  | 0.18\n",
      "[epoch: 4, batch:   3322] loss: 0.20878  | 0.18\n",
      "[epoch: 4, batch:   3324] loss: 0.55293  | 0.18\n",
      "[epoch: 4, batch:   3326] loss: 0.05223  | 0.19\n",
      "[epoch: 4, batch:   3328] loss: 0.03547  | 0.18\n",
      "[epoch: 4, batch:   3330] loss: 0.37339  | 0.17\n",
      "[epoch: 4, batch:   3332] loss: 0.12534  | 0.18\n",
      "[epoch: 4, batch:   3334] loss: 0.10084  | 0.19\n",
      "[epoch: 4, batch:   3336] loss: 0.14232  | 0.18\n",
      "[epoch: 4, batch:   3338] loss: 0.11220  | 0.18\n",
      "[epoch: 4, batch:   3340] loss: 0.05398  | 0.18\n",
      "[epoch: 4, batch:   3342] loss: 0.08253  | 0.19\n",
      "[epoch: 4, batch:   3344] loss: 0.20830  | 0.18\n",
      "[epoch: 4, batch:   3346] loss: 0.12561  | 0.18\n",
      "[epoch: 4, batch:   3348] loss: 0.34730  | 0.18\n",
      "[epoch: 4, batch:   3350] loss: 0.08912  | 0.18\n",
      "[epoch: 4, batch:   3352] loss: 0.03995  | 0.18\n",
      "[epoch: 4, batch:   3354] loss: 0.14879  | 0.18\n",
      "[epoch: 4, batch:   3356] loss: 0.29149  | 0.18\n",
      "[epoch: 4, batch:   3358] loss: 0.06409  | 0.19\n",
      "[epoch: 4, batch:   3360] loss: 0.08734  | 0.23\n",
      "[epoch: 4, batch:   3362] loss: 0.05112  | 0.18\n",
      "[epoch: 4, batch:   3364] loss: 0.52917  | 0.18\n",
      "[epoch: 4, batch:   3366] loss: 0.04451  | 0.19\n",
      "[epoch: 4, batch:   3368] loss: 0.15519  | 0.71\n",
      "[epoch: 4, batch:   3370] loss: 0.32977  | 0.18\n",
      "[epoch: 4, batch:   3372] loss: 0.01435  | 0.18\n",
      "[epoch: 4, batch:   3374] loss: 0.01052  | 0.18\n",
      "[epoch: 4, batch:   3376] loss: 0.06410  | 0.18\n",
      "[epoch: 4, batch:   3378] loss: 0.13036  | 0.18\n",
      "[epoch: 4, batch:   3380] loss: 0.14357  | 0.18\n",
      "[epoch: 4, batch:   3382] loss: 0.03951  | 0.19\n",
      "[epoch: 4, batch:   3384] loss: 0.01373  | 0.19\n",
      "[epoch: 4, batch:   3386] loss: 0.06079  | 0.17\n",
      "[epoch: 4, batch:   3388] loss: 0.13591  | 0.18\n",
      "[epoch: 4, batch:   3390] loss: 0.04277  | 0.18\n",
      "[epoch: 4, batch:   3392] loss: 0.11466  | 0.23\n",
      "[epoch: 4, batch:   3394] loss: 0.02720  | 0.18\n",
      "[epoch: 4, batch:   3396] loss: 0.64235  | 0.18\n",
      "[epoch: 4, batch:   3398] loss: 0.05832  | 0.17\n",
      "[epoch: 4, batch:   3400] loss: 0.03197  | 0.19\n",
      "[epoch: 4, batch:   3402] loss: 0.03921  | 0.41\n",
      "[epoch: 4, batch:   3404] loss: 0.34122  | 0.17\n",
      "[epoch: 4, batch:   3406] loss: 0.69179  | 0.18\n",
      "[epoch: 4, batch:   3408] loss: 0.13226  | 0.18\n",
      "[epoch: 4, batch:   3410] loss: 0.40499  | 0.19\n",
      "[epoch: 4, batch:   3412] loss: 0.14186  | 0.17\n",
      "[epoch: 4, batch:   3414] loss: 0.21238  | 0.18\n",
      "[epoch: 4, batch:   3416] loss: 0.19203  | 0.18\n",
      "[epoch: 4, batch:   3418] loss: 0.68169  | 0.19\n",
      "[epoch: 4, batch:   3420] loss: 0.35292  | 0.18\n",
      "[epoch: 4, batch:   3422] loss: 0.14973  | 0.18\n",
      "[epoch: 4, batch:   3424] loss: 0.17984  | 0.18\n",
      "[epoch: 4, batch:   3426] loss: 0.05037  | 0.19\n",
      "[epoch: 4, batch:   3428] loss: 0.03831  | 0.17\n",
      "[epoch: 4, batch:   3430] loss: 0.12710  | 0.18\n",
      "[epoch: 4, batch:   3432] loss: 0.17361  | 0.18\n",
      "[epoch: 4, batch:   3434] loss: 0.06911  | 1.35\n",
      "[epoch: 4, batch:   3436] loss: 0.10677  | 0.17\n",
      "[epoch: 4, batch:   3438] loss: 0.03866  | 0.18\n",
      "[epoch: 4, batch:   3440] loss: 0.11463  | 0.18\n",
      "[epoch: 4, batch:   3442] loss: 0.19511  | 0.18\n",
      "[epoch: 4, batch:   3444] loss: 0.18113  | 0.18\n",
      "[epoch: 4, batch:   3446] loss: 0.07392  | 0.18\n",
      "[epoch: 4, batch:   3448] loss: 0.28470  | 0.18\n",
      "[epoch: 4, batch:   3450] loss: 0.36779  | 0.18\n",
      "[epoch: 4, batch:   3452] loss: 0.06215  | 0.18\n",
      "[epoch: 4, batch:   3454] loss: 0.22178  | 0.18\n",
      "[epoch: 4, batch:   3456] loss: 0.11529  | 0.18\n",
      "[epoch: 4, batch:   3458] loss: 0.14997  | 0.18\n",
      "[epoch: 4, batch:   3460] loss: 0.08764  | 0.18\n",
      "[epoch: 4, batch:   3462] loss: 0.14693  | 0.18\n",
      "[epoch: 4, batch:   3464] loss: 0.12799  | 0.18\n",
      "[epoch: 4, batch:   3466] loss: 0.36619  | 0.18\n",
      "[epoch: 4, batch:   3468] loss: 0.37637  | 0.18\n",
      "[epoch: 4, batch:   3470] loss: 0.13376  | 0.19\n",
      "[epoch: 4, batch:   3472] loss: 0.15524  | 0.17\n",
      "[epoch: 4, batch:   3474] loss: 0.35010  | 0.18\n",
      "[epoch: 4, batch:   3476] loss: 0.24151  | 0.18\n",
      "[epoch: 4, batch:   3478] loss: 0.14252  | 0.20\n",
      "[epoch: 4, batch:   3480] loss: 0.08468  | 0.17\n",
      "[epoch: 4, batch:   3482] loss: 0.63064  | 0.18\n",
      "[epoch: 4, batch:   3484] loss: 0.02489  | 0.18\n",
      "[epoch: 4, batch:   3486] loss: 0.04391  | 0.19\n",
      "[epoch: 4, batch:   3488] loss: 0.06054  | 0.17\n",
      "[epoch: 4, batch:   3490] loss: 0.24050  | 0.19\n",
      "[epoch: 4, batch:   3492] loss: 0.19250  | 0.17\n",
      "[epoch: 4, batch:   3494] loss: 0.69195  | 0.18\n",
      "[epoch: 4, batch:   3496] loss: 1.51827  | 0.18\n",
      "[epoch: 4, batch:   3498] loss: 0.04583  | 0.18\n",
      "[epoch: 4, batch:   3500] loss: 0.97385  | 0.19\n",
      "[epoch: 4, batch:   3502] loss: 0.08945  | 0.18\n",
      "[epoch: 4, batch:   3504] loss: 0.07682  | 0.18\n",
      "[epoch: 4, batch:   3506] loss: 0.35215  | 0.18\n",
      "[epoch: 4, batch:   3508] loss: 0.34557  | 0.18\n",
      "[epoch: 4, batch:   3510] loss: 0.16473  | 0.18\n",
      "[epoch: 4, batch:   3512] loss: 0.15075  | 0.18\n",
      "[epoch: 4, batch:   3514] loss: 0.03440  | 0.18\n",
      "[epoch: 4, batch:   3516] loss: 0.12887  | 0.18\n",
      "[epoch: 4, batch:   3518] loss: 0.02581  | 0.18\n",
      "[epoch: 4, batch:   3520] loss: 0.02997  | 0.18\n",
      "[epoch: 4, batch:   3522] loss: 0.31816  | 0.19\n",
      "[epoch: 4, batch:   3524] loss: 0.10144  | 0.18\n",
      "[epoch: 4, batch:   3526] loss: 0.10510  | 0.18\n",
      "[epoch: 4, batch:   3528] loss: 0.05014  | 0.18\n",
      "[epoch: 4, batch:   3530] loss: 0.17301  | 0.18\n",
      "[epoch: 4, batch:   3532] loss: 0.31344  | 0.18\n",
      "[epoch: 4, batch:   3534] loss: 0.22392  | 0.18\n",
      "[epoch: 4, batch:   3536] loss: 0.07447  | 0.18\n",
      "[epoch: 4, batch:   3538] loss: 0.18985  | 0.18\n",
      "[epoch: 4, batch:   3540] loss: 0.15978  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4, batch:   3542] loss: 0.32111  | 0.18\n",
      "[epoch: 4, batch:   3544] loss: 0.15488  | 0.18\n",
      "[epoch: 4, batch:   3546] loss: 0.11457  | 0.18\n",
      "[epoch: 4, batch:   3548] loss: 0.17598  | 0.18\n",
      "[epoch: 4, batch:   3550] loss: 0.04194  | 0.18\n",
      "[epoch: 4, batch:   3552] loss: 0.16441  | 0.18\n",
      "[epoch: 4, batch:   3554] loss: 0.37082  | 0.18\n",
      "[epoch: 4, batch:   3556] loss: 0.02594  | 0.18\n",
      "[epoch: 4, batch:   3558] loss: 0.79043  | 0.18\n",
      "[epoch: 4, batch:   3560] loss: 0.74208  | 0.18\n",
      "[epoch: 4, batch:   3562] loss: 0.08322  | 0.19\n",
      "[epoch: 4, batch:   3564] loss: 0.09577  | 0.18\n",
      "[epoch: 4, batch:   3566] loss: 0.07875  | 0.18\n",
      "[epoch: 4, batch:   3568] loss: 0.03016  | 0.18\n",
      "[epoch: 4, batch:   3570] loss: 0.25501  | 0.18\n",
      "[epoch: 4, batch:   3572] loss: 0.44735  | 0.18\n",
      "[epoch: 4, batch:   3574] loss: 0.07799  | 0.18\n",
      "[epoch: 4, batch:   3576] loss: 0.03706  | 0.18\n",
      "[epoch: 4, batch:   3578] loss: 0.76420  | 0.18\n",
      "[epoch: 4, batch:   3580] loss: 0.25105  | 0.18\n",
      "[epoch: 4, batch:   3582] loss: 0.99799  | 0.18\n",
      "[epoch: 4, batch:   3584] loss: 0.11158  | 0.18\n",
      "[epoch: 4, batch:   3586] loss: 0.52066  | 0.18\n",
      "[epoch: 4, batch:   3588] loss: 0.15358  | 0.18\n",
      "[epoch: 4, batch:   3590] loss: 0.10495  | 0.18\n",
      "[epoch: 4, batch:   3592] loss: 0.16026  | 0.18\n",
      "[epoch: 4, batch:   3594] loss: 0.14123  | 0.18\n",
      "[epoch: 4, batch:   3596] loss: 0.19155  | 0.18\n",
      "[epoch: 4, batch:   3598] loss: 0.59624  | 0.18\n",
      "[epoch: 4, batch:   3600] loss: 0.17655  | 0.18\n",
      "[epoch: 4, batch:   3602] loss: 0.87243  | 0.36\n",
      "[epoch: 4, batch:   3604] loss: 0.02483  | 0.18\n",
      "[epoch: 4, batch:   3606] loss: 0.04638  | 0.18\n",
      "[epoch: 4, batch:   3608] loss: 0.01565  | 0.18\n",
      "[epoch: 4, batch:   3610] loss: 0.24433  | 0.18\n",
      "[epoch: 4, batch:   3612] loss: 0.11415  | 0.18\n",
      "[epoch: 4, batch:   3614] loss: 0.22898  | 0.18\n",
      "[epoch: 4, batch:   3616] loss: 0.14604  | 0.18\n",
      "[epoch: 4, batch:   3618] loss: 0.01689  | 0.18\n",
      "[epoch: 4, batch:   3620] loss: 0.21082  | 0.37\n",
      "[epoch: 4, batch:   3622] loss: 1.76355  | 0.18\n",
      "[epoch: 4, batch:   3624] loss: 0.10885  | 0.18\n",
      "[epoch: 4, batch:   3626] loss: 0.10896  | 0.17\n",
      "[epoch: 4, batch:   3628] loss: 0.07124  | 0.18\n",
      "[epoch: 4, batch:   3630] loss: 0.10259  | 0.18\n",
      "[epoch: 4, batch:   3632] loss: 0.19773  | 0.18\n",
      "[epoch: 4, batch:   3634] loss: 0.02355  | 0.18\n",
      "[epoch: 4, batch:   3636] loss: 0.05459  | 0.18\n",
      "[epoch: 4, batch:   3638] loss: 0.56448  | 0.18\n",
      "[epoch: 4, batch:   3640] loss: 0.18660  | 0.18\n",
      "[epoch: 4, batch:   3642] loss: 0.10853  | 0.18\n",
      "[epoch: 4, batch:   3644] loss: 0.07806  | 0.18\n",
      "[epoch: 4, batch:   3646] loss: 0.05637  | 0.17\n",
      "[epoch: 4, batch:   3648] loss: 0.29931  | 0.18\n",
      "[epoch: 4, batch:   3650] loss: 0.12318  | 0.18\n",
      "[epoch: 4, batch:   3652] loss: 0.05342  | 0.18\n",
      "[epoch: 4, batch:   3654] loss: 0.39740  | 0.18\n",
      "[epoch: 4, batch:   3656] loss: 0.35039  | 0.18\n",
      "[epoch: 4, batch:   3658] loss: 0.06550  | 0.18\n",
      "[epoch: 4, batch:   3660] loss: 0.03896  | 0.18\n",
      "[epoch: 4, batch:   3662] loss: 0.87622  | 0.18\n",
      "[epoch: 4, batch:   3664] loss: 0.04540  | 0.18\n",
      "[epoch: 4, batch:   3666] loss: 0.20316  | 1.26\n",
      "[epoch: 4, batch:   3668] loss: 0.02124  | 0.18\n",
      "[epoch: 4, batch:   3670] loss: 0.14261  | 0.18\n",
      "[epoch: 4, batch:   3672] loss: 0.20296  | 0.17\n",
      "[epoch: 4, batch:   3674] loss: 0.08767  | 0.53\n",
      "[epoch: 4, batch:   3676] loss: 0.15262  | 0.17\n",
      "[epoch: 4, batch:   3678] loss: 0.04299  | 0.18\n",
      "[epoch: 4, batch:   3680] loss: 0.49173  | 0.18\n",
      "[epoch: 4, batch:   3682] loss: 0.04265  | 0.19\n",
      "[epoch: 4, batch:   3684] loss: 0.18410  | 0.17\n",
      "[epoch: 4, batch:   3686] loss: 0.45001  | 0.18\n",
      "[epoch: 4, batch:   3688] loss: 0.05859  | 0.18\n",
      "[epoch: 4, batch:   3690] loss: 0.15081  | 0.18\n",
      "[epoch: 4, batch:   3692] loss: 0.00510  | 0.18\n",
      "[epoch: 4, batch:   3694] loss: 0.05210  | 0.18\n",
      "[epoch: 4, batch:   3696] loss: 0.16531  | 0.18\n",
      "[epoch: 4, batch:   3698] loss: 0.13957  | 0.19\n",
      "[epoch: 4, batch:   3700] loss: 0.02866  | 0.18\n",
      "[epoch: 4, batch:   3702] loss: 0.22410  | 0.18\n",
      "[epoch: 4, batch:   3704] loss: 0.23343  | 0.29\n",
      "[epoch: 4, batch:   3706] loss: 0.07255  | 0.18\n",
      "[epoch: 4, batch:   3708] loss: 0.18407  | 0.18\n",
      "[epoch: 4, batch:   3710] loss: 0.04824  | 0.18\n",
      "[epoch: 4, batch:   3712] loss: 0.18687  | 0.18\n",
      "[epoch: 4, batch:   3714] loss: 0.22773  | 0.17\n",
      "[epoch: 4, batch:   3716] loss: 0.01701  | 0.18\n",
      "[epoch: 4, batch:   3718] loss: 0.06558  | 0.18\n",
      "[epoch: 4, batch:   3720] loss: 0.18426  | 0.18\n",
      "[epoch: 4, batch:   3722] loss: 0.19098  | 0.18\n",
      "[epoch: 4, batch:   3724] loss: 0.13917  | 0.18\n",
      "[epoch: 4, batch:   3726] loss: 0.18848  | 0.18\n",
      "[epoch: 4, batch:   3728] loss: 0.05234  | 0.18\n",
      "[epoch: 4, batch:   3730] loss: 0.17772  | 0.18\n",
      "[epoch: 4, batch:   3732] loss: 0.14430  | 0.19\n",
      "[epoch: 4, batch:   3734] loss: 0.02831  | 0.18\n",
      "[epoch: 4, batch:   3736] loss: 0.19505  | 0.18\n",
      "[epoch: 4, batch:   3738] loss: 0.39444  | 0.18\n",
      "[epoch: 4, batch:   3740] loss: 0.06827  | 0.19\n",
      "[epoch: 4, batch:   3742] loss: 0.17960  | 0.17\n",
      "[epoch: 4, batch:   3744] loss: 0.03682  | 0.18\n",
      "[epoch: 4, batch:   3746] loss: 0.06257  | 0.18\n",
      "[epoch: 4, batch:   3748] loss: 0.15749  | 0.19\n",
      "[epoch: 4, batch:   3750] loss: 0.11616  | 0.17\n",
      "[epoch: 4, batch:   3752] loss: 0.41879  | 0.18\n",
      "[epoch: 4, batch:   3754] loss: 0.05482  | 0.18\n",
      "[epoch: 4, batch:   3756] loss: 0.08283  | 0.18\n",
      "[epoch: 4, batch:   3758] loss: 1.12337  | 0.18\n",
      "[epoch: 4, batch:   3760] loss: 0.05671  | 0.18\n",
      "[epoch: 4, batch:   3762] loss: 0.03466  | 0.18\n",
      "[epoch: 4, batch:   3764] loss: 0.27700  | 0.18\n",
      "[epoch: 4, batch:   3766] loss: 0.15850  | 0.18\n",
      "[epoch: 4, batch:   3768] loss: 0.36161  | 0.18\n",
      "[epoch: 4, batch:   3770] loss: 0.34748  | 0.18\n",
      "[epoch: 4, batch:   3772] loss: 0.15714  | 0.18\n",
      "[epoch: 4, batch:   3774] loss: 0.09444  | 0.18\n",
      "[epoch: 4, batch:   3776] loss: 0.06016  | 0.19\n",
      "[epoch: 4, batch:   3778] loss: 0.06702  | 0.18\n",
      "[epoch: 4, batch:   3780] loss: 0.36833  | 0.18\n",
      "[epoch: 4, batch:   3782] loss: 0.05357  | 0.18\n",
      "[epoch: 4, batch:   3784] loss: 0.24950  | 0.18\n",
      "[epoch: 4, batch:   3786] loss: 0.10678  | 0.18\n",
      "[epoch: 4, batch:   3788] loss: 0.02650  | 0.18\n",
      "[epoch: 4, batch:   3790] loss: 0.01993  | 0.18\n",
      "[epoch: 4, batch:   3792] loss: 0.12119  | 0.20\n",
      "[epoch: 4, batch:   3794] loss: 0.11544  | 0.17\n",
      "[epoch: 4, batch:   3796] loss: 0.02219  | 0.18\n",
      "[epoch: 4, batch:   3798] loss: 0.00519  | 0.18\n",
      "[epoch: 4, batch:   3800] loss: 0.27422  | 0.18\n",
      "[epoch: 4, batch:   3802] loss: 0.12014  | 0.17\n",
      "[epoch: 4, batch:   3804] loss: 0.01550  | 0.18\n",
      "[epoch: 4, batch:   3806] loss: 0.47320  | 0.18\n",
      "[epoch: 4, batch:   3808] loss: 0.18935  | 0.18\n",
      "[epoch: 4, batch:   3810] loss: 0.10303  | 0.19\n",
      "[epoch: 4, batch:   3812] loss: 0.12198  | 0.18\n",
      "[epoch: 4, batch:   3814] loss: 0.02841  | 0.18\n",
      "[epoch: 4, batch:   3816] loss: 0.22115  | 0.18\n",
      "[epoch: 4, batch:   3818] loss: 0.05436  | 0.18\n",
      "[epoch: 4, batch:   3820] loss: 0.25560  | 0.18\n",
      "[epoch: 4, batch:   3822] loss: 0.27332  | 0.18\n",
      "[epoch: 4, batch:   3824] loss: 0.17353  | 0.18\n",
      "[epoch: 4, batch:   3826] loss: 0.39027  | 0.18\n",
      "[epoch: 4, batch:   3828] loss: 1.10811  | 0.19\n",
      "[epoch: 4, batch:   3830] loss: 0.12032  | 0.17\n",
      "[epoch: 4, batch:   3832] loss: 0.10094  | 0.19\n",
      "[epoch: 4, batch:   3834] loss: 0.09655  | 0.18\n",
      "[epoch: 4, batch:   3836] loss: 0.03631  | 0.19\n",
      "[epoch: 4, batch:   3838] loss: 0.06225  | 0.18\n",
      "[epoch: 4, batch:   3840] loss: 0.08366  | 0.18\n",
      "[epoch: 4, batch:   3842] loss: 0.09440  | 0.18\n",
      "[epoch: 4, batch:   3844] loss: 0.04655  | 0.18\n",
      "[epoch: 4, batch:   3846] loss: 0.03067  | 0.18\n",
      "[epoch: 4, batch:   3848] loss: 0.14567  | 0.18\n",
      "[epoch: 4, batch:   3850] loss: 0.04047  | 0.18\n",
      "[epoch: 4, batch:   3852] loss: 0.08731  | 0.18\n",
      "[epoch: 4, batch:   3854] loss: 0.12297  | 0.18\n",
      "[epoch: 4, batch:   3856] loss: 0.12344  | 0.18\n",
      "[epoch: 4, batch:   3858] loss: 0.11096  | 0.19\n",
      "[epoch: 4, batch:   3860] loss: 0.06512  | 0.18\n",
      "[epoch: 4, batch:   3862] loss: 0.04092  | 0.18\n",
      "[epoch: 4, batch:   3864] loss: 0.06016  | 0.18\n",
      "[epoch: 4, batch:   3866] loss: 0.23871  | 0.18\n",
      "[epoch: 4, batch:   3868] loss: 0.19788  | 0.19\n",
      "[epoch: 4, batch:   3870] loss: 0.12296  | 0.17\n",
      "[epoch: 4, batch:   3872] loss: 0.27507  | 0.18\n",
      "[epoch: 4, batch:   3874] loss: 0.84952  | 0.18\n",
      "[epoch: 4, batch:   3876] loss: 0.04419  | 0.18\n",
      "[epoch: 4, batch:   3878] loss: 0.08558  | 0.18\n",
      "[epoch: 4, batch:   3880] loss: 0.07383  | 0.18\n",
      "[epoch: 4, batch:   3882] loss: 0.45190  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4, batch:   3884] loss: 0.08098  | 0.18\n",
      "[epoch: 4, batch:   3886] loss: 0.02679  | 0.18\n",
      "[epoch: 4, batch:   3888] loss: 1.20751  | 0.18\n",
      "[epoch: 4, batch:   3890] loss: 0.14083  | 0.18\n",
      "[epoch: 4, batch:   3892] loss: 0.06822  | 0.18\n",
      "[epoch: 4, batch:   3894] loss: 0.12028  | 0.19\n",
      "[epoch: 4, batch:   3896] loss: 0.34219  | 0.18\n",
      "[epoch: 4, batch:   3898] loss: 0.22087  | 0.18\n",
      "[epoch: 4, batch:   3900] loss: 0.02377  | 0.18\n",
      "[epoch: 4, batch:   3902] loss: 0.08003  | 0.18\n",
      "[epoch: 4, batch:   3904] loss: 0.09119  | 0.18\n",
      "[epoch: 4, batch:   3906] loss: 0.03211  | 0.18\n",
      "[epoch: 4, batch:   3908] loss: 0.70380  | 0.18\n",
      "[epoch: 4, batch:   3910] loss: 0.05595  | 0.19\n",
      "[epoch: 4, batch:   3912] loss: 0.04443  | 0.18\n",
      "[epoch: 4, batch:   3914] loss: 0.03738  | 0.17\n",
      "[epoch: 4, batch:   3916] loss: 0.06517  | 0.18\n",
      "[epoch: 4, batch:   3918] loss: 0.19837  | 0.19\n",
      "[epoch: 4, batch:   3920] loss: 0.08448  | 0.18\n",
      "[epoch: 4, batch:   3922] loss: 0.48568  | 0.18\n",
      "[epoch: 4, batch:   3924] loss: 0.97499  | 0.18\n",
      "[epoch: 4, batch:   3926] loss: 0.15539  | 0.18\n",
      "[epoch: 4, batch:   3928] loss: 0.06161  | 0.18\n",
      "[epoch: 4, batch:   3930] loss: 0.14660  | 0.18\n",
      "[epoch: 4, batch:   3932] loss: 0.21245  | 0.41\n",
      "[epoch: 4, batch:   3934] loss: 0.73664  | 0.17\n",
      "[epoch: 4, batch:   3936] loss: 0.06062  | 0.18\n",
      "[epoch: 4, batch:   3938] loss: 0.06711  | 0.18\n",
      "[epoch: 4, batch:   3940] loss: 0.03774  | 0.18\n",
      "[epoch: 4, batch:   3942] loss: 0.00471  | 0.17\n",
      "[epoch: 4, batch:   3944] loss: 0.05800  | 0.18\n",
      "[epoch: 4, batch:   3946] loss: 0.16523  | 0.18\n",
      "[epoch: 4, batch:   3948] loss: 0.23085  | 0.18\n",
      "[epoch: 4, batch:   3950] loss: 0.19247  | 0.18\n",
      "[epoch: 4, batch:   3952] loss: 0.04568  | 0.18\n",
      "[epoch: 4, batch:   3954] loss: 0.22953  | 0.19\n",
      "[epoch: 4, batch:   3956] loss: 0.02402  | 0.18\n",
      "[epoch: 4, batch:   3958] loss: 0.32962  | 0.18\n",
      "[epoch: 4, batch:   3960] loss: 0.47363  | 0.18\n",
      "[epoch: 4, batch:   3962] loss: 0.46885  | 0.18\n",
      "[epoch: 4, batch:   3964] loss: 0.07216  | 0.19\n",
      "[epoch: 4, batch:   3966] loss: 0.02888  | 0.18\n",
      "[epoch: 4, batch:   3968] loss: 0.02047  | 0.19\n",
      "[epoch: 4, batch:   3970] loss: 0.54432  | 0.17\n",
      "[epoch: 4, batch:   3972] loss: 0.77511  | 0.18\n",
      "[epoch: 4, batch:   3974] loss: 0.10571  | 0.18\n",
      "[epoch: 4, batch:   3976] loss: 0.23416  | 0.19\n",
      "[epoch: 4, batch:   3978] loss: 0.42404  | 0.18\n",
      "[epoch: 4, batch:   3980] loss: 0.05264  | 0.18\n",
      "[epoch: 4, batch:   3982] loss: 0.05528  | 0.17\n",
      "[epoch: 4, batch:   3984] loss: 0.07501  | 0.18\n",
      "[epoch: 4, batch:   3986] loss: 0.08748  | 0.18\n",
      "[epoch: 4, batch:   3988] loss: 0.01670  | 0.18\n",
      "[epoch: 4, batch:   3990] loss: 1.20301  | 0.18\n",
      "[epoch: 4, batch:   3992] loss: 0.36577  | 0.18\n",
      "[epoch: 4, batch:   3994] loss: 0.16755  | 0.18\n",
      "[epoch: 4, batch:   3996] loss: 0.06473  | 0.18\n",
      "[epoch: 4, batch:   3998] loss: 0.69329  | 0.20\n",
      "[epoch: 4, batch:   4000] loss: 0.44222  | 0.18\n",
      "[epoch: 4, batch:   4002] loss: 0.01503  | 0.18\n",
      "[epoch: 4, batch:   4004] loss: 0.04842  | 0.18\n",
      "[epoch: 4, batch:   4006] loss: 0.15520  | 0.17\n",
      "[epoch: 4, batch:   4008] loss: 0.22712  | 0.18\n",
      "[epoch: 4, batch:   4010] loss: 0.02042  | 0.18\n",
      "[epoch: 4, batch:   4012] loss: 0.04004  | 0.19\n",
      "[epoch: 4, batch:   4014] loss: 0.71915  | 0.18\n",
      "[epoch: 4, batch:   4016] loss: 0.03836  | 0.18\n",
      "[epoch: 4, batch:   4018] loss: 0.40443  | 0.18\n",
      "[epoch: 4, batch:   4020] loss: 0.09703  | 0.18\n",
      "[epoch: 4, batch:   4022] loss: 0.05319  | 0.18\n",
      "[epoch: 4, batch:   4024] loss: 0.16027  | 0.18\n",
      "[epoch: 4, batch:   4026] loss: 0.14686  | 0.19\n",
      "[epoch: 4, batch:   4028] loss: 0.27993  | 0.18\n",
      "[epoch: 4, batch:   4030] loss: 0.06167  | 0.19\n",
      "[epoch: 4, batch:   4032] loss: 0.12924  | 0.18\n",
      "[epoch: 4, batch:   4034] loss: 0.37360  | 0.18\n",
      "[epoch: 4, batch:   4036] loss: 0.29904  | 0.18\n",
      "[epoch: 4, batch:   4038] loss: 0.14965  | 0.18\n",
      "[epoch: 4, batch:   4040] loss: 0.15282  | 0.18\n",
      "[epoch: 4, batch:   4042] loss: 0.05592  | 0.18\n",
      "[epoch: 4, batch:   4044] loss: 0.26309  | 0.18\n",
      "[epoch: 4, batch:   4046] loss: 2.00670  | 0.20\n",
      "[epoch: 4, batch:   4048] loss: 1.12657  | 0.18\n",
      "[epoch: 4, batch:   4050] loss: 0.05425  | 0.18\n",
      "[epoch: 4, batch:   4052] loss: 0.37265  | 0.17\n",
      "[epoch: 4, batch:   4054] loss: 0.05052  | 0.18\n",
      "[epoch: 4, batch:   4056] loss: 0.03512  | 0.18\n",
      "[epoch: 4, batch:   4058] loss: 0.82952  | 0.18\n",
      "[epoch: 4, batch:   4060] loss: 0.02303  | 0.18\n",
      "[epoch: 4, batch:   4062] loss: 0.03663  | 0.18\n",
      "[epoch: 4, batch:   4064] loss: 0.01723  | 0.18\n",
      "[epoch: 4, batch:   4066] loss: 0.10616  | 0.18\n",
      "[epoch: 4, batch:   4068] loss: 0.36001  | 0.18\n",
      "[epoch: 4, batch:   4070] loss: 0.16093  | 0.18\n",
      "[epoch: 4, batch:   4072] loss: 0.38074  | 0.18\n",
      "[epoch: 4, batch:   4074] loss: 0.10586  | 0.19\n",
      "[epoch: 4, batch:   4076] loss: 0.36600  | 0.18\n",
      "[epoch: 4, batch:   4078] loss: 0.05862  | 0.18\n",
      "[epoch: 4, batch:   4080] loss: 0.15846  | 0.17\n",
      "[epoch: 4, batch:   4082] loss: 0.06350  | 0.18\n",
      "[epoch: 4, batch:   4084] loss: 0.84089  | 0.18\n",
      "[epoch: 4, batch:   4086] loss: 0.10913  | 0.18\n",
      "[epoch: 4, batch:   4088] loss: 0.01874  | 0.18\n",
      "[epoch: 4, batch:   4090] loss: 0.01045  | 0.18\n",
      "[epoch: 4, batch:   4092] loss: 0.02580  | 0.18\n",
      "[epoch: 4, batch:   4094] loss: 0.49717  | 0.18\n",
      "[epoch: 4, batch:   4096] loss: 0.13356  | 0.18\n",
      "[epoch: 4, batch:   4098] loss: 0.37929  | 0.18\n",
      "[epoch: 4, batch:   4100] loss: 0.00600  | 0.18\n",
      "[epoch: 4, batch:   4102] loss: 0.02358  | 0.18\n",
      "[epoch: 4, batch:   4104] loss: 0.20606  | 0.18\n",
      "[epoch: 4, batch:   4106] loss: 0.12763  | 0.18\n",
      "[epoch: 4, batch:   4108] loss: 0.00578  | 0.18\n",
      "[epoch: 4, batch:   4110] loss: 0.08058  | 0.18\n",
      "[epoch: 4, batch:   4112] loss: 0.24339  | 0.44\n",
      "[epoch: 4, batch:   4114] loss: 0.02017  | 0.17\n",
      "[epoch: 4, batch:   4116] loss: 0.02420  | 0.18\n",
      "[epoch: 4, batch:   4118] loss: 0.59663  | 0.18\n",
      "[epoch: 4, batch:   4120] loss: 1.70140  | 0.18\n",
      "[epoch: 4, batch:   4122] loss: 0.46958  | 0.17\n",
      "[epoch: 4, batch:   4124] loss: 0.18763  | 0.18\n",
      "[epoch: 4, batch:   4126] loss: 0.05829  | 0.18\n",
      "[epoch: 4, batch:   4128] loss: 0.16596  | 0.19\n",
      "[epoch: 4, batch:   4130] loss: 0.05385  | 0.17\n",
      "[epoch: 4, batch:   4132] loss: 0.07931  | 0.17\n",
      "[epoch: 4, batch:   4134] loss: 0.11986  | 0.18\n",
      "[epoch: 4, batch:   4136] loss: 0.05243  | 0.18\n",
      "[epoch: 4, batch:   4138] loss: 0.13792  | 0.18\n",
      "[epoch: 4, batch:   4140] loss: 0.35656  | 0.18\n",
      "[epoch: 4, batch:   4142] loss: 0.67635  | 0.18\n",
      "[epoch: 4, batch:   4144] loss: 0.09630  | 0.18\n",
      "[epoch: 4, batch:   4146] loss: 0.11061  | 0.18\n",
      "[epoch: 4, batch:   4148] loss: 0.02847  | 0.18\n",
      "[epoch: 4, batch:   4150] loss: 0.01628  | 0.18\n",
      "[epoch: 4, batch:   4152] loss: 0.24539  | 0.54\n",
      "[epoch: 4, batch:   4154] loss: 0.21579  | 0.17\n",
      "[epoch: 4, batch:   4156] loss: 0.07021  | 0.18\n",
      "[epoch: 4, batch:   4158] loss: 0.36248  | 0.18\n",
      "[epoch: 4, batch:   4160] loss: 0.56010  | 0.29\n",
      "[epoch: 4, batch:   4162] loss: 0.16615  | 0.18\n",
      "[epoch: 4, batch:   4164] loss: 0.06242  | 0.17\n",
      "[epoch: 4, batch:   4166] loss: 0.05852  | 0.18\n",
      "[epoch: 4, batch:   4168] loss: 0.11968  | 0.18\n",
      "[epoch: 4, batch:   4170] loss: 0.39872  | 0.19\n",
      "[epoch: 4, batch:   4172] loss: 0.01561  | 0.18\n",
      "[epoch: 4, batch:   4174] loss: 0.20964  | 0.18\n",
      "[epoch: 4, batch:   4176] loss: 0.16298  | 0.17\n",
      "[epoch: 4, batch:   4178] loss: 0.06303  | 0.18\n",
      "[epoch: 4, batch:   4180] loss: 0.29052  | 0.18\n",
      "[epoch: 4, batch:   4182] loss: 0.40192  | 0.19\n",
      "[epoch: 4, batch:   4184] loss: 0.20603  | 0.17\n",
      "[epoch: 4, batch:   4186] loss: 0.02246  | 0.18\n",
      "[epoch: 4, batch:   4188] loss: 0.50353  | 0.18\n",
      "[epoch: 4, batch:   4190] loss: 0.73961  | 0.19\n",
      "[epoch: 4, batch:   4192] loss: 0.02224  | 0.18\n",
      "[epoch: 4, batch:   4194] loss: 0.14331  | 0.17\n",
      "[epoch: 4, batch:   4196] loss: 0.12647  | 0.18\n",
      "[epoch: 4, batch:   4198] loss: 0.06470  | 0.18\n",
      "[epoch: 4, batch:   4200] loss: 0.65571  | 0.19\n",
      "[epoch: 4, batch:   4202] loss: 0.29028  | 0.17\n",
      "[epoch: 4, batch:   4204] loss: 0.90272  | 0.17\n",
      "[epoch: 4, batch:   4206] loss: 0.13456  | 0.18\n",
      "[epoch: 4, batch:   4208] loss: 0.70929  | 0.19\n",
      "[epoch: 4, batch:   4210] loss: 0.05181  | 0.17\n",
      "[epoch: 4, batch:   4212] loss: 1.41691  | 0.17\n",
      "[epoch: 4, batch:   4214] loss: 0.21817  | 0.54\n",
      "[epoch: 4, batch:   4216] loss: 0.18377  | 0.17\n",
      "[epoch: 4, batch:   4218] loss: 0.33529  | 0.17\n",
      "[epoch: 4, batch:   4220] loss: 0.49801  | 0.32\n",
      "[epoch: 4, batch:   4222] loss: 0.04372  | 0.18\n",
      "[epoch: 4, batch:   4224] loss: 0.07984  | 0.18\n",
      "[epoch: 4, batch:   4226] loss: 0.10009  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4, batch:   4228] loss: 0.11456  | 0.18\n",
      "[epoch: 4, batch:   4230] loss: 0.06068  | 0.19\n",
      "[epoch: 4, batch:   4232] loss: 0.14566  | 0.18\n",
      "[epoch: 4, batch:   4234] loss: 0.03837  | 0.18\n",
      "[epoch: 4, batch:   4236] loss: 0.07257  | 0.18\n",
      "[epoch: 4, batch:   4238] loss: 0.17395  | 1.40\n",
      "[epoch: 4, batch:   4240] loss: 0.11540  | 0.17\n",
      "[epoch: 4, batch:   4242] loss: 0.71442  | 0.18\n",
      "[epoch: 4, batch:   4244] loss: 0.27871  | 0.18\n",
      "[epoch: 4, batch:   4246] loss: 0.76891  | 0.18\n",
      "[epoch: 4, batch:   4248] loss: 0.54728  | 0.17\n",
      "[epoch: 4, batch:   4250] loss: 0.18566  | 0.18\n",
      "[epoch: 4, batch:   4252] loss: 0.20870  | 0.18\n",
      "[epoch: 4, batch:   4254] loss: 0.20547  | 0.19\n",
      "[epoch: 4, batch:   4256] loss: 0.08078  | 0.17\n",
      "[epoch: 4, batch:   4258] loss: 0.08472  | 0.18\n",
      "[epoch: 4, batch:   4260] loss: 0.37705  | 0.18\n",
      "[epoch: 4, batch:   4262] loss: 0.09284  | 0.19\n",
      "[epoch: 4, batch:   4264] loss: 0.51051  | 0.18\n",
      "[epoch: 4, batch:   4266] loss: 0.03379  | 0.19\n",
      "[epoch: 4, batch:   4268] loss: 0.17696  | 0.17\n",
      "[epoch: 4, batch:   4270] loss: 0.09609  | 0.18\n",
      "[epoch: 4, batch:   4272] loss: 0.18054  | 0.18\n",
      "[epoch: 4, batch:   4274] loss: 0.04976  | 0.19\n",
      "[epoch: 4, batch:   4276] loss: 0.08288  | 0.17\n",
      "[epoch: 4, batch:   4278] loss: 0.03960  | 0.18\n",
      "[epoch: 4, batch:   4280] loss: 0.07217  | 0.18\n",
      "[epoch: 4, batch:   4282] loss: 0.11558  | 0.19\n",
      "[epoch: 4, batch:   4284] loss: 0.39357  | 0.18\n",
      "[epoch: 4, batch:   4286] loss: 0.28266  | 0.17\n",
      "[epoch: 4, batch:   4288] loss: 0.16780  | 0.18\n",
      "[epoch: 4, batch:   4290] loss: 0.19799  | 0.18\n",
      "[epoch: 4, batch:   4292] loss: 0.10374  | 0.18\n",
      "[epoch: 4, batch:   4294] loss: 0.01553  | 0.18\n",
      "[epoch: 4, batch:   4296] loss: 0.12851  | 0.17\n",
      "[epoch: 4, batch:   4298] loss: 0.25130  | 0.20\n",
      "[epoch: 4, batch:   4300] loss: 0.00749  | 0.18\n",
      "[epoch: 4, batch:   4302] loss: 0.03132  | 0.18\n",
      "[epoch: 4, batch:   4304] loss: 0.04301  | 0.17\n",
      "[epoch: 4, batch:   4306] loss: 0.22910  | 0.54\n",
      "[epoch: 4, batch:   4308] loss: 0.24512  | 0.17\n",
      "[epoch: 4, batch:   4310] loss: 0.35116  | 0.18\n",
      "[epoch: 4, batch:   4312] loss: 0.22319  | 0.18\n",
      "[epoch: 4, batch:   4314] loss: 0.10495  | 0.18\n",
      "[epoch: 4, batch:   4316] loss: 0.08022  | 0.18\n",
      "[epoch: 4, batch:   4318] loss: 0.75079  | 0.17\n",
      "[epoch: 4, batch:   4320] loss: 0.05704  | 0.18\n",
      "[epoch: 4, batch:   4322] loss: 0.98993  | 0.38\n",
      "[epoch: 4, batch:   4324] loss: 0.07616  | 0.18\n",
      "[epoch: 4, batch:   4326] loss: 0.53932  | 0.17\n",
      "[epoch: 4, batch:   4328] loss: 0.06497  | 0.98\n",
      "[epoch: 4, batch:   4330] loss: 0.03585  | 0.18\n",
      "[epoch: 4, batch:   4332] loss: 0.03009  | 0.17\n",
      "[epoch: 4, batch:   4334] loss: 0.26733  | 0.17\n",
      "[epoch: 4, batch:   4336] loss: 0.03133  | 0.18\n",
      "[epoch: 4, batch:   4338] loss: 0.02706  | 0.18\n",
      "[epoch: 4, batch:   4340] loss: 0.16686  | 0.18\n",
      "[epoch: 4, batch:   4342] loss: 0.90252  | 0.19\n",
      "[epoch: 4, batch:   4344] loss: 0.09988  | 0.17\n",
      "[epoch: 4, batch:   4346] loss: 1.03038  | 0.18\n",
      "[epoch: 4, batch:   4348] loss: 0.08984  | 0.18\n",
      "[epoch: 4, batch:   4350] loss: 0.07839  | 0.19\n",
      "[epoch: 4, batch:   4352] loss: 0.09158  | 0.18\n",
      "[epoch: 4, batch:   4354] loss: 0.08252  | 0.18\n",
      "[epoch: 4, batch:   4356] loss: 1.01271  | 0.18\n",
      "[epoch: 4, batch:   4358] loss: 0.03009  | 0.19\n",
      "[epoch: 4, batch:   4360] loss: 0.12114  | 0.18\n",
      "[epoch: 4, batch:   4362] loss: 0.30475  | 0.17\n",
      "[epoch: 4, batch:   4364] loss: 1.52655  | 0.18\n",
      "[epoch: 4, batch:   4366] loss: 0.06318  | 0.18\n",
      "[epoch: 4, batch:   4368] loss: 0.10175  | 0.18\n",
      "[epoch: 4, batch:   4370] loss: 0.17464  | 0.17\n",
      "[epoch: 4, batch:   4372] loss: 0.08356  | 0.19\n",
      "[epoch: 4, batch:   4374] loss: 0.06917  | 0.18\n",
      "[epoch: 4, batch:   4376] loss: 0.07611  | 0.18\n",
      "[epoch: 4, batch:   4378] loss: 0.03665  | 0.17\n",
      "[epoch: 4, batch:   4380] loss: 0.14223  | 0.19\n",
      "[epoch: 4, batch:   4382] loss: 0.04478  | 0.17\n",
      "[epoch: 4, batch:   4384] loss: 0.04604  | 0.18\n",
      "[epoch: 4, batch:   4386] loss: 0.11592  | 0.18\n",
      "[epoch: 4, batch:   4388] loss: 0.11689  | 0.19\n",
      "[epoch: 4, batch:   4390] loss: 0.51731  | 0.18\n",
      "[epoch: 4, batch:   4392] loss: 0.07780  | 0.18\n",
      "[epoch: 4, batch:   4394] loss: 0.02950  | 0.18\n",
      "[epoch: 4, batch:   4396] loss: 0.03860  | 1.27\n",
      "[epoch: 4, batch:   4398] loss: 0.50449  | 0.18\n",
      "[epoch: 4, batch:   4400] loss: 0.17335  | 0.18\n",
      "[epoch: 4, batch:   4402] loss: 0.41637  | 0.18\n",
      "[epoch: 4, batch:   4404] loss: 0.14478  | 0.60\n",
      "[epoch: 4, batch:   4406] loss: 0.33164  | 0.17\n",
      "[epoch: 4, batch:   4408] loss: 0.01225  | 0.17\n",
      "[epoch: 4, batch:   4410] loss: 0.14032  | 0.18\n",
      "[epoch: 4, batch:   4412] loss: 0.33908  | 0.18\n",
      "[epoch: 4, batch:   4414] loss: 0.13951  | 0.17\n",
      "[epoch: 4, batch:   4416] loss: 0.07209  | 0.18\n",
      "[epoch: 4, batch:   4418] loss: 0.16171  | 0.18\n",
      "[epoch: 4, batch:   4420] loss: 0.08362  | 0.18\n",
      "[epoch: 4, batch:   4422] loss: 0.13706  | 0.18\n",
      "[epoch: 4, batch:   4424] loss: 0.10336  | 0.18\n",
      "[epoch: 4, batch:   4426] loss: 0.48499  | 0.18\n",
      "[epoch: 4, batch:   4428] loss: 0.04554  | 0.18\n",
      "[epoch: 4, batch:   4430] loss: 0.20781  | 0.18\n",
      "[epoch: 4, batch:   4432] loss: 0.32874  | 0.18\n",
      "[epoch: 4, batch:   4434] loss: 0.35856  | 0.18\n",
      "[epoch: 4, batch:   4436] loss: 0.28820  | 0.19\n",
      "[epoch: 4, batch:   4438] loss: 0.11464  | 0.65\n",
      "[epoch: 4, batch:   4440] loss: 0.09929  | 0.17\n",
      "[epoch: 4, batch:   4442] loss: 0.13033  | 0.18\n",
      "[epoch: 4, batch:   4444] loss: 0.15198  | 0.18\n",
      "[epoch: 4, batch:   4446] loss: 0.14076  | 0.18\n",
      "[epoch: 4, batch:   4448] loss: 0.20497  | 0.18\n",
      "[epoch: 4, batch:   4450] loss: 0.06436  | 0.17\n",
      "[epoch: 4, batch:   4452] loss: 0.54923  | 0.18\n",
      "[epoch: 4, batch:   4454] loss: 0.30356  | 0.18\n",
      "[epoch: 4, batch:   4456] loss: 0.00852  | 0.18\n",
      "[epoch: 4, batch:   4458] loss: 0.04963  | 0.20\n",
      "[epoch: 4, batch:   4460] loss: 0.22017  | 0.17\n",
      "[epoch: 4, batch:   4462] loss: 0.06334  | 0.18\n",
      "[epoch: 4, batch:   4464] loss: 0.11615  | 0.18\n",
      "[epoch: 4, batch:   4466] loss: 0.01227  | 0.19\n",
      "[epoch: 4, batch:   4468] loss: 0.04352  | 0.17\n",
      "[epoch: 4, batch:   4470] loss: 0.12565  | 0.18\n",
      "[epoch: 4, batch:   4472] loss: 0.06467  | 0.18\n",
      "[epoch: 4, batch:   4474] loss: 0.05489  | 0.18\n",
      "[epoch: 4, batch:   4476] loss: 0.03832  | 0.17\n",
      "[epoch: 4, batch:   4478] loss: 0.08402  | 0.18\n",
      "[epoch: 4, batch:   4480] loss: 0.11230  | 0.18\n",
      "[epoch: 4, batch:   4482] loss: 0.39816  | 0.19\n",
      "[epoch: 4, batch:   4484] loss: 0.14242  | 0.17\n",
      "[epoch: 4, batch:   4486] loss: 0.08106  | 0.18\n",
      "[epoch: 4, batch:   4488] loss: 0.15719  | 0.18\n",
      "[epoch: 4, batch:   4490] loss: 0.43586  | 0.19\n",
      "[epoch: 4, batch:   4492] loss: 0.11218  | 0.18\n",
      "[epoch: 4, batch:   4494] loss: 0.14636  | 0.17\n",
      "[epoch: 4, batch:   4496] loss: 0.42880  | 0.18\n",
      "[epoch: 4, batch:   4498] loss: 0.03403  | 0.49\n",
      "[epoch: 4, batch:   4500] loss: 0.08655  | 0.18\n",
      "[epoch: 4, batch:   4502] loss: 0.02896  | 0.17\n",
      "[epoch: 4, batch:   4504] loss: 0.49324  | 0.17\n",
      "[epoch: 4, batch:   4506] loss: 0.01567  | 0.18\n",
      "[epoch: 4, batch:   4508] loss: 0.13893  | 0.18\n",
      "[epoch: 4, batch:   4510] loss: 0.13303  | 0.18\n",
      "[epoch: 4, batch:   4512] loss: 0.05013  | 0.18\n",
      "[epoch: 4, batch:   4514] loss: 0.20180  | 0.19\n",
      "[epoch: 4, batch:   4516] loss: 0.32935  | 0.18\n",
      "[epoch: 4, batch:   4518] loss: 0.20301  | 0.18\n",
      "[epoch: 4, batch:   4520] loss: 0.18080  | 0.17\n",
      "[epoch: 4, batch:   4522] loss: 0.11410  | 1.49\n",
      "[epoch: 4, batch:   4524] loss: 0.12613  | 0.18\n",
      "[epoch: 4, batch:   4526] loss: 0.02502  | 0.18\n",
      "[epoch: 4, batch:   4528] loss: 0.06016  | 0.17\n",
      "[epoch: 4, batch:   4530] loss: 0.13753  | 1.34\n",
      "[epoch: 4, batch:   4532] loss: 0.12822  | 0.18\n",
      "[epoch: 4, batch:   4534] loss: 0.13179  | 0.18\n",
      "[epoch: 4, batch:   4536] loss: 0.05155  | 0.17\n",
      "[epoch: 4, batch:   4538] loss: 0.00997  | 0.18\n",
      "[epoch: 4, batch:   4540] loss: 0.08661  | 0.18\n",
      "[epoch: 4, batch:   4542] loss: 0.62758  | 0.18\n",
      "[epoch: 4, batch:   4544] loss: 0.18700  | 0.17\n",
      "[epoch: 4, batch:   4546] loss: 0.01102  | 0.19\n",
      "[epoch: 4, batch:   4548] loss: 0.06441  | 0.18\n",
      "[epoch: 4, batch:   4550] loss: 0.05218  | 0.18\n",
      "[epoch: 4, batch:   4552] loss: 0.02755  | 0.19\n",
      "[epoch: 4, batch:   4554] loss: 0.07216  | 0.18\n",
      "[epoch: 4, batch:   4556] loss: 0.26795  | 0.18\n",
      "[epoch: 4, batch:   4558] loss: 0.01660  | 0.18\n",
      "[epoch: 4, batch:   4560] loss: 0.13571  | 0.19\n",
      "[epoch: 4, batch:   4562] loss: 0.11496  | 0.18\n",
      "[epoch: 4, batch:   4564] loss: 0.14438  | 0.19\n",
      "[epoch: 4, batch:   4566] loss: 0.38919  | 0.18\n",
      "[epoch: 4, batch:   4568] loss: 0.02808  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4, batch:   4570] loss: 0.13716  | 0.18\n",
      "[epoch: 4, batch:   4572] loss: 0.15786  | 0.19\n",
      "[epoch: 4, batch:   4574] loss: 0.09896  | 0.18\n",
      "[epoch: 4, batch:   4576] loss: 0.05882  | 0.18\n",
      "[epoch: 4, batch:   4578] loss: 0.12842  | 0.18\n",
      "[epoch: 4, batch:   4580] loss: 0.13628  | 0.18\n",
      "[epoch: 4, batch:   4582] loss: 0.39775  | 0.19\n",
      "[epoch: 4, batch:   4584] loss: 0.02592  | 0.17\n",
      "[epoch: 4, batch:   4586] loss: 0.19830  | 0.18\n",
      "[epoch: 4, batch:   4588] loss: 0.03996  | 0.18\n",
      "[epoch: 4, batch:   4590] loss: 0.08161  | 0.20\n",
      "[epoch: 4, batch:   4592] loss: 0.10050  | 0.17\n",
      "[epoch: 4, batch:   4594] loss: 0.17477  | 0.18\n",
      "[epoch: 4, batch:   4596] loss: 0.34470  | 0.17\n",
      "[epoch: 4, batch:   4598] loss: 0.09387  | 0.18\n",
      "[epoch: 4, batch:   4600] loss: 0.14674  | 0.18\n",
      "[epoch: 4, batch:   4602] loss: 0.08143  | 0.19\n",
      "[epoch: 4, batch:   4604] loss: 0.04929  | 0.17\n",
      "[epoch: 4, batch:   4606] loss: 0.04019  | 0.18\n",
      "[epoch: 4, batch:   4608] loss: 0.03960  | 0.18\n",
      "[epoch: 4, batch:   4610] loss: 0.13149  | 0.18\n",
      "[epoch: 4, batch:   4612] loss: 0.02288  | 0.18\n",
      "[epoch: 4, batch:   4614] loss: 0.02362  | 0.19\n",
      "[epoch: 4, batch:   4616] loss: 0.24028  | 0.17\n",
      "[epoch: 4, batch:   4618] loss: 0.02803  | 0.18\n",
      "[epoch: 4, batch:   4620] loss: 0.15088  | 0.18\n",
      "[epoch: 4, batch:   4622] loss: 0.22135  | 0.20\n",
      "[epoch: 4, batch:   4624] loss: 0.02141  | 0.17\n",
      "[epoch: 4, batch:   4626] loss: 0.12238  | 0.18\n",
      "[epoch: 4, batch:   4628] loss: 0.06165  | 0.17\n",
      "[epoch: 4, batch:   4630] loss: 0.52885  | 0.18\n",
      "[epoch: 4, batch:   4632] loss: 0.06820  | 0.17\n",
      "[epoch: 4, batch:   4634] loss: 0.18688  | 0.19\n",
      "[epoch: 4, batch:   4636] loss: 0.05497  | 0.18\n",
      "[epoch: 4, batch:   4638] loss: 0.08699  | 0.20\n",
      "[epoch: 4, batch:   4640] loss: 0.07950  | 0.17\n",
      "[epoch: 4, batch:   4642] loss: 0.41212  | 0.18\n",
      "[epoch: 4, batch:   4644] loss: 0.08312  | 0.19\n",
      "[epoch: 4, batch:   4646] loss: 0.20494  | 0.18\n",
      "[epoch: 4, batch:   4648] loss: 0.04478  | 0.18\n",
      "[epoch: 4, batch:   4650] loss: 0.17571  | 0.18\n",
      "[epoch: 4, batch:   4652] loss: 0.13591  | 0.18\n",
      "[epoch: 4, batch:   4654] loss: 0.39505  | 0.19\n",
      "[epoch: 4, batch:   4656] loss: 0.03731  | 0.18\n",
      "[epoch: 4, batch:   4658] loss: 0.06330  | 0.18\n",
      "[epoch: 4, batch:   4660] loss: 0.13365  | 0.18\n",
      "[epoch: 4, batch:   4662] loss: 0.07841  | 0.18\n",
      "[epoch: 4, batch:   4664] loss: 0.03815  | 0.18\n",
      "[epoch: 4, batch:   4666] loss: 0.53468  | 0.18\n",
      "[epoch: 4, batch:   4668] loss: 0.28420  | 0.18\n",
      "[epoch: 4, batch:   4670] loss: 0.04339  | 0.18\n",
      "[epoch: 4, batch:   4672] loss: 0.12130  | 0.18\n",
      "[epoch: 4, batch:   4674] loss: 0.27213  | 0.19\n",
      "[epoch: 4, batch:   4676] loss: 0.06895  | 0.18\n",
      "[epoch: 4, batch:   4678] loss: 0.44827  | 0.18\n",
      "[epoch: 4, batch:   4680] loss: 0.16936  | 0.69\n",
      "[epoch: 4, batch:   4682] loss: 0.09460  | 0.17\n",
      "[epoch: 4, batch:   4684] loss: 1.13349  | 0.18\n",
      "[epoch: 4, batch:   4686] loss: 0.24366  | 0.18\n",
      "[epoch: 4, batch:   4688] loss: 0.15252  | 0.18\n",
      "[epoch: 4, batch:   4690] loss: 0.02007  | 0.17\n",
      "[epoch: 4, batch:   4692] loss: 0.16967  | 0.18\n",
      "[epoch: 4, batch:   4694] loss: 0.02167  | 0.18\n",
      "[epoch: 4, batch:   4696] loss: 0.06950  | 0.19\n",
      "[epoch: 4, batch:   4698] loss: 0.15949  | 0.17\n",
      "[epoch: 4, batch:   4700] loss: 0.14576  | 0.20\n",
      "[epoch: 4, batch:   4702] loss: 0.29017  | 0.18\n",
      "[epoch: 4, batch:   4704] loss: 0.05054  | 0.19\n",
      "[epoch: 4, batch:   4706] loss: 0.27711  | 0.18\n",
      "[epoch: 4, batch:   4708] loss: 0.15166  | 0.18\n",
      "[epoch: 4, batch:   4710] loss: 0.61233  | 0.17\n",
      "[epoch: 4, batch:   4712] loss: 0.03371  | 0.19\n",
      "[epoch: 4, batch:   4714] loss: 0.00730  | 0.18\n",
      "[epoch: 4, batch:   4716] loss: 0.02019  | 0.18\n",
      "[epoch: 4, batch:   4718] loss: 0.04802  | 0.17\n",
      "[epoch: 4, batch:   4720] loss: 0.04245  | 0.18\n",
      "[epoch: 4, batch:   4722] loss: 0.09987  | 0.20\n",
      "[epoch: 4, batch:   4724] loss: 0.08146  | 0.18\n",
      "[epoch: 4, batch:   4726] loss: 0.04999  | 0.17\n",
      "[epoch: 4, batch:   4728] loss: 0.03416  | 0.18\n",
      "[epoch: 4, batch:   4730] loss: 0.09663  | 0.19\n",
      "[epoch: 4, batch:   4732] loss: 0.06469  | 0.18\n",
      "[epoch: 4, batch:   4734] loss: 0.39500  | 0.18\n",
      "[epoch: 4, batch:   4736] loss: 1.69888  | 0.18\n",
      "[epoch: 4, batch:   4738] loss: 0.08115  | 0.19\n",
      "[epoch: 4, batch:   4740] loss: 0.04932  | 0.18\n",
      "[epoch: 4, batch:   4742] loss: 0.21521  | 0.18\n",
      "[epoch: 4, batch:   4744] loss: 0.03424  | 0.18\n",
      "[epoch: 4, batch:   4746] loss: 0.77836  | 0.52\n",
      "[epoch: 4, batch:   4748] loss: 0.47701  | 0.18\n",
      "[epoch: 4, batch:   4750] loss: 0.17714  | 0.18\n",
      "[epoch: 4, batch:   4752] loss: 0.66806  | 0.17\n",
      "[epoch: 4, batch:   4754] loss: 0.02437  | 0.18\n",
      "[epoch: 4, batch:   4756] loss: 0.24200  | 0.18\n",
      "[epoch: 4, batch:   4758] loss: 0.58418  | 0.18\n",
      "[epoch: 4, batch:   4760] loss: 0.19637  | 0.17\n",
      "[epoch: 4, batch:   4762] loss: 0.25674  | 0.18\n",
      "[epoch: 4, batch:   4764] loss: 0.14292  | 0.18\n",
      "[epoch: 4, batch:   4766] loss: 0.00607  | 0.18\n",
      "[epoch: 4, batch:   4768] loss: 0.12574  | 0.18\n",
      "[epoch: 4, batch:   4770] loss: 0.12226  | 0.18\n",
      "[epoch: 4, batch:   4772] loss: 0.11164  | 0.18\n",
      "[epoch: 4, batch:   4774] loss: 0.02297  | 0.21\n",
      "[epoch: 4, batch:   4776] loss: 0.20280  | 0.18\n",
      "[epoch: 4, batch:   4778] loss: 0.03593  | 0.18\n",
      "[epoch: 4, batch:   4780] loss: 0.07754  | 0.17\n",
      "[epoch: 4, batch:   4782] loss: 0.03959  | 0.18\n",
      "[epoch: 4, batch:   4784] loss: 0.26384  | 0.18\n",
      "[epoch: 4, batch:   4786] loss: 0.13885  | 0.18\n",
      "[epoch: 4, batch:   4788] loss: 0.06298  | 0.19\n",
      "[epoch: 4, batch:   4790] loss: 1.04621  | 0.18\n",
      "[epoch: 4, batch:   4792] loss: 0.32794  | 0.18\n",
      "[epoch: 4, batch:   4794] loss: 0.08514  | 0.18\n",
      "[epoch: 4, batch:   4796] loss: 0.00703  | 0.18\n",
      "[epoch: 4, batch:   4798] loss: 0.58046  | 0.18\n",
      "[epoch: 4, batch:   4800] loss: 0.29307  | 0.18\n",
      "[epoch: 4, batch:   4802] loss: 0.09761  | 0.18\n",
      "[epoch: 4, batch:   4804] loss: 0.61000  | 0.18\n",
      "[epoch: 4, batch:   4806] loss: 0.02714  | 0.19\n",
      "[epoch: 4, batch:   4808] loss: 0.14682  | 0.17\n",
      "[epoch: 4, batch:   4810] loss: 0.03579  | 0.18\n",
      "[epoch: 4, batch:   4812] loss: 0.53801  | 0.18\n",
      "[epoch: 4, batch:   4814] loss: 0.17136  | 0.20\n",
      "[epoch: 4, batch:   4816] loss: 0.02186  | 0.18\n",
      "[epoch: 4, batch:   4818] loss: 0.14730  | 0.18\n",
      "[epoch: 4, batch:   4820] loss: 0.21158  | 0.17\n",
      "[epoch: 4, batch:   4822] loss: 0.09221  | 0.18\n",
      "[epoch: 4, batch:   4824] loss: 0.06042  | 0.18\n",
      "[epoch: 4, batch:   4826] loss: 0.03347  | 0.19\n",
      "[epoch: 4, batch:   4828] loss: 0.08048  | 0.17\n",
      "[epoch: 4, batch:   4830] loss: 0.24727  | 0.18\n",
      "[epoch: 4, batch:   4832] loss: 0.01720  | 0.18\n",
      "[epoch: 4, batch:   4834] loss: 0.09653  | 0.18\n",
      "[epoch: 4, batch:   4836] loss: 0.02903  | 0.18\n",
      "[epoch: 4, batch:   4838] loss: 0.24807  | 0.18\n",
      "[epoch: 4, batch:   4840] loss: 0.50901  | 0.18\n",
      "[epoch: 4, batch:   4842] loss: 0.03341  | 0.18\n",
      "[epoch: 4, batch:   4844] loss: 0.04961  | 0.18\n",
      "[epoch: 4, batch:   4846] loss: 0.51459  | 0.19\n",
      "[epoch: 4, batch:   4848] loss: 0.26138  | 0.17\n",
      "[epoch: 4, batch:   4850] loss: 0.27116  | 0.18\n",
      "[epoch: 4, batch:   4852] loss: 0.09335  | 0.18\n",
      "[epoch: 4, batch:   4854] loss: 0.13981  | 0.19\n",
      "[epoch: 4, batch:   4856] loss: 0.16452  | 0.18\n",
      "[epoch: 4, batch:   4858] loss: 0.34711  | 0.18\n",
      "[epoch: 4, batch:   4860] loss: 0.14005  | 0.18\n",
      "[epoch: 4, batch:   4862] loss: 0.16777  | 0.18\n",
      "[epoch: 4, batch:   4864] loss: 0.03092  | 0.18\n",
      "[epoch: 4, batch:   4866] loss: 0.07854  | 0.18\n",
      "[epoch: 4, batch:   4868] loss: 0.06404  | 0.18\n",
      "[epoch: 4, batch:   4870] loss: 0.34481  | 0.18\n",
      "[epoch: 4, batch:   4872] loss: 0.36398  | 0.18\n",
      "[epoch: 4, batch:   4874] loss: 0.09756  | 0.18\n",
      "[epoch: 4, batch:   4876] loss: 0.01502  | 0.18\n",
      "[epoch: 4, batch:   4878] loss: 0.06271  | 0.18\n",
      "[epoch: 4, batch:   4880] loss: 0.29770  | 0.19\n",
      "[epoch: 4, batch:   4882] loss: 0.08742  | 0.18\n",
      "[epoch: 4, batch:   4884] loss: 0.12602  | 0.18\n",
      "[epoch: 4, batch:   4886] loss: 0.09675  | 0.18\n",
      "[epoch: 4, batch:   4888] loss: 0.30815  | 0.18\n",
      "[epoch: 4, batch:   4890] loss: 0.12470  | 0.18\n",
      "[epoch: 4, batch:   4892] loss: 0.08201  | 0.18\n",
      "[epoch: 4, batch:   4894] loss: 0.01747  | 0.18\n",
      "[epoch: 4, batch:   4896] loss: 0.09236  | 0.18\n",
      "[epoch: 4, batch:   4898] loss: 0.02193  | 0.18\n",
      "[epoch: 4, batch:   4900] loss: 0.08001  | 0.17\n",
      "[epoch: 4, batch:   4902] loss: 0.59451  | 0.18\n",
      "[epoch: 4, batch:   4904] loss: 0.07827  | 0.18\n",
      "[epoch: 4, batch:   4906] loss: 0.03590  | 0.20\n",
      "[epoch: 4, batch:   4908] loss: 0.11176  | 0.46\n",
      "[epoch: 4, batch:   4910] loss: 0.57184  | 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4, batch:   4912] loss: 0.12679  | 0.18\n",
      "[epoch: 4, batch:   4914] loss: 0.07131  | 0.19\n",
      "[epoch: 4, batch:   4916] loss: 0.13122  | 0.18\n",
      "[epoch: 4, batch:   4918] loss: 0.65096  | 0.18\n",
      "[epoch: 4, batch:   4920] loss: 0.07656  | 0.18\n",
      "[epoch: 4, batch:   4922] loss: 0.32122  | 0.18\n",
      "[epoch: 4, batch:   4924] loss: 0.01624  | 0.18\n",
      "[epoch: 4, batch:   4926] loss: 1.07035  | 0.19\n",
      "[epoch: 4, batch:   4928] loss: 0.04456  | 0.18\n",
      "[epoch: 4, batch:   4930] loss: 0.02753  | 0.18\n",
      "[epoch: 4, batch:   4932] loss: 0.40706  | 0.19\n",
      "[epoch: 4, batch:   4934] loss: 0.13438  | 0.17\n",
      "[epoch: 4, batch:   4936] loss: 0.04396  | 0.18\n",
      "[epoch: 4, batch:   4938] loss: 0.06788  | 0.18\n",
      "[epoch: 4, batch:   4940] loss: 1.83881  | 0.18\n",
      "[epoch: 4, batch:   4942] loss: 0.05477  | 0.18\n",
      "[epoch: 4, batch:   4944] loss: 0.56070  | 0.18\n",
      "[epoch: 4, batch:   4946] loss: 0.50468  | 0.18\n",
      "[epoch: 4, batch:   4948] loss: 0.02084  | 0.19\n",
      "[epoch: 4, batch:   4950] loss: 0.07221  | 0.18\n",
      "[epoch: 4, batch:   4952] loss: 0.04971  | 0.18\n",
      "[epoch: 4, batch:   4954] loss: 0.06348  | 0.18\n",
      "[epoch: 4, batch:   4956] loss: 0.09872  | 0.18\n",
      "[epoch: 4, batch:   4958] loss: 0.15928  | 0.18\n",
      "[epoch: 4, batch:   4960] loss: 0.05301  | 0.19\n",
      "[epoch: 4, batch:   4962] loss: 0.06331  | 0.18\n",
      "[epoch: 4, batch:   4964] loss: 0.04122  | 0.20\n",
      "[epoch: 4, batch:   4966] loss: 0.20785  | 0.17\n",
      "[epoch: 4, batch:   4968] loss: 0.02585  | 0.18\n",
      "[epoch: 4, batch:   4970] loss: 0.32698  | 0.17\n",
      "[epoch: 4, batch:   4972] loss: 0.30748  | 0.19\n",
      "[epoch: 4, batch:   4974] loss: 0.28198  | 0.17\n",
      "[epoch: 4, batch:   4976] loss: 0.20446  | 0.18\n",
      "[epoch: 4, batch:   4978] loss: 0.08233  | 0.18\n",
      "[epoch: 4, batch:   4980] loss: 0.11731  | 0.18\n",
      "[epoch: 4, batch:   4982] loss: 0.08028  | 0.18\n",
      "[epoch: 4, batch:   4984] loss: 0.64620  | 0.19\n",
      "[epoch: 4, batch:   4986] loss: 0.58806  | 0.17\n",
      "[epoch: 4, batch:   4988] loss: 0.05751  | 0.60\n",
      "[epoch: 4, batch:   4990] loss: 0.12637  | 0.18\n",
      "[epoch: 4, batch:   4992] loss: 0.02002  | 0.18\n",
      "[epoch: 4, batch:   4994] loss: 0.25505  | 0.17\n",
      "[epoch: 4, batch:   4996] loss: 0.04895  | 0.18\n",
      "[epoch: 4, batch:   4998] loss: 0.06210  | 0.18\n",
      "[epoch: 4, batch:   5000] loss: 0.16242  | 0.18\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c6f725f74172>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mepoch_error\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from time import time\n",
    "import gc\n",
    "\n",
    "criterion1 = nn.SmoothL1Loss()\n",
    "criterion2 = nn.SmoothL1Loss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "model.train()\n",
    "epoch_error = {}\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    start_time = time()\n",
    "    epoch_error[epoch] = []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(data)\n",
    "        \n",
    "        loss = criterion1(prediction['canSpeed'].cuda(), target['canSpeed'].cuda()) \\\n",
    "                + criterion2(prediction['canSteering'].cuda(), target['canSteering'].cuda())\n",
    "        \n",
    "#         loss = criterion1(prediction['canSpeed'].cuda(), target['canSpeed'].cuda())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % 2 == 1:\n",
    "            cost_time = time() - start_time\n",
    "          \n",
    "            print('[epoch: %d, batch:  %5d] loss: %.5f  | %.2f' %\n",
    "                  (epoch + 1, batch_idx + 1, running_loss / 2.0, cost_time))\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            start_time = time()\n",
    "        \n",
    "        epoch_error[epoch].append(loss)\n",
    "        \n",
    "        # Remove this when actually training. \n",
    "        # Used to terminate early. \n",
    "        if batch_idx >= 5000: \n",
    "            break\n",
    "            \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SomeDrivingModel(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (intermediate): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (lstm): LSTM(128, 64, num_layers=3)\n",
       "  (lstm_rear): LSTM(128, 64, num_layers=3)\n",
       "  (control_angle): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       "  (control_speed): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## freeze all parts except angle regressor\n",
    "\n",
    "# for param in model.parameters():  # freeze all\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# for param in model.control_angle.parameters():  # unfreeze angle regressor\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "# criterion2 = nn.SmoothL1Loss()\n",
    "\n",
    "# for epoch in range(3):\n",
    "#     running_loss = 0.0\n",
    "#     start_time = time()\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#             optimizer.zero_grad()\n",
    "#             prediction = model(data)\n",
    "#             loss = criterion2(prediction['canSteering'].cuda(), target['canSteering'].cuda())\n",
    "\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # print statistics\n",
    "#             running_loss += loss.item()\n",
    "#             if batch_idx % 2 == 1:\n",
    "#                 cost_time = time() - start_time\n",
    "\n",
    "#                 print('[epoch: %d, batch:  %5d] loss: %.5f  | %.2f' %\n",
    "#                       (epoch + 1, batch_idx + 1, running_loss / 2.0, cost_time))\n",
    "\n",
    "#                 running_loss = 0.0\n",
    "#                 start_time = time()\n",
    "\n",
    "#             # Remove this when actually training. \n",
    "#             # Used to terminate early. \n",
    "#             if batch_idx >= 100: \n",
    "#                 break\n",
    "\n",
    "# for param in model.parameters():  # freeze all\n",
    "#     param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle MSE: 1521.36 (872.67), Speed MSE: 889.55 (5.766)\n"
     ]
    }
   ],
   "source": [
    "## Local Evaluation\n",
    "\n",
    "\n",
    "\"\"\" undo normalization\n",
    "\"target\":{\n",
    "        \"normalize\": true,\n",
    "        \"mean\": {\"canSteering\": -5.406788214535221,\n",
    "                \"canSpeed\": 13.426163367846936},\n",
    "        \"std\": {\"canSteering\": 73.41232589456718,\n",
    "                \"canSpeed\": 7.8257638553586455}\n",
    "    },\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    speed_mse = []\n",
    "    steer_mse = []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(validation_loader):\n",
    "        prediction = model(data)\n",
    "        # Again only evaluating the canSpeed \n",
    "        # predictions, add canSteering when \n",
    "        # jointly training.\n",
    "#         print('pred:', prediction['canSpeed'])\n",
    "#         print('target:', target['canSpeed'])\n",
    "        speed_mse.append(\n",
    "            (\n",
    "                np.square(\n",
    "                    (\n",
    "                        prediction['canSpeed'] * config['target']['std']['canSpeed'] + config['target']['mean']['canSpeed'] \n",
    "                        - target['canSpeed'].cuda() * config['target']['std']['canSpeed'] + config['target']['mean']['canSpeed'] \n",
    "                    ).cpu()\n",
    "                )\n",
    "            ).mean()\n",
    "        )\n",
    "    \n",
    "        steer_mse.append(\n",
    "            (\n",
    "                np.square(\n",
    "                    (\n",
    "                        prediction['canSteering'] * config['target']['std']['canSteering'] + config['target']['mean']['canSteering'] \n",
    "                        - target['canSteering'].cuda() * config['target']['std']['canSteering'] + config['target']['mean']['canSteering'] \n",
    "                    ).cpu()\n",
    "                )\n",
    "            ).mean()\n",
    "        )\n",
    "        \n",
    "        # Used to terminate early, remove.\n",
    "#         if batch_idx >= 100: \n",
    "#             break\n",
    "\n",
    "print('Angle MSE: %.2f (872.67), Speed MSE: %.2f (5.766)' \n",
    "      % (np.array(steer_mse).mean(), np.array(speed_mse).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model6.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" create submission file \"\"\"\n",
    "\n",
    "\n",
    "normalize_targets = config['target']['normalize']\n",
    "target_mean = config['target']['mean']\n",
    "target_std = config['target']['std']\n",
    "\n",
    "def add_results(results, output):\n",
    "    steering = np.squeeze(output['canSteering'].cpu().data.numpy())\n",
    "    speed = np.squeeze(output['canSpeed'].cpu().data.numpy())\n",
    "    if normalize_targets:\n",
    "        steering = (steering*target_std['canSteering'])+target_mean['canSteering']\n",
    "        speed = (speed*target_std['canSpeed'])+target_mean['canSpeed']\n",
    "    if np.isscalar(steering):\n",
    "        steering = [steering]\n",
    "    if np.isscalar(speed):\n",
    "        speed = [speed]\n",
    "    results['canSteering'].extend(steering)\n",
    "    results['canSpeed'].extend(speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2883\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2887\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2892\n",
      "2893\n",
      "2894\n",
      "2895\n",
      "2896\n",
      "2897\n",
      "2898\n",
      "2899\n",
      "2900\n",
      "2901\n",
      "2902\n",
      "2903\n",
      "2904\n",
      "2905\n",
      "2906\n",
      "2907\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2911\n",
      "2912\n",
      "2913\n",
      "2914\n",
      "2915\n",
      "2916\n",
      "2917\n",
      "2918\n",
      "2919\n",
      "2920\n",
      "2921\n",
      "2922\n",
      "2923\n",
      "2924\n",
      "2925\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "2933\n",
      "2934\n",
      "2935\n",
      "2936\n",
      "2937\n",
      "2938\n",
      "2939\n",
      "2940\n",
      "2941\n",
      "2942\n",
      "2943\n",
      "2944\n",
      "2945\n",
      "2946\n",
      "2947\n",
      "2948\n",
      "2949\n",
      "2950\n",
      "2951\n",
      "2952\n",
      "2953\n",
      "2954\n",
      "2955\n",
      "2956\n",
      "2957\n",
      "2958\n",
      "2959\n",
      "2960\n",
      "2961\n",
      "2962\n",
      "2963\n",
      "2964\n",
      "2965\n",
      "2966\n",
      "2967\n",
      "2968\n",
      "2969\n",
      "2970\n",
      "2971\n",
      "2972\n",
      "2973\n",
      "2974\n",
      "2975\n",
      "2976\n",
      "2977\n",
      "2978\n",
      "2979\n",
      "2980\n",
      "2981\n",
      "2982\n",
      "2983\n",
      "2984\n",
      "2985\n",
      "2986\n",
      "2987\n",
      "2988\n",
      "2989\n",
      "2990\n",
      "2991\n",
      "2992\n",
      "2993\n",
      "2994\n",
      "2995\n",
      "2996\n",
      "2997\n",
      "2998\n",
      "2999\n",
      "3000\n",
      "3001\n",
      "3002\n",
      "3003\n",
      "3004\n",
      "3005\n",
      "3006\n",
      "3007\n",
      "3008\n",
      "3009\n",
      "3010\n",
      "3011\n",
      "3012\n",
      "3013\n",
      "3014\n",
      "3015\n",
      "3016\n",
      "3017\n",
      "3018\n",
      "3019\n",
      "3020\n",
      "3021\n",
      "3022\n",
      "3023\n",
      "3024\n",
      "3025\n",
      "3026\n",
      "3027\n",
      "3028\n",
      "3029\n",
      "3030\n",
      "3031\n",
      "3032\n",
      "3033\n",
      "3034\n",
      "3035\n",
      "3036\n",
      "3037\n",
      "3038\n",
      "3039\n",
      "3040\n",
      "3041\n",
      "3042\n",
      "3043\n",
      "3044\n",
      "3045\n",
      "3046\n",
      "3047\n",
      "3048\n",
      "3049\n",
      "3050\n",
      "3051\n",
      "3052\n",
      "3053\n",
      "3054\n",
      "3055\n",
      "3056\n",
      "3057\n",
      "3058\n",
      "3059\n",
      "3060\n",
      "3061\n",
      "3062\n",
      "3063\n",
      "3064\n",
      "3065\n",
      "3066\n",
      "3067\n",
      "3068\n",
      "3069\n",
      "3070\n",
      "3071\n",
      "3072\n",
      "3073\n",
      "3074\n",
      "3075\n",
      "3076\n",
      "3077\n",
      "3078\n",
      "3079\n",
      "3080\n",
      "3081\n",
      "3082\n",
      "3083\n",
      "3084\n",
      "3085\n",
      "3086\n",
      "3087\n",
      "3088\n",
      "3089\n",
      "3090\n",
      "3091\n",
      "3092\n",
      "3093\n",
      "3094\n",
      "3095\n",
      "3096\n",
      "3097\n",
      "3098\n",
      "3099\n",
      "3100\n",
      "3101\n",
      "3102\n",
      "3103\n",
      "3104\n",
      "3105\n",
      "3106\n",
      "3107\n",
      "3108\n",
      "3109\n",
      "3110\n",
      "3111\n",
      "3112\n",
      "3113\n",
      "3114\n",
      "3115\n",
      "3116\n",
      "3117\n",
      "3118\n",
      "3119\n",
      "3120\n",
      "3121\n",
      "3122\n",
      "3123\n",
      "3124\n",
      "3125\n",
      "3126\n",
      "3127\n",
      "3128\n",
      "3129\n",
      "3130\n",
      "3131\n",
      "3132\n",
      "3133\n",
      "3134\n",
      "3135\n",
      "3136\n",
      "3137\n",
      "3138\n",
      "3139\n",
      "3140\n",
      "3141\n",
      "3142\n",
      "3143\n",
      "3144\n",
      "3145\n",
      "3146\n",
      "3147\n",
      "3148\n",
      "3149\n",
      "3150\n",
      "3151\n",
      "3152\n",
      "3153\n",
      "3154\n",
      "3155\n",
      "3156\n",
      "3157\n",
      "3158\n",
      "3159\n",
      "3160\n",
      "3161\n",
      "3162\n",
      "3163\n",
      "3164\n",
      "3165\n",
      "3166\n",
      "3167\n",
      "3168\n",
      "3169\n",
      "3170\n",
      "3171\n",
      "3172\n",
      "3173\n",
      "3174\n",
      "3175\n",
      "3176\n",
      "3177\n",
      "3178\n",
      "3179\n",
      "3180\n",
      "3181\n",
      "3182\n",
      "3183\n",
      "3184\n",
      "3185\n",
      "3186\n",
      "3187\n",
      "3188\n",
      "3189\n",
      "3190\n",
      "3191\n",
      "3192\n",
      "3193\n",
      "3194\n",
      "3195\n",
      "3196\n",
      "3197\n",
      "3198\n",
      "3199\n",
      "3200\n",
      "3201\n",
      "3202\n",
      "3203\n",
      "3204\n",
      "3205\n",
      "3206\n",
      "3207\n",
      "3208\n",
      "3209\n",
      "3210\n",
      "3211\n",
      "3212\n",
      "3213\n",
      "3214\n",
      "3215\n",
      "3216\n",
      "3217\n",
      "3218\n",
      "3219\n",
      "3220\n",
      "3221\n",
      "3222\n",
      "3223\n",
      "3224\n",
      "3225\n",
      "3226\n",
      "3227\n",
      "3228\n",
      "3229\n",
      "3230\n",
      "3231\n",
      "3232\n",
      "3233\n",
      "3234\n",
      "3235\n",
      "3236\n",
      "3237\n",
      "3238\n",
      "3239\n",
      "3240\n",
      "3241\n",
      "3242\n",
      "3243\n",
      "3244\n",
      "3245\n",
      "3246\n",
      "3247\n",
      "3248\n",
      "3249\n",
      "3250\n",
      "3251\n",
      "3252\n",
      "3253\n",
      "3254\n",
      "3255\n",
      "3256\n",
      "3257\n",
      "3258\n",
      "3259\n",
      "3260\n",
      "3261\n",
      "3262\n",
      "3263\n",
      "3264\n",
      "3265\n",
      "3266\n",
      "3267\n",
      "3268\n",
      "3269\n",
      "3270\n",
      "3271\n",
      "3272\n",
      "3273\n",
      "3274\n",
      "3275\n",
      "3276\n",
      "3277\n",
      "3278\n",
      "3279\n",
      "3280\n",
      "3281\n",
      "3282\n",
      "3283\n",
      "3284\n",
      "3285\n",
      "3286\n",
      "3287\n",
      "3288\n",
      "3289\n",
      "3290\n",
      "3291\n",
      "3292\n",
      "3293\n",
      "3294\n",
      "3295\n",
      "3296\n",
      "3297\n",
      "3298\n",
      "3299\n",
      "3300\n",
      "3301\n",
      "3302\n",
      "3303\n",
      "3304\n",
      "3305\n",
      "3306\n",
      "3307\n",
      "3308\n",
      "3309\n",
      "3310\n",
      "3311\n",
      "3312\n",
      "3313\n",
      "3314\n",
      "3315\n",
      "3316\n",
      "3317\n",
      "3318\n",
      "3319\n",
      "3320\n",
      "3321\n",
      "3322\n",
      "3323\n",
      "3324\n",
      "3325\n",
      "3326\n",
      "3327\n",
      "3328\n",
      "3329\n",
      "3330\n",
      "3331\n",
      "3332\n",
      "3333\n",
      "3334\n",
      "3335\n",
      "3336\n",
      "3337\n",
      "3338\n",
      "3339\n",
      "3340\n",
      "3341\n",
      "3342\n",
      "3343\n",
      "3344\n",
      "3345\n",
      "3346\n",
      "3347\n",
      "3348\n",
      "3349\n",
      "3350\n",
      "3351\n",
      "3352\n",
      "3353\n",
      "3354\n",
      "3355\n",
      "3356\n",
      "3357\n",
      "3358\n",
      "3359\n",
      "3360\n",
      "3361\n",
      "3362\n",
      "3363\n",
      "3364\n",
      "3365\n",
      "3366\n",
      "3367\n",
      "3368\n",
      "3369\n",
      "3370\n",
      "3371\n",
      "3372\n",
      "3373\n",
      "3374\n",
      "3375\n",
      "3376\n",
      "3377\n",
      "3378\n",
      "3379\n",
      "3380\n",
      "3381\n",
      "3382\n",
      "3383\n",
      "3384\n",
      "3385\n",
      "3386\n",
      "3387\n",
      "3388\n",
      "3389\n",
      "3390\n",
      "3391\n",
      "3392\n",
      "3393\n",
      "3394\n",
      "3395\n",
      "3396\n",
      "3397\n",
      "3398\n",
      "3399\n",
      "3400\n",
      "3401\n",
      "3402\n",
      "3403\n",
      "3404\n",
      "3405\n",
      "3406\n",
      "3407\n",
      "3408\n",
      "3409\n",
      "3410\n",
      "3411\n",
      "3412\n",
      "3413\n",
      "3414\n",
      "3415\n",
      "3416\n",
      "3417\n",
      "3418\n",
      "3419\n",
      "3420\n",
      "3421\n",
      "3422\n",
      "3423\n",
      "3424\n",
      "3425\n",
      "3426\n",
      "3427\n",
      "3428\n",
      "3429\n",
      "3430\n",
      "3431\n",
      "3432\n",
      "3433\n",
      "3434\n",
      "3435\n",
      "3436\n",
      "3437\n",
      "3438\n",
      "3439\n",
      "3440\n",
      "3441\n",
      "3442\n",
      "3443\n",
      "3444\n",
      "3445\n",
      "3446\n",
      "3447\n",
      "3448\n",
      "3449\n",
      "3450\n",
      "3451\n",
      "3452\n",
      "3453\n",
      "3454\n",
      "3455\n",
      "3456\n",
      "3457\n",
      "3458\n",
      "3459\n",
      "3460\n",
      "3461\n",
      "3462\n",
      "3463\n",
      "3464\n",
      "3465\n",
      "3466\n",
      "3467\n",
      "3468\n",
      "3469\n",
      "3470\n",
      "3471\n",
      "3472\n",
      "3473\n",
      "3474\n",
      "3475\n",
      "3476\n",
      "3477\n",
      "3478\n",
      "3479\n",
      "3480\n",
      "3481\n",
      "3482\n",
      "3483\n",
      "3484\n",
      "3485\n",
      "3486\n",
      "3487\n",
      "3488\n",
      "3489\n",
      "3490\n",
      "3491\n",
      "3492\n",
      "3493\n",
      "3494\n",
      "3495\n",
      "3496\n",
      "3497\n",
      "3498\n",
      "3499\n",
      "3500\n",
      "3501\n",
      "3502\n",
      "3503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3504\n",
      "3505\n",
      "3506\n",
      "3507\n",
      "3508\n",
      "3509\n",
      "3510\n",
      "3511\n",
      "3512\n",
      "3513\n",
      "3514\n",
      "3515\n",
      "3516\n",
      "3517\n",
      "3518\n",
      "3519\n",
      "3520\n",
      "3521\n",
      "3522\n",
      "3523\n",
      "3524\n",
      "3525\n",
      "3526\n",
      "3527\n",
      "3528\n",
      "3529\n",
      "3530\n",
      "3531\n",
      "3532\n",
      "3533\n",
      "3534\n",
      "3535\n",
      "3536\n",
      "3537\n",
      "3538\n",
      "3539\n",
      "3540\n",
      "3541\n",
      "3542\n",
      "3543\n",
      "3544\n",
      "3545\n",
      "3546\n",
      "3547\n",
      "3548\n",
      "3549\n",
      "3550\n",
      "3551\n",
      "3552\n",
      "3553\n",
      "3554\n",
      "3555\n",
      "3556\n",
      "3557\n",
      "3558\n",
      "3559\n",
      "3560\n",
      "3561\n",
      "3562\n",
      "3563\n",
      "3564\n",
      "3565\n",
      "3566\n",
      "3567\n",
      "3568\n",
      "3569\n",
      "3570\n",
      "3571\n",
      "3572\n",
      "3573\n",
      "3574\n",
      "3575\n",
      "3576\n",
      "3577\n",
      "3578\n",
      "3579\n",
      "3580\n",
      "3581\n",
      "3582\n",
      "3583\n",
      "3584\n",
      "3585\n",
      "3586\n",
      "3587\n",
      "3588\n",
      "3589\n",
      "3590\n",
      "3591\n",
      "3592\n",
      "3593\n",
      "3594\n",
      "3595\n",
      "3596\n",
      "3597\n",
      "3598\n",
      "3599\n",
      "3600\n",
      "3601\n",
      "3602\n",
      "3603\n",
      "3604\n",
      "3605\n",
      "3606\n",
      "3607\n",
      "3608\n",
      "3609\n",
      "3610\n",
      "3611\n",
      "3612\n",
      "3613\n",
      "3614\n",
      "3615\n",
      "3616\n",
      "3617\n",
      "3618\n",
      "3619\n",
      "3620\n",
      "3621\n",
      "3622\n",
      "3623\n",
      "3624\n",
      "3625\n",
      "3626\n",
      "3627\n",
      "3628\n",
      "3629\n",
      "3630\n",
      "3631\n",
      "3632\n",
      "3633\n",
      "3634\n",
      "3635\n",
      "3636\n",
      "3637\n",
      "3638\n",
      "3639\n",
      "3640\n",
      "3641\n",
      "3642\n",
      "3643\n",
      "3644\n",
      "3645\n",
      "3646\n",
      "3647\n",
      "3648\n",
      "3649\n",
      "3650\n",
      "3651\n",
      "3652\n",
      "3653\n",
      "3654\n",
      "3655\n",
      "3656\n",
      "3657\n",
      "3658\n",
      "3659\n",
      "3660\n",
      "3661\n",
      "3662\n",
      "3663\n",
      "3664\n",
      "3665\n",
      "3666\n",
      "3667\n",
      "3668\n",
      "3669\n",
      "3670\n",
      "3671\n",
      "3672\n",
      "3673\n",
      "3674\n",
      "3675\n",
      "3676\n",
      "3677\n",
      "3678\n",
      "3679\n",
      "3680\n",
      "3681\n",
      "3682\n",
      "3683\n",
      "3684\n",
      "3685\n",
      "3686\n",
      "3687\n",
      "3688\n",
      "3689\n",
      "3690\n",
      "3691\n",
      "3692\n",
      "3693\n",
      "3694\n",
      "3695\n",
      "3696\n",
      "3697\n",
      "3698\n",
      "3699\n",
      "3700\n",
      "3701\n",
      "3702\n",
      "3703\n",
      "3704\n",
      "3705\n",
      "3706\n",
      "3707\n",
      "3708\n",
      "3709\n",
      "3710\n",
      "3711\n",
      "3712\n",
      "3713\n",
      "3714\n",
      "3715\n",
      "3716\n",
      "3717\n",
      "3718\n",
      "3719\n",
      "3720\n",
      "3721\n",
      "3722\n",
      "3723\n",
      "3724\n",
      "3725\n",
      "3726\n",
      "3727\n",
      "3728\n",
      "3729\n",
      "3730\n",
      "3731\n",
      "3732\n",
      "3733\n",
      "3734\n",
      "3735\n",
      "3736\n",
      "3737\n",
      "3738\n",
      "3739\n",
      "3740\n",
      "3741\n",
      "3742\n",
      "3743\n",
      "3744\n",
      "3745\n",
      "3746\n",
      "3747\n",
      "3748\n",
      "3749\n",
      "3750\n",
      "3751\n",
      "3752\n",
      "3753\n",
      "3754\n",
      "3755\n",
      "3756\n",
      "3757\n",
      "3758\n",
      "3759\n",
      "3760\n",
      "3761\n",
      "3762\n",
      "3763\n",
      "3764\n",
      "3765\n",
      "3766\n",
      "3767\n",
      "3768\n",
      "3769\n",
      "3770\n",
      "3771\n",
      "3772\n",
      "3773\n",
      "3774\n",
      "3775\n",
      "3776\n",
      "3777\n",
      "3778\n",
      "3779\n",
      "3780\n",
      "3781\n",
      "3782\n",
      "3783\n",
      "3784\n",
      "3785\n",
      "3786\n",
      "3787\n",
      "3788\n",
      "3789\n",
      "3790\n",
      "3791\n",
      "3792\n",
      "3793\n",
      "3794\n",
      "3795\n",
      "3796\n",
      "3797\n",
      "3798\n",
      "3799\n",
      "3800\n",
      "3801\n",
      "3802\n",
      "3803\n",
      "3804\n",
      "3805\n",
      "3806\n",
      "3807\n",
      "3808\n",
      "3809\n",
      "3810\n",
      "3811\n",
      "3812\n",
      "3813\n",
      "3814\n",
      "3815\n",
      "3816\n",
      "3817\n",
      "3818\n",
      "3819\n",
      "3820\n",
      "3821\n",
      "3822\n",
      "3823\n",
      "3824\n",
      "3825\n",
      "3826\n",
      "3827\n",
      "3828\n",
      "3829\n",
      "3830\n",
      "3831\n",
      "3832\n",
      "3833\n",
      "3834\n",
      "3835\n",
      "3836\n",
      "3837\n",
      "3838\n",
      "3839\n",
      "3840\n",
      "3841\n",
      "3842\n",
      "3843\n",
      "3844\n",
      "3845\n",
      "3846\n",
      "3847\n",
      "3848\n",
      "3849\n",
      "3850\n",
      "3851\n",
      "3852\n",
      "3853\n",
      "3854\n",
      "3855\n",
      "3856\n",
      "3857\n",
      "3858\n",
      "3859\n",
      "3860\n",
      "3861\n",
      "3862\n",
      "3863\n",
      "3864\n",
      "3865\n",
      "3866\n",
      "3867\n",
      "3868\n",
      "3869\n",
      "3870\n",
      "3871\n",
      "3872\n",
      "3873\n",
      "3874\n",
      "3875\n",
      "3876\n",
      "3877\n",
      "3878\n",
      "3879\n",
      "3880\n",
      "3881\n",
      "3882\n",
      "3883\n",
      "3884\n",
      "3885\n",
      "3886\n",
      "3887\n",
      "3888\n",
      "3889\n",
      "3890\n",
      "3891\n",
      "3892\n",
      "3893\n",
      "3894\n",
      "3895\n",
      "3896\n",
      "3897\n",
      "3898\n",
      "3899\n",
      "3900\n",
      "3901\n",
      "3902\n",
      "3903\n",
      "3904\n",
      "3905\n",
      "3906\n",
      "3907\n",
      "3908\n",
      "3909\n",
      "3910\n",
      "3911\n",
      "3912\n",
      "3913\n",
      "3914\n",
      "3915\n",
      "3916\n",
      "3917\n",
      "3918\n",
      "3919\n",
      "3920\n",
      "3921\n",
      "3922\n",
      "3923\n",
      "3924\n",
      "3925\n",
      "3926\n",
      "3927\n",
      "3928\n",
      "3929\n",
      "3930\n",
      "3931\n",
      "3932\n",
      "3933\n",
      "3934\n",
      "3935\n",
      "3936\n",
      "3937\n",
      "3938\n",
      "3939\n",
      "3940\n",
      "3941\n",
      "3942\n",
      "3943\n",
      "3944\n",
      "3945\n",
      "3946\n",
      "3947\n",
      "3948\n",
      "3949\n",
      "3950\n",
      "3951\n",
      "3952\n",
      "3953\n",
      "3954\n",
      "3955\n",
      "3956\n",
      "3957\n",
      "3958\n",
      "3959\n",
      "3960\n",
      "3961\n",
      "3962\n",
      "3963\n",
      "3964\n",
      "3965\n",
      "3966\n",
      "3967\n",
      "3968\n",
      "3969\n",
      "3970\n",
      "3971\n",
      "3972\n",
      "3973\n",
      "3974\n",
      "3975\n",
      "3976\n",
      "3977\n",
      "3978\n",
      "3979\n",
      "3980\n",
      "3981\n",
      "3982\n",
      "3983\n",
      "3984\n",
      "3985\n",
      "3986\n",
      "3987\n",
      "3988\n",
      "3989\n",
      "3990\n",
      "3991\n",
      "3992\n",
      "3993\n",
      "3994\n",
      "3995\n",
      "3996\n",
      "3997\n",
      "3998\n",
      "3999\n",
      "4000\n",
      "4001\n",
      "4002\n",
      "4003\n",
      "4004\n",
      "4005\n",
      "4006\n",
      "4007\n",
      "4008\n",
      "4009\n",
      "4010\n",
      "4011\n",
      "4012\n",
      "4013\n",
      "4014\n",
      "4015\n",
      "4016\n",
      "4017\n",
      "4018\n",
      "4019\n",
      "4020\n",
      "4021\n",
      "4022\n",
      "4023\n",
      "4024\n",
      "4025\n",
      "4026\n",
      "4027\n",
      "4028\n",
      "4029\n",
      "4030\n",
      "4031\n",
      "4032\n",
      "4033\n",
      "4034\n",
      "4035\n",
      "4036\n",
      "4037\n",
      "4038\n",
      "4039\n",
      "4040\n",
      "4041\n",
      "4042\n",
      "4043\n",
      "4044\n",
      "4045\n",
      "4046\n",
      "4047\n",
      "4048\n",
      "4049\n",
      "4050\n",
      "4051\n",
      "4052\n",
      "4053\n",
      "4054\n",
      "4055\n",
      "4056\n",
      "4057\n",
      "4058\n",
      "4059\n",
      "4060\n",
      "4061\n",
      "4062\n",
      "4063\n",
      "4064\n",
      "4065\n",
      "4066\n",
      "4067\n",
      "4068\n",
      "4069\n",
      "4070\n",
      "4071\n",
      "4072\n",
      "4073\n",
      "4074\n",
      "4075\n",
      "4076\n",
      "4077\n",
      "4078\n",
      "4079\n",
      "4080\n",
      "4081\n",
      "4082\n",
      "4083\n",
      "4084\n",
      "4085\n",
      "4086\n",
      "4087\n",
      "4088\n",
      "4089\n",
      "4090\n",
      "4091\n",
      "4092\n",
      "4093\n",
      "4094\n",
      "4095\n",
      "4096\n",
      "4097\n",
      "4098\n",
      "4099\n",
      "4100\n",
      "4101\n",
      "4102\n",
      "4103\n",
      "4104\n",
      "4105\n",
      "4106\n",
      "4107\n",
      "4108\n",
      "4109\n",
      "4110\n",
      "4111\n",
      "4112\n",
      "4113\n",
      "4114\n",
      "4115\n",
      "4116\n",
      "4117\n",
      "4118\n",
      "4119\n",
      "4120\n",
      "4121\n",
      "4122\n",
      "4123\n",
      "4124\n",
      "4125\n",
      "4126\n",
      "4127\n",
      "4128\n",
      "4129\n",
      "4130\n",
      "4131\n",
      "4132\n",
      "4133\n",
      "4134\n",
      "4135\n",
      "4136\n",
      "4137\n",
      "4138\n",
      "4139\n",
      "4140\n",
      "4141\n",
      "4142\n",
      "4143\n",
      "4144\n",
      "4145\n",
      "4146\n",
      "4147\n",
      "4148\n",
      "4149\n",
      "4150\n",
      "4151\n",
      "4152\n",
      "4153\n",
      "4154\n",
      "4155\n",
      "4156\n",
      "4157\n",
      "4158\n",
      "4159\n",
      "4160\n",
      "4161\n",
      "4162\n",
      "4163\n",
      "4164\n",
      "4165\n",
      "4166\n",
      "4167\n",
      "4168\n",
      "4169\n",
      "4170\n",
      "4171\n",
      "4172\n",
      "4173\n",
      "4174\n",
      "4175\n",
      "4176\n",
      "4177\n",
      "4178\n",
      "4179\n",
      "4180\n",
      "4181\n",
      "4182\n",
      "4183\n",
      "4184\n",
      "4185\n",
      "4186\n",
      "4187\n",
      "4188\n",
      "4189\n",
      "4190\n",
      "4191\n",
      "4192\n",
      "4193\n",
      "4194\n",
      "4195\n",
      "4196\n",
      "4197\n",
      "4198\n",
      "4199\n",
      "4200\n",
      "4201\n",
      "4202\n",
      "4203\n",
      "4204\n",
      "4205\n",
      "4206\n",
      "4207\n",
      "4208\n",
      "4209\n",
      "4210\n",
      "4211\n",
      "4212\n",
      "4213\n",
      "4214\n",
      "4215\n",
      "4216\n",
      "4217\n",
      "4218\n",
      "4219\n",
      "4220\n",
      "4221\n",
      "4222\n",
      "4223\n",
      "4224\n",
      "4225\n",
      "4226\n",
      "4227\n",
      "4228\n",
      "4229\n",
      "4230\n",
      "4231\n",
      "4232\n",
      "4233\n",
      "4234\n",
      "4235\n",
      "4236\n",
      "4237\n",
      "4238\n",
      "4239\n",
      "4240\n",
      "4241\n",
      "4242\n",
      "4243\n",
      "4244\n",
      "4245\n",
      "4246\n",
      "4247\n",
      "4248\n",
      "4249\n",
      "4250\n",
      "4251\n",
      "4252\n",
      "4253\n",
      "4254\n",
      "4255\n",
      "4256\n",
      "4257\n",
      "4258\n",
      "4259\n",
      "4260\n",
      "4261\n",
      "4262\n",
      "4263\n",
      "4264\n",
      "4265\n",
      "4266\n",
      "4267\n",
      "4268\n",
      "4269\n",
      "4270\n",
      "4271\n",
      "4272\n",
      "4273\n",
      "4274\n",
      "4275\n",
      "4276\n",
      "4277\n",
      "4278\n",
      "4279\n",
      "4280\n",
      "4281\n",
      "4282\n",
      "4283\n",
      "4284\n",
      "4285\n",
      "4286\n",
      "4287\n",
      "4288\n",
      "4289\n",
      "4290\n",
      "4291\n",
      "4292\n",
      "4293\n",
      "4294\n",
      "4295\n",
      "4296\n",
      "4297\n",
      "4298\n",
      "4299\n",
      "4300\n",
      "4301\n",
      "4302\n",
      "4303\n",
      "4304\n",
      "4305\n",
      "4306\n",
      "4307\n",
      "4308\n",
      "4309\n",
      "4310\n",
      "4311\n",
      "4312\n",
      "4313\n",
      "4314\n",
      "4315\n",
      "4316\n",
      "4317\n",
      "4318\n",
      "4319\n",
      "4320\n",
      "4321\n",
      "4322\n",
      "4323\n",
      "4324\n",
      "4325\n",
      "4326\n",
      "4327\n",
      "4328\n",
      "4329\n",
      "4330\n",
      "4331\n",
      "4332\n",
      "4333\n",
      "4334\n",
      "4335\n",
      "4336\n",
      "4337\n",
      "4338\n",
      "4339\n",
      "4340\n",
      "4341\n",
      "4342\n",
      "4343\n",
      "4344\n",
      "4345\n",
      "4346\n",
      "4347\n",
      "4348\n",
      "4349\n",
      "4350\n",
      "4351\n",
      "4352\n",
      "4353\n",
      "4354\n",
      "4355\n",
      "4356\n",
      "4357\n",
      "4358\n",
      "4359\n",
      "4360\n",
      "4361\n",
      "4362\n",
      "4363\n",
      "4364\n",
      "4365\n",
      "4366\n",
      "4367\n",
      "4368\n",
      "4369\n",
      "4370\n",
      "4371\n",
      "4372\n",
      "4373\n",
      "4374\n",
      "4375\n",
      "4376\n",
      "4377\n",
      "4378\n",
      "4379\n",
      "4380\n",
      "4381\n",
      "4382\n",
      "4383\n",
      "4384\n",
      "4385\n",
      "4386\n",
      "4387\n",
      "4388\n",
      "4389\n",
      "4390\n",
      "4391\n",
      "4392\n",
      "4393\n",
      "4394\n",
      "4395\n",
      "4396\n",
      "4397\n",
      "4398\n",
      "4399\n",
      "4400\n",
      "4401\n",
      "4402\n",
      "4403\n",
      "4404\n",
      "4405\n",
      "4406\n",
      "4407\n",
      "4408\n",
      "4409\n",
      "4410\n",
      "4411\n",
      "4412\n",
      "4413\n",
      "4414\n",
      "4415\n",
      "4416\n",
      "4417\n",
      "4418\n",
      "4419\n",
      "4420\n",
      "4421\n",
      "4422\n",
      "4423\n",
      "4424\n",
      "4425\n",
      "4426\n",
      "4427\n",
      "4428\n",
      "4429\n",
      "4430\n",
      "4431\n",
      "4432\n",
      "4433\n",
      "4434\n",
      "4435\n",
      "4436\n",
      "4437\n",
      "4438\n",
      "4439\n",
      "4440\n",
      "4441\n",
      "4442\n",
      "4443\n",
      "4444\n",
      "4445\n",
      "4446\n",
      "4447\n",
      "4448\n",
      "4449\n",
      "4450\n",
      "4451\n",
      "4452\n",
      "4453\n",
      "4454\n",
      "4455\n",
      "4456\n",
      "4457\n",
      "4458\n",
      "4459\n",
      "4460\n",
      "4461\n",
      "4462\n",
      "4463\n",
      "4464\n",
      "4465\n",
      "4466\n",
      "4467\n",
      "4468\n",
      "4469\n",
      "4470\n",
      "4471\n",
      "4472\n",
      "4473\n",
      "4474\n",
      "4475\n",
      "4476\n",
      "4477\n",
      "4478\n",
      "4479\n",
      "4480\n",
      "4481\n",
      "4482\n",
      "4483\n",
      "4484\n",
      "4485\n",
      "4486\n",
      "4487\n",
      "4488\n",
      "4489\n",
      "4490\n",
      "4491\n",
      "4492\n",
      "4493\n",
      "4494\n",
      "4495\n",
      "4496\n",
      "4497\n",
      "4498\n",
      "4499\n",
      "4500\n",
      "4501\n",
      "4502\n",
      "4503\n",
      "4504\n",
      "4505\n",
      "4506\n",
      "4507\n",
      "4508\n",
      "4509\n",
      "4510\n",
      "4511\n",
      "4512\n",
      "4513\n",
      "4514\n",
      "4515\n",
      "4516\n",
      "4517\n",
      "4518\n",
      "4519\n",
      "4520\n",
      "4521\n",
      "4522\n",
      "4523\n",
      "4524\n",
      "4525\n",
      "4526\n",
      "4527\n",
      "4528\n",
      "4529\n",
      "4530\n",
      "4531\n",
      "4532\n",
      "4533\n",
      "4534\n",
      "4535\n",
      "4536\n",
      "4537\n",
      "4538\n",
      "4539\n",
      "4540\n",
      "4541\n",
      "4542\n",
      "4543\n",
      "4544\n",
      "4545\n",
      "4546\n",
      "4547\n",
      "4548\n",
      "4549\n",
      "4550\n",
      "4551\n",
      "4552\n",
      "4553\n",
      "4554\n",
      "4555\n",
      "4556\n",
      "4557\n",
      "4558\n",
      "4559\n",
      "4560\n",
      "4561\n",
      "4562\n",
      "4563\n",
      "4564\n",
      "4565\n",
      "4566\n",
      "4567\n",
      "4568\n",
      "4569\n",
      "4570\n",
      "4571\n",
      "4572\n",
      "4573\n",
      "4574\n",
      "4575\n",
      "4576\n",
      "4577\n",
      "4578\n",
      "4579\n",
      "4580\n",
      "4581\n",
      "4582\n",
      "4583\n",
      "4584\n",
      "4585\n",
      "4586\n",
      "4587\n",
      "4588\n",
      "4589\n",
      "4590\n",
      "4591\n",
      "4592\n",
      "4593\n",
      "4594\n",
      "4595\n",
      "4596\n",
      "4597\n",
      "4598\n",
      "4599\n",
      "4600\n",
      "4601\n",
      "4602\n",
      "4603\n",
      "4604\n",
      "4605\n",
      "4606\n",
      "4607\n",
      "4608\n",
      "4609\n",
      "4610\n",
      "4611\n",
      "4612\n",
      "4613\n",
      "4614\n",
      "4615\n",
      "4616\n",
      "4617\n",
      "4618\n",
      "4619\n",
      "4620\n",
      "4621\n",
      "4622\n",
      "4623\n",
      "4624\n",
      "4625\n",
      "4626\n",
      "4627\n",
      "4628\n",
      "4629\n",
      "4630\n",
      "4631\n",
      "4632\n",
      "4633\n",
      "4634\n",
      "4635\n",
      "4636\n",
      "4637\n",
      "4638\n",
      "4639\n",
      "4640\n",
      "4641\n",
      "4642\n",
      "4643\n",
      "4644\n",
      "4645\n",
      "4646\n",
      "4647\n",
      "4648\n",
      "4649\n",
      "4650\n",
      "4651\n",
      "4652\n",
      "4653\n",
      "4654\n",
      "4655\n",
      "4656\n",
      "4657\n",
      "4658\n",
      "4659\n",
      "4660\n",
      "4661\n",
      "4662\n",
      "4663\n",
      "4664\n",
      "4665\n",
      "4666\n",
      "4667\n",
      "4668\n",
      "4669\n",
      "4670\n",
      "4671\n",
      "4672\n",
      "4673\n",
      "4674\n",
      "4675\n",
      "4676\n",
      "4677\n",
      "4678\n",
      "4679\n",
      "4680\n",
      "4681\n",
      "4682\n",
      "4683\n",
      "4684\n",
      "4685\n",
      "4686\n",
      "4687\n",
      "4688\n",
      "4689\n",
      "4690\n",
      "4691\n",
      "4692\n",
      "4693\n",
      "4694\n",
      "4695\n",
      "4696\n",
      "4697\n",
      "4698\n",
      "4699\n",
      "4700\n",
      "4701\n",
      "4702\n",
      "4703\n",
      "4704\n",
      "4705\n",
      "4706\n",
      "4707\n",
      "4708\n",
      "4709\n",
      "4710\n",
      "4711\n",
      "4712\n",
      "4713\n",
      "4714\n",
      "4715\n",
      "4716\n",
      "4717\n",
      "4718\n",
      "4719\n",
      "4720\n",
      "4721\n",
      "4722\n",
      "4723\n",
      "4724\n",
      "4725\n",
      "4726\n",
      "4727\n",
      "4728\n",
      "4729\n",
      "4730\n",
      "4731\n",
      "4732\n",
      "4733\n",
      "4734\n",
      "4735\n",
      "4736\n",
      "4737\n",
      "4738\n",
      "4739\n",
      "4740\n",
      "4741\n",
      "4742\n",
      "4743\n",
      "4744\n",
      "4745\n",
      "4746\n",
      "4747\n",
      "4748\n",
      "4749\n",
      "4750\n",
      "4751\n",
      "4752\n",
      "4753\n",
      "4754\n",
      "4755\n",
      "4756\n",
      "4757\n",
      "4758\n",
      "4759\n",
      "4760\n",
      "4761\n",
      "4762\n",
      "4763\n",
      "4764\n",
      "4765\n",
      "4766\n",
      "4767\n",
      "4768\n",
      "4769\n",
      "4770\n",
      "4771\n",
      "4772\n",
      "4773\n",
      "4774\n",
      "4775\n",
      "4776\n",
      "4777\n",
      "4778\n",
      "4779\n",
      "4780\n",
      "4781\n",
      "4782\n",
      "4783\n",
      "4784\n",
      "4785\n",
      "4786\n",
      "4787\n",
      "4788\n",
      "4789\n",
      "4790\n",
      "4791\n",
      "4792\n",
      "4793\n",
      "4794\n",
      "4795\n",
      "4796\n",
      "4797\n",
      "4798\n",
      "4799\n",
      "4800\n",
      "4801\n",
      "4802\n",
      "4803\n",
      "4804\n",
      "4805\n",
      "4806\n",
      "4807\n",
      "4808\n",
      "4809\n",
      "4810\n",
      "4811\n",
      "4812\n",
      "4813\n",
      "4814\n",
      "4815\n",
      "4816\n",
      "4817\n",
      "4818\n",
      "4819\n",
      "4820\n",
      "4821\n",
      "4822\n",
      "4823\n",
      "4824\n",
      "4825\n",
      "4826\n",
      "4827\n",
      "4828\n",
      "4829\n",
      "4830\n",
      "4831\n",
      "4832\n",
      "4833\n",
      "4834\n",
      "4835\n",
      "4836\n",
      "4837\n",
      "4838\n",
      "4839\n",
      "4840\n",
      "4841\n",
      "4842\n",
      "4843\n",
      "4844\n",
      "4845\n",
      "4846\n",
      "4847\n",
      "4848\n",
      "4849\n",
      "4850\n",
      "4851\n",
      "4852\n",
      "4853\n",
      "4854\n",
      "4855\n",
      "4856\n",
      "4857\n",
      "4858\n",
      "4859\n",
      "4860\n",
      "4861\n",
      "4862\n",
      "4863\n",
      "4864\n",
      "4865\n",
      "4866\n",
      "4867\n",
      "4868\n",
      "4869\n",
      "4870\n",
      "4871\n",
      "4872\n",
      "4873\n",
      "4874\n",
      "4875\n",
      "4876\n",
      "4877\n",
      "4878\n",
      "4879\n",
      "4880\n",
      "4881\n",
      "4882\n",
      "4883\n",
      "4884\n",
      "4885\n",
      "4886\n",
      "4887\n",
      "4888\n",
      "4889\n",
      "4890\n",
      "4891\n",
      "4892\n",
      "4893\n",
      "4894\n",
      "4895\n",
      "4896\n",
      "4897\n",
      "4898\n",
      "4899\n",
      "4900\n",
      "4901\n",
      "4902\n",
      "4903\n",
      "4904\n",
      "4905\n",
      "4906\n",
      "4907\n",
      "4908\n",
      "4909\n",
      "4910\n",
      "4911\n",
      "4912\n",
      "4913\n",
      "4914\n",
      "4915\n",
      "4916\n",
      "4917\n",
      "4918\n",
      "4919\n",
      "4920\n",
      "4921\n",
      "4922\n",
      "4923\n",
      "4924\n",
      "4925\n",
      "4926\n",
      "4927\n",
      "4928\n",
      "4929\n",
      "4930\n",
      "4931\n",
      "4932\n",
      "4933\n",
      "4934\n",
      "4935\n",
      "4936\n",
      "4937\n",
      "4938\n",
      "4939\n",
      "4940\n",
      "4941\n",
      "4942\n",
      "4943\n",
      "4944\n",
      "4945\n",
      "4946\n",
      "4947\n",
      "4948\n",
      "4949\n",
      "4950\n",
      "4951\n",
      "4952\n",
      "4953\n",
      "4954\n",
      "4955\n",
      "4956\n",
      "4957\n",
      "4958\n",
      "4959\n",
      "4960\n",
      "4961\n",
      "4962\n",
      "4963\n",
      "4964\n",
      "4965\n",
      "4966\n",
      "4967\n",
      "4968\n",
      "4969\n",
      "4970\n",
      "4971\n",
      "4972\n",
      "4973\n",
      "4974\n",
      "4975\n",
      "4976\n",
      "4977\n",
      "4978\n",
      "4979\n",
      "4980\n",
      "4981\n",
      "4982\n",
      "4983\n",
      "4984\n",
      "4985\n",
      "4986\n",
      "4987\n",
      "4988\n",
      "4989\n",
      "4990\n",
      "4991\n",
      "4992\n",
      "4993\n",
      "4994\n",
      "4995\n",
      "4996\n",
      "4997\n",
      "4998\n",
      "4999\n",
      "5000\n",
      "5001\n",
      "5002\n",
      "5003\n",
      "5004\n",
      "5005\n",
      "5006\n",
      "5007\n",
      "5008\n",
      "5009\n",
      "5010\n",
      "5011\n",
      "5012\n",
      "5013\n",
      "5014\n",
      "5015\n",
      "5016\n",
      "5017\n",
      "5018\n",
      "5019\n",
      "5020\n",
      "5021\n",
      "5022\n",
      "5023\n",
      "5024\n",
      "5025\n",
      "5026\n",
      "5027\n",
      "5028\n",
      "5029\n",
      "5030\n",
      "5031\n",
      "5032\n",
      "5033\n",
      "5034\n",
      "5035\n",
      "5036\n",
      "5037\n",
      "5038\n",
      "5039\n",
      "5040\n",
      "5041\n",
      "5042\n",
      "5043\n",
      "5044\n",
      "5045\n",
      "5046\n",
      "5047\n",
      "5048\n",
      "5049\n",
      "5050\n",
      "5051\n",
      "5052\n",
      "5053\n",
      "5054\n",
      "5055\n",
      "5056\n",
      "5057\n",
      "5058\n",
      "5059\n",
      "5060\n",
      "5061\n",
      "5062\n",
      "5063\n",
      "5064\n",
      "5065\n",
      "5066\n",
      "5067\n",
      "5068\n",
      "5069\n",
      "5070\n",
      "5071\n",
      "5072\n",
      "5073\n",
      "5074\n",
      "5075\n",
      "5076\n",
      "5077\n",
      "5078\n",
      "5079\n",
      "5080\n",
      "5081\n",
      "5082\n",
      "5083\n",
      "5084\n",
      "5085\n",
      "5086\n",
      "5087\n",
      "5088\n",
      "5089\n",
      "5090\n",
      "5091\n",
      "5092\n",
      "5093\n",
      "5094\n",
      "5095\n",
      "5096\n",
      "5097\n",
      "5098\n",
      "5099\n",
      "5100\n",
      "5101\n",
      "5102\n",
      "5103\n",
      "5104\n",
      "5105\n",
      "5106\n",
      "5107\n",
      "5108\n",
      "5109\n",
      "5110\n",
      "5111\n",
      "5112\n",
      "5113\n",
      "5114\n",
      "5115\n",
      "5116\n",
      "5117\n",
      "5118\n",
      "5119\n",
      "5120\n",
      "5121\n",
      "5122\n",
      "5123\n",
      "5124\n",
      "5125\n",
      "5126\n",
      "5127\n",
      "5128\n",
      "5129\n",
      "5130\n",
      "5131\n",
      "5132\n",
      "5133\n",
      "5134\n",
      "5135\n",
      "5136\n",
      "5137\n",
      "5138\n",
      "5139\n",
      "5140\n",
      "5141\n",
      "5142\n",
      "5143\n",
      "5144\n",
      "5145\n",
      "5146\n",
      "5147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5148\n",
      "5149\n",
      "5150\n",
      "5151\n",
      "5152\n",
      "5153\n",
      "5154\n",
      "5155\n",
      "5156\n",
      "5157\n",
      "5158\n",
      "5159\n",
      "5160\n",
      "5161\n",
      "5162\n",
      "5163\n",
      "5164\n",
      "5165\n",
      "5166\n",
      "5167\n",
      "5168\n",
      "5169\n",
      "5170\n",
      "5171\n",
      "5172\n",
      "5173\n",
      "5174\n",
      "5175\n",
      "5176\n",
      "5177\n",
      "5178\n",
      "5179\n",
      "5180\n",
      "5181\n",
      "5182\n",
      "5183\n",
      "5184\n",
      "5185\n",
      "5186\n",
      "5187\n",
      "5188\n",
      "5189\n",
      "5190\n",
      "5191\n",
      "5192\n",
      "5193\n",
      "5194\n",
      "5195\n",
      "5196\n",
      "5197\n",
      "5198\n",
      "5199\n",
      "5200\n",
      "5201\n",
      "5202\n",
      "5203\n",
      "5204\n",
      "5205\n",
      "5206\n",
      "5207\n",
      "5208\n",
      "5209\n",
      "5210\n",
      "5211\n",
      "5212\n",
      "5213\n",
      "5214\n",
      "5215\n",
      "5216\n",
      "5217\n",
      "5218\n",
      "5219\n",
      "5220\n",
      "5221\n",
      "5222\n",
      "5223\n",
      "5224\n",
      "5225\n",
      "5226\n",
      "5227\n",
      "5228\n",
      "5229\n",
      "5230\n",
      "5231\n",
      "5232\n",
      "5233\n",
      "5234\n",
      "5235\n",
      "5236\n",
      "5237\n",
      "5238\n",
      "5239\n",
      "5240\n",
      "5241\n",
      "5242\n",
      "5243\n",
      "5244\n",
      "5245\n",
      "5246\n",
      "5247\n",
      "5248\n",
      "5249\n",
      "5250\n",
      "5251\n",
      "5252\n",
      "5253\n",
      "5254\n",
      "5255\n",
      "5256\n",
      "5257\n",
      "5258\n",
      "5259\n",
      "5260\n",
      "5261\n",
      "5262\n",
      "5263\n",
      "5264\n",
      "5265\n",
      "5266\n",
      "5267\n",
      "5268\n",
      "5269\n",
      "5270\n",
      "5271\n",
      "5272\n",
      "5273\n",
      "5274\n",
      "5275\n",
      "5276\n",
      "5277\n",
      "5278\n",
      "5279\n",
      "5280\n",
      "5281\n",
      "5282\n",
      "5283\n",
      "5284\n",
      "5285\n",
      "5286\n",
      "5287\n",
      "5288\n",
      "5289\n",
      "5290\n",
      "5291\n",
      "5292\n",
      "5293\n",
      "5294\n",
      "5295\n",
      "5296\n",
      "5297\n",
      "5298\n",
      "5299\n",
      "5300\n",
      "5301\n",
      "5302\n",
      "5303\n",
      "5304\n",
      "5305\n",
      "5306\n",
      "5307\n",
      "5308\n",
      "5309\n",
      "5310\n",
      "5311\n",
      "5312\n",
      "5313\n",
      "5314\n",
      "5315\n",
      "5316\n",
      "5317\n",
      "5318\n",
      "5319\n",
      "5320\n",
      "5321\n",
      "5322\n",
      "5323\n",
      "5324\n",
      "5325\n",
      "5326\n",
      "5327\n",
      "5328\n",
      "5329\n",
      "5330\n",
      "5331\n",
      "5332\n",
      "5333\n",
      "5334\n",
      "5335\n",
      "5336\n",
      "5337\n",
      "5338\n",
      "5339\n",
      "5340\n",
      "5341\n",
      "5342\n",
      "5343\n",
      "5344\n",
      "5345\n",
      "5346\n",
      "5347\n",
      "5348\n",
      "5349\n",
      "5350\n",
      "5351\n",
      "5352\n",
      "5353\n",
      "5354\n",
      "5355\n",
      "5356\n",
      "5357\n",
      "5358\n",
      "5359\n",
      "5360\n",
      "5361\n",
      "5362\n",
      "5363\n",
      "5364\n",
      "5365\n",
      "5366\n",
      "5367\n",
      "5368\n",
      "5369\n",
      "5370\n",
      "5371\n",
      "5372\n",
      "5373\n",
      "5374\n",
      "5375\n",
      "5376\n",
      "5377\n",
      "5378\n",
      "5379\n",
      "5380\n",
      "5381\n",
      "5382\n",
      "5383\n",
      "5384\n",
      "5385\n",
      "5386\n",
      "5387\n",
      "5388\n",
      "5389\n",
      "5390\n",
      "5391\n",
      "5392\n",
      "5393\n",
      "5394\n",
      "5395\n",
      "5396\n",
      "5397\n",
      "5398\n",
      "5399\n",
      "5400\n",
      "5401\n",
      "5402\n",
      "5403\n",
      "5404\n",
      "5405\n",
      "5406\n",
      "5407\n",
      "5408\n",
      "5409\n",
      "5410\n",
      "5411\n",
      "5412\n",
      "5413\n",
      "5414\n",
      "5415\n",
      "5416\n",
      "5417\n",
      "5418\n",
      "5419\n",
      "5420\n",
      "5421\n",
      "5422\n",
      "5423\n",
      "5424\n",
      "5425\n",
      "5426\n",
      "5427\n",
      "5428\n",
      "5429\n",
      "5430\n",
      "5431\n",
      "5432\n",
      "5433\n",
      "5434\n",
      "5435\n",
      "5436\n",
      "5437\n",
      "5438\n",
      "5439\n",
      "5440\n",
      "5441\n",
      "5442\n",
      "5443\n",
      "5444\n",
      "5445\n",
      "5446\n",
      "5447\n",
      "5448\n",
      "5449\n",
      "5450\n",
      "5451\n",
      "5452\n",
      "5453\n",
      "5454\n",
      "5455\n",
      "5456\n",
      "5457\n",
      "5458\n",
      "5459\n",
      "5460\n",
      "5461\n",
      "5462\n",
      "5463\n",
      "5464\n",
      "5465\n",
      "5466\n",
      "5467\n",
      "5468\n",
      "5469\n",
      "5470\n",
      "5471\n",
      "5472\n",
      "5473\n",
      "5474\n",
      "5475\n",
      "5476\n",
      "5477\n",
      "5478\n",
      "5479\n",
      "5480\n",
      "5481\n",
      "5482\n",
      "5483\n",
      "5484\n",
      "5485\n",
      "5486\n",
      "5487\n",
      "5488\n",
      "5489\n",
      "5490\n",
      "5491\n",
      "5492\n",
      "5493\n",
      "5494\n",
      "5495\n",
      "5496\n",
      "5497\n",
      "5498\n",
      "5499\n",
      "5500\n",
      "5501\n",
      "5502\n",
      "5503\n",
      "5504\n",
      "5505\n",
      "5506\n",
      "5507\n",
      "5508\n",
      "5509\n",
      "5510\n",
      "5511\n",
      "5512\n",
      "5513\n",
      "5514\n",
      "5515\n",
      "5516\n",
      "5517\n",
      "5518\n",
      "5519\n",
      "5520\n",
      "5521\n",
      "5522\n",
      "5523\n",
      "5524\n",
      "5525\n",
      "5526\n",
      "5527\n",
      "5528\n",
      "5529\n",
      "5530\n",
      "5531\n",
      "5532\n",
      "5533\n",
      "5534\n",
      "5535\n",
      "5536\n",
      "5537\n",
      "5538\n",
      "5539\n",
      "5540\n",
      "5541\n",
      "5542\n",
      "5543\n",
      "5544\n",
      "5545\n",
      "5546\n",
      "5547\n",
      "5548\n",
      "5549\n",
      "5550\n",
      "5551\n",
      "5552\n",
      "5553\n",
      "5554\n",
      "5555\n",
      "5556\n",
      "5557\n",
      "5558\n",
      "5559\n",
      "5560\n",
      "5561\n",
      "5562\n",
      "5563\n",
      "5564\n",
      "5565\n",
      "5566\n",
      "5567\n",
      "5568\n",
      "5569\n",
      "5570\n",
      "5571\n",
      "5572\n",
      "5573\n",
      "5574\n",
      "5575\n",
      "5576\n",
      "5577\n",
      "5578\n",
      "5579\n",
      "5580\n",
      "5581\n",
      "5582\n",
      "5583\n",
      "5584\n",
      "5585\n",
      "5586\n",
      "5587\n",
      "5588\n",
      "5589\n",
      "5590\n",
      "5591\n",
      "5592\n",
      "5593\n",
      "5594\n",
      "5595\n",
      "5596\n",
      "5597\n",
      "5598\n",
      "5599\n",
      "5600\n",
      "5601\n",
      "5602\n",
      "5603\n",
      "5604\n",
      "5605\n",
      "5606\n",
      "5607\n",
      "5608\n",
      "5609\n",
      "5610\n",
      "5611\n",
      "5612\n",
      "5613\n",
      "5614\n",
      "5615\n",
      "5616\n",
      "5617\n",
      "5618\n",
      "5619\n",
      "5620\n",
      "5621\n",
      "5622\n",
      "5623\n",
      "5624\n",
      "5625\n",
      "5626\n",
      "5627\n",
      "5628\n",
      "5629\n",
      "5630\n",
      "5631\n",
      "5632\n",
      "5633\n",
      "5634\n",
      "5635\n",
      "5636\n",
      "5637\n",
      "5638\n",
      "5639\n",
      "5640\n",
      "5641\n",
      "5642\n",
      "5643\n",
      "5644\n",
      "5645\n",
      "5646\n",
      "5647\n",
      "5648\n",
      "5649\n",
      "5650\n",
      "5651\n",
      "5652\n",
      "5653\n",
      "5654\n",
      "5655\n",
      "5656\n",
      "5657\n",
      "5658\n",
      "5659\n",
      "5660\n",
      "5661\n",
      "5662\n",
      "5663\n",
      "5664\n",
      "5665\n",
      "5666\n",
      "5667\n",
      "5668\n",
      "5669\n",
      "5670\n",
      "5671\n",
      "5672\n",
      "5673\n",
      "5674\n",
      "5675\n",
      "5676\n",
      "5677\n",
      "5678\n",
      "5679\n",
      "5680\n",
      "5681\n",
      "5682\n",
      "5683\n",
      "5684\n",
      "5685\n",
      "5686\n",
      "5687\n",
      "5688\n",
      "5689\n",
      "5690\n",
      "5691\n",
      "5692\n",
      "5693\n",
      "5694\n",
      "5695\n",
      "5696\n",
      "5697\n",
      "5698\n",
      "5699\n",
      "5700\n",
      "5701\n",
      "5702\n",
      "5703\n",
      "5704\n",
      "5705\n",
      "5706\n",
      "5707\n",
      "5708\n",
      "5709\n",
      "5710\n",
      "5711\n",
      "5712\n",
      "5713\n",
      "5714\n",
      "5715\n",
      "5716\n",
      "5717\n",
      "5718\n",
      "5719\n",
      "5720\n",
      "5721\n",
      "5722\n",
      "5723\n",
      "5724\n",
      "5725\n",
      "5726\n",
      "5727\n",
      "5728\n",
      "5729\n",
      "5730\n",
      "5731\n",
      "5732\n",
      "5733\n",
      "5734\n",
      "5735\n",
      "5736\n",
      "5737\n",
      "5738\n",
      "5739\n",
      "5740\n",
      "5741\n",
      "5742\n",
      "5743\n",
      "5744\n",
      "5745\n",
      "5746\n",
      "5747\n",
      "5748\n",
      "5749\n",
      "5750\n",
      "5751\n",
      "5752\n",
      "5753\n",
      "5754\n",
      "5755\n",
      "5756\n",
      "5757\n",
      "5758\n",
      "5759\n",
      "5760\n",
      "5761\n",
      "5762\n",
      "5763\n",
      "5764\n",
      "5765\n",
      "5766\n",
      "5767\n",
      "5768\n",
      "5769\n",
      "5770\n",
      "5771\n",
      "5772\n",
      "5773\n",
      "5774\n",
      "5775\n",
      "5776\n",
      "5777\n",
      "5778\n",
      "5779\n",
      "5780\n",
      "5781\n",
      "5782\n",
      "5783\n",
      "5784\n",
      "5785\n",
      "5786\n",
      "5787\n",
      "5788\n",
      "5789\n",
      "5790\n",
      "5791\n",
      "5792\n",
      "5793\n",
      "5794\n",
      "5795\n",
      "5796\n",
      "5797\n",
      "5798\n",
      "5799\n",
      "5800\n",
      "5801\n",
      "5802\n",
      "5803\n",
      "5804\n",
      "5805\n",
      "5806\n",
      "5807\n",
      "5808\n",
      "5809\n",
      "5810\n",
      "5811\n",
      "5812\n",
      "5813\n",
      "5814\n",
      "5815\n",
      "5816\n",
      "5817\n",
      "5818\n",
      "5819\n",
      "5820\n",
      "5821\n",
      "5822\n",
      "5823\n",
      "5824\n",
      "5825\n",
      "5826\n",
      "5827\n",
      "5828\n",
      "5829\n",
      "5830\n",
      "5831\n",
      "5832\n",
      "5833\n",
      "5834\n",
      "5835\n",
      "5836\n",
      "5837\n",
      "5838\n",
      "5839\n",
      "5840\n",
      "5841\n",
      "5842\n",
      "5843\n",
      "5844\n",
      "5845\n",
      "5846\n",
      "5847\n",
      "5848\n",
      "5849\n",
      "5850\n",
      "5851\n",
      "5852\n",
      "5853\n",
      "5854\n",
      "5855\n",
      "5856\n",
      "5857\n",
      "5858\n",
      "5859\n",
      "5860\n",
      "5861\n",
      "5862\n",
      "5863\n",
      "5864\n",
      "5865\n",
      "5866\n",
      "5867\n",
      "5868\n",
      "5869\n",
      "5870\n",
      "5871\n",
      "5872\n",
      "5873\n",
      "5874\n",
      "5875\n",
      "5876\n",
      "5877\n",
      "5878\n",
      "5879\n",
      "5880\n",
      "5881\n",
      "5882\n",
      "5883\n",
      "5884\n",
      "5885\n",
      "5886\n",
      "5887\n",
      "5888\n",
      "5889\n",
      "5890\n",
      "5891\n",
      "5892\n",
      "5893\n",
      "5894\n",
      "5895\n",
      "5896\n",
      "5897\n",
      "5898\n",
      "5899\n",
      "5900\n",
      "5901\n",
      "5902\n",
      "5903\n",
      "5904\n",
      "5905\n",
      "5906\n",
      "5907\n",
      "5908\n",
      "5909\n",
      "5910\n",
      "5911\n",
      "5912\n",
      "5913\n",
      "5914\n",
      "5915\n",
      "5916\n",
      "5917\n",
      "5918\n",
      "5919\n",
      "5920\n",
      "5921\n",
      "5922\n",
      "5923\n",
      "5924\n",
      "5925\n",
      "5926\n",
      "5927\n",
      "5928\n",
      "5929\n",
      "5930\n",
      "5931\n",
      "5932\n",
      "5933\n",
      "5934\n",
      "5935\n",
      "5936\n",
      "5937\n",
      "5938\n",
      "5939\n",
      "5940\n",
      "5941\n",
      "5942\n",
      "5943\n",
      "5944\n",
      "5945\n",
      "5946\n",
      "5947\n",
      "5948\n",
      "5949\n",
      "5950\n",
      "5951\n",
      "5952\n",
      "5953\n",
      "5954\n",
      "5955\n",
      "5956\n",
      "5957\n",
      "5958\n",
      "5959\n",
      "5960\n",
      "5961\n",
      "5962\n",
      "5963\n",
      "5964\n",
      "5965\n",
      "5966\n",
      "5967\n",
      "5968\n",
      "5969\n",
      "5970\n",
      "5971\n",
      "5972\n",
      "5973\n",
      "5974\n",
      "5975\n",
      "5976\n",
      "5977\n",
      "5978\n",
      "5979\n",
      "5980\n",
      "5981\n",
      "5982\n",
      "5983\n",
      "5984\n",
      "5985\n",
      "5986\n",
      "5987\n",
      "5988\n",
      "5989\n",
      "5990\n",
      "5991\n",
      "5992\n",
      "5993\n",
      "5994\n",
      "5995\n",
      "5996\n",
      "5997\n",
      "5998\n",
      "5999\n",
      "6000\n",
      "6001\n",
      "6002\n",
      "6003\n",
      "6004\n",
      "6005\n",
      "6006\n",
      "6007\n",
      "6008\n",
      "6009\n",
      "6010\n",
      "6011\n",
      "6012\n",
      "6013\n",
      "6014\n",
      "6015\n",
      "6016\n",
      "6017\n",
      "6018\n",
      "6019\n",
      "6020\n",
      "6021\n",
      "6022\n",
      "6023\n",
      "6024\n",
      "6025\n",
      "6026\n",
      "6027\n",
      "6028\n",
      "6029\n",
      "6030\n",
      "6031\n",
      "6032\n",
      "6033\n",
      "6034\n",
      "6035\n",
      "6036\n",
      "6037\n",
      "6038\n",
      "6039\n",
      "6040\n",
      "6041\n",
      "6042\n",
      "6043\n",
      "6044\n",
      "6045\n",
      "6046\n",
      "6047\n",
      "6048\n",
      "6049\n",
      "6050\n",
      "6051\n",
      "6052\n",
      "6053\n",
      "6054\n",
      "6055\n",
      "6056\n",
      "6057\n",
      "6058\n",
      "6059\n",
      "6060\n",
      "6061\n",
      "6062\n",
      "6063\n",
      "6064\n",
      "6065\n",
      "6066\n",
      "6067\n",
      "6068\n",
      "6069\n",
      "6070\n",
      "6071\n",
      "6072\n",
      "6073\n",
      "6074\n",
      "6075\n",
      "6076\n",
      "6077\n",
      "6078\n",
      "6079\n",
      "6080\n",
      "6081\n",
      "6082\n",
      "6083\n",
      "6084\n",
      "6085\n",
      "6086\n",
      "6087\n",
      "6088\n",
      "6089\n",
      "6090\n",
      "6091\n",
      "6092\n",
      "6093\n",
      "6094\n",
      "6095\n",
      "6096\n",
      "6097\n",
      "6098\n",
      "6099\n",
      "6100\n",
      "6101\n",
      "6102\n",
      "6103\n",
      "6104\n",
      "6105\n",
      "6106\n",
      "6107\n",
      "6108\n",
      "6109\n",
      "6110\n",
      "6111\n",
      "6112\n",
      "6113\n",
      "6114\n",
      "6115\n",
      "6116\n",
      "6117\n",
      "6118\n",
      "6119\n",
      "6120\n",
      "6121\n",
      "6122\n",
      "6123\n",
      "6124\n",
      "6125\n",
      "6126\n",
      "6127\n",
      "6128\n",
      "6129\n",
      "6130\n",
      "6131\n",
      "6132\n",
      "6133\n",
      "6134\n",
      "6135\n",
      "6136\n",
      "6137\n",
      "6138\n",
      "6139\n",
      "6140\n",
      "6141\n",
      "6142\n",
      "6143\n",
      "6144\n",
      "6145\n",
      "6146\n",
      "6147\n",
      "6148\n",
      "6149\n",
      "6150\n",
      "6151\n",
      "6152\n",
      "6153\n",
      "6154\n",
      "6155\n",
      "6156\n",
      "6157\n",
      "6158\n",
      "6159\n",
      "6160\n",
      "6161\n",
      "6162\n",
      "6163\n",
      "6164\n",
      "6165\n",
      "6166\n",
      "6167\n",
      "6168\n",
      "6169\n",
      "6170\n",
      "6171\n",
      "6172\n",
      "6173\n",
      "6174\n",
      "6175\n",
      "6176\n",
      "6177\n",
      "6178\n",
      "6179\n",
      "6180\n",
      "6181\n",
      "6182\n",
      "6183\n",
      "6184\n",
      "6185\n",
      "6186\n",
      "6187\n",
      "6188\n",
      "6189\n",
      "6190\n",
      "6191\n",
      "6192\n",
      "6193\n",
      "6194\n",
      "6195\n",
      "6196\n",
      "6197\n",
      "6198\n",
      "6199\n",
      "6200\n",
      "6201\n",
      "6202\n",
      "6203\n",
      "6204\n",
      "6205\n",
      "6206\n",
      "6207\n",
      "6208\n",
      "6209\n",
      "6210\n",
      "6211\n",
      "6212\n",
      "6213\n",
      "6214\n",
      "6215\n",
      "6216\n",
      "6217\n",
      "6218\n",
      "6219\n",
      "6220\n",
      "6221\n",
      "6222\n",
      "6223\n",
      "6224\n",
      "6225\n",
      "6226\n",
      "6227\n",
      "6228\n",
      "6229\n",
      "6230\n",
      "6231\n",
      "6232\n",
      "6233\n",
      "6234\n",
      "6235\n",
      "6236\n",
      "6237\n",
      "6238\n",
      "6239\n",
      "6240\n",
      "6241\n",
      "6242\n",
      "6243\n",
      "6244\n",
      "6245\n",
      "6246\n",
      "6247\n",
      "6248\n",
      "6249\n",
      "6250\n",
      "6251\n",
      "6252\n",
      "6253\n",
      "6254\n",
      "6255\n",
      "6256\n",
      "6257\n",
      "6258\n",
      "6259\n",
      "6260\n",
      "6261\n",
      "6262\n",
      "6263\n",
      "6264\n",
      "6265\n",
      "6266\n",
      "6267\n",
      "6268\n",
      "6269\n",
      "6270\n",
      "6271\n",
      "6272\n",
      "6273\n",
      "6274\n",
      "6275\n",
      "6276\n",
      "6277\n",
      "6278\n",
      "6279\n",
      "6280\n",
      "6281\n",
      "6282\n",
      "6283\n",
      "6284\n",
      "6285\n",
      "6286\n",
      "6287\n",
      "6288\n",
      "6289\n",
      "6290\n",
      "6291\n",
      "6292\n",
      "6293\n",
      "6294\n",
      "6295\n",
      "6296\n",
      "6297\n",
      "6298\n",
      "6299\n",
      "6300\n",
      "6301\n",
      "6302\n",
      "6303\n",
      "6304\n",
      "6305\n",
      "6306\n",
      "6307\n",
      "6308\n",
      "6309\n",
      "6310\n",
      "6311\n",
      "6312\n",
      "6313\n",
      "6314\n",
      "6315\n",
      "6316\n",
      "6317\n",
      "6318\n",
      "6319\n",
      "6320\n",
      "6321\n",
      "6322\n",
      "6323\n",
      "6324\n",
      "6325\n",
      "6326\n",
      "6327\n",
      "6328\n",
      "6329\n",
      "6330\n",
      "6331\n",
      "6332\n",
      "6333\n",
      "6334\n",
      "6335\n",
      "6336\n",
      "6337\n",
      "6338\n",
      "6339\n",
      "6340\n",
      "6341\n",
      "6342\n",
      "6343\n",
      "6344\n",
      "6345\n",
      "6346\n",
      "6347\n",
      "6348\n",
      "6349\n",
      "6350\n",
      "6351\n",
      "6352\n",
      "6353\n",
      "6354\n",
      "6355\n",
      "6356\n",
      "6357\n",
      "6358\n",
      "6359\n",
      "6360\n",
      "6361\n",
      "6362\n",
      "6363\n",
      "6364\n",
      "6365\n",
      "6366\n",
      "6367\n",
      "6368\n",
      "6369\n",
      "6370\n",
      "6371\n",
      "6372\n",
      "6373\n",
      "6374\n",
      "6375\n",
      "6376\n",
      "6377\n",
      "6378\n",
      "6379\n",
      "6380\n",
      "6381\n",
      "6382\n",
      "6383\n",
      "6384\n",
      "6385\n",
      "6386\n",
      "6387\n",
      "6388\n",
      "6389\n",
      "6390\n",
      "6391\n",
      "6392\n",
      "6393\n",
      "6394\n",
      "6395\n",
      "6396\n",
      "6397\n",
      "6398\n",
      "6399\n",
      "6400\n",
      "6401\n",
      "6402\n",
      "6403\n",
      "6404\n",
      "6405\n",
      "6406\n",
      "6407\n",
      "6408\n",
      "6409\n",
      "6410\n",
      "6411\n",
      "6412\n",
      "6413\n",
      "6414\n",
      "6415\n",
      "6416\n",
      "6417\n",
      "6418\n",
      "6419\n",
      "6420\n",
      "6421\n",
      "6422\n",
      "6423\n",
      "6424\n",
      "6425\n",
      "6426\n",
      "6427\n",
      "6428\n",
      "6429\n",
      "6430\n",
      "6431\n",
      "6432\n",
      "6433\n",
      "6434\n",
      "6435\n",
      "6436\n",
      "6437\n",
      "6438\n",
      "6439\n",
      "6440\n",
      "6441\n",
      "6442\n",
      "6443\n",
      "6444\n",
      "6445\n",
      "6446\n",
      "6447\n",
      "6448\n",
      "6449\n",
      "6450\n",
      "6451\n",
      "6452\n",
      "6453\n",
      "6454\n",
      "6455\n",
      "6456\n",
      "6457\n",
      "6458\n",
      "6459\n",
      "6460\n",
      "6461\n",
      "6462\n",
      "6463\n",
      "6464\n",
      "6465\n",
      "6466\n",
      "6467\n",
      "6468\n",
      "6469\n",
      "6470\n",
      "6471\n",
      "6472\n",
      "6473\n",
      "6474\n",
      "6475\n",
      "6476\n",
      "6477\n",
      "6478\n",
      "6479\n",
      "6480\n",
      "6481\n",
      "6482\n",
      "6483\n",
      "6484\n",
      "6485\n",
      "6486\n",
      "6487\n",
      "6488\n",
      "6489\n",
      "6490\n",
      "6491\n",
      "6492\n",
      "6493\n",
      "6494\n",
      "6495\n",
      "6496\n",
      "6497\n",
      "6498\n",
      "6499\n",
      "6500\n",
      "6501\n",
      "6502\n",
      "6503\n",
      "6504\n",
      "6505\n",
      "6506\n",
      "6507\n",
      "6508\n",
      "6509\n",
      "6510\n",
      "6511\n",
      "6512\n",
      "6513\n",
      "6514\n",
      "6515\n",
      "6516\n",
      "6517\n",
      "6518\n",
      "6519\n",
      "6520\n",
      "6521\n",
      "6522\n",
      "6523\n",
      "6524\n",
      "6525\n",
      "6526\n",
      "6527\n",
      "6528\n",
      "6529\n",
      "6530\n",
      "6531\n",
      "6532\n",
      "6533\n",
      "6534\n",
      "6535\n",
      "6536\n",
      "6537\n",
      "6538\n",
      "6539\n",
      "6540\n",
      "6541\n",
      "6542\n",
      "6543\n",
      "6544\n",
      "6545\n",
      "6546\n",
      "6547\n",
      "6548\n",
      "6549\n",
      "6550\n",
      "6551\n",
      "6552\n",
      "6553\n",
      "6554\n",
      "6555\n",
      "6556\n",
      "6557\n",
      "6558\n",
      "6559\n",
      "6560\n",
      "6561\n",
      "6562\n",
      "6563\n",
      "6564\n",
      "6565\n",
      "6566\n",
      "6567\n",
      "6568\n",
      "6569\n",
      "6570\n",
      "6571\n",
      "6572\n",
      "6573\n",
      "6574\n",
      "6575\n",
      "6576\n",
      "6577\n",
      "6578\n",
      "6579\n",
      "6580\n",
      "6581\n",
      "6582\n",
      "6583\n",
      "6584\n",
      "6585\n",
      "6586\n",
      "6587\n",
      "6588\n",
      "6589\n",
      "6590\n",
      "6591\n",
      "6592\n",
      "6593\n",
      "6594\n",
      "6595\n",
      "6596\n",
      "6597\n",
      "6598\n",
      "6599\n",
      "6600\n",
      "6601\n",
      "6602\n",
      "6603\n",
      "6604\n",
      "6605\n",
      "6606\n",
      "6607\n",
      "6608\n",
      "6609\n",
      "6610\n",
      "6611\n",
      "6612\n",
      "6613\n",
      "6614\n",
      "6615\n",
      "6616\n",
      "6617\n",
      "6618\n",
      "6619\n",
      "6620\n",
      "6621\n",
      "6622\n",
      "6623\n",
      "6624\n",
      "6625\n",
      "6626\n",
      "6627\n",
      "6628\n",
      "6629\n",
      "6630\n",
      "6631\n",
      "6632\n",
      "6633\n",
      "6634\n",
      "6635\n",
      "6636\n",
      "6637\n",
      "6638\n",
      "6639\n",
      "6640\n",
      "6641\n",
      "6642\n",
      "6643\n",
      "6644\n",
      "6645\n",
      "6646\n",
      "6647\n",
      "6648\n",
      "6649\n",
      "6650\n",
      "6651\n",
      "6652\n",
      "6653\n",
      "6654\n",
      "6655\n",
      "6656\n",
      "6657\n",
      "6658\n",
      "6659\n",
      "6660\n",
      "6661\n",
      "6662\n",
      "6663\n",
      "6664\n",
      "6665\n",
      "6666\n",
      "6667\n",
      "6668\n",
      "6669\n",
      "6670\n",
      "6671\n",
      "6672\n",
      "6673\n",
      "6674\n",
      "6675\n",
      "6676\n",
      "6677\n",
      "6678\n",
      "6679\n",
      "6680\n",
      "6681\n",
      "6682\n",
      "6683\n",
      "6684\n",
      "6685\n",
      "6686\n",
      "6687\n",
      "6688\n",
      "6689\n",
      "6690\n",
      "6691\n",
      "6692\n",
      "6693\n",
      "6694\n",
      "6695\n",
      "6696\n",
      "6697\n",
      "6698\n",
      "6699\n",
      "6700\n",
      "6701\n",
      "6702\n",
      "6703\n",
      "6704\n",
      "6705\n",
      "6706\n",
      "6707\n",
      "6708\n",
      "6709\n",
      "6710\n",
      "6711\n",
      "6712\n",
      "6713\n",
      "6714\n",
      "6715\n",
      "6716\n",
      "6717\n",
      "6718\n",
      "6719\n",
      "6720\n",
      "6721\n",
      "6722\n",
      "6723\n",
      "6724\n",
      "6725\n",
      "6726\n",
      "6727\n",
      "6728\n",
      "6729\n",
      "6730\n",
      "6731\n",
      "6732\n",
      "6733\n",
      "6734\n",
      "6735\n",
      "6736\n",
      "6737\n",
      "6738\n",
      "6739\n",
      "6740\n",
      "6741\n",
      "6742\n",
      "6743\n",
      "6744\n",
      "6745\n",
      "6746\n",
      "6747\n",
      "6748\n",
      "6749\n",
      "6750\n",
      "6751\n",
      "6752\n",
      "6753\n",
      "6754\n",
      "6755\n",
      "6756\n",
      "6757\n",
      "6758\n",
      "6759\n",
      "6760\n",
      "6761\n",
      "6762\n",
      "6763\n",
      "6764\n",
      "6765\n",
      "6766\n",
      "6767\n",
      "6768\n",
      "6769\n",
      "6770\n",
      "6771\n",
      "6772\n",
      "6773\n",
      "6774\n",
      "6775\n",
      "6776\n",
      "6777\n",
      "6778\n",
      "6779\n",
      "6780\n",
      "6781\n",
      "6782\n",
      "6783\n",
      "6784\n",
      "6785\n",
      "6786\n",
      "6787\n",
      "6788\n",
      "6789\n",
      "6790\n",
      "6791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6792\n",
      "6793\n",
      "6794\n",
      "6795\n",
      "6796\n",
      "6797\n",
      "6798\n",
      "6799\n",
      "6800\n",
      "6801\n",
      "6802\n",
      "6803\n",
      "6804\n",
      "6805\n",
      "6806\n",
      "6807\n",
      "6808\n",
      "6809\n",
      "6810\n",
      "6811\n",
      "6812\n",
      "6813\n",
      "6814\n",
      "6815\n",
      "6816\n",
      "6817\n",
      "6818\n",
      "6819\n",
      "6820\n",
      "6821\n",
      "6822\n",
      "6823\n",
      "6824\n",
      "6825\n",
      "6826\n",
      "6827\n",
      "6828\n",
      "6829\n",
      "6830\n",
      "6831\n",
      "6832\n",
      "6833\n",
      "6834\n",
      "6835\n",
      "6836\n",
      "6837\n",
      "6838\n",
      "6839\n",
      "6840\n",
      "6841\n",
      "6842\n",
      "6843\n",
      "6844\n",
      "6845\n",
      "6846\n",
      "6847\n",
      "6848\n",
      "6849\n",
      "6850\n",
      "6851\n",
      "6852\n",
      "6853\n",
      "6854\n",
      "6855\n",
      "6856\n",
      "6857\n",
      "6858\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = {\n",
    "    'canSteering': [],\n",
    "    'canSpeed': [],\n",
    "    'cameraRightFile': []\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        print(batch_idx)\n",
    "        prediction = model(data)\n",
    "        add_results(results, prediction)\n",
    "#         print(target)\n",
    "        results['cameraRightFile'].append(target['cameraRightFile'][0])\n",
    "\n",
    "        # Used to terminate early, remove.\n",
    "#         if batch_idx >= 200: \n",
    "#             break\n",
    "        \n",
    "# df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge with full test file\n",
    "test3 = pd.DataFrame.from_dict(results)\n",
    "\n",
    "full_test = pd.read_csv('test_full.csv')\n",
    "full_test['imageNumber'] = full_test['cameraRight'].str.split('/').str[-1].str[3:8].astype(int)\n",
    "final = full_test[full_test['imageNumber']>100].copy()\n",
    "\n",
    "test3['canSteering'] = results['canSteering']\n",
    "test3['canSpeed'] = results['canSpeed']\n",
    "\n",
    "final = final.merge(test3, left_on='cameraRight', right_on='cameraRightFile', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.groupby('chapter').apply(lambda group: group.interpolate(limit_direction='both'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279863, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "file = 'result/submission_%s.csv' % dt.now().strftime('%Y%m%dT%H%M%S')\n",
    "final[['canSpeed', 'canSteering']].to_csv(file, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epoch_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c1e79f5345ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mepoch_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'epoch_error' is not defined"
     ]
    }
   ],
   "source": [
    "epoch_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using Python 3.7.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"You are using Python {}.{}.\".format(sys.version_info.major, sys.version_info.minor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
